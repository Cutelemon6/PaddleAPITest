test begin: paddle.add(Tensor([4, 3, 2],"float32"), Tensor([4, 3, 2],"bfloat16"), )
I0214 18:08:54.518720 57006 build_cinn_pass.cc:68] Time of building group ops (size=4): 0 min 0 s 0 ms
I0214 18:08:54.519436 57006 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 18:08:54.555972 57006 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and bfloat16
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():bfloat16.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.add(Tensor([4, 3, 2],"float32"), Tensor([4, 3, 2],"bfloat16"), ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.add(Tensor([4, 3, 2],"float32"), Tensor([4, 3, 2],"float16"), )
I0214 18:08:54.624719 57006 build_cinn_pass.cc:68] Time of building group ops (size=4): 0 min 0 s 0 ms
I0214 18:08:54.625435 57006 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 18:08:54.661775 57006 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float16
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float16.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.add(Tensor([4, 3, 2],"float32"), Tensor([4, 3, 2],"float16"), ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.exp(Tensor([10, 200, 300],"int32"), )
I0214 18:25:30.570314 69867 build_cinn_pass.cc:68] Time of building group ops (size=3): 0 min 0 s 0 ms
I0214 18:25:30.571133 69867 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 18:25:30.646195 69867 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::PostProcess(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > > const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> >, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::vector<cinn::ir::Argument, std::allocator<cinn::ir::Argument> >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
14  cinn::optim::Optimize(cinn::ir::LoweredFunc, cinn::common::Target, bool, bool)
15  cinn::optim::MapExternCall(cinn::ir::Expr*, cinn::common::Target)
16  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
17  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
18  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
19  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
20  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
21  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
22  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
23  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
24  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
25  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
26  cinn::ir::IRMutator<cinn::ir::Expr*>::Visit(cinn::ir::Store const*, cinn::ir::Expr*)
27  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
28  cinn::optim::DealWithIntrinsics(cinn::common::Arch, cinn::ir::Call*, cinn::ir::Expr*)
29  cinn::optim::DealWithIntrinsicsNvHygon(cinn::ir::Call*, cinn::ir::Expr*)
30  cinn::lang::CallExtern(std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::map<std::string, std::variant<int, float, bool, std::string >, std::less<std::string >, std::allocator<std::pair<std::string const, std::variant<int, float, bool, std::string > > > > const&)
31  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
32  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: No extern function prototype cinn_nvgpu_exp_int32 found
Existing records are:
atanhf
cinn_nvgpu_ceil_fp64
cinn_nvgpu_gt_num_fp64
cinn_nvgpu_bitwise_and_bool
cinn_nvgpu_logical_right_shift_int16
cinn_discrete_reduce_max_int32
cinn_grid_reduce_prod_fp16
cinn_nvgpu_log10_fp32
block_shuffle_all
cinn_nvgpu_tan_bf16
cinn_discrete_reduce_prod_fp16
bitwise_xor
cinn_grid_reduce_min_fp64
cinn_nvgpu_atanh_fp16
block_shuffle_min_fp16
cinn_nvgpu_lt_num_fp16
cinn_nvgpu_tan_fp64
cinn_host_lt_num_fp32
cinn_block_reduce_min_bf16
cinn_nvgpu_trunc_int32
cinn_nvgpu_trunc_bf16
cinn_nvgpu_isnan_bf16
cinn_call_cuda_kernel
cinn_nvgpu_round_fp16
cinn_discrete_reduce_min_fp32
cinn_nvgpu_floor_bf16
cinn_grid_reduce_min_fp32
cinn_call_cudnn_conv2d_backward_data
cinn_nvgpu_index_add_fp64
cinn_nvgpu_mod_fp16
cinn_block_reduce_sum_fp16
cinn_mkl_exp_v_fp64
cinn_nvgpu_lt_num_int32
cinn_call_cholesky_host
cinn_block_reduce_max_fp32
cinn_block_reduce_prod_fp64
cinn_call_cudnn_conv2d_backward_filter
erff
cinn_nvgpu_atanh_fp32
cinn_nvgpu_asin_bf16
cinn_nvgpu_tan_fp16
cinn_mkl_round_v_fp32
log2
cinn_nvgpu_bitwise_or_bool
bitwise_or
cinn_discrete_reduce_min_fp16
cinn_grid_reduce_min_int64
block_shuffle_prod_fp64
cinn_nvgpu_log_bf16
cinn_nvgpu_round_fp64
cinn_discrete_reduce_prod_bf16
cinn_nvgpu_acos_fp64
cinn_nvgpu_trunc_fp32
cinn_discrete_reduce_sum_int32
cinn_nvgpu_tanh_bf16
cinn_nvgpu_mod_fp64
cinn_nvgpu_index_add_int32
cinn_mkl_ceil_v_fp32
cinn_grid_reduce_prod_bf16
cinn_block_reduce_sum_fp32
cinn_nvgpu_acos_fp16
cinn_grid_reduce_prod_int64
cinn_discrete_reduce_prod_int32
block_shuffle_max_int32
cinn_host_resize_bilinear
cinn_discrete_reduce_max_fp32
cinn_nvgpu_clz_int64
cinn_nvgpu_isinf_fp32
cinn_call_uniform_random
cinn_grid_reduce_prod_int32
log
cinn_host_gt_num_fp64
cinn_get_value_in_cuda_kernel_args
cinn_discrete_reduce_min_fp64
atanf
cinn_host_logical_right_shift_int64
cinn_nvgpu_lt_num_fp64
block_shuffle_prod_fp16
cinn_cpu_mkl_gemm_fp32
cinn_nvgpu_sinh_fp32
cinn_nvgpu_log_fp64
cinn_nvgpu_atanh_fp64
cinn_host_popc_int64
cinn_nvgpu_isnan_fp64
cinn_nvgpu_gt_num_uint8
cinn_nvgpu_bitwise_and_int16
cinn_nvgpu_floor_fp32
right_shift
cinn_block_reduce_sum_int64
cinn_nvgpu_next_smallest_int32
cinn_discrete_reduce_min_int32
cinn_block_reduce_prod_fp32
cinn_nvgpu_bitwise_xor_int64
floor
cinn_nvgpu_lt_num_int16
cinn_host_lt_num_fp64
cinn_block_reduce_prod_int32
cinn_nvgpu_abs_fp64
cinn_nvgpu_atan_fp64
cinn_grid_reduce_max_int32
block_shuffle_sum_fp16
cinn_cuda_resize_bicubic
cinn_nvgpu_log10_fp64
block_shuffle_sum_fp32
cinn_host_find_int_nd
cinn_nvgpu_sin_bf16
block_shuffle_sum_int32
cinn_nvgpu_sinh_bf16
cinn_nvgpu_acosh_bf16
cinn_nvgpu_log2_fp64
cinn_nvgpu_pow_fp64
cinn_nvgpu_atan_bf16
cinn_nvgpu_floor_fp16
isinf
cinn_nvgpu_bitwise_not_int32
ceil
bitwise_not
trunc
cinn_nvgpu_bitwise_not_int64
cinn_nvgpu_rsqrt_fp32
tanh_v
cinn_nvgpu_logical_right_shift_int8
cinn_block_reduce_prod_bf16
cinn_discrete_reduce_max_bf16
cinn_grid_reduce_prod_fp64
cinn_call_cudnn_pool2d_forward
cinn_nvgpu_asinh_fp32
cinn_grid_reduce_any
cinn_call_batched_cublas
cinn_mkl_erf_v_fp32
cinn_nvgpu_bitwise_or_int16
cinn_call_cudnn_conv2d_forward
cinn_nvgpu_isnan_fp32
cinn_cuda_find_int_nd
cinn_cuda_find_float_nd
block_shuffle_min_bf16
cinn_nvgpu_bitwise_xor_int8
cinn_nvgpu_cosh_fp32
cinn_nvgpu_log2_fp16
cinn_nvgpu_log10_fp16
cinn_nvgpu_cbrt_fp16
cinn_discrete_reduce_sum_bf16
cinn_nvgpu_isnan_fp16
cinn_host_cbrt_fp32
cinn_nvgpu_cbrt_fp64
cinn_nvgpu_isfinite_fp64
cinn_block_reduce_min_int64
cinn_nvgpu_isfinite_bf16
cinn_nvgpu_sinh_fp16
cinn_nvgpu_abs_fp32
cinn_nvgpu_index_add_int8
cinn_mkl_tanh_v_fp64
cinn_block_reduce_all
cinn_call_cudnn_softmax_forward
cinn_nvgpu_sqrt_fp32
cinn_nvgpu_sin_fp64
cinn_mkl_sqrt_v_fp32
block_shuffle_min_int32
log10
cinn_nvgpu_acosh_fp64
cinn_host_clz_int32
cinn_grid_reduce_max_bf16
cinn_host_find_float_nd
cinn_discrete_reduce_max_int64
cinn_discrete_reduce_sum_int64
cinn_nvgpu_trunc_fp64
asinf
block_shuffle_max_fp64
block_shuffle_min_fp64
cinn_nvgpu_popc_int64
cinn_nvgpu_pow_bf16
cinn_cpu_onednn_conv2d_nchw_fp32
cinn_nvgpu_log2_bf16
cinn_call_randint
cinn_host_popc_int32
cinn_nvgpu_erf_fp32
cinn_nvgpu_bitwise_or_int8
cinn_grid_reduce_update_semaphore
atanh
block_shuffle_sum_fp64
cinn_nvgpu_erf_bf16
cinn_call_gaussian_random
cinn_nvgpu_exp_fp16
cinn_host_pow_int64
cinn_nvgpu_asin_fp16
cinn_nvgpu_atan_fp16
cinn_nvgpu_exp_fp32
cinn_grid_reduce_sum_int32
cinn_grid_reduce_sum_fp16
cinn_nvgpu_rsqrt_bf16
cinn_nvgpu_cos_fp16
cinn_discrete_reduce_any
atan
cinn_nvgpu_cos_fp32
cinn_nvgpu_right_shift_int32
cinn_nvgpu_lt_num_uint8
cinn_nvgpu_index_add_fp32
cinn_block_reduce_min_fp64
cinn_nvgpu_log10_bf16
cinn_nvgpu_cbrt_bf16
cinn_discrete_reduce_max_fp16
block_shuffle_min_fp32
cinn_nvgpu_exp_fp64
asinhf
cinn_nvgpu_bitwise_xor_int16
cinn_block_reduce_min_fp32
sinh
acos
cinn_mkl_floor_v_fp64
isnan
cinn_mkl_sqrt_v_fp64
cinn_nvgpu_cos_fp64
cinn_nvgpu_rsqrt_fp64
cinn_cuda_find_float_from
cinn_host_find_float
cinn_block_reduce_max_int64
cinn_block_reduce_prod_fp16
cinn_grid_reduce_max_fp16
cinn_nvgpu_cosh_bf16
exp
cinn_cuda_resize_bilinear
cosh
cinn_nvgpu_tanh_fp16
cinn_block_reduce_min_fp16
cinn_host_find_int
cinn_discrete_reduce_sum_fp16
cinn_nvgpu_pow_fp32
powf
block_shuffle_max_int64
tanh
cinn_mkl_log_v_fp64
cinn_nvgpu_ceil_fp16
cinn_nvgpu_rsqrt_fp16
sin
cinn_block_reduce_sum_bf16
cinn_discrete_reduce_all
cinn_nvgpu_sigmoid_fp32
left_shift
cinn_cuda_find_float
cinn_nvgpu_tanh_fp32
cinn_call_cuda_memset
cinn_nvgpu_gt_num_int64
cinn_block_reduce_max_fp16
cinn_nvgpu_mod_bf16
cinn_host_resize_bicubic
cinn_host_cbrt_fp64
fabs
cinn_nvgpu_bitwise_xor_bool
cinn_nvgpu_bitwise_xor_uint8
cinn_nvgpu_bitwise_not_uint8
cinn_nvgpu_bitwise_not_int16
cinn_call_cublas
cinn_nvgpu_left_shift_int32
cinn_nvgpu_index_add_bool
cinn_nvgpu_mod_fp32
cinn_nvgpu_bitwise_and_uint8
cinn_discrete_reduce_min_int64
cinn_grid_reduce_max_fp64
cinn_nvgpu_log2_fp32
cinn_nvgpu_bitwise_xor_int32
cinn_nvgpu_erf_fp64
asin
cinn_nvgpu_sqrt_bf16
cinn_nvgpu_bitwise_and_int32
cinn_nvgpu_trunc_int64
cinn_discrete_reduce_prod_int64
cinn_grid_reduce_min_fp16
cinn_discrete_reduce_min_bf16
cinn_nvgpu_abs_fp16
cinn_nvgpu_erf_fp16
cinn_nvgpu_bitwise_and_int8
cinn_grid_reduce_min_int32
cinn_nvgpu_acosh_fp32
cinn_mkl_erf_v_fp64
block_shuffle_max_fp16
cinn_nvgpu_trunc_fp16
acosf
acoshf
cinn_grid_reduce_sum_fp64
cinn_nvgpu_log_fp16
cinn_nvgpu_bitwise_not_int8
cinn_nvgpu_lt_num_int64
cinn_mkl_round_v_fp64
cinn_nvgpu_acos_fp32
cinn_nvgpu_cosh_fp16
cinn_nvgpu_asin_fp64
asinh
cinn_host_logical_right_shift_int32
cinn_nvgpu_bitwise_or_int32
cinn_block_reduce_max_bf16
block_shuffle_prod_fp32
cinn_host_pow_fp32
cinn_nvgpu_pow_fp16
cinn_call_cudnn_pool2d_backward
cinn_nvgpu_isinf_fp64
cinn_discrete_reduce_max_fp64
cinn_nvgpu_ceil_fp32
cinn_nvgpu_sin_fp16
cinn_nvgpu_sin_fp32
cinn_mkl_floor_v_fp32
sigmoid
cinn_nvgpu_round_fp32
infer_shape_set_value
cinn_nvgpu_logical_right_shift_uint8
cinn_block_reduce_sum_fp64
cinn_cuda_find_int_from
cinn_nvgpu_gt_num_int16
cinn_host_gt_num_int64
cinn_nvgpu_mod_int32
cinn_mkl_exp_v_fp32
cinn_nvgpu_log_fp32
cinn_nvgpu_sigmoid_fp64
cinn_nvgpu_exp_bf16
cinn_block_reduce_max_fp64
cinn_nvgpu_asinh_bf16
cinn_nvgpu_sqrt_fp16
cinn_nvgpu_gt_num_fp16
cinn_nvgpu_atan_fp32
block_shuffle_max_fp32
cinn_nvgpu_logical_right_shift_int32
cinn_grid_reduce_sum_fp32
cinn_grid_reduce_sum_int64
cinn_nvgpu_round_bf16
cinn_nvgpu_index_add_fp16
cinn_nvgpu_isinf_fp16
block_shuffle_max_bf16
cinn_nvgpu_abs_bf16
cinn_call_cudnn_softmax_backward
cinn_nvgpu_tan_fp32
cinn_host_pow_int32
cinn_nvgpu_pow_int64
cinn_nvgpu_bitwise_and_int64
cinn_nvgpu_mod_int64
cinn_nvgpu_bitwise_or_int64
block_shuffle_sum_int64
cinn_get_item_in_cuda_kernel_args
cinn_nvgpu_bitwise_or_uint8
cinn_host_clz_int64
block_shuffle_any
cinn_nvgpu_ceil_bf16
cinn_nvgpu_acosh_fp16
cinn_nvgpu_clz_int32
cinn_nvgpu_sigmoid_fp16
cinn_grid_reduce_max_int64
cinn_nvgpu_popc_int32
cinn_grid_reduce_min_bf16
cinn_nvgpu_asinh_fp16
cinn_nvgpu_gt_num_int32
cinn_nvgpu_acos_bf16
cinn_block_reduce_any
cinn_host_gt_num_int32
bitwise_and
cinn_nvgpu_cos_bf16
cinn_call_cuda_memcpy
cinn_host_pow_fp64
cos
cinn_nvgpu_isfinite_fp16
cinn_grid_reduce_max_fp32
cinn_host_lt_num_int64
block_shuffle_sum_bf16
cinn_discrete_reduce_prod_fp32
cinn_nvgpu_isinf_bf16
cinn_nvgpu_floor_fp64
cinn_mkl_tanh_v_fp32
cinn_cuda_find_int
cinn_nvgpu_pow_int32
erf
cinn_block_reduce_sum_int32
cinn_grid_reduce_prod_fp32
cinn_discrete_reduce_sum_fp64
cinn_nvgpu_atanh_bf16
cinn_nvgpu_sigmoid_bf16
cinn_nvgpu_asin_fp32
isfinite
cinn_nvgpu_sqrt_fp64
cinn_mkl_ceil_v_fp64
sqrt
cinn_block_reduce_min_int32
cinn_nvgpu_logical_right_shift_int64
cinn_block_reduce_prod_int64
cinn_nvgpu_isfinite_fp32
cinn_nvgpu_bitwise_not_bool
cinn_host_gt_num_fp32
cinn_discrete_reduce_sum_fp32
cinn_grid_reduce_sum_bf16
round
cinn_discrete_reduce_prod_fp64
cinn_nvgpu_cbrt_fp32
cinn_host_next_smallest_int32
cinn_call_triangular_solve_nvgpu
cinn_nvgpu_sinh_fp64
acosh
cinn_mkl_log_v_fp32
cinn_cpu_mkl_gemm_batch_fp32
cinn_nvgpu_asinh_fp64
cinn_nvgpu_gt_num_fp32
cinn_grid_reduce_all
tan
cinn_nvgpu_lt_num_fp32
cinn_host_lt_num_int32
block_shuffle_prod_int32
cinn_cpu_onednn_softmax_fp32
cinn_call_cholesky_nvgpu
cinn_nvgpu_index_add_int64
block_shuffle_prod_bf16
cinn_block_reduce_max_int32
cinn_nvgpu_tanh_fp64
block_shuffle_prod_int64
block_shuffle_min_int64
cinn_nvgpu_cosh_fp64

  [Hint: proto should not be null.] (at ../paddle/cinn/lang/compute.cc:266)
[paddle error] paddle.exp(Tensor([10, 200, 300],"int32"), ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.exp(Tensor([10, 200, 300],"int64"), )
I0214 18:25:30.688023 69867 build_cinn_pass.cc:68] Time of building group ops (size=3): 0 min 0 s 0 ms
I0214 18:25:30.688843 69867 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 18:25:30.770036 69867 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::PostProcess(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > > const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> >, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::vector<cinn::ir::Argument, std::allocator<cinn::ir::Argument> >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
14  cinn::optim::Optimize(cinn::ir::LoweredFunc, cinn::common::Target, bool, bool)
15  cinn::optim::MapExternCall(cinn::ir::Expr*, cinn::common::Target)
16  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
17  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
18  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
19  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
20  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
21  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
22  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
23  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
24  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
25  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
26  cinn::ir::IRMutator<cinn::ir::Expr*>::Visit(cinn::ir::Store const*, cinn::ir::Expr*)
27  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
28  cinn::optim::DealWithIntrinsics(cinn::common::Arch, cinn::ir::Call*, cinn::ir::Expr*)
29  cinn::optim::DealWithIntrinsicsNvHygon(cinn::ir::Call*, cinn::ir::Expr*)
30  cinn::lang::CallExtern(std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::map<std::string, std::variant<int, float, bool, std::string >, std::less<std::string >, std::allocator<std::pair<std::string const, std::variant<int, float, bool, std::string > > > > const&)
31  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
32  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: No extern function prototype cinn_nvgpu_exp_int64 found
Existing records are:
atanhf
cinn_nvgpu_ceil_fp64
cinn_nvgpu_gt_num_fp64
cinn_nvgpu_bitwise_and_bool
cinn_nvgpu_logical_right_shift_int16
cinn_discrete_reduce_max_int32
cinn_grid_reduce_prod_fp16
cinn_nvgpu_log10_fp32
block_shuffle_all
cinn_nvgpu_tan_bf16
cinn_discrete_reduce_prod_fp16
bitwise_xor
cinn_grid_reduce_min_fp64
cinn_nvgpu_atanh_fp16
block_shuffle_min_fp16
cinn_nvgpu_lt_num_fp16
cinn_nvgpu_tan_fp64
cinn_host_lt_num_fp32
cinn_block_reduce_min_bf16
cinn_nvgpu_trunc_int32
cinn_nvgpu_trunc_bf16
cinn_nvgpu_isnan_bf16
cinn_call_cuda_kernel
cinn_nvgpu_round_fp16
cinn_discrete_reduce_min_fp32
cinn_nvgpu_floor_bf16
cinn_grid_reduce_min_fp32
cinn_call_cudnn_conv2d_backward_data
cinn_nvgpu_index_add_fp64
cinn_nvgpu_mod_fp16
cinn_block_reduce_sum_fp16
cinn_mkl_exp_v_fp64
cinn_nvgpu_lt_num_int32
cinn_call_cholesky_host
cinn_block_reduce_max_fp32
cinn_block_reduce_prod_fp64
cinn_call_cudnn_conv2d_backward_filter
erff
cinn_nvgpu_atanh_fp32
cinn_nvgpu_asin_bf16
cinn_nvgpu_tan_fp16
cinn_mkl_round_v_fp32
log2
cinn_nvgpu_bitwise_or_bool
bitwise_or
cinn_discrete_reduce_min_fp16
cinn_grid_reduce_min_int64
block_shuffle_prod_fp64
cinn_nvgpu_log_bf16
cinn_nvgpu_round_fp64
cinn_discrete_reduce_prod_bf16
cinn_nvgpu_acos_fp64
cinn_nvgpu_trunc_fp32
cinn_discrete_reduce_sum_int32
cinn_nvgpu_tanh_bf16
cinn_nvgpu_mod_fp64
cinn_nvgpu_index_add_int32
cinn_mkl_ceil_v_fp32
cinn_grid_reduce_prod_bf16
cinn_block_reduce_sum_fp32
cinn_nvgpu_acos_fp16
cinn_grid_reduce_prod_int64
cinn_discrete_reduce_prod_int32
block_shuffle_max_int32
cinn_host_resize_bilinear
cinn_discrete_reduce_max_fp32
cinn_nvgpu_clz_int64
cinn_nvgpu_isinf_fp32
cinn_call_uniform_random
cinn_grid_reduce_prod_int32
log
cinn_host_gt_num_fp64
cinn_get_value_in_cuda_kernel_args
cinn_discrete_reduce_min_fp64
atanf
cinn_host_logical_right_shift_int64
cinn_nvgpu_lt_num_fp64
block_shuffle_prod_fp16
cinn_cpu_mkl_gemm_fp32
cinn_nvgpu_sinh_fp32
cinn_nvgpu_log_fp64
cinn_nvgpu_atanh_fp64
cinn_host_popc_int64
cinn_nvgpu_isnan_fp64
cinn_nvgpu_gt_num_uint8
cinn_nvgpu_bitwise_and_int16
cinn_nvgpu_floor_fp32
right_shift
cinn_block_reduce_sum_int64
cinn_nvgpu_next_smallest_int32
cinn_discrete_reduce_min_int32
cinn_block_reduce_prod_fp32
cinn_nvgpu_bitwise_xor_int64
floor
cinn_nvgpu_lt_num_int16
cinn_host_lt_num_fp64
cinn_block_reduce_prod_int32
cinn_nvgpu_abs_fp64
cinn_nvgpu_atan_fp64
cinn_grid_reduce_max_int32
block_shuffle_sum_fp16
cinn_cuda_resize_bicubic
cinn_nvgpu_log10_fp64
block_shuffle_sum_fp32
cinn_host_find_int_nd
cinn_nvgpu_sin_bf16
block_shuffle_sum_int32
cinn_nvgpu_sinh_bf16
cinn_nvgpu_acosh_bf16
cinn_nvgpu_log2_fp64
cinn_nvgpu_pow_fp64
cinn_nvgpu_atan_bf16
cinn_nvgpu_floor_fp16
isinf
cinn_nvgpu_bitwise_not_int32
ceil
bitwise_not
trunc
cinn_nvgpu_bitwise_not_int64
cinn_nvgpu_rsqrt_fp32
tanh_v
cinn_nvgpu_logical_right_shift_int8
cinn_block_reduce_prod_bf16
cinn_discrete_reduce_max_bf16
cinn_grid_reduce_prod_fp64
cinn_call_cudnn_pool2d_forward
cinn_nvgpu_asinh_fp32
cinn_grid_reduce_any
cinn_call_batched_cublas
cinn_mkl_erf_v_fp32
cinn_nvgpu_bitwise_or_int16
cinn_call_cudnn_conv2d_forward
cinn_nvgpu_isnan_fp32
cinn_cuda_find_int_nd
cinn_cuda_find_float_nd
block_shuffle_min_bf16
cinn_nvgpu_bitwise_xor_int8
cinn_nvgpu_cosh_fp32
cinn_nvgpu_log2_fp16
cinn_nvgpu_log10_fp16
cinn_nvgpu_cbrt_fp16
cinn_discrete_reduce_sum_bf16
cinn_nvgpu_isnan_fp16
cinn_host_cbrt_fp32
cinn_nvgpu_cbrt_fp64
cinn_nvgpu_isfinite_fp64
cinn_block_reduce_min_int64
cinn_nvgpu_isfinite_bf16
cinn_nvgpu_sinh_fp16
cinn_nvgpu_abs_fp32
cinn_nvgpu_index_add_int8
cinn_mkl_tanh_v_fp64
cinn_block_reduce_all
cinn_call_cudnn_softmax_forward
cinn_nvgpu_sqrt_fp32
cinn_nvgpu_sin_fp64
cinn_mkl_sqrt_v_fp32
block_shuffle_min_int32
log10
cinn_nvgpu_acosh_fp64
cinn_host_clz_int32
cinn_grid_reduce_max_bf16
cinn_host_find_float_nd
cinn_discrete_reduce_max_int64
cinn_discrete_reduce_sum_int64
cinn_nvgpu_trunc_fp64
asinf
block_shuffle_max_fp64
block_shuffle_min_fp64
cinn_nvgpu_popc_int64
cinn_nvgpu_pow_bf16
cinn_cpu_onednn_conv2d_nchw_fp32
cinn_nvgpu_log2_bf16
cinn_call_randint
cinn_host_popc_int32
cinn_nvgpu_erf_fp32
cinn_nvgpu_bitwise_or_int8
cinn_grid_reduce_update_semaphore
atanh
block_shuffle_sum_fp64
cinn_nvgpu_erf_bf16
cinn_call_gaussian_random
cinn_nvgpu_exp_fp16
cinn_host_pow_int64
cinn_nvgpu_asin_fp16
cinn_nvgpu_atan_fp16
cinn_nvgpu_exp_fp32
cinn_grid_reduce_sum_int32
cinn_grid_reduce_sum_fp16
cinn_nvgpu_rsqrt_bf16
cinn_nvgpu_cos_fp16
cinn_discrete_reduce_any
atan
cinn_nvgpu_cos_fp32
cinn_nvgpu_right_shift_int32
cinn_nvgpu_lt_num_uint8
cinn_nvgpu_index_add_fp32
cinn_block_reduce_min_fp64
cinn_nvgpu_log10_bf16
cinn_nvgpu_cbrt_bf16
cinn_discrete_reduce_max_fp16
block_shuffle_min_fp32
cinn_nvgpu_exp_fp64
asinhf
cinn_nvgpu_bitwise_xor_int16
cinn_block_reduce_min_fp32
sinh
acos
cinn_mkl_floor_v_fp64
isnan
cinn_mkl_sqrt_v_fp64
cinn_nvgpu_cos_fp64
cinn_nvgpu_rsqrt_fp64
cinn_cuda_find_float_from
cinn_host_find_float
cinn_block_reduce_max_int64
cinn_block_reduce_prod_fp16
cinn_grid_reduce_max_fp16
cinn_nvgpu_cosh_bf16
exp
cinn_cuda_resize_bilinear
cosh
cinn_nvgpu_tanh_fp16
cinn_block_reduce_min_fp16
cinn_host_find_int
cinn_discrete_reduce_sum_fp16
cinn_nvgpu_pow_fp32
powf
block_shuffle_max_int64
tanh
cinn_mkl_log_v_fp64
cinn_nvgpu_ceil_fp16
cinn_nvgpu_rsqrt_fp16
sin
cinn_block_reduce_sum_bf16
cinn_discrete_reduce_all
cinn_nvgpu_sigmoid_fp32
left_shift
cinn_cuda_find_float
cinn_nvgpu_tanh_fp32
cinn_call_cuda_memset
cinn_nvgpu_gt_num_int64
cinn_block_reduce_max_fp16
cinn_nvgpu_mod_bf16
cinn_host_resize_bicubic
cinn_host_cbrt_fp64
fabs
cinn_nvgpu_bitwise_xor_bool
cinn_nvgpu_bitwise_xor_uint8
cinn_nvgpu_bitwise_not_uint8
cinn_nvgpu_bitwise_not_int16
cinn_call_cublas
cinn_nvgpu_left_shift_int32
cinn_nvgpu_index_add_bool
cinn_nvgpu_mod_fp32
cinn_nvgpu_bitwise_and_uint8
cinn_discrete_reduce_min_int64
cinn_grid_reduce_max_fp64
cinn_nvgpu_log2_fp32
cinn_nvgpu_bitwise_xor_int32
cinn_nvgpu_erf_fp64
asin
cinn_nvgpu_sqrt_bf16
cinn_nvgpu_bitwise_and_int32
cinn_nvgpu_trunc_int64
cinn_discrete_reduce_prod_int64
cinn_grid_reduce_min_fp16
cinn_discrete_reduce_min_bf16
cinn_nvgpu_abs_fp16
cinn_nvgpu_erf_fp16
cinn_nvgpu_bitwise_and_int8
cinn_grid_reduce_min_int32
cinn_nvgpu_acosh_fp32
cinn_mkl_erf_v_fp64
block_shuffle_max_fp16
cinn_nvgpu_trunc_fp16
acosf
acoshf
cinn_grid_reduce_sum_fp64
cinn_nvgpu_log_fp16
cinn_nvgpu_bitwise_not_int8
cinn_nvgpu_lt_num_int64
cinn_mkl_round_v_fp64
cinn_nvgpu_acos_fp32
cinn_nvgpu_cosh_fp16
cinn_nvgpu_asin_fp64
asinh
cinn_host_logical_right_shift_int32
cinn_nvgpu_bitwise_or_int32
cinn_block_reduce_max_bf16
block_shuffle_prod_fp32
cinn_host_pow_fp32
cinn_nvgpu_pow_fp16
cinn_call_cudnn_pool2d_backward
cinn_nvgpu_isinf_fp64
cinn_discrete_reduce_max_fp64
cinn_nvgpu_ceil_fp32
cinn_nvgpu_sin_fp16
cinn_nvgpu_sin_fp32
cinn_mkl_floor_v_fp32
sigmoid
cinn_nvgpu_round_fp32
infer_shape_set_value
cinn_nvgpu_logical_right_shift_uint8
cinn_block_reduce_sum_fp64
cinn_cuda_find_int_from
cinn_nvgpu_gt_num_int16
cinn_host_gt_num_int64
cinn_nvgpu_mod_int32
cinn_mkl_exp_v_fp32
cinn_nvgpu_log_fp32
cinn_nvgpu_sigmoid_fp64
cinn_nvgpu_exp_bf16
cinn_block_reduce_max_fp64
cinn_nvgpu_asinh_bf16
cinn_nvgpu_sqrt_fp16
cinn_nvgpu_gt_num_fp16
cinn_nvgpu_atan_fp32
block_shuffle_max_fp32
cinn_nvgpu_logical_right_shift_int32
cinn_grid_reduce_sum_fp32
cinn_grid_reduce_sum_int64
cinn_nvgpu_round_bf16
cinn_nvgpu_index_add_fp16
cinn_nvgpu_isinf_fp16
block_shuffle_max_bf16
cinn_nvgpu_abs_bf16
cinn_call_cudnn_softmax_backward
cinn_nvgpu_tan_fp32
cinn_host_pow_int32
cinn_nvgpu_pow_int64
cinn_nvgpu_bitwise_and_int64
cinn_nvgpu_mod_int64
cinn_nvgpu_bitwise_or_int64
block_shuffle_sum_int64
cinn_get_item_in_cuda_kernel_args
cinn_nvgpu_bitwise_or_uint8
cinn_host_clz_int64
block_shuffle_any
cinn_nvgpu_ceil_bf16
cinn_nvgpu_acosh_fp16
cinn_nvgpu_clz_int32
cinn_nvgpu_sigmoid_fp16
cinn_grid_reduce_max_int64
cinn_nvgpu_popc_int32
cinn_grid_reduce_min_bf16
cinn_nvgpu_asinh_fp16
cinn_nvgpu_gt_num_int32
cinn_nvgpu_acos_bf16
cinn_block_reduce_any
cinn_host_gt_num_int32
bitwise_and
cinn_nvgpu_cos_bf16
cinn_call_cuda_memcpy
cinn_host_pow_fp64
cos
cinn_nvgpu_isfinite_fp16
cinn_grid_reduce_max_fp32
cinn_host_lt_num_int64
block_shuffle_sum_bf16
cinn_discrete_reduce_prod_fp32
cinn_nvgpu_isinf_bf16
cinn_nvgpu_floor_fp64
cinn_mkl_tanh_v_fp32
cinn_cuda_find_int
cinn_nvgpu_pow_int32
erf
cinn_block_reduce_sum_int32
cinn_grid_reduce_prod_fp32
cinn_discrete_reduce_sum_fp64
cinn_nvgpu_atanh_bf16
cinn_nvgpu_sigmoid_bf16
cinn_nvgpu_asin_fp32
isfinite
cinn_nvgpu_sqrt_fp64
cinn_mkl_ceil_v_fp64
sqrt
cinn_block_reduce_min_int32
cinn_nvgpu_logical_right_shift_int64
cinn_block_reduce_prod_int64
cinn_nvgpu_isfinite_fp32
cinn_nvgpu_bitwise_not_bool
cinn_host_gt_num_fp32
cinn_discrete_reduce_sum_fp32
cinn_grid_reduce_sum_bf16
round
cinn_discrete_reduce_prod_fp64
cinn_nvgpu_cbrt_fp32
cinn_host_next_smallest_int32
cinn_call_triangular_solve_nvgpu
cinn_nvgpu_sinh_fp64
acosh
cinn_mkl_log_v_fp32
cinn_cpu_mkl_gemm_batch_fp32
cinn_nvgpu_asinh_fp64
cinn_nvgpu_gt_num_fp32
cinn_grid_reduce_all
tan
cinn_nvgpu_lt_num_fp32
cinn_host_lt_num_int32
block_shuffle_prod_int32
cinn_cpu_onednn_softmax_fp32
cinn_call_cholesky_nvgpu
cinn_nvgpu_index_add_int64
block_shuffle_prod_bf16
cinn_block_reduce_max_int32
cinn_nvgpu_tanh_fp64
block_shuffle_prod_int64
block_shuffle_min_int64
cinn_nvgpu_cosh_fp64

  [Hint: proto should not be null.] (at ../paddle/cinn/lang/compute.cc:266)
[paddle error] paddle.exp(Tensor([10, 200, 300],"int64"), ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.gather(Tensor([2, 3],"float32"), Tensor([],"int64"), )
E0214 18:27:47.841445 71869 shape_optimization_pass.cc:183] Warning : Check InferSymbolicShape for pd_op.gather [id:16278]  carefully! rank of infer_meta_shape is [1], but rank of infer_sym_shape is [2].
I0214 18:27:47.842108 71869 build_cinn_pass.cc:68] Time of building group ops (size=6): 0 min 0 s 0 ms
I0214 18:27:47.842841 71869 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 18:27:47.878918 71869 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Gather(cinn::ir::Tensor const&, cinn::ir::Tensor const&, int, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::string const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Tensor::operator()(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&) const
18  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
19  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
PreconditionNotMetError: number of indices not match the dimension
  [Hint: Expected compatible_indices.size() == ndims(), but received compatible_indices.size():1 != ndims():2.] (at ../paddle/cinn/ir/tensor.cc:185)
[paddle error] paddle.gather(Tensor([2, 3],"float32"), Tensor([],"int64"), ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.gather_nd(Tensor([2, 3],"float32"), Tensor([2],"int64"), )
I0214 18:28:16.071360 73157 build_cinn_pass.cc:68] Time of building group ops (size=4): 0 min 0 s 0 ms
I0214 18:28:16.072158 73157 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 18:28:16.107517 73157 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::lang::LowerToAstVec(std::string const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> > const&, cinn::ast_gen_ius::TensorGroup*, cinn::common::Target const&)
16  cinn::lang::detail::LowerTensorGroup::operator()()
17  cinn::lang::detail::LowerTensorGroup::GenerateFunctionBody(cinn::ast_gen_ius::TensorGroup*)
18  cinn::ast_gen_ius::AstGen::Build(cinn::ir::Tensor const&, cinn::ast_gen_ius::TensorGroup*)
19  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
20  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: Internal Error: Tensor has different shape and axis length in AstGen
  [Hint: Expected shape.size() == axis_len, but received shape.size():1 != axis_len:0.] (at ../paddle/cinn/ast_gen_ius/ast_gen.cc:83)
[paddle error] paddle.gather_nd(Tensor([2, 3],"float32"), Tensor([2],"int64"), ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.gather_nd(Tensor([5],"float32"), Tensor([1],"int64"), )
I0214 18:28:16.144513 73157 build_cinn_pass.cc:68] Time of building group ops (size=4): 0 min 0 s 0 ms
I0214 18:28:16.145326 73157 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 18:28:16.179533 73157 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::lang::LowerToAstVec(std::string const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> > const&, cinn::ast_gen_ius::TensorGroup*, cinn::common::Target const&)
16  cinn::lang::detail::LowerTensorGroup::operator()()
17  cinn::lang::detail::LowerTensorGroup::GenerateFunctionBody(cinn::ast_gen_ius::TensorGroup*)
18  cinn::ast_gen_ius::AstGen::Build(cinn::ir::Tensor const&, cinn::ast_gen_ius::TensorGroup*)
19  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
20  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: Internal Error: Tensor has different shape and axis length in AstGen
  [Hint: Expected shape.size() == axis_len, but received shape.size():1 != axis_len:0.] (at ../paddle/cinn/ast_gen_ius/ast_gen.cc:83)
[paddle error] paddle.gather_nd(Tensor([5],"float32"), Tensor([1],"int64"), ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.logical_not(Tensor([],"int64"), )
I0214 18:43:42.415758 83490 build_cinn_pass.cc:68] Time of building group ops (size=3): 0 min 0 s 0 ms
I0214 18:43:42.416353 83490 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 18:43:42.468456 83490 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::CodegenAndJit()
12  cinn::hlir::framework::CompilationTask::BuildPirCINNKernelInfo(cinn::ir::Module const&, cinn::ir::Module const&, bool)
13  cinn::backends::Compiler::AppendCX86(cinn::ir::Module const&)
14  void cinn::backends::ExecutionEngine::Link<cinn::backends::CodeGenX86>(cinn::ir::Module const&)
15  cinn::backends::CodeGenLLVM::Visit(cinn::ir::_Module_ const*)
16  cinn::ir::ir_utils::IrVerify(cinn::ir::_Module_ const*)
17  cinn::ir::IRMutator<cinn::ir::Expr*>::Visit(cinn::ir::_Module_*)
18  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
19  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
20  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
21  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
22  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
23  cinn::ir::Not::Verify() const
24  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
25  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The type of the operand of the node [Not] should be bool
  [Hint: Expected v().type() == type_of<bool>(), but received v().type():int64 != type_of<bool>():bool.] (at ../paddle/cinn/ir/ir.cc:327)
[paddle error] paddle.logical_not(Tensor([],"int64"), ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.logical_not(Tensor([1, 4],"int64"), )
I0214 18:43:43.676604 83490 build_cinn_pass.cc:68] Time of building group ops (size=3): 0 min 0 s 0 ms
I0214 18:43:43.677250 83490 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 18:43:43.733909 83490 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::CodegenAndJit()
12  cinn::hlir::framework::CompilationTask::BuildPirCINNKernelInfo(cinn::ir::Module const&, cinn::ir::Module const&, bool)
13  cinn::backends::Compiler::AppendCX86(cinn::ir::Module const&)
14  void cinn::backends::ExecutionEngine::Link<cinn::backends::CodeGenX86>(cinn::ir::Module const&)
15  cinn::backends::CodeGenLLVM::Visit(cinn::ir::_Module_ const*)
16  cinn::ir::ir_utils::IrVerify(cinn::ir::_Module_ const*)
17  cinn::ir::IRMutator<cinn::ir::Expr*>::Visit(cinn::ir::_Module_*)
18  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
19  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
20  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
21  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
22  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
23  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
24  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
25  cinn::ir::Not::Verify() const
26  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
27  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The type of the operand of the node [Not] should be bool
  [Hint: Expected v().type() == type_of<bool>(), but received v().type():int64 != type_of<bool>():bool.] (at ../paddle/cinn/ir/ir.cc:327)
[paddle error] paddle.logical_not(Tensor([1, 4],"int64"), ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.logical_not(Tensor([2, 1],"int64"), )
I0214 18:43:45.811753 83490 build_cinn_pass.cc:68] Time of building group ops (size=3): 0 min 0 s 0 ms
I0214 18:43:45.812382 83490 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 18:43:45.868728 83490 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::CodegenAndJit()
12  cinn::hlir::framework::CompilationTask::BuildPirCINNKernelInfo(cinn::ir::Module const&, cinn::ir::Module const&, bool)
13  cinn::backends::Compiler::AppendCX86(cinn::ir::Module const&)
14  void cinn::backends::ExecutionEngine::Link<cinn::backends::CodeGenX86>(cinn::ir::Module const&)
15  cinn::backends::CodeGenLLVM::Visit(cinn::ir::_Module_ const*)
16  cinn::ir::ir_utils::IrVerify(cinn::ir::_Module_ const*)
17  cinn::ir::IRMutator<cinn::ir::Expr*>::Visit(cinn::ir::_Module_*)
18  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
19  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
20  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
21  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
22  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
23  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
24  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
25  cinn::ir::Not::Verify() const
26  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
27  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The type of the operand of the node [Not] should be bool
  [Hint: Expected v().type() == type_of<bool>(), but received v().type():int64 != type_of<bool>():bool.] (at ../paddle/cinn/ir/ir.cc:327)
[paddle error] paddle.logical_not(Tensor([2, 1],"int64"), ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.logical_not(Tensor([3, 1],"int64"), )
I0214 18:43:48.269898 83490 build_cinn_pass.cc:68] Time of building group ops (size=3): 0 min 0 s 0 ms
I0214 18:43:48.270545 83490 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 18:43:48.326781 83490 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::CodegenAndJit()
12  cinn::hlir::framework::CompilationTask::BuildPirCINNKernelInfo(cinn::ir::Module const&, cinn::ir::Module const&, bool)
13  cinn::backends::Compiler::AppendCX86(cinn::ir::Module const&)
14  void cinn::backends::ExecutionEngine::Link<cinn::backends::CodeGenX86>(cinn::ir::Module const&)
15  cinn::backends::CodeGenLLVM::Visit(cinn::ir::_Module_ const*)
16  cinn::ir::ir_utils::IrVerify(cinn::ir::_Module_ const*)
17  cinn::ir::IRMutator<cinn::ir::Expr*>::Visit(cinn::ir::_Module_*)
18  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
19  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
20  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
21  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
22  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
23  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
24  cinn::ir::IRVisitorRequireReImpl<void, cinn::ir::Expr*>::Visit(cinn::ir::Expr const*, cinn::ir::Expr*)
25  cinn::ir::Not::Verify() const
26  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
27  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The type of the operand of the node [Not] should be bool
  [Hint: Expected v().type() == type_of<bool>(), but received v().type():int64 != type_of<bool>():bool.] (at ../paddle/cinn/ir/ir.cc:327)
[paddle error] paddle.logical_not(Tensor([3, 1],"int64"), ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.glu(Tensor([5, 20],"float64"), -1, )
W0214 18:58:45.082384 97238 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
I0214 18:58:45.085780 97238 build_cinn_pass.cc:68] Time of building group ops (size=14): 0 min 0 s 0 ms
I0214 18:58:45.087921 97238 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 18:58:45.125036 97238 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.glu(Tensor([5, 20],"float64"), -1, ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.glu(Tensor([6, 20],"float64"), 0, None, )
W0214 18:58:45.159636 97238 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
I0214 18:58:45.163376 97238 build_cinn_pass.cc:68] Time of building group ops (size=14): 0 min 0 s 0 ms
I0214 18:58:45.165635 97238 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 18:58:45.202531 97238 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.glu(Tensor([6, 20],"float64"), 0, None, ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.glu(Tensor([6, 20],"float64"), 1, None, )
W0214 18:58:45.236744 97238 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
I0214 18:58:45.240336 97238 build_cinn_pass.cc:68] Time of building group ops (size=14): 0 min 0 s 0 ms
I0214 18:58:45.242512 97238 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 18:58:45.279254 97238 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.glu(Tensor([6, 20],"float64"), 1, None, ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.glu(Tensor([6, 20],"float64"), -1, None, )
W0214 18:58:45.313886 97238 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
I0214 18:58:45.317498 97238 build_cinn_pass.cc:68] Time of building group ops (size=14): 0 min 0 s 0 ms
I0214 18:58:45.319731 97238 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 18:58:45.356483 97238 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.glu(Tensor([6, 20],"float64"), -1, None, ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.sigmoid(Tensor([1, 32],"float64"), )
I0214 19:10:45.308820 106263 build_cinn_pass.cc:68] Time of building group ops (size=7): 0 min 0 s 0 ms
I0214 19:10:45.310411 106263 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:10:45.347229 106263 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.sigmoid(Tensor([1, 32],"float64"), ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.sigmoid(Tensor([10],"float64"), )
I0214 19:10:47.744837 106263 build_cinn_pass.cc:68] Time of building group ops (size=7): 0 min 0 s 0 ms
I0214 19:10:47.746201 106263 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:10:47.782927 106263 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.sigmoid(Tensor([10],"float64"), ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.sigmoid(Tensor([3, 1],"float64"), )
I0214 19:10:53.117183 106263 build_cinn_pass.cc:68] Time of building group ops (size=7): 0 min 0 s 0 ms
I0214 19:10:53.118817 106263 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:10:53.156011 106263 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerX86(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, bool)
14  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
15  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
16  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
17  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
18  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
19  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
20  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
21  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
22  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.sigmoid(Tensor([3, 1],"float64"), ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.sigmoid(Tensor([32, 32],"float64"), )
I0214 19:10:54.155699 106263 build_cinn_pass.cc:68] Time of building group ops (size=7): 0 min 0 s 0 ms
I0214 19:10:54.157270 106263 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:10:54.193905 106263 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.sigmoid(Tensor([32, 32],"float64"), ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.sigmoid(Tensor([4, 16],"float64"), )
I0214 19:10:59.451455 106263 build_cinn_pass.cc:68] Time of building group ops (size=7): 0 min 0 s 0 ms
I0214 19:10:59.453042 106263 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:10:59.489699 106263 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.sigmoid(Tensor([4, 16],"float64"), ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.sigmoid(Tensor([4, 32],"float64"), )
I0214 19:10:59.526650 106263 build_cinn_pass.cc:68] Time of building group ops (size=7): 0 min 0 s 0 ms
I0214 19:10:59.528312 106263 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:10:59.564965 106263 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.sigmoid(Tensor([4, 32],"float64"), ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.sigmoid(Tensor([5, 10],"float64"), )
I0214 19:11:09.623842 106263 build_cinn_pass.cc:68] Time of building group ops (size=7): 0 min 0 s 0 ms
I0214 19:11:09.625488 106263 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:11:09.662312 106263 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.sigmoid(Tensor([5, 10],"float64"), ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), None, alpha=0.25, gamma=0.0, reduction="mean", )
W0214 19:11:14.010660 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
W0214 19:11:14.016618 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
I0214 19:11:14.018210 106263 build_cinn_pass.cc:68] Time of building group ops (size=49): 0 min 0 s 1 ms
I0214 19:11:14.026923 106263 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:11:14.065605 106263 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), None, alpha=0.25, gamma=0.0, reduction="mean", ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), None, alpha=0.25, gamma=0.0, reduction="none", )
W0214 19:11:14.115605 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
W0214 19:11:14.121351 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
I0214 19:11:14.122903 106263 build_cinn_pass.cc:68] Time of building group ops (size=47): 0 min 0 s 1 ms
I0214 19:11:14.131632 106263 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:11:14.170135 106263 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), None, alpha=0.25, gamma=0.0, reduction="none", ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), None, alpha=0.25, gamma=0.0, reduction="sum", )
W0214 19:11:14.222185 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
W0214 19:11:14.228181 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
I0214 19:11:14.229809 106263 build_cinn_pass.cc:68] Time of building group ops (size=51): 0 min 0 s 1 ms
I0214 19:11:14.239147 106263 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:11:14.277704 106263 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), None, alpha=0.25, gamma=0.0, reduction="sum", ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), None, alpha=0.25, gamma=3, reduction="mean", )
W0214 19:11:14.328547 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
W0214 19:11:14.334661 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
I0214 19:11:14.336282 106263 build_cinn_pass.cc:68] Time of building group ops (size=49): 0 min 0 s 1 ms
I0214 19:11:14.344827 106263 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:11:14.383358 106263 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), None, alpha=0.25, gamma=3, reduction="mean", ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), None, alpha=0.25, gamma=3, reduction="none", )
W0214 19:11:14.433427 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
W0214 19:11:14.439316 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
I0214 19:11:14.440851 106263 build_cinn_pass.cc:68] Time of building group ops (size=47): 0 min 0 s 1 ms
I0214 19:11:14.449365 106263 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:11:14.487983 106263 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), None, alpha=0.25, gamma=3, reduction="none", ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), None, alpha=0.25, gamma=3, reduction="sum", )
W0214 19:11:14.538947 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
W0214 19:11:14.544991 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
I0214 19:11:14.546623 106263 build_cinn_pass.cc:68] Time of building group ops (size=51): 0 min 0 s 1 ms
I0214 19:11:14.555855 106263 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:11:14.594282 106263 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), None, alpha=0.25, gamma=3, reduction="sum", ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), None, alpha=0.5, gamma=0.0, reduction="mean", )
W0214 19:11:14.645084 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
W0214 19:11:14.651016 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
I0214 19:11:14.652593 106263 build_cinn_pass.cc:68] Time of building group ops (size=49): 0 min 0 s 1 ms
I0214 19:11:14.660969 106263 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:11:14.699445 106263 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), None, alpha=0.5, gamma=0.0, reduction="mean", ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), None, alpha=0.5, gamma=0.0, reduction="none", )
W0214 19:11:14.749679 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
W0214 19:11:14.755528 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
I0214 19:11:14.757120 106263 build_cinn_pass.cc:68] Time of building group ops (size=47): 0 min 0 s 1 ms
I0214 19:11:14.765528 106263 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:11:14.804009 106263 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), None, alpha=0.5, gamma=0.0, reduction="none", ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), None, alpha=0.5, gamma=0.0, reduction="sum", )
W0214 19:11:14.855348 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
W0214 19:11:14.861378 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
I0214 19:11:14.863029 106263 build_cinn_pass.cc:68] Time of building group ops (size=51): 0 min 0 s 1 ms
I0214 19:11:14.872367 106263 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:11:14.910844 106263 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), None, alpha=0.5, gamma=0.0, reduction="sum", ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), None, alpha=0.5, gamma=3, reduction="mean", )
W0214 19:11:14.961463 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
W0214 19:11:14.967443 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
I0214 19:11:14.969034 106263 build_cinn_pass.cc:68] Time of building group ops (size=49): 0 min 0 s 1 ms
I0214 19:11:14.977427 106263 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:11:15.015838 106263 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), None, alpha=0.5, gamma=3, reduction="mean", ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), None, alpha=0.5, gamma=3, reduction="none", )
W0214 19:11:15.065985 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
W0214 19:11:15.071877 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
I0214 19:11:15.073426 106263 build_cinn_pass.cc:68] Time of building group ops (size=47): 0 min 0 s 1 ms
I0214 19:11:15.081964 106263 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:11:15.120429 106263 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), None, alpha=0.5, gamma=3, reduction="none", ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), None, alpha=0.5, gamma=3, reduction="sum", )
W0214 19:11:15.172291 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
W0214 19:11:15.178484 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
I0214 19:11:15.180127 106263 build_cinn_pass.cc:68] Time of building group ops (size=51): 0 min 0 s 1 ms
I0214 19:11:15.189343 106263 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:11:15.227946 106263 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), None, alpha=0.5, gamma=3, reduction="sum", ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=0.0, reduction="mean", )
W0214 19:11:15.280382 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
W0214 19:11:15.286530 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
I0214 19:11:15.288190 106263 build_cinn_pass.cc:68] Time of building group ops (size=52): 0 min 0 s 1 ms
I0214 19:11:15.297241 106263 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:11:15.335724 106263 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=0.0, reduction="mean", ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=0.0, reduction="none", )
W0214 19:11:15.387527 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
W0214 19:11:15.393576 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
I0214 19:11:15.395195 106263 build_cinn_pass.cc:68] Time of building group ops (size=50): 0 min 0 s 1 ms
I0214 19:11:15.404250 106263 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:11:15.442775 106263 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=0.0, reduction="none", ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=0.0, reduction="sum", )
W0214 19:11:15.495307 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
W0214 19:11:15.501521 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
I0214 19:11:15.503233 106263 build_cinn_pass.cc:68] Time of building group ops (size=54): 0 min 0 s 1 ms
I0214 19:11:15.513103 106263 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:11:15.551621 106263 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=0.0, reduction="sum", ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=3, reduction="mean", )
W0214 19:11:15.603865 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
W0214 19:11:15.609957 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
I0214 19:11:15.611606 106263 build_cinn_pass.cc:68] Time of building group ops (size=52): 0 min 0 s 1 ms
I0214 19:11:15.620702 106263 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:11:15.659154 106263 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=3, reduction="mean", ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=3, reduction="none", )
W0214 19:11:15.710368 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
W0214 19:11:15.716387 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
I0214 19:11:15.718036 106263 build_cinn_pass.cc:68] Time of building group ops (size=50): 0 min 0 s 1 ms
I0214 19:11:15.727095 106263 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:11:15.765661 106263 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=3, reduction="none", ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=3, reduction="sum", )
W0214 19:11:15.818236 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
W0214 19:11:15.824506 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
I0214 19:11:15.826211 106263 build_cinn_pass.cc:68] Time of building group ops (size=54): 0 min 0 s 1 ms
I0214 19:11:15.836030 106263 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:11:15.874473 106263 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.25, gamma=3, reduction="sum", ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=0.0, reduction="mean", )
W0214 19:11:15.926760 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
W0214 19:11:15.932941 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
I0214 19:11:15.934589 106263 build_cinn_pass.cc:68] Time of building group ops (size=52): 0 min 0 s 1 ms
I0214 19:11:15.943728 106263 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:11:15.982290 106263 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=0.0, reduction="mean", ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=0.0, reduction="none", )
W0214 19:11:16.034751 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
W0214 19:11:16.041054 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
I0214 19:11:16.042706 106263 build_cinn_pass.cc:68] Time of building group ops (size=50): 0 min 0 s 1 ms
I0214 19:11:16.051890 106263 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:11:16.090564 106263 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=0.0, reduction="none", ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=0.0, reduction="sum", )
W0214 19:11:16.142845 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
W0214 19:11:16.149209 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
I0214 19:11:16.150890 106263 build_cinn_pass.cc:68] Time of building group ops (size=54): 0 min 0 s 1 ms
I0214 19:11:16.160753 106263 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:11:16.199350 106263 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=0.0, reduction="sum", ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=3, reduction="mean", )
W0214 19:11:16.251771 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
W0214 19:11:16.257951 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
I0214 19:11:16.259599 106263 build_cinn_pass.cc:68] Time of building group ops (size=52): 0 min 0 s 1 ms
I0214 19:11:16.268774 106263 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:11:16.307189 106263 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=3, reduction="mean", ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=3, reduction="none", )
W0214 19:11:16.358819 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
W0214 19:11:16.364871 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
I0214 19:11:16.366485 106263 build_cinn_pass.cc:68] Time of building group ops (size=50): 0 min 0 s 1 ms
I0214 19:11:16.375556 106263 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:11:16.414690 106263 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=3, reduction="none", ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=3, reduction="sum", )
W0214 19:11:16.468999 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
W0214 19:11:16.475363 106263 pattern_rewrite_driver.cc:235] The pattern rewrite did not converge after scanning 10 times
I0214 19:11:16.477115 106263 build_cinn_pass.cc:68] Time of building group ops (size=54): 0 min 0 s 1 ms
I0214 19:11:16.487036 106263 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:11:16.525513 106263 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::Lowering()
12  cinn::hlir::framework::pir::OpLowererImpl::BucketLower(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&)
13  cinn::hlir::framework::pir::OpLowererImpl::LowerOps(std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> const&, std::vector<pir::Operation*, std::allocator<pir::Operation*> > const&, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*)
14  cinn::hlir::framework::pir::OpLowererImpl::DoOpLower(std::shared_ptr<cinn::hlir::framework::OpImpl>, pir::Operation*, std::unordered_map<pir::Value, cinn::ir::Tensor, std::hash<pir::Value>, std::equal_to<pir::Value>, std::allocator<std::pair<pir::Value const, cinn::ir::Tensor> > >*, std::vector<cinn::ir::Tensor, std::allocator<cinn::ir::Tensor> >*)
15  cinn::hlir::pe::Add(cinn::ir::Tensor const&, cinn::ir::Tensor const&, std::string const&, cinn::ir::Expr const&)
16  cinn::lang::Compute(std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&, std::function<cinn::ir::Expr (std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)>, std::string const&, std::vector<cinn::ir::Expr, std::allocator<cinn::ir::Expr> > const&)
17  cinn::ir::Add::Make(cinn::ir::Expr, cinn::ir::Expr)
18  cinn::ir::Add* cinn::common::make_shared<cinn::ir::Add, cinn::ir::Expr&, cinn::ir::Expr&>(cinn::ir::Expr&, cinn::ir::Expr&)
19  cinn::ir::BinaryNodeVerify(cinn::ir::Expr const&, cinn::ir::Expr const&, std::basic_string_view<char, std::char_traits<char> >)
20  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
21  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: The operands' types of the node [Add] don't match. Received types: float32 and float64
  [Hint: Expected a.type() == b.type(), but received a.type():float32 != b.type():float64.] (at ../paddle/cinn/ir/ir.cc:142)
[paddle error] paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 10],"float64"), Tensor([2, 3, 4, 10],"float64"), Tensor([1],"float64"), alpha=0.5, gamma=3, reduction="sum", ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.Tensor.tril(Tensor([1, 2, 2],"float32"), -1, )
I0214 19:35:21.331105 124633 build_cinn_pass.cc:68] Time of building group ops (size=3): 0 min 0 s 0 ms
I0214 19:35:21.331830 124633 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:35:21.404814 124633 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::CodegenAndJit()
12  cinn::hlir::framework::CompilationTask::BuildPirCINNKernelInfo(cinn::ir::Module const&, cinn::ir::Module const&, bool)
13  cinn::backends::Compiler::AppendCX86(cinn::ir::Module const&)
14  void cinn::backends::ExecutionEngine::Link<cinn::backends::CodeGenX86>(cinn::ir::Module const&)
15  cinn::backends::CodeGenLLVM::Visit(cinn::ir::_Module_ const*)
16  cinn::backends::CodeGenLLVM::Visit(cinn::ir::_LoweredFunc_ const*)
17  cinn::ir::IRVisitorRequireReImpl<llvm::Value*>::Visit(cinn::ir::Expr const*)
18  cinn::backends::CodeGenLLVM::Visit(cinn::ir::Block const*)
19  cinn::ir::IRVisitorRequireReImpl<llvm::Value*>::Visit(cinn::ir::Expr const*)
20  cinn::backends::CodeGenLLVM::Visit(cinn::ir::Block const*)
21  cinn::ir::IRVisitorRequireReImpl<llvm::Value*>::Visit(cinn::ir::Expr const*)
22  cinn::backends::CodeGenX86::Visit(cinn::ir::For const*)
23  cinn::backends::CodeGenLLVM::CreateSerialFor(cinn::ir::For const*, int)
24  cinn::ir::IRVisitorRequireReImpl<llvm::Value*>::Visit(cinn::ir::Expr const*)
25  cinn::backends::CodeGenLLVM::Visit(cinn::ir::Block const*)
26  cinn::ir::IRVisitorRequireReImpl<llvm::Value*>::Visit(cinn::ir::Expr const*)
27  cinn::backends::CodeGenX86::Visit(cinn::ir::For const*)
28  cinn::backends::CodeGenLLVM::CreateSerialFor(cinn::ir::For const*, int)
29  cinn::ir::IRVisitorRequireReImpl<llvm::Value*>::Visit(cinn::ir::Expr const*)
30  cinn::backends::CodeGenLLVM::Visit(cinn::ir::Block const*)
31  cinn::ir::IRVisitorRequireReImpl<llvm::Value*>::Visit(cinn::ir::Expr const*)
32  cinn::backends::CodeGenX86::Visit(cinn::ir::For const*)
33  cinn::backends::CodeGenLLVM::CreateSerialFor(cinn::ir::For const*, int)
34  cinn::ir::IRVisitorRequireReImpl<llvm::Value*>::Visit(cinn::ir::Expr const*)
35  cinn::backends::CodeGenLLVM::Visit(cinn::ir::Block const*)
36  cinn::ir::IRVisitorRequireReImpl<llvm::Value*>::Visit(cinn::ir::Expr const*)
37  cinn::backends::CodeGenLLVM::Visit(cinn::ir::Store const*)
38  cinn::ir::IRVisitorRequireReImpl<llvm::Value*>::Visit(cinn::ir::Expr const*)
39  cinn::backends::CodeGenLLVM::Visit(cinn::ir::Select const*)
40  cinn::ir::IRVisitorRequireReImpl<llvm::Value*>::Visit(cinn::ir::Expr const*)
41  cinn::backends::CodeGenLLVM::Visit(cinn::ir::GE const*)
42  cinn::ir::IRVisitorRequireReImpl<llvm::Value*>::Visit(cinn::ir::Expr const*)
43  cinn::backends::CodeGenLLVM::Visit(cinn::ir::Add const*)
44  cinn::backends::CodeGenLLVM::EmitBinaryOp(llvm::Value*, llvm::Value*, char, bool, bool)
45  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
46  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: the types of operands of binary operation are mismatch
  [Hint: Expected lhs->getType() == rhs->getType(), but received lhs->getType():0x65810748 != rhs->getType():0x65810730.] (at ../paddle/cinn/backends/llvm/codegen_llvm.cc:212)
[paddle error] paddle.Tensor.tril(Tensor([1, 2, 2],"float32"), -1, ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


test begin: paddle.Tensor.tril(Tensor([2, 2],"float32"), -1, )
I0214 19:35:21.884896 124633 build_cinn_pass.cc:68] Time of building group ops (size=3): 0 min 0 s 0 ms
I0214 19:35:21.885607 124633 add_cinn_pass.cc:285] FusionOp count before lowering : *****[ 1 ]*****
E0214 19:35:21.951297 124633 multi_threading.cc:101] 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   cinn::utils::parallel_run(std::function<void (int)> const&, cinn::utils::JobDispatcher&&, int)
9   cinn::hlir::framework::PirCompiler::Compile(cinn::hlir::framework::GroupCompilationContext*)
10  cinn::hlir::framework::CompilationTask::operator()()
11  cinn::hlir::framework::CompilationTask::CodegenAndJit()
12  cinn::hlir::framework::CompilationTask::BuildPirCINNKernelInfo(cinn::ir::Module const&, cinn::ir::Module const&, bool)
13  cinn::backends::Compiler::AppendCX86(cinn::ir::Module const&)
14  void cinn::backends::ExecutionEngine::Link<cinn::backends::CodeGenX86>(cinn::ir::Module const&)
15  cinn::backends::CodeGenLLVM::Visit(cinn::ir::_Module_ const*)
16  cinn::backends::CodeGenLLVM::Visit(cinn::ir::_LoweredFunc_ const*)
17  cinn::ir::IRVisitorRequireReImpl<llvm::Value*>::Visit(cinn::ir::Expr const*)
18  cinn::backends::CodeGenLLVM::Visit(cinn::ir::Block const*)
19  cinn::ir::IRVisitorRequireReImpl<llvm::Value*>::Visit(cinn::ir::Expr const*)
20  cinn::backends::CodeGenLLVM::Visit(cinn::ir::Block const*)
21  cinn::ir::IRVisitorRequireReImpl<llvm::Value*>::Visit(cinn::ir::Expr const*)
22  cinn::backends::CodeGenX86::Visit(cinn::ir::For const*)
23  cinn::backends::CodeGenLLVM::CreateSerialFor(cinn::ir::For const*, int)
24  cinn::ir::IRVisitorRequireReImpl<llvm::Value*>::Visit(cinn::ir::Expr const*)
25  cinn::backends::CodeGenLLVM::Visit(cinn::ir::Block const*)
26  cinn::ir::IRVisitorRequireReImpl<llvm::Value*>::Visit(cinn::ir::Expr const*)
27  cinn::backends::CodeGenX86::Visit(cinn::ir::For const*)
28  cinn::backends::CodeGenLLVM::CreateSerialFor(cinn::ir::For const*, int)
29  cinn::ir::IRVisitorRequireReImpl<llvm::Value*>::Visit(cinn::ir::Expr const*)
30  cinn::backends::CodeGenLLVM::Visit(cinn::ir::Block const*)
31  cinn::ir::IRVisitorRequireReImpl<llvm::Value*>::Visit(cinn::ir::Expr const*)
32  cinn::backends::CodeGenLLVM::Visit(cinn::ir::Store const*)
33  cinn::ir::IRVisitorRequireReImpl<llvm::Value*>::Visit(cinn::ir::Expr const*)
34  cinn::backends::CodeGenLLVM::Visit(cinn::ir::Select const*)
35  cinn::ir::IRVisitorRequireReImpl<llvm::Value*>::Visit(cinn::ir::Expr const*)
36  cinn::backends::CodeGenLLVM::Visit(cinn::ir::GE const*)
37  cinn::ir::IRVisitorRequireReImpl<llvm::Value*>::Visit(cinn::ir::Expr const*)
38  cinn::backends::CodeGenLLVM::Visit(cinn::ir::Add const*)
39  cinn::backends::CodeGenLLVM::EmitBinaryOp(llvm::Value*, llvm::Value*, char, bool, bool)
40  common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
41  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
InvalidArgumentError: the types of operands of binary operation are mismatch
  [Hint: Expected lhs->getType() == rhs->getType(), but received lhs->getType():0x64e1df48 != rhs->getType():0x64e1df30.] (at ../paddle/cinn/backends/llvm/codegen_llvm.cc:212)
[paddle error] paddle.Tensor.tril(Tensor([2, 2],"float32"), -1, ) 
 In transformed code:


    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 715, in __call__
	attrs = self._prepare_attributes(in_sot_mode=False)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 1104, in _prepare_attributes
	self.program.forward_program,
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 921, in program
	return self.train_program
    File "/usr/lib/python3.9/functools.py", line 993, in __get__
	val = self.func(instance)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 937, in train_program
	return self._create_program()
    File "/usr/local/lib/python3.9/dist-packages/decorator.py", line 232, in fun
	return caller(func, *(extras + args), **kw)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/wrapped_decorator.py", line 40, in __impl__
	return wrapped_func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/base/dygraph/base.py", line 101, in __impl__
	return func(*args, **kwargs)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 903, in _create_program
	train_program.apply_pir_program_pass(pass_fn)
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 351, in apply_pir_program_pass
	self.forward_program, self.backward_program = pass_fn(
    File "/usr/local/lib/python3.9/dist-packages/paddle/jit/dy2static/pir_partial_program.py", line 892, in pass_fn
	paddle.base.libpaddle.pir.apply_cinn_pass(forward_program)

    SystemError: 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   cinn::dialect::ir::ApplyCinnPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&, bool)
1   cinn::dialect::ir::ApplyCinnLowerPass(pir::Program*, std::function<std::shared_ptr<pir::PassManager> ()> const&)
2   pir::PassManager::Run(pir::Program*)
3   pir::PassManager::Run(pir::Operation*)
4   pir::detail::PassAdaptor::RunPipeline(pir::PassManager const&, pir::Operation*, pir::AnalysisManager, unsigned char, bool)
5   cinn::dialect::ir::details::LowerCinnFusionOpPass::CanApplyOn(pir::Operation*) const
6   cinn::dialect::ir::details::FusionOpAnalysis::PreCompileGroup()
7   cinn::hlir::framework::PirCompiler::Build(std::vector<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup>, std::allocator<std::shared_ptr<cinn::hlir::framework::pir::OpLoweringGroup> > > const&)
8   common::enforce::EnforceNotMet::EnforceNotMet(common::ErrorSummary const&, char const*, int)
9   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
FatalError: Parallel compile Paddle enforce error (at ../paddle/cinn/utils/multi_threading.cc:103)


