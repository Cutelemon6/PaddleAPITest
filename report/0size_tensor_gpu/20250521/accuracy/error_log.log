2025-05-21 22:07:06.509543 GPU 1 69596 test begin: paddle.Tensor.amax(Tensor([0, 2, 4, 5],"float32"), axis=-1, keepdim=True, )
[paddle error] paddle.Tensor.amax(Tensor([0, 2, 4, 5],"float32"), axis=-1, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:07.962947 GPU 1 69600 test begin: paddle.Tensor.amax(Tensor([0, 2, 5, 4],"float32"), axis=2, keepdim=True, )
[paddle error] paddle.Tensor.amax(Tensor([0, 2, 5, 4],"float32"), axis=2, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:08.135264 GPU 1 69597 test begin: paddle.Tensor.amax(Tensor([0, 2, 5, 4],"float32"), axis=tuple(1,2,), keepdim=True, )
[paddle error] paddle.Tensor.amax(Tensor([0, 2, 5, 4],"float32"), axis=tuple(1,2,), keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:08.317405 GPU 1 69598 test begin: paddle.Tensor.amax(Tensor([3, 0, 4, 5],"float32"), axis=-1, keepdim=True, )
[paddle error] paddle.Tensor.amax(Tensor([3, 0, 4, 5],"float32"), axis=-1, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:08.584647 GPU 1 69603 test begin: paddle.Tensor.amax(Tensor([3, 0, 5, 4],"float32"), axis=2, keepdim=True, )
[paddle error] paddle.Tensor.amax(Tensor([3, 0, 5, 4],"float32"), axis=2, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:08.685731 GPU 1 69599 test begin: paddle.Tensor.amax(Tensor([3, 2, 0, 5],"float32"), axis=-1, keepdim=True, )
[paddle error] paddle.Tensor.amax(Tensor([3, 2, 0, 5],"float32"), axis=-1, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:09.181284 GPU 1 69608 test begin: paddle.Tensor.amax(Tensor([3, 2, 5, 0],"float32"), axis=2, keepdim=True, )
[paddle error] paddle.Tensor.amax(Tensor([3, 2, 5, 0],"float32"), axis=2, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:09.197579 GPU 1 69602 test begin: paddle.Tensor.amax(Tensor([3, 2, 5, 0],"float32"), axis=tuple(1,2,), keepdim=True, )
[paddle error] paddle.Tensor.amax(Tensor([3, 2, 5, 0],"float32"), axis=tuple(1,2,), keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:09.316424 GPU 1 69612 test begin: paddle.Tensor.amin(Tensor([0, 2, 4, 5],"float32"), axis=-1, keepdim=True, )
[paddle error] paddle.Tensor.amin(Tensor([0, 2, 4, 5],"float32"), axis=-1, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:09.374052 GPU 1 69609 test begin: paddle.Tensor.amin(Tensor([0, 2, 5, 4],"float32"), axis=2, keepdim=True, )
[paddle error] paddle.Tensor.amin(Tensor([0, 2, 5, 4],"float32"), axis=2, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:09.382051 GPU 1 69611 test begin: paddle.Tensor.amin(Tensor([0, 2, 5, 4],"float32"), axis=tuple(1,2,), keepdim=True, )
[paddle error] paddle.Tensor.amin(Tensor([0, 2, 5, 4],"float32"), axis=tuple(1,2,), keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:09.383769 GPU 1 69621 test begin: paddle.Tensor.amin(Tensor([3, 0, 4, 5],"float32"), axis=-1, keepdim=True, )
[paddle error] paddle.Tensor.amin(Tensor([3, 0, 4, 5],"float32"), axis=-1, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:09.827611 GPU 1 69618 test begin: paddle.Tensor.amin(Tensor([3, 0, 5, 4],"float32"), axis=2, keepdim=True, )
[paddle error] paddle.Tensor.amin(Tensor([3, 0, 5, 4],"float32"), axis=2, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:09.945367 GPU 1 69606 test begin: paddle.Tensor.amin(Tensor([3, 2, 0, 5],"float32"), axis=-1, keepdim=True, )
[paddle error] paddle.Tensor.amin(Tensor([3, 2, 0, 5],"float32"), axis=-1, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:10.297482 GPU 1 69604 test begin: paddle.Tensor.amin(Tensor([3, 2, 5, 0],"float32"), axis=2, keepdim=True, )
[paddle error] paddle.Tensor.amin(Tensor([3, 2, 5, 0],"float32"), axis=2, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:10.319913 GPU 1 69610 test begin: paddle.Tensor.amin(Tensor([3, 2, 5, 0],"float32"), axis=tuple(1,2,), keepdim=True, )
[paddle error] paddle.Tensor.amin(Tensor([3, 2, 5, 0],"float32"), axis=tuple(1,2,), keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:10.570234 GPU 1 69601 test begin: paddle.Tensor.argmax(Tensor([0, 1, 10285],"float32"), axis=-2, )
[paddle error] paddle.Tensor.argmax(Tensor([0, 1, 10285],"float32"), axis=-2, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:10.760315 GPU 1 69619 test begin: paddle.Tensor.argmax(Tensor([0, 1, 24276],"float32"), axis=-2, )
[paddle error] paddle.Tensor.argmax(Tensor([0, 1, 24276],"float32"), axis=-2, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:10.902651 GPU 1 69616 test begin: paddle.Tensor.argmax(Tensor([0, 100, 8000],"float32"), axis=2, )
[paddle error] paddle.Tensor.argmax(Tensor([0, 100, 8000],"float32"), axis=2, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:10.915164 GPU 1 69615 test begin: paddle.Tensor.argmax(Tensor([0, 101, 8000],"float32"), axis=2, )
[paddle error] paddle.Tensor.argmax(Tensor([0, 101, 8000],"float32"), axis=2, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:10.973363 GPU 1 69613 test begin: paddle.Tensor.argmax(Tensor([0, 10],"float32"), axis=1, )
[paddle error] paddle.Tensor.argmax(Tensor([0, 10],"float32"), axis=1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:10.977868 GPU 1 69607 test begin: paddle.Tensor.argmax(Tensor([0, 157920, 2],"float32"), axis=-1, )
[paddle error] paddle.Tensor.argmax(Tensor([0, 157920, 2],"float32"), axis=-1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:11.068829 GPU 1 69629 test begin: paddle.Tensor.argmax(Tensor([0, 3, 3],"float32"), 1, )
[paddle error] paddle.Tensor.argmax(Tensor([0, 3, 3],"float32"), 1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:11.078351 GPU 1 69605 test begin: paddle.Tensor.argmax(Tensor([0, 3],"float32"), 1, )
[paddle error] paddle.Tensor.argmax(Tensor([0, 3],"float32"), 1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:11.560724 GPU 1 69617 test begin: paddle.Tensor.argmax(Tensor([0, 4],"float32"), axis=-1, )
[paddle error] paddle.Tensor.argmax(Tensor([0, 4],"float32"), axis=-1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:11.677113 GPU 1 69614 test begin: paddle.Tensor.argmax(Tensor([0, 77],"int64"), axis=-1, )
[paddle error] paddle.Tensor.argmax(Tensor([0, 77],"int64"), axis=-1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:27.501849 GPU 1 69596 test begin: paddle.Tensor.argmax(Tensor([0, 7],"int32"), -1, )
[paddle error] paddle.Tensor.argmax(Tensor([0, 7],"int32"), -1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:27.617522 GPU 1 69596 test begin: paddle.Tensor.argmax(Tensor([0, 90, 22400],"float32"), axis=1, )
[paddle error] paddle.Tensor.argmax(Tensor([0, 90, 22400],"float32"), axis=1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:27.770329 GPU 1 69596 test begin: paddle.Tensor.argmax(Tensor([1, 1, 0],"float32"), axis=-2, )
[paddle error] paddle.Tensor.argmax(Tensor([1, 1, 0],"float32"), axis=-2, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:27.937159 GPU 1 69596 test begin: paddle.Tensor.argmax(Tensor([13, 3, 0],"float32"), 1, )
[paddle error] paddle.Tensor.argmax(Tensor([13, 3, 0],"float32"), 1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:28.058075 GPU 1 69596 test begin: paddle.Tensor.argmax(Tensor([30, 0, 8000],"float32"), axis=2, )
[paddle error] paddle.Tensor.argmax(Tensor([30, 0, 8000],"float32"), axis=2, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:28.172298 GPU 1 69596 test begin: paddle.Tensor.argmax(Tensor([4, 0, 2],"float32"), axis=-1, )
[paddle error] paddle.Tensor.argmax(Tensor([4, 0, 2],"float32"), axis=-1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:28.316292 GPU 1 69596 test begin: paddle.Tensor.argmax(Tensor([4, 90, 0],"float32"), axis=1, )
[paddle error] paddle.Tensor.argmax(Tensor([4, 90, 0],"float32"), axis=1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:28.458949 GPU 1 69596 test begin: paddle.Tensor.bmm(Tensor([0, 108472, 3],"float32"), Tensor([0, 3, 2],"float32"), )
W0521 22:07:28.592558 69596 backward.cc:437] While running Node (BmmGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.bmm(Tensor([0, 108472, 3],"float32"), Tensor([0, 3, 2],"float32"), ) 
 (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 24, memory's size is 0.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):24 > memory_size():0.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)


2025-05-21 22:07:28.598849 GPU 1 69596 test begin: paddle.Tensor.bmm(Tensor([0, 1156, 3],"float32"), Tensor([0, 3, 2],"float32"), )
W0521 22:07:28.954368 69596 backward.cc:437] While running Node (BmmGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.bmm(Tensor([0, 1156, 3],"float32"), Tensor([0, 3, 2],"float32"), ) 
 (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 24, memory's size is 0.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):24 > memory_size():0.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)


2025-05-21 22:07:28.959975 GPU 1 69596 test begin: paddle.Tensor.bmm(Tensor([1, 108472, 3],"float32"), Tensor([1, 3, 0],"float32"), )
W0521 22:07:35.474337 69596 backward.cc:437] While running Node (BmmGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.bmm(Tensor([1, 108472, 3],"float32"), Tensor([1, 3, 0],"float32"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:76)


2025-05-21 22:07:29.119014 GPU 1 69597 test begin: paddle.Tensor.bmm(Tensor([1, 1156, 3],"float32"), Tensor([1, 3, 0],"float32"), )
W0521 22:07:35.590328 69597 backward.cc:437] While running Node (BmmGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.bmm(Tensor([1, 1156, 3],"float32"), Tensor([1, 3, 0],"float32"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:76)


2025-05-21 22:07:29.180919 GPU 1 69598 test begin: paddle.Tensor.cholesky_solve(x=Tensor([0, 2, 4, 3],"float64"), y=Tensor([0, 2, 4, 4],"float64"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/autograd/graph.py:823: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:180.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[paddle error] paddle.Tensor.cholesky_solve(x=Tensor([0, 2, 4, 3],"float64"), y=Tensor([0, 2, 4, 4],"float64"), ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:29.780749 GPU 1 69603 test begin: paddle.Tensor.cholesky_solve(x=Tensor([0, 2, 4, 3],"float64"), y=Tensor([0, 2, 4, 4],"float64"), upper=True, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/autograd/graph.py:823: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:180.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[paddle error] paddle.Tensor.cholesky_solve(x=Tensor([0, 2, 4, 3],"float64"), y=Tensor([0, 2, 4, 4],"float64"), upper=True, ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:31.339431 GPU 1 69600 test begin: paddle.Tensor.cholesky_solve(x=Tensor([0, 4, 3],"float64"), y=Tensor([0, 4, 4],"float64"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/autograd/graph.py:823: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:180.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[paddle error] paddle.Tensor.cholesky_solve(x=Tensor([0, 4, 3],"float64"), y=Tensor([0, 4, 4],"float64"), ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:31.812033 GPU 1 69599 test begin: paddle.Tensor.cholesky_solve(x=Tensor([4, 0],"float32"), y=Tensor([4, 4],"float32"), )
[paddle error] paddle.Tensor.cholesky_solve(x=Tensor([4, 0],"float32"), y=Tensor([4, 4],"float32"), ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:32.079547 GPU 1 69608 test begin: paddle.Tensor.cholesky_solve(x=Tensor([4, 0],"float64"), y=Tensor([4, 4],"float64"), )
[paddle error] paddle.Tensor.cholesky_solve(x=Tensor([4, 0],"float64"), y=Tensor([4, 4],"float64"), ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:32.672400 GPU 1 69602 test begin: paddle.Tensor.cholesky_solve(x=Tensor([5, 0, 4, 3],"float64"), y=Tensor([5, 0, 4, 4],"float64"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/autograd/graph.py:823: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:180.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[paddle error] paddle.Tensor.cholesky_solve(x=Tensor([5, 0, 4, 3],"float64"), y=Tensor([5, 0, 4, 4],"float64"), ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:32.792039 GPU 1 69609 test begin: paddle.Tensor.cholesky_solve(x=Tensor([5, 0, 4, 3],"float64"), y=Tensor([5, 0, 4, 4],"float64"), upper=True, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/autograd/graph.py:823: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:180.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[paddle error] paddle.Tensor.cholesky_solve(x=Tensor([5, 0, 4, 3],"float64"), y=Tensor([5, 0, 4, 4],"float64"), upper=True, ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:32.922769 GPU 1 69612 test begin: paddle.Tensor.cholesky_solve(x=Tensor([5, 2, 4, 0],"float64"), y=Tensor([5, 2, 4, 4],"float64"), )
[paddle error] paddle.Tensor.cholesky_solve(x=Tensor([5, 2, 4, 0],"float64"), y=Tensor([5, 2, 4, 4],"float64"), ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:33.038184 GPU 1 69621 test begin: paddle.Tensor.cholesky_solve(x=Tensor([5, 2, 4, 0],"float64"), y=Tensor([5, 2, 4, 4],"float64"), upper=True, )
[paddle error] paddle.Tensor.cholesky_solve(x=Tensor([5, 2, 4, 0],"float64"), y=Tensor([5, 2, 4, 4],"float64"), upper=True, ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:33.067251 GPU 1 69606 test begin: paddle.Tensor.cholesky_solve(x=Tensor([5, 4, 0],"float64"), y=Tensor([5, 4, 4],"float64"), )
[paddle error] paddle.Tensor.cholesky_solve(x=Tensor([5, 4, 0],"float64"), y=Tensor([5, 4, 4],"float64"), ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:33.772111 GPU 1 69611 test begin: paddle.Tensor.cumsum(Tensor([0, 10, 8],"float32"), 1, )
[cuda error] paddle.Tensor.cumsum(Tensor([0, 10, 8],"float32"), 1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:33.945527 GPU 1 69616 test begin: paddle.Tensor.cumsum(Tensor([0, 10, 8],"float32"), 2, )
[cuda error] paddle.Tensor.cumsum(Tensor([0, 10, 8],"float32"), 2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:34.174274 GPU 1 69611 test begin: paddle.Tensor.cumsum(Tensor([0, 100],"int64"), axis=1, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.cumsum(Tensor([0, 100],"int64"), axis=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:34.586508 GPU 1 69601 test begin: paddle.Tensor.cumsum(Tensor([0, 10],"int64"), axis=1, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.cumsum(Tensor([0, 10],"int64"), axis=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:34.586719 GPU 1 69604 test begin: paddle.Tensor.cumsum(Tensor([0, 12, 9],"float32"), 1, )
[cuda error] paddle.Tensor.cumsum(Tensor([0, 12, 9],"float32"), 1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:34.676921 GPU 1 69616 test begin: paddle.Tensor.cumsum(Tensor([0, 12, 9],"float32"), 2, )
[cuda error] paddle.Tensor.cumsum(Tensor([0, 12, 9],"float32"), 2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:34.717470 GPU 1 69611 test begin: paddle.Tensor.cumsum(Tensor([0, 14],"int32"), -1, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.cumsum(Tensor([0, 14],"int32"), -1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:34.977715 GPU 1 69604 test begin: paddle.Tensor.cumsum(Tensor([0, 1],"float32"), axis=-1, )
[cuda error] paddle.Tensor.cumsum(Tensor([0, 1],"float32"), axis=-1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:35.213237 GPU 1 69611 test begin: paddle.Tensor.cumsum(Tensor([0, 2],"float32"), axis=-1, )
[cuda error] paddle.Tensor.cumsum(Tensor([0, 2],"float32"), axis=-1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:35.244947 GPU 1 69601 test begin: paddle.Tensor.cumsum(Tensor([0, 4, 2],"int64"), axis=1, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.cumsum(Tensor([0, 4, 2],"int64"), axis=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:35.329445 GPU 1 69616 test begin: paddle.Tensor.cumsum(Tensor([0, 4, 2],"int64"), axis=2, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.cumsum(Tensor([0, 4, 2],"int64"), axis=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:35.378148 GPU 1 69604 test begin: paddle.Tensor.cumsum(Tensor([1, 0, 8],"float32"), 2, )
[cuda error] paddle.Tensor.cumsum(Tensor([1, 0, 8],"float32"), 2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:35.438699 GPU 1 69616 test begin: paddle.Tensor.cumsum(Tensor([1, 0, 9],"float32"), 2, )
[cuda error] paddle.Tensor.cumsum(Tensor([1, 0, 9],"float32"), 2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:35.488504 GPU 1 69601 test begin: paddle.Tensor.cumsum(Tensor([1, 10, 0],"float32"), 1, )
[cuda error] paddle.Tensor.cumsum(Tensor([1, 10, 0],"float32"), 1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:35.491342 GPU 1 69611 test begin: paddle.Tensor.cumsum(Tensor([1, 12, 0],"float32"), 1, )
[cuda error] paddle.Tensor.cumsum(Tensor([1, 12, 0],"float32"), 1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:35.499976 GPU 1 69596 test begin: paddle.Tensor.cumsum(Tensor([3, 0, 2],"int64"), axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.cumsum(Tensor([3, 0, 2],"int64"), axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:35.567323 GPU 1 69604 test begin: paddle.Tensor.cumsum(Tensor([3, 0, 2],"int64"), axis=2, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.cumsum(Tensor([3, 0, 2],"int64"), axis=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:35.594415 GPU 1 69597 test begin: paddle.Tensor.cumsum(Tensor([3, 0],"int64"), axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.cumsum(Tensor([3, 0],"int64"), axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:35.653226 GPU 1 69607 test begin: paddle.Tensor.cumsum(Tensor([3, 4, 0],"int64"), axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.cumsum(Tensor([3, 4, 0],"int64"), axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:35.703173 GPU 1 69611 test begin: paddle.Tensor.cumsum(Tensor([3, 4, 0],"int64"), axis=1, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.cumsum(Tensor([3, 4, 0],"int64"), axis=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:35.703962 GPU 1 69604 test begin: paddle.Tensor.cumsum(Tensor([5, 0],"int64"), axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.cumsum(Tensor([5, 0],"int64"), axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:35.704640 GPU 1 69596 test begin: paddle.Tensor.diag_embed(Tensor([0, 1, 2],"float32"), )
[cuda error] paddle.Tensor.diag_embed(Tensor([0, 1, 2],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:35.734629 GPU 1 69616 test begin: paddle.Tensor.diag_embed(Tensor([1, 0, 2],"float32"), )
[cuda error] paddle.Tensor.diag_embed(Tensor([1, 0, 2],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:35.882205 GPU 1 69601 test begin: paddle.Tensor.diag_embed(Tensor([1, 1, 0],"float32"), )
[cuda error] paddle.Tensor.diag_embed(Tensor([1, 1, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:35.885214 GPU 1 69596 test begin: paddle.Tensor.diagonal(Tensor([0, 2],"float32"), axis1=-2, axis2=-1, )
W0521 22:07:36.028092 69596 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.diagonal(Tensor([0, 2],"float32"), axis1=-2, axis2=-1, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:35.891006 GPU 1 69597 test begin: paddle.Tensor.diagonal(Tensor([0, 3],"float64"), axis1=-2, axis2=-1, )
W0521 22:07:36.178346 69597 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.diagonal(Tensor([0, 3],"float64"), axis1=-2, axis2=-1, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:35.939659 GPU 1 69619 test begin: paddle.Tensor.diagonal(Tensor([2, 0],"float32"), axis1=-2, axis2=-1, )
W0521 22:07:36.606710 69619 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.diagonal(Tensor([2, 0],"float32"), axis1=-2, axis2=-1, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:35.969053 GPU 1 69611 test begin: paddle.Tensor.diagonal(Tensor([3, 0],"float64"), axis1=-2, axis2=-1, )
W0521 22:07:36.288512 69611 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.diagonal(Tensor([3, 0],"float64"), axis1=-2, axis2=-1, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:36.013499 GPU 1 69604 test begin: paddle.Tensor.expand_as(Tensor([0, 1, 1, 1],"float32"), Tensor([0, 3, 28, 28],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([0, 1, 1, 1],"float32"), Tensor([0, 3, 28, 28],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:36.024427 GPU 1 69613 test begin: paddle.Tensor.expand_as(Tensor([0, 1, 1, 1],"float32"), Tensor([0, 3, 280, 350],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([0, 1, 1, 1],"float32"), Tensor([0, 3, 280, 350],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:36.029006 GPU 1 69596 test begin: paddle.Tensor.expand_as(Tensor([0, 1, 32],"float32"), Tensor([0, 4, 32],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([0, 1, 32],"float32"), Tensor([0, 4, 32],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:36.075551 GPU 1 69615 test begin: paddle.Tensor.expand_as(Tensor([0, 128],"int32"), Tensor([0, 128],"int64"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.expand_as(Tensor([0, 128],"int32"), Tensor([0, 128],"int64"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:36.093810 GPU 1 69616 test begin: paddle.Tensor.expand_as(Tensor([0, 1],"int32"), Tensor([0, 1],"int64"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.expand_as(Tensor([0, 1],"int32"), Tensor([0, 1],"int64"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:36.179595 GPU 1 69597 test begin: paddle.Tensor.expand_as(Tensor([1, 0, 1, 1],"float32"), Tensor([1, 0, 28, 28],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([1, 0, 1, 1],"float32"), Tensor([1, 0, 28, 28],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:36.186510 GPU 1 69596 test begin: paddle.Tensor.expand_as(Tensor([1, 0, 1, 1],"float32"), Tensor([1, 0, 280, 350],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([1, 0, 1, 1],"float32"), Tensor([1, 0, 280, 350],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:36.192235 GPU 1 69601 test begin: paddle.Tensor.expand_as(Tensor([1, 0],"int32"), Tensor([5, 0],"int64"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.expand_as(Tensor([1, 0],"int32"), Tensor([5, 0],"int64"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:36.210874 GPU 1 69605 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 0, 1],"float32"), Tensor([1, 3, 0, 28],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([1, 1, 0, 1],"float32"), Tensor([1, 3, 0, 28],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:36.289327 GPU 1 69611 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 0, 1],"float32"), Tensor([1, 3, 0, 350],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([1, 1, 0, 1],"float32"), Tensor([1, 3, 0, 350],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:36.311610 GPU 1 69607 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 0],"float32"), Tensor([1, 3, 28, 0],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([1, 1, 1, 0],"float32"), Tensor([1, 3, 28, 0],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:36.313257 GPU 1 69604 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 0],"float32"), Tensor([1, 3, 280, 0],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([1, 1, 1, 0],"float32"), Tensor([1, 3, 280, 0],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:36.342853 GPU 1 69596 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([0, 3, 28, 28],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([0, 3, 28, 28],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:36.382566 GPU 1 69616 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([0, 3, 280, 350],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([0, 3, 280, 350],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:36.416911 GPU 1 69618 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 0, 28, 28],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 0, 28, 28],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:36.454920 GPU 1 69604 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 0, 280, 350],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 0, 280, 350],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:36.456517 GPU 1 69601 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 0, 28],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 0, 28],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:36.516048 GPU 1 69611 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 0, 350],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 0, 350],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:36.527928 GPU 1 69597 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 28, 0],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 28, 0],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:36.529749 GPU 1 69596 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 280, 0],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 280, 0],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:36.568748 GPU 1 69616 test begin: paddle.Tensor.expand_as(Tensor([1, 128],"int32"), Tensor([0, 128],"int64"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.expand_as(Tensor([1, 128],"int32"), Tensor([0, 128],"int64"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:36.598407 GPU 1 69610 test begin: paddle.Tensor.expand_as(Tensor([1, 1],"int32"), Tensor([0, 1],"int64"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.expand_as(Tensor([1, 1],"int32"), Tensor([0, 1],"int64"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:36.607560 GPU 1 69619 test begin: paddle.Tensor.expand_as(Tensor([1, 1],"int32"), Tensor([5, 0],"int64"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.expand_as(Tensor([1, 1],"int32"), Tensor([5, 0],"int64"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:36.632279 GPU 1 69615 test begin: paddle.Tensor.expand_as(Tensor([2, 0, 32],"float32"), Tensor([2, 0, 32],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([2, 0, 32],"float32"), Tensor([2, 0, 32],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:36.656671 GPU 1 69614 test begin: paddle.Tensor.expand_as(Tensor([2, 1, 0],"float32"), Tensor([2, 4, 0],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([2, 1, 0],"float32"), Tensor([2, 4, 0],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:36.662791 GPU 1 69605 test begin: paddle.Tensor.expand_as(Tensor([2, 1, 32],"float32"), Tensor([2, 0, 32],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([2, 1, 32],"float32"), Tensor([2, 0, 32],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:36.664415 GPU 1 69607 test begin: paddle.Tensor.fill_diagonal_(Tensor([0, 128],"float32"), 0, wrap=False, )
[cuda error] paddle.Tensor.fill_diagonal_(Tensor([0, 128],"float32"), 0, wrap=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:36.680654 GPU 1 69613 test begin: paddle.Tensor.fill_diagonal_(Tensor([128, 0],"float32"), 0, wrap=False, )
[cuda error] paddle.Tensor.fill_diagonal_(Tensor([128, 0],"float32"), 0, wrap=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:36.692396 GPU 1 69618 test begin: paddle.Tensor.flip(Tensor([0, 14],"int32"), list[-1,], )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.flip(Tensor([0, 14],"int32"), list[-1,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:36.703072 GPU 1 69596 test begin: paddle.Tensor.flip(Tensor([0, 224, 224],"float32"), axis=list[-1,], )
[cuda error] paddle.Tensor.flip(Tensor([0, 224, 224],"float32"), axis=list[-1,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:36.722988 GPU 1 69616 test begin: paddle.Tensor.flip(Tensor([0, 280, 350],"float32"), axis=list[-1,], )
[cuda error] paddle.Tensor.flip(Tensor([0, 280, 350],"float32"), axis=list[-1,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:36.776195 GPU 1 69604 test begin: paddle.Tensor.flip(Tensor([0, 280, 350],"float32"), axis=list[-2,], )
[cuda error] paddle.Tensor.flip(Tensor([0, 280, 350],"float32"), axis=list[-2,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:36.777321 GPU 1 69611 test begin: paddle.Tensor.flip(Tensor([0, 2],"int64"), list[1,], )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.flip(Tensor([0, 2],"int64"), list[1,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:36.779762 GPU 1 69601 test begin: paddle.Tensor.flip(Tensor([0, 400, 300],"float32"), axis=list[-2,], )
[cuda error] paddle.Tensor.flip(Tensor([0, 400, 300],"float32"), axis=list[-2,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:36.810257 GPU 1 69610 test begin: paddle.Tensor.flip(Tensor([13, 0],"int32"), list[-1,], )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.flip(Tensor([13, 0],"int32"), list[-1,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:36.838838 GPU 1 69618 test begin: paddle.Tensor.flip(Tensor([3, 0, 224],"float32"), axis=list[-1,], )
[cuda error] paddle.Tensor.flip(Tensor([3, 0, 224],"float32"), axis=list[-1,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:36.847606 GPU 1 69597 test begin: paddle.Tensor.flip(Tensor([3, 0, 300],"float32"), axis=list[-2,], )
[cuda error] paddle.Tensor.flip(Tensor([3, 0, 300],"float32"), axis=list[-2,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:36.866165 GPU 1 69619 test begin: paddle.Tensor.flip(Tensor([3, 0, 350],"float32"), axis=list[-1,], )
[cuda error] paddle.Tensor.flip(Tensor([3, 0, 350],"float32"), axis=list[-1,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:36.887580 GPU 1 69596 test begin: paddle.Tensor.flip(Tensor([3, 0, 350],"float32"), axis=list[-2,], )
[cuda error] paddle.Tensor.flip(Tensor([3, 0, 350],"float32"), axis=list[-2,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:36.904791 GPU 1 69615 test begin: paddle.Tensor.flip(Tensor([3, 224, 0],"float32"), axis=list[-1,], )
[cuda error] paddle.Tensor.flip(Tensor([3, 224, 0],"float32"), axis=list[-1,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:36.934389 GPU 1 69613 test begin: paddle.Tensor.flip(Tensor([3, 280, 0],"float32"), axis=list[-1,], )
[cuda error] paddle.Tensor.flip(Tensor([3, 280, 0],"float32"), axis=list[-1,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:36.951608 GPU 1 69610 test begin: paddle.Tensor.flip(Tensor([3, 280, 0],"float32"), axis=list[-2,], )
[cuda error] paddle.Tensor.flip(Tensor([3, 280, 0],"float32"), axis=list[-2,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:36.961497 GPU 1 69603 test begin: paddle.Tensor.flip(Tensor([3, 400, 0],"float32"), axis=list[-2,], )
[cuda error] paddle.Tensor.flip(Tensor([3, 400, 0],"float32"), axis=list[-2,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:36.964263 GPU 1 69607 test begin: paddle.Tensor.flip(Tensor([4, 0],"int64"), list[1,], )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.flip(Tensor([4, 0],"int64"), list[1,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:36.980189 GPU 1 69618 test begin: paddle.Tensor.flip(Tensor([5, 0],"int64"), list[1,], )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.flip(Tensor([5, 0],"int64"), list[1,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:36.987655 GPU 1 69617 test begin: paddle.Tensor.inner(x=Tensor([0],"float64"), y=Tensor([0],"float64"), )
[paddle error] paddle.Tensor.inner(x=Tensor([0],"float64"), y=Tensor([0],"float64"), ) 
 (InvalidArgument) can not reshape 0 to -1, 0, because the unspecified dimension 0 can be any number and is ambiguous
  [Hint: Expected unk_dim_idx == -1, but received unk_dim_idx:0 != -1:-1.] (at ../paddle/phi/infermeta/unary.cc:2209)


2025-05-21 22:07:36.988694 GPU 1 69611 test begin: paddle.Tensor.inner(x=Tensor([2, 5, 3, 0],"float64"), y=Tensor([3, 2, 5, 0],"float64"), )
[paddle error] paddle.Tensor.inner(x=Tensor([2, 5, 3, 0],"float64"), y=Tensor([3, 2, 5, 0],"float64"), ) 
 (InvalidArgument) can not reshape 2, 5, 3, 0 to -1, 0, because the unspecified dimension 0 can be any number and is ambiguous
  [Hint: Expected unk_dim_idx == -1, but received unk_dim_idx:0 != -1:-1.] (at ../paddle/phi/infermeta/unary.cc:2209)


2025-05-21 22:07:36.993287 GPU 1 69605 test begin: paddle.Tensor.inner(x=Tensor([2, 5, 3, 4],"float64"), y=Tensor([0, 2, 5, 4],"float64"), )
W0521 22:07:42.491957 69605 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.inner(x=Tensor([2, 5, 3, 4],"float64"), y=Tensor([0, 2, 5, 4],"float64"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:07:37.017862 GPU 1 69616 test begin: paddle.Tensor.inner(x=Tensor([2, 5, 3, 4],"float64"), y=Tensor([3, 0, 5, 4],"float64"), )
W0521 22:07:42.326774 69616 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.inner(x=Tensor([2, 5, 3, 4],"float64"), y=Tensor([3, 0, 5, 4],"float64"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:07:37.023331 GPU 1 69598 test begin: paddle.Tensor.inner(x=Tensor([2, 5, 3, 4],"float64"), y=Tensor([3, 2, 0, 4],"float64"), )
W0521 22:07:38.851033 69598 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.inner(x=Tensor([2, 5, 3, 4],"float64"), y=Tensor([3, 2, 0, 4],"float64"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:07:37.027566 GPU 1 69596 test begin: paddle.Tensor.inner(x=Tensor([3, 0],"float64"), y=Tensor([5, 0],"float64"), )
[paddle error] paddle.Tensor.inner(x=Tensor([3, 0],"float64"), y=Tensor([5, 0],"float64"), ) 
 (InvalidArgument) can not reshape 3, 0 to -1, 0, because the unspecified dimension 0 can be any number and is ambiguous
  [Hint: Expected unk_dim_idx == -1, but received unk_dim_idx:0 != -1:-1.] (at ../paddle/phi/infermeta/unary.cc:2209)


2025-05-21 22:07:37.028276 GPU 1 69601 test begin: paddle.Tensor.inner(x=Tensor([3, 4],"float64"), y=Tensor([0, 2, 4],"float64"), )
W0521 22:07:42.426338 69601 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.inner(x=Tensor([3, 4],"float64"), y=Tensor([0, 2, 4],"float64"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:07:37.041267 GPU 1 69597 test begin: paddle.Tensor.inner(x=Tensor([3, 4],"float64"), y=Tensor([0, 2, 5, 4],"float64"), )
W0521 22:07:37.420451 69597 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.inner(x=Tensor([3, 4],"float64"), y=Tensor([0, 2, 5, 4],"float64"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:07:37.049781 GPU 1 69604 test begin: paddle.Tensor.inner(x=Tensor([3, 4],"float64"), y=Tensor([0, 4],"float64"), )
W0521 22:07:42.414310 69604 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.inner(x=Tensor([3, 4],"float64"), y=Tensor([0, 4],"float64"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:07:37.106455 GPU 1 69615 test begin: paddle.Tensor.inner(x=Tensor([3, 4],"float64"), y=Tensor([3, 0, 4],"float64"), )
W0521 22:07:42.415838 69615 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.inner(x=Tensor([3, 4],"float64"), y=Tensor([3, 0, 4],"float64"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:07:37.119146 GPU 1 69610 test begin: paddle.Tensor.inner(x=Tensor([3, 4],"float64"), y=Tensor([3, 0, 5, 4],"float64"), )
W0521 22:07:42.525305 69610 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.inner(x=Tensor([3, 4],"float64"), y=Tensor([3, 0, 5, 4],"float64"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:07:37.119908 GPU 1 69618 test begin: paddle.Tensor.inner(x=Tensor([3, 4],"float64"), y=Tensor([3, 2, 0, 4],"float64"), )
[paddle error] paddle.Tensor.inner(x=Tensor([3, 4],"float64"), y=Tensor([3, 2, 0, 4],"float64"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

W0521 22:07:42.414814 69618 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception

2025-05-21 22:07:37.154967 GPU 1 69613 test begin: paddle.Tensor.inner(x=Tensor([4, 0],"float32"), y=Tensor([4, 0],"float32"), )
[paddle error] paddle.Tensor.inner(x=Tensor([4, 0],"float32"), y=Tensor([4, 0],"float32"), ) 
 (InvalidArgument) can not reshape 4, 0 to -1, 0, because the unspecified dimension 0 can be any number and is ambiguous
  [Hint: Expected unk_dim_idx == -1, but received unk_dim_idx:0 != -1:-1.] (at ../paddle/phi/infermeta/unary.cc:2209)


2025-05-21 22:07:37.211702 GPU 1 69607 test begin: paddle.Tensor.inner(x=Tensor([4, 4],"float32"), y=Tensor([0, 4],"float32"), )
W0521 22:07:42.434170 69607 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.inner(x=Tensor([4, 4],"float32"), y=Tensor([0, 4],"float32"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:40)


2025-05-21 22:07:37.240017 GPU 1 69619 test begin: paddle.Tensor.inner(x=Tensor([5, 3, 0],"float64"), y=Tensor([2, 5, 0],"float64"), )
[paddle error] paddle.Tensor.inner(x=Tensor([5, 3, 0],"float64"), y=Tensor([2, 5, 0],"float64"), ) 
 (InvalidArgument) can not reshape 5, 3, 0 to -1, 0, because the unspecified dimension 0 can be any number and is ambiguous
  [Hint: Expected unk_dim_idx == -1, but received unk_dim_idx:0 != -1:-1.] (at ../paddle/phi/infermeta/unary.cc:2209)


2025-05-21 22:07:37.260161 GPU 1 69603 test begin: paddle.Tensor.inner(x=Tensor([5, 3, 4],"float64"), y=Tensor([0, 5, 4],"float64"), )
W0521 22:07:38.944144 69603 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.inner(x=Tensor([5, 3, 4],"float64"), y=Tensor([0, 5, 4],"float64"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:07:37.322652 GPU 1 69614 test begin: paddle.Tensor.inner(x=Tensor([5, 3, 4],"float64"), y=Tensor([2, 0, 4],"float64"), )
W0521 22:07:42.580139 69614 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.inner(x=Tensor([5, 3, 4],"float64"), y=Tensor([2, 0, 4],"float64"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:07:37.386963 GPU 1 69611 test begin: paddle.Tensor.isclose(x=Tensor([0, 4, 5],"float64"), y=Tensor([0, 4, 5],"float64"), )
[Pass] paddle.Tensor.isclose(x=Tensor([0, 4, 5],"float64"), y=Tensor([0, 4, 5],"float64"), )

2025-05-21 22:07:37.387039 GPU 1 69596 test begin: paddle.Tensor.isclose(x=Tensor([0],"float32"), y=Tensor([0],"float32"), )
[Pass] paddle.Tensor.isclose(x=Tensor([0],"float32"), y=Tensor([0],"float32"), )

2025-05-21 22:07:37.421284 GPU 1 69597 test begin: paddle.Tensor.isclose(x=Tensor([0],"float64"), y=Tensor([0],"float64"), )
[Pass] paddle.Tensor.isclose(x=Tensor([0],"float64"), y=Tensor([0],"float64"), )

2025-05-21 22:07:37.514274 GPU 1 69596 test begin: paddle.Tensor.isclose(x=Tensor([3, 0, 5],"float64"), y=Tensor([3, 0, 5],"float64"), )
[Pass] paddle.Tensor.isclose(x=Tensor([3, 0, 5],"float64"), y=Tensor([3, 0, 5],"float64"), )

2025-05-21 22:07:37.598914 GPU 1 69611 test begin: paddle.Tensor.isclose(x=Tensor([3, 4, 0],"float64"), y=Tensor([3, 4, 0],"float64"), )
[Pass] paddle.Tensor.isclose(x=Tensor([3, 4, 0],"float64"), y=Tensor([3, 4, 0],"float64"), )

2025-05-21 22:07:37.761633 GPU 1 69613 test begin: paddle.Tensor.kthvalue(Tensor([0, 200, 10],"float32"), k=200, axis=1, )
element 1 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.kthvalue(Tensor([0, 200, 10],"float32"), k=200, axis=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:37.784472 GPU 1 69597 test begin: paddle.Tensor.kthvalue(Tensor([2, 200, 0],"float32"), k=200, axis=1, )
element 1 of tensors does not require grad and does not have a grad_fn
 ** On entry to SgemmStridedBatched parameter number 8 had an illegal value
 ** On entry to DGEMM  parameter number 8 had an illegal value


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_kthvalue(_object*, _object*, _object*)
1   kthvalue_ad_func(paddle::Tensor const&, int, int, bool)
2   paddle::experimental::kthvalue(paddle::Tensor const&, int, int, bool)
3   void phi::KthvalueKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, int, int, bool, phi::DenseTensor*, phi::DenseTensor*)
4   phi::funcs::Transpose<phi::GPUContext, float, 3>::operator()(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*, std::vector<int, std::allocator<int> > const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836458 (unix time) try "date -d @1747836458" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f0196ddadaa) received by PID 69597 (TID 0x7f02a04e5740) from PID 18446744071945694634 ***]


2025-05-21 22:07:37.905027 GPU 1 69596 test begin: paddle.Tensor.lerp(x=Tensor([0, 5, 4, 3],"float64"), y=Tensor([0, 5, 4, 3],"float64"), weight=0.0, )
[paddle error] paddle.Tensor.lerp(x=Tensor([0, 5, 4, 3],"float64"), y=Tensor([0, 5, 4, 3],"float64"), weight=0.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:37.951186 GPU 1 69611 test begin: paddle.Tensor.lerp(x=Tensor([0, 5, 4, 3],"float64"), y=Tensor([0, 5, 4, 3],"float64"), weight=0.5, )
[paddle error] paddle.Tensor.lerp(x=Tensor([0, 5, 4, 3],"float64"), y=Tensor([0, 5, 4, 3],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:37.962172 GPU 1 69613 test begin: paddle.Tensor.lerp(x=Tensor([0, 5, 4, 3],"float64"), y=Tensor([0, 5, 4, 3],"float64"), weight=1.0, )
[paddle error] paddle.Tensor.lerp(x=Tensor([0, 5, 4, 3],"float64"), y=Tensor([0, 5, 4, 3],"float64"), weight=1.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:38.297586 GPU 1 69617 test begin: paddle.Tensor.lerp(x=Tensor([0, 5, 4],"float64"), y=Tensor([0, 5, 4],"float64"), weight=0.5, )
[paddle error] paddle.Tensor.lerp(x=Tensor([0, 5, 4],"float64"), y=Tensor([0, 5, 4],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:38.313199 GPU 1 69629 test begin: paddle.Tensor.lerp(x=Tensor([0, 5],"float64"), y=Tensor([0, 5],"float64"), weight=0.5, )
[paddle error] paddle.Tensor.lerp(x=Tensor([0, 5],"float64"), y=Tensor([0, 5],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:38.340484 GPU 1 69596 test begin: paddle.Tensor.lerp(x=Tensor([0, 5],"float64"), y=Tensor([1],"float64"), weight=0.2, )
[paddle error] paddle.Tensor.lerp(x=Tensor([0, 5],"float64"), y=Tensor([1],"float64"), weight=0.2, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:38.501983 GPU 1 69619 test begin: paddle.Tensor.lerp(x=Tensor([0],"float32"), y=Tensor([0],"float32"), weight=0.5, )
[paddle error] paddle.Tensor.lerp(x=Tensor([0],"float32"), y=Tensor([0],"float32"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:38.608811 GPU 1 69617 test begin: paddle.Tensor.lerp(x=Tensor([0],"float64"), y=Tensor([0],"float64"), weight=0.5, )
[paddle error] paddle.Tensor.lerp(x=Tensor([0],"float64"), y=Tensor([0],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:38.692119 GPU 1 69611 test begin: paddle.Tensor.lerp(x=Tensor([4, 0, 4, 3],"float64"), y=Tensor([4, 0, 4, 3],"float64"), weight=0.0, )
[paddle error] paddle.Tensor.lerp(x=Tensor([4, 0, 4, 3],"float64"), y=Tensor([4, 0, 4, 3],"float64"), weight=0.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:38.749717 GPU 1 69596 test begin: paddle.Tensor.lerp(x=Tensor([4, 0, 4, 3],"float64"), y=Tensor([4, 0, 4, 3],"float64"), weight=0.5, )
[paddle error] paddle.Tensor.lerp(x=Tensor([4, 0, 4, 3],"float64"), y=Tensor([4, 0, 4, 3],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:38.753101 GPU 1 69619 test begin: paddle.Tensor.lerp(x=Tensor([4, 0, 4, 3],"float64"), y=Tensor([4, 0, 4, 3],"float64"), weight=1.0, )
[paddle error] paddle.Tensor.lerp(x=Tensor([4, 0, 4, 3],"float64"), y=Tensor([4, 0, 4, 3],"float64"), weight=1.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:38.764745 GPU 1 69617 test begin: paddle.Tensor.lerp(x=Tensor([4, 0, 4],"float64"), y=Tensor([4, 0, 4],"float64"), weight=0.5, )
[paddle error] paddle.Tensor.lerp(x=Tensor([4, 0, 4],"float64"), y=Tensor([4, 0, 4],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:38.794833 GPU 1 69613 test begin: paddle.Tensor.lerp(x=Tensor([4, 0],"float64"), y=Tensor([1],"float64"), weight=0.2, )
[paddle error] paddle.Tensor.lerp(x=Tensor([4, 0],"float64"), y=Tensor([1],"float64"), weight=0.2, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:38.852104 GPU 1 69598 test begin: paddle.Tensor.lerp(x=Tensor([4, 0],"float64"), y=Tensor([4, 0],"float64"), weight=0.5, )
[paddle error] paddle.Tensor.lerp(x=Tensor([4, 0],"float64"), y=Tensor([4, 0],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:38.853911 GPU 1 69600 test begin: paddle.Tensor.lerp(x=Tensor([4, 5, 0, 3],"float64"), y=Tensor([4, 5, 0, 3],"float64"), weight=0.0, )
[paddle error] paddle.Tensor.lerp(x=Tensor([4, 5, 0, 3],"float64"), y=Tensor([4, 5, 0, 3],"float64"), weight=0.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:38.854784 GPU 1 69611 test begin: paddle.Tensor.lerp(x=Tensor([4, 5, 0, 3],"float64"), y=Tensor([4, 5, 0, 3],"float64"), weight=0.5, )
[paddle error] paddle.Tensor.lerp(x=Tensor([4, 5, 0, 3],"float64"), y=Tensor([4, 5, 0, 3],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:38.906169 GPU 1 69596 test begin: paddle.Tensor.lerp(x=Tensor([4, 5, 0, 3],"float64"), y=Tensor([4, 5, 0, 3],"float64"), weight=1.0, )
[paddle error] paddle.Tensor.lerp(x=Tensor([4, 5, 0, 3],"float64"), y=Tensor([4, 5, 0, 3],"float64"), weight=1.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:38.917011 GPU 1 69617 test begin: paddle.Tensor.lerp(x=Tensor([4, 5, 0],"float64"), y=Tensor([4, 5, 0],"float64"), weight=0.5, )
[paddle error] paddle.Tensor.lerp(x=Tensor([4, 5, 0],"float64"), y=Tensor([4, 5, 0],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:38.945752 GPU 1 69603 test begin: paddle.Tensor.lerp(x=Tensor([4, 5, 4, 0],"float64"), y=Tensor([4, 5, 4, 0],"float64"), weight=0.0, )
[paddle error] paddle.Tensor.lerp(x=Tensor([4, 5, 4, 0],"float64"), y=Tensor([4, 5, 4, 0],"float64"), weight=0.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:38.958153 GPU 1 69629 test begin: paddle.Tensor.lerp(x=Tensor([4, 5, 4, 0],"float64"), y=Tensor([4, 5, 4, 0],"float64"), weight=0.5, )
[paddle error] paddle.Tensor.lerp(x=Tensor([4, 5, 4, 0],"float64"), y=Tensor([4, 5, 4, 0],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:38.966445 GPU 1 69600 test begin: paddle.Tensor.lerp(x=Tensor([4, 5, 4, 0],"float64"), y=Tensor([4, 5, 4, 0],"float64"), weight=1.0, )
[paddle error] paddle.Tensor.lerp(x=Tensor([4, 5, 4, 0],"float64"), y=Tensor([4, 5, 4, 0],"float64"), weight=1.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:39.000115 GPU 1 69611 test begin: paddle.Tensor.lu(Tensor([0, 3, 2, 2],"float64"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/_tensor.py:902: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.
LU, pivots = torch.lu(A, compute_pivots)
should be replaced with
LU, pivots = torch.linalg.lu_factor(A, compute_pivots)
and
LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)
should be replaced with
LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2053.)
  LU, pivots, infos = torch._lu_with_info(
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.lu(Tensor([0, 3, 2, 2],"float64"), ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/lu_kernel_impl.h:532)


2025-05-21 22:07:39.031701 GPU 1 69619 test begin: paddle.Tensor.lu(Tensor([0, 3, 3],"float64"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/_tensor.py:902: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.
LU, pivots = torch.lu(A, compute_pivots)
should be replaced with
LU, pivots = torch.linalg.lu_factor(A, compute_pivots)
and
LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)
should be replaced with
LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2053.)
  LU, pivots, infos = torch._lu_with_info(
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.lu(Tensor([0, 3, 3],"float64"), ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/lu_kernel_impl.h:532)


2025-05-21 22:07:39.044656 GPU 1 69596 test begin: paddle.Tensor.lu(Tensor([0, 3],"float32"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/_tensor.py:902: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.
LU, pivots = torch.lu(A, compute_pivots)
should be replaced with
LU, pivots = torch.linalg.lu_factor(A, compute_pivots)
and
LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)
should be replaced with
LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2053.)
  LU, pivots, infos = torch._lu_with_info(
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.lu(Tensor([0, 3],"float32"), ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/lu_kernel_impl.h:532)


2025-05-21 22:07:39.055055 GPU 1 69613 test begin: paddle.Tensor.lu(Tensor([0, 3],"float64"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/_tensor.py:902: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.
LU, pivots = torch.lu(A, compute_pivots)
should be replaced with
LU, pivots = torch.linalg.lu_factor(A, compute_pivots)
and
LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)
should be replaced with
LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2053.)
  LU, pivots, infos = torch._lu_with_info(
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.lu(Tensor([0, 3],"float64"), ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/lu_kernel_impl.h:532)


2025-05-21 22:07:39.079424 GPU 1 69600 test begin: paddle.Tensor.lu(Tensor([3, 0, 3],"float64"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/_tensor.py:902: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.
LU, pivots = torch.lu(A, compute_pivots)
should be replaced with
LU, pivots = torch.linalg.lu_factor(A, compute_pivots)
and
LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)
should be replaced with
LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2053.)
  LU, pivots, infos = torch._lu_with_info(
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.lu(Tensor([3, 0, 3],"float64"), ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/lu_kernel_impl.h:532)


2025-05-21 22:07:39.085910 GPU 1 69598 test begin: paddle.Tensor.lu(Tensor([3, 0],"float32"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/_tensor.py:902: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.
LU, pivots = torch.lu(A, compute_pivots)
should be replaced with
LU, pivots = torch.linalg.lu_factor(A, compute_pivots)
and
LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)
should be replaced with
LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2053.)
  LU, pivots, infos = torch._lu_with_info(
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.lu(Tensor([3, 0],"float32"), ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/lu_kernel_impl.h:532)


2025-05-21 22:07:39.088903 GPU 1 69617 test begin: paddle.Tensor.lu(Tensor([3, 0],"float64"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/_tensor.py:902: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.
LU, pivots = torch.lu(A, compute_pivots)
should be replaced with
LU, pivots = torch.linalg.lu_factor(A, compute_pivots)
and
LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)
should be replaced with
LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2053.)
  LU, pivots, infos = torch._lu_with_info(
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.lu(Tensor([3, 0],"float64"), ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/lu_kernel_impl.h:532)


2025-05-21 22:07:39.089456 GPU 1 69603 test begin: paddle.Tensor.lu(Tensor([3, 3, 0],"float64"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/_tensor.py:902: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.
LU, pivots = torch.lu(A, compute_pivots)
should be replaced with
LU, pivots = torch.linalg.lu_factor(A, compute_pivots)
and
LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)
should be replaced with
LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2053.)
  LU, pivots, infos = torch._lu_with_info(
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.lu(Tensor([3, 3, 0],"float64"), ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/lu_kernel_impl.h:532)


2025-05-21 22:07:39.135057 GPU 1 69611 test begin: paddle.Tensor.lu(Tensor([4, 0, 2, 2],"float64"), )
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.lu(Tensor([4, 0, 2, 2],"float64"), ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/lu_kernel_impl.h:532)


2025-05-21 22:07:39.166569 GPU 1 69596 test begin: paddle.Tensor.lu(Tensor([4, 3, 0, 2],"float64"), )
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.lu(Tensor([4, 3, 0, 2],"float64"), ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/lu_kernel_impl.h:532)


2025-05-21 22:07:39.193724 GPU 1 69599 test begin: paddle.Tensor.lu(Tensor([4, 3, 2, 0],"float64"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/_tensor.py:902: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.
LU, pivots = torch.lu(A, compute_pivots)
should be replaced with
LU, pivots = torch.linalg.lu_factor(A, compute_pivots)
and
LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)
should be replaced with
LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2053.)
  LU, pivots, infos = torch._lu_with_info(
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.lu(Tensor([4, 3, 2, 0],"float64"), ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/lu_kernel_impl.h:532)


2025-05-21 22:07:39.194081 GPU 1 69629 test begin: paddle.Tensor.matmul(Tensor([0, 100, 1],"float64"), Tensor([0, 1, 40],"float64"), )
[accuracy error] paddle.Tensor.matmul(Tensor([0, 100, 1],"float64"), Tensor([0, 1, 40],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (0, 100, 1, 40), (0, 100, 40) mismatch)
 ACTUAL: array([], shape=(0, 100, 1, 40), dtype=float64)
 DESIRED: array([], shape=(0, 100, 40), dtype=float64)

2025-05-21 22:07:39.214084 GPU 1 69600 test begin: paddle.Tensor.matmul(Tensor([0, 100, 1],"float64"), Tensor([0, 1, 4],"float64"), )
[accuracy error] paddle.Tensor.matmul(Tensor([0, 100, 1],"float64"), Tensor([0, 1, 4],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (0, 100, 1, 4), (0, 100, 4) mismatch)
 ACTUAL: array([], shape=(0, 100, 1, 4), dtype=float64)
 DESIRED: array([], shape=(0, 100, 4), dtype=float64)

2025-05-21 22:07:39.216195 GPU 1 69603 test begin: paddle.Tensor.matmul(Tensor([0, 100, 1],"float64"), Tensor([1, 1, 40],"float64"), )
[accuracy error] paddle.Tensor.matmul(Tensor([0, 100, 1],"float64"), Tensor([1, 1, 40],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (0, 100, 1, 40), (0, 100, 40) mismatch)
 ACTUAL: array([], shape=(0, 100, 1, 40), dtype=float64)
 DESIRED: array([], shape=(0, 100, 40), dtype=float64)

2025-05-21 22:07:39.219193 GPU 1 69619 test begin: paddle.Tensor.matmul(Tensor([0, 100, 1],"float64"), Tensor([1, 1, 4],"float64"), )
[accuracy error] paddle.Tensor.matmul(Tensor([0, 100, 1],"float64"), Tensor([1, 1, 4],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (0, 100, 1, 4), (0, 100, 4) mismatch)
 ACTUAL: array([], shape=(0, 100, 1, 4), dtype=float64)
 DESIRED: array([], shape=(0, 100, 4), dtype=float64)

2025-05-21 22:07:39.228771 GPU 1 69608 test begin: paddle.Tensor.matmul(Tensor([0, 12, 197, 197],"float16"), Tensor([0, 12, 197, 64],"float16"), )
[accuracy error] paddle.Tensor.matmul(Tensor([0, 12, 197, 197],"float16"), Tensor([0, 12, 197, 64],"float16"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (0, 12, 197, 12, 197, 64), (0, 12, 197, 64) mismatch)
 ACTUAL: array([], shape=(0, 12, 197, 12, 197, 64), dtype=float16)
 DESIRED: array([], shape=(0, 12, 197, 64), dtype=float16)

2025-05-21 22:07:39.243528 GPU 1 69598 test begin: paddle.Tensor.matmul(Tensor([0, 12, 197, 197],"float32"), Tensor([0, 12, 197, 64],"float32"), )
[accuracy error] paddle.Tensor.matmul(Tensor([0, 12, 197, 197],"float32"), Tensor([0, 12, 197, 64],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (0, 12, 197, 12, 197, 64), (0, 12, 197, 64) mismatch)
 ACTUAL: array([], shape=(0, 12, 197, 12, 197, 64), dtype=float32)
 DESIRED: array([], shape=(0, 12, 197, 64), dtype=float32)

2025-05-21 22:07:39.268246 GPU 1 69611 test begin: paddle.Tensor.matmul(Tensor([1, 0, 1],"float64"), Tensor([1, 1, 40],"float64"), )
[accuracy error] paddle.Tensor.matmul(Tensor([1, 0, 1],"float64"), Tensor([1, 1, 40],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (1, 0, 1, 40), (1, 0, 40) mismatch)
 ACTUAL: array([], shape=(1, 0, 1, 40), dtype=float64)
 DESIRED: array([], shape=(1, 0, 40), dtype=float64)

2025-05-21 22:07:39.291392 GPU 1 69617 test begin: paddle.Tensor.matmul(Tensor([1, 0, 1],"float64"), Tensor([1, 1, 4],"float64"), )
[accuracy error] paddle.Tensor.matmul(Tensor([1, 0, 1],"float64"), Tensor([1, 1, 4],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (1, 0, 1, 4), (1, 0, 4) mismatch)
 ACTUAL: array([], shape=(1, 0, 1, 4), dtype=float64)
 DESIRED: array([], shape=(1, 0, 4), dtype=float64)

2025-05-21 22:07:39.292888 GPU 1 69596 test begin: paddle.Tensor.matmul(Tensor([1, 100, 1],"float64"), Tensor([0, 1, 40],"float64"), )
[accuracy error] paddle.Tensor.matmul(Tensor([1, 100, 1],"float64"), Tensor([0, 1, 40],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (1, 100, 1, 40), (0, 100, 40) mismatch)
 ACTUAL: array([[[[0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.]],...
 DESIRED: array([], shape=(0, 100, 40), dtype=float64)

2025-05-21 22:07:39.328630 GPU 1 69600 test begin: paddle.Tensor.matmul(Tensor([1, 100, 1],"float64"), Tensor([0, 1, 4],"float64"), )
[accuracy error] paddle.Tensor.matmul(Tensor([1, 100, 1],"float64"), Tensor([0, 1, 4],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (1, 100, 1, 4), (0, 100, 4) mismatch)
 ACTUAL: array([[[[0., 0., 0., 0.]],

        [[0., 0., 0., 0.]],...
 DESIRED: array([], shape=(0, 100, 4), dtype=float64)

2025-05-21 22:07:39.345106 GPU 1 69608 test begin: paddle.Tensor.matmul(Tensor([1, 100, 1],"float64"), Tensor([1, 1, 0],"float64"), )
[accuracy error] paddle.Tensor.matmul(Tensor([1, 100, 1],"float64"), Tensor([1, 1, 0],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (1, 100, 1, 0), (1, 100, 0) mismatch)
 ACTUAL: array([], shape=(1, 100, 1, 0), dtype=float64)
 DESIRED: array([], shape=(1, 100, 0), dtype=float64)

2025-05-21 22:07:39.349721 GPU 1 69613 test begin: paddle.Tensor.matmul(Tensor([1, 1],"float64"), Tensor([1, 0],"float64"), )
W0521 22:07:42.947245 69613 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.matmul(Tensor([1, 1],"float64"), Tensor([1, 0],"float64"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:07:39.350310 GPU 1 69603 test begin: paddle.Tensor.matmul(Tensor([112, 0, 197, 197],"float16"), Tensor([112, 0, 197, 64],"float16"), )
[accuracy error] paddle.Tensor.matmul(Tensor([112, 0, 197, 197],"float16"), Tensor([112, 0, 197, 64],"float16"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (112, 0, 197, 0, 197, 64), (112, 0, 197, 64) mismatch)
 ACTUAL: array([], shape=(112, 0, 197, 0, 197, 64), dtype=float16)
 DESIRED: array([], shape=(112, 0, 197, 64), dtype=float16)

2025-05-21 22:07:39.350838 GPU 1 69599 test begin: paddle.Tensor.matmul(Tensor([112, 0, 197, 197],"float32"), Tensor([112, 0, 197, 64],"float32"), )
[accuracy error] paddle.Tensor.matmul(Tensor([112, 0, 197, 197],"float32"), Tensor([112, 0, 197, 64],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (112, 0, 197, 0, 197, 64), (112, 0, 197, 64) mismatch)
 ACTUAL: array([], shape=(112, 0, 197, 0, 197, 64), dtype=float32)
 DESIRED: array([], shape=(112, 0, 197, 64), dtype=float32)

2025-05-21 22:07:39.406186 GPU 1 69598 test begin: paddle.Tensor.matmul(Tensor([112, 12, 0, 197],"float16"), Tensor([112, 12, 197, 64],"float16"), )
[accuracy error] paddle.Tensor.matmul(Tensor([112, 12, 0, 197],"float16"), Tensor([112, 12, 197, 64],"float16"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (112, 12, 0, 12, 197, 64), (112, 12, 0, 64) mismatch)
 ACTUAL: array([], shape=(112, 12, 0, 12, 197, 64), dtype=float16)
 DESIRED: array([], shape=(112, 12, 0, 64), dtype=float16)

2025-05-21 22:07:39.412950 GPU 1 69629 test begin: paddle.Tensor.matmul(Tensor([112, 12, 0, 197],"float32"), Tensor([112, 12, 197, 64],"float32"), )
[accuracy error] paddle.Tensor.matmul(Tensor([112, 12, 0, 197],"float32"), Tensor([112, 12, 197, 64],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (112, 12, 0, 12, 197, 64), (112, 12, 0, 64) mismatch)
 ACTUAL: array([], shape=(112, 12, 0, 12, 197, 64), dtype=float32)
 DESIRED: array([], shape=(112, 12, 0, 64), dtype=float32)

2025-05-21 22:07:39.425340 GPU 1 69619 test begin: paddle.Tensor.matmul(Tensor([112, 12, 197, 197],"float16"), Tensor([112, 12, 197, 0],"float16"), )
[accuracy error] paddle.Tensor.matmul(Tensor([112, 12, 197, 197],"float16"), Tensor([112, 12, 197, 0],"float16"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (112, 12, 197, 12, 197, 0), (112, 12, 197, 0) mismatch)
 ACTUAL: array([], shape=(112, 12, 197, 12, 197, 0), dtype=float16)
 DESIRED: array([], shape=(112, 12, 197, 0), dtype=float16)

2025-05-21 22:07:39.462964 GPU 1 69600 test begin: paddle.Tensor.matmul(Tensor([112, 12, 197, 197],"float32"), Tensor([112, 12, 197, 0],"float32"), )
[accuracy error] paddle.Tensor.matmul(Tensor([112, 12, 197, 197],"float32"), Tensor([112, 12, 197, 0],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (112, 12, 197, 12, 197, 0), (112, 12, 197, 0) mismatch)
 ACTUAL: array([], shape=(112, 12, 197, 12, 197, 0), dtype=float32)
 DESIRED: array([], shape=(112, 12, 197, 0), dtype=float32)

2025-05-21 22:07:39.463835 GPU 1 69603 test begin: paddle.Tensor.median(Tensor([0, 784],"float32"), )
 ** On entry to DGEMM  parameter number 8 had an illegal value
[paddle error] paddle.Tensor.median(Tensor([0, 784],"float32"), ) 
 In median, the size of input x should not be 0.

2025-05-21 22:07:39.468621 GPU 1 69608 test begin: paddle.Tensor.median(Tensor([1000, 0],"float32"), )
[paddle error] paddle.Tensor.median(Tensor([1000, 0],"float32"), ) 
 In median, the size of input x should not be 0.

2025-05-21 22:07:39.471152 GPU 1 69596 test begin: paddle.Tensor.mm(Tensor([10, 10],"float32"), Tensor([10, 0],"float32"), )
W0521 22:07:39.601959 69596 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.mm(Tensor([10, 10],"float32"), Tensor([10, 0],"float32"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:40)


2025-05-21 22:07:39.489122 GPU 1 69611 test begin: paddle.Tensor.mode(Tensor([0, 2, 3],"float64"), )
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.mode(Tensor([0, 2, 3],"float64"), ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < in_dims[i], but received 0:0 >= in_dims[i]:0.] (at ../paddle/phi/kernels/gpu/mode_kernel.cu:36)


2025-05-21 22:07:39.493537 GPU 1 69599 test begin: paddle.Tensor.mode(Tensor([0, 2, 3],"float64"), axis=1, keepdim=False, )
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.mode(Tensor([0, 2, 3],"float64"), axis=1, keepdim=False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < in_dims[i], but received 0:0 >= in_dims[i]:0.] (at ../paddle/phi/kernels/gpu/mode_kernel.cu:36)


2025-05-21 22:07:39.505420 GPU 1 69617 test begin: paddle.Tensor.mode(Tensor([0, 2, 3],"float64"), axis=2, keepdim=True, )
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.mode(Tensor([0, 2, 3],"float64"), axis=2, keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < in_dims[i], but received 0:0 >= in_dims[i]:0.] (at ../paddle/phi/kernels/gpu/mode_kernel.cu:36)


2025-05-21 22:07:39.592977 GPU 1 69603 test begin: paddle.Tensor.mode(Tensor([3, 0, 3],"float64"), )
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.mode(Tensor([3, 0, 3],"float64"), ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < in_dims[i], but received 0:0 >= in_dims[i]:0.] (at ../paddle/phi/kernels/gpu/mode_kernel.cu:36)


2025-05-21 22:07:39.599589 GPU 1 69608 test begin: paddle.Tensor.mode(Tensor([3, 0, 3],"float64"), axis=2, keepdim=True, )
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.mode(Tensor([3, 0, 3],"float64"), axis=2, keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < in_dims[i], but received 0:0 >= in_dims[i]:0.] (at ../paddle/phi/kernels/gpu/mode_kernel.cu:36)


2025-05-21 22:07:39.602750 GPU 1 69596 test begin: paddle.Tensor.mode(Tensor([3, 2, 0],"float64"), axis=1, keepdim=False, )
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.mode(Tensor([3, 2, 0],"float64"), axis=1, keepdim=False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < in_dims[i], but received 0:0 >= in_dims[i]:0.] (at ../paddle/phi/kernels/gpu/mode_kernel.cu:36)


2025-05-21 22:07:39.612349 GPU 1 69599 test begin: paddle.Tensor.multigammaln(Tensor([0],"float32"), 3, )
[cuda error] paddle.Tensor.multigammaln(Tensor([0],"float32"), 3, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:39.625443 GPU 1 69617 test begin: paddle.Tensor.nansum(Tensor([0, 2, 3, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, )
[cuda error] paddle.Tensor.nansum(Tensor([0, 2, 3, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:39.627795 GPU 1 69611 test begin: paddle.Tensor.nansum(Tensor([0, 3, 3],"float32"), )
[cuda error] paddle.Tensor.nansum(Tensor([0, 3, 3],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:39.691608 GPU 1 69602 test begin: paddle.Tensor.nansum(Tensor([0, 3, 3],"float64"), )
[cuda error] paddle.Tensor.nansum(Tensor([0, 3, 3],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:39.706457 GPU 1 69603 test begin: paddle.Tensor.nansum(Tensor([0, 3, 3],"float64"), axis=-1, )
[cuda error] paddle.Tensor.nansum(Tensor([0, 3, 3],"float64"), axis=-1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:39.707153 GPU 1 69608 test begin: paddle.Tensor.nansum(Tensor([0, 3, 3],"float64"), axis=0, keepdim=True, )
[cuda error] paddle.Tensor.nansum(Tensor([0, 3, 3],"float64"), axis=0, keepdim=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:39.759188 GPU 1 69617 test begin: paddle.Tensor.nansum(Tensor([3, 0, 3, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, )
[cuda error] paddle.Tensor.nansum(Tensor([3, 0, 3, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:39.763983 GPU 1 69596 test begin: paddle.Tensor.nansum(Tensor([3, 0, 3],"float32"), )
[cuda error] paddle.Tensor.nansum(Tensor([3, 0, 3],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:39.821034 GPU 1 69603 test begin: paddle.Tensor.nansum(Tensor([3, 0, 3],"float64"), )
[cuda error] paddle.Tensor.nansum(Tensor([3, 0, 3],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:39.831072 GPU 1 69608 test begin: paddle.Tensor.nansum(Tensor([3, 0, 3],"float64"), axis=-1, )
[cuda error] paddle.Tensor.nansum(Tensor([3, 0, 3],"float64"), axis=-1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:39.835880 GPU 1 69599 test begin: paddle.Tensor.nansum(Tensor([3, 0, 3],"float64"), axis=0, keepdim=True, )
[cuda error] paddle.Tensor.nansum(Tensor([3, 0, 3],"float64"), axis=0, keepdim=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:39.855046 GPU 1 69609 test begin: paddle.Tensor.nansum(Tensor([3, 2, 0, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, )
[cuda error] paddle.Tensor.nansum(Tensor([3, 2, 0, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:39.896653 GPU 1 69602 test begin: paddle.Tensor.nansum(Tensor([3, 2, 3, 0, 5, 1, 2],"float64"), axis=3, keepdim=True, )
[cuda error] paddle.Tensor.nansum(Tensor([3, 2, 3, 0, 5, 1, 2],"float64"), axis=3, keepdim=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:39.899733 GPU 1 69611 test begin: paddle.Tensor.nansum(Tensor([3, 2, 3, 4, 0, 1, 2],"float64"), axis=3, keepdim=True, )
[cuda error] paddle.Tensor.nansum(Tensor([3, 2, 3, 4, 0, 1, 2],"float64"), axis=3, keepdim=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:39.936879 GPU 1 69608 test begin: paddle.Tensor.nansum(Tensor([3, 2, 3, 4, 5, 0, 2],"float64"), axis=3, keepdim=True, )
[cuda error] paddle.Tensor.nansum(Tensor([3, 2, 3, 4, 5, 0, 2],"float64"), axis=3, keepdim=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:39.954449 GPU 1 69603 test begin: paddle.Tensor.nansum(Tensor([3, 2, 3, 4, 5, 1, 0],"float64"), axis=3, keepdim=True, )
[cuda error] paddle.Tensor.nansum(Tensor([3, 2, 3, 4, 5, 1, 0],"float64"), axis=3, keepdim=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:39.987618 GPU 1 69596 test begin: paddle.Tensor.nansum(Tensor([3, 3, 0],"float32"), )
[cuda error] paddle.Tensor.nansum(Tensor([3, 3, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.003847 GPU 1 69612 test begin: paddle.Tensor.nansum(Tensor([3, 3, 0],"float64"), )
[cuda error] paddle.Tensor.nansum(Tensor([3, 3, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.039298 GPU 1 69608 test begin: paddle.Tensor.nansum(Tensor([3, 3, 0],"float64"), axis=-1, )
[cuda error] paddle.Tensor.nansum(Tensor([3, 3, 0],"float64"), axis=-1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.041450 GPU 1 69599 test begin: paddle.Tensor.nansum(Tensor([3, 3, 0],"float64"), axis=0, keepdim=True, )
[cuda error] paddle.Tensor.nansum(Tensor([3, 3, 0],"float64"), axis=0, keepdim=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.062502 GPU 1 69603 test begin: paddle.Tensor.outer(x=Tensor([4],"float64"), y=Tensor([0],"float64"), )
W0521 22:07:40.183480 69603 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.outer(x=Tensor([4],"float64"), y=Tensor([0],"float64"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:07:40.083824 GPU 1 69602 test begin: paddle.Tensor.repeat_interleave(Tensor([0, 1, 1, 3],"float32"), 1, axis=0, )
[cuda error] paddle.Tensor.repeat_interleave(Tensor([0, 1, 1, 3],"float32"), 1, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.099545 GPU 1 69611 test begin: paddle.Tensor.repeat_interleave(Tensor([0, 1, 1, 3],"float32"), 2, axis=0, )
[cuda error] paddle.Tensor.repeat_interleave(Tensor([0, 1, 1, 3],"float32"), 2, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.109905 GPU 1 69609 test begin: paddle.Tensor.repeat_interleave(Tensor([0, 1, 1, 3],"float32"), 3, axis=0, )
[cuda error] paddle.Tensor.repeat_interleave(Tensor([0, 1, 1, 3],"float32"), 3, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.158302 GPU 1 69617 test begin: paddle.Tensor.repeat_interleave(Tensor([0, 1, 10, 10],"int64"), 1, axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.repeat_interleave(Tensor([0, 1, 10, 10],"int64"), 1, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.162280 GPU 1 69598 test begin: paddle.Tensor.repeat_interleave(Tensor([0, 1, 10, 10],"int64"), 2, axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.repeat_interleave(Tensor([0, 1, 10, 10],"int64"), 2, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.165736 GPU 1 69629 test begin: paddle.Tensor.repeat_interleave(Tensor([0, 1, 10, 10],"int64"), 3, axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.repeat_interleave(Tensor([0, 1, 10, 10],"int64"), 3, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.168268 GPU 1 69608 test begin: paddle.Tensor.repeat_interleave(Tensor([0, 10],"int64"), 1, axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.repeat_interleave(Tensor([0, 10],"int64"), 1, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.175691 GPU 1 69596 test begin: paddle.Tensor.repeat_interleave(Tensor([0, 10],"int64"), 2, axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.repeat_interleave(Tensor([0, 10],"int64"), 2, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.184148 GPU 1 69603 test begin: paddle.Tensor.repeat_interleave(Tensor([0, 10],"int64"), 3, axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.repeat_interleave(Tensor([0, 10],"int64"), 3, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.208643 GPU 1 69599 test begin: paddle.Tensor.repeat_interleave(Tensor([0, 1],"int64"), 1, axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.repeat_interleave(Tensor([0, 1],"int64"), 1, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.221712 GPU 1 69621 test begin: paddle.Tensor.repeat_interleave(Tensor([0, 1],"int64"), 2, axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.repeat_interleave(Tensor([0, 1],"int64"), 2, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.235918 GPU 1 69602 test begin: paddle.Tensor.repeat_interleave(Tensor([0, 1],"int64"), 3, axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.repeat_interleave(Tensor([0, 1],"int64"), 3, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.279248 GPU 1 69608 test begin: paddle.Tensor.repeat_interleave(Tensor([0, 3, 16],"float32"), 1, axis=0, )
[cuda error] paddle.Tensor.repeat_interleave(Tensor([0, 3, 16],"float32"), 1, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.284702 GPU 1 69612 test begin: paddle.Tensor.repeat_interleave(Tensor([0, 3, 16],"float32"), 2, axis=0, )
[cuda error] paddle.Tensor.repeat_interleave(Tensor([0, 3, 16],"float32"), 2, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.302361 GPU 1 69603 test begin: paddle.Tensor.repeat_interleave(Tensor([0, 3, 16],"float32"), 3, axis=0, )
[cuda error] paddle.Tensor.repeat_interleave(Tensor([0, 3, 16],"float32"), 3, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.323069 GPU 1 69609 test begin: paddle.Tensor.repeat_interleave(Tensor([0, 3, 32],"float32"), 1, axis=0, )
[cuda error] paddle.Tensor.repeat_interleave(Tensor([0, 3, 32],"float32"), 1, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.357117 GPU 1 69629 test begin: paddle.Tensor.repeat_interleave(Tensor([0, 3, 32],"float32"), 2, axis=0, )
[cuda error] paddle.Tensor.repeat_interleave(Tensor([0, 3, 32],"float32"), 2, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.359890 GPU 1 69611 test begin: paddle.Tensor.repeat_interleave(Tensor([0, 3, 32],"float32"), 3, axis=0, )
[cuda error] paddle.Tensor.repeat_interleave(Tensor([0, 3, 32],"float32"), 3, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.373034 GPU 1 69596 test begin: paddle.Tensor.repeat_interleave(Tensor([2, 0, 1, 3],"float32"), 1, axis=0, )
[cuda error] paddle.Tensor.repeat_interleave(Tensor([2, 0, 1, 3],"float32"), 1, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.380298 GPU 1 69602 test begin: paddle.Tensor.repeat_interleave(Tensor([2, 0, 1, 3],"float32"), 2, axis=0, )
[cuda error] paddle.Tensor.repeat_interleave(Tensor([2, 0, 1, 3],"float32"), 2, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.391348 GPU 1 69608 test begin: paddle.Tensor.repeat_interleave(Tensor([2, 0, 1, 3],"float32"), 3, axis=0, )
[cuda error] paddle.Tensor.repeat_interleave(Tensor([2, 0, 1, 3],"float32"), 3, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.409260 GPU 1 69603 test begin: paddle.Tensor.repeat_interleave(Tensor([2, 0, 10, 10],"int64"), 1, axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.repeat_interleave(Tensor([2, 0, 10, 10],"int64"), 1, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.411176 GPU 1 69599 test begin: paddle.Tensor.repeat_interleave(Tensor([2, 0, 10, 10],"int64"), 2, axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.repeat_interleave(Tensor([2, 0, 10, 10],"int64"), 2, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.424271 GPU 1 69617 test begin: paddle.Tensor.repeat_interleave(Tensor([2, 0, 10, 10],"int64"), 3, axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.repeat_interleave(Tensor([2, 0, 10, 10],"int64"), 3, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.498770 GPU 1 69612 test begin: paddle.Tensor.repeat_interleave(Tensor([2, 0, 16],"float32"), 1, axis=0, )
[cuda error] paddle.Tensor.repeat_interleave(Tensor([2, 0, 16],"float32"), 1, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.506074 GPU 1 69609 test begin: paddle.Tensor.repeat_interleave(Tensor([2, 0, 16],"float32"), 2, axis=0, )
[cuda error] paddle.Tensor.repeat_interleave(Tensor([2, 0, 16],"float32"), 2, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.517160 GPU 1 69603 test begin: paddle.Tensor.repeat_interleave(Tensor([2, 0, 16],"float32"), 3, axis=0, )
[cuda error] paddle.Tensor.repeat_interleave(Tensor([2, 0, 16],"float32"), 3, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.517919 GPU 1 69621 test begin: paddle.Tensor.repeat_interleave(Tensor([2, 0, 32],"float32"), 1, axis=0, )
[cuda error] paddle.Tensor.repeat_interleave(Tensor([2, 0, 32],"float32"), 1, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.524281 GPU 1 69608 test begin: paddle.Tensor.repeat_interleave(Tensor([2, 0, 32],"float32"), 2, axis=0, )
[cuda error] paddle.Tensor.repeat_interleave(Tensor([2, 0, 32],"float32"), 2, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.530803 GPU 1 69596 test begin: paddle.Tensor.repeat_interleave(Tensor([2, 0, 32],"float32"), 3, axis=0, )
[cuda error] paddle.Tensor.repeat_interleave(Tensor([2, 0, 32],"float32"), 3, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.547203 GPU 1 69599 test begin: paddle.Tensor.repeat_interleave(Tensor([2, 0],"int64"), 1, axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.repeat_interleave(Tensor([2, 0],"int64"), 1, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.558491 GPU 1 69611 test begin: paddle.Tensor.repeat_interleave(Tensor([2, 0],"int64"), 2, axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.repeat_interleave(Tensor([2, 0],"int64"), 2, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.575901 GPU 1 69629 test begin: paddle.Tensor.repeat_interleave(Tensor([2, 0],"int64"), 3, axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.repeat_interleave(Tensor([2, 0],"int64"), 3, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.576637 GPU 1 69602 test begin: paddle.Tensor.repeat_interleave(Tensor([2, 1, 0, 10],"int64"), 1, axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.repeat_interleave(Tensor([2, 1, 0, 10],"int64"), 1, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.655085 GPU 1 69598 test begin: paddle.Tensor.repeat_interleave(Tensor([2, 1, 0, 10],"int64"), 2, axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.repeat_interleave(Tensor([2, 1, 0, 10],"int64"), 2, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.659744 GPU 1 69606 test begin: paddle.Tensor.repeat_interleave(Tensor([2, 1, 0, 10],"int64"), 3, axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.repeat_interleave(Tensor([2, 1, 0, 10],"int64"), 3, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.723436 GPU 1 69600 test begin: paddle.Tensor.repeat_interleave(Tensor([2, 1, 0, 3],"float32"), 1, axis=0, )
[cuda error] paddle.Tensor.repeat_interleave(Tensor([2, 1, 0, 3],"float32"), 1, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.762939 GPU 1 69612 test begin: paddle.Tensor.repeat_interleave(Tensor([2, 1, 0, 3],"float32"), 2, axis=0, )
[cuda error] paddle.Tensor.repeat_interleave(Tensor([2, 1, 0, 3],"float32"), 2, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.768775 GPU 1 69608 test begin: paddle.Tensor.repeat_interleave(Tensor([2, 1, 0, 3],"float32"), 3, axis=0, )
[cuda error] paddle.Tensor.repeat_interleave(Tensor([2, 1, 0, 3],"float32"), 3, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.768949 GPU 1 69603 test begin: paddle.Tensor.repeat_interleave(Tensor([2, 1, 1, 0],"float32"), 1, axis=0, )
[cuda error] paddle.Tensor.repeat_interleave(Tensor([2, 1, 1, 0],"float32"), 1, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.772176 GPU 1 69599 test begin: paddle.Tensor.repeat_interleave(Tensor([2, 1, 1, 0],"float32"), 2, axis=0, )
[cuda error] paddle.Tensor.repeat_interleave(Tensor([2, 1, 1, 0],"float32"), 2, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.778183 GPU 1 69621 test begin: paddle.Tensor.repeat_interleave(Tensor([2, 1, 1, 0],"float32"), 3, axis=0, )
[cuda error] paddle.Tensor.repeat_interleave(Tensor([2, 1, 1, 0],"float32"), 3, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.795855 GPU 1 69596 test begin: paddle.Tensor.repeat_interleave(Tensor([2, 1, 10, 0],"int64"), 1, axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.repeat_interleave(Tensor([2, 1, 10, 0],"int64"), 1, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.796416 GPU 1 69606 test begin: paddle.Tensor.repeat_interleave(Tensor([2, 1, 10, 0],"int64"), 2, axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.repeat_interleave(Tensor([2, 1, 10, 0],"int64"), 2, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.818723 GPU 1 69602 test begin: paddle.Tensor.repeat_interleave(Tensor([2, 1, 10, 0],"int64"), 3, axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.repeat_interleave(Tensor([2, 1, 10, 0],"int64"), 3, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.821945 GPU 1 69617 test begin: paddle.Tensor.repeat_interleave(Tensor([2, 3, 0],"float32"), 1, axis=0, )
[cuda error] paddle.Tensor.repeat_interleave(Tensor([2, 3, 0],"float32"), 1, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.858661 GPU 1 69609 test begin: paddle.Tensor.repeat_interleave(Tensor([2, 3, 0],"float32"), 2, axis=0, )
[cuda error] paddle.Tensor.repeat_interleave(Tensor([2, 3, 0],"float32"), 2, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.868118 GPU 1 69598 test begin: paddle.Tensor.repeat_interleave(Tensor([2, 3, 0],"float32"), 3, axis=0, )
[cuda error] paddle.Tensor.repeat_interleave(Tensor([2, 3, 0],"float32"), 3, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.935930 GPU 1 69596 test begin: paddle.Tensor.repeat_interleave(x=Tensor([0, 2, 4, 4, 5],"float64"), repeats=2, )
[cuda error] paddle.Tensor.repeat_interleave(x=Tensor([0, 2, 4, 4, 5],"float64"), repeats=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.938049 GPU 1 69612 test begin: paddle.Tensor.repeat_interleave(x=Tensor([0, 2, 4, 4, 5],"float64"), repeats=2, axis=1, )
[cuda error] paddle.Tensor.repeat_interleave(x=Tensor([0, 2, 4, 4, 5],"float64"), repeats=2, axis=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.938883 GPU 1 69599 test begin: paddle.Tensor.repeat_interleave(x=Tensor([0, 2, 4, 4, 5],"int32"), repeats=2, axis=3, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.repeat_interleave(x=Tensor([0, 2, 4, 4, 5],"int32"), repeats=2, axis=3, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.939512 GPU 1 69608 test begin: paddle.Tensor.repeat_interleave(x=Tensor([0, 2, 4, 5],"float64"), repeats=2, )
[cuda error] paddle.Tensor.repeat_interleave(x=Tensor([0, 2, 4, 5],"float64"), repeats=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.941643 GPU 1 69603 test begin: paddle.Tensor.repeat_interleave(x=Tensor([0, 2, 4],"float64"), repeats=2, )
[cuda error] paddle.Tensor.repeat_interleave(x=Tensor([0, 2, 4],"float64"), repeats=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.945292 GPU 1 69621 test begin: paddle.Tensor.repeat_interleave(x=Tensor([0, 2],"float64"), repeats=2, )
[cuda error] paddle.Tensor.repeat_interleave(x=Tensor([0, 2],"float64"), repeats=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:40.955686 GPU 1 69602 test begin: paddle.Tensor.repeat_interleave(x=Tensor([0],"float32"), repeats=3, )
[cuda error] paddle.Tensor.repeat_interleave(x=Tensor([0],"float32"), repeats=3, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.014079 GPU 1 69600 test begin: paddle.Tensor.repeat_interleave(x=Tensor([0],"float64"), repeats=3, )
[cuda error] paddle.Tensor.repeat_interleave(x=Tensor([0],"float64"), repeats=3, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.121814 GPU 1 69596 test begin: paddle.Tensor.repeat_interleave(x=Tensor([4, 0, 4, 4, 5],"float64"), repeats=2, )
[cuda error] paddle.Tensor.repeat_interleave(x=Tensor([4, 0, 4, 4, 5],"float64"), repeats=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.124036 GPU 1 69600 test begin: paddle.Tensor.repeat_interleave(x=Tensor([4, 0, 4, 4, 5],"float64"), repeats=2, axis=1, )
[cuda error] paddle.Tensor.repeat_interleave(x=Tensor([4, 0, 4, 4, 5],"float64"), repeats=2, axis=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.124199 GPU 1 69608 test begin: paddle.Tensor.repeat_interleave(x=Tensor([4, 0, 4, 4, 5],"int32"), repeats=2, axis=3, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.repeat_interleave(x=Tensor([4, 0, 4, 4, 5],"int32"), repeats=2, axis=3, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.127342 GPU 1 69603 test begin: paddle.Tensor.repeat_interleave(x=Tensor([4, 0, 4, 5],"float64"), repeats=2, )
[cuda error] paddle.Tensor.repeat_interleave(x=Tensor([4, 0, 4, 5],"float64"), repeats=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.152205 GPU 1 69606 test begin: paddle.Tensor.repeat_interleave(x=Tensor([4, 0, 4],"float64"), repeats=2, )
[cuda error] paddle.Tensor.repeat_interleave(x=Tensor([4, 0, 4],"float64"), repeats=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.158981 GPU 1 69602 test begin: paddle.Tensor.repeat_interleave(x=Tensor([4, 0],"float64"), repeats=2, )
[cuda error] paddle.Tensor.repeat_interleave(x=Tensor([4, 0],"float64"), repeats=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.169553 GPU 1 69612 test begin: paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 0, 4, 5],"float64"), repeats=2, )
[cuda error] paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 0, 4, 5],"float64"), repeats=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.187027 GPU 1 69599 test begin: paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 0, 4, 5],"float64"), repeats=2, axis=1, )
[cuda error] paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 0, 4, 5],"float64"), repeats=2, axis=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.193720 GPU 1 69611 test begin: paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 0, 4, 5],"int32"), repeats=2, axis=3, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 0, 4, 5],"int32"), repeats=2, axis=3, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.197154 GPU 1 69609 test begin: paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 0, 5],"float64"), repeats=2, )
[cuda error] paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 0, 5],"float64"), repeats=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.219609 GPU 1 69598 test begin: paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 0],"float64"), repeats=2, )
[cuda error] paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 0],"float64"), repeats=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.232880 GPU 1 69621 test begin: paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 4, 0, 5],"float64"), repeats=2, )
[cuda error] paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 4, 0, 5],"float64"), repeats=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.309541 GPU 1 69608 test begin: paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 4, 0, 5],"float64"), repeats=2, axis=1, )
[cuda error] paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 4, 0, 5],"float64"), repeats=2, axis=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.339724 GPU 1 69600 test begin: paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 4, 0, 5],"int32"), repeats=2, axis=3, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 4, 0, 5],"int32"), repeats=2, axis=3, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.342324 GPU 1 69603 test begin: paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 4, 0],"float64"), repeats=2, )
[cuda error] paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 4, 0],"float64"), repeats=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.347727 GPU 1 69602 test begin: paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 4, 4, 0],"float64"), repeats=2, )
[cuda error] paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 4, 4, 0],"float64"), repeats=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.366218 GPU 1 69612 test begin: paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 4, 4, 0],"float64"), repeats=2, axis=1, )
[cuda error] paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 4, 4, 0],"float64"), repeats=2, axis=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.375107 GPU 1 69606 test begin: paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 4, 4, 0],"int32"), repeats=2, axis=3, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.Tensor.repeat_interleave(x=Tensor([4, 2, 4, 4, 0],"int32"), repeats=2, axis=3, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.392638 GPU 1 69629 test begin: paddle.Tensor.rot90(Tensor([0, 2],"float32"), 1, axes=list[0,1,], )
[cuda error] paddle.Tensor.rot90(Tensor([0, 2],"float32"), 1, axes=list[0,1,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.415832 GPU 1 69596 test begin: paddle.Tensor.rot90(Tensor([3, 0],"float32"), 1, axes=list[0,1,], )
[cuda error] paddle.Tensor.rot90(Tensor([3, 0],"float32"), 1, axes=list[0,1,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.490420 GPU 1 69599 test begin: paddle.Tensor.rot90(x=Tensor([0, 4, 4, 4],"float64"), )
[cuda error] paddle.Tensor.rot90(x=Tensor([0, 4, 4, 4],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.503274 GPU 1 69608 test begin: paddle.Tensor.rot90(x=Tensor([0, 4, 4, 4],"float64"), k=-1, axes=list[1,2,], )
[cuda error] paddle.Tensor.rot90(x=Tensor([0, 4, 4, 4],"float64"), k=-1, axes=list[1,2,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.531115 GPU 1 69606 test begin: paddle.Tensor.rot90(x=Tensor([0, 4, 4, 4],"float64"), k=-1, axes=tuple(2,3,), )
[cuda error] paddle.Tensor.rot90(x=Tensor([0, 4, 4, 4],"float64"), k=-1, axes=tuple(2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.532460 GPU 1 69600 test begin: paddle.Tensor.rot90(x=Tensor([0, 4, 4],"float64"), )
[cuda error] paddle.Tensor.rot90(x=Tensor([0, 4, 4],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.535469 GPU 1 69603 test begin: paddle.Tensor.rot90(x=Tensor([0, 4],"float32"), )
[cuda error] paddle.Tensor.rot90(x=Tensor([0, 4],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.536671 GPU 1 69621 test begin: paddle.Tensor.rot90(x=Tensor([0, 4],"float64"), )
[cuda error] paddle.Tensor.rot90(x=Tensor([0, 4],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.561207 GPU 1 69602 test begin: paddle.Tensor.rot90(x=Tensor([0, 4],"float64"), k=-1, )
[cuda error] paddle.Tensor.rot90(x=Tensor([0, 4],"float64"), k=-1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.566391 GPU 1 69617 test begin: paddle.Tensor.rot90(x=Tensor([3, 0],"float64"), )
[cuda error] paddle.Tensor.rot90(x=Tensor([3, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.583620 GPU 1 69609 test begin: paddle.Tensor.rot90(x=Tensor([4, 0, 4, 4],"float64"), )
[cuda error] paddle.Tensor.rot90(x=Tensor([4, 0, 4, 4],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.612020 GPU 1 69598 test begin: paddle.Tensor.rot90(x=Tensor([4, 0, 4, 4],"float64"), k=-1, axes=list[1,2,], )
[cuda error] paddle.Tensor.rot90(x=Tensor([4, 0, 4, 4],"float64"), k=-1, axes=list[1,2,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.681679 GPU 1 69608 test begin: paddle.Tensor.rot90(x=Tensor([4, 0, 4, 4],"float64"), k=-1, axes=tuple(2,3,), )
[cuda error] paddle.Tensor.rot90(x=Tensor([4, 0, 4, 4],"float64"), k=-1, axes=tuple(2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.690590 GPU 1 69600 test begin: paddle.Tensor.rot90(x=Tensor([4, 0, 4],"float64"), )
[cuda error] paddle.Tensor.rot90(x=Tensor([4, 0, 4],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.700853 GPU 1 69612 test begin: paddle.Tensor.rot90(x=Tensor([4, 0],"float32"), )
[cuda error] paddle.Tensor.rot90(x=Tensor([4, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.701747 GPU 1 69602 test begin: paddle.Tensor.rot90(x=Tensor([4, 0],"float64"), k=-1, )
[cuda error] paddle.Tensor.rot90(x=Tensor([4, 0],"float64"), k=-1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.758362 GPU 1 69609 test begin: paddle.Tensor.rot90(x=Tensor([4, 4, 0, 4],"float64"), )
[cuda error] paddle.Tensor.rot90(x=Tensor([4, 4, 0, 4],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.773068 GPU 1 69619 test begin: paddle.Tensor.rot90(x=Tensor([4, 4, 0, 4],"float64"), k=-1, axes=list[1,2,], )
[cuda error] paddle.Tensor.rot90(x=Tensor([4, 4, 0, 4],"float64"), k=-1, axes=list[1,2,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.790902 GPU 1 69599 test begin: paddle.Tensor.rot90(x=Tensor([4, 4, 0, 4],"float64"), k=-1, axes=tuple(2,3,), )
[cuda error] paddle.Tensor.rot90(x=Tensor([4, 4, 0, 4],"float64"), k=-1, axes=tuple(2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.804274 GPU 1 69596 test begin: paddle.Tensor.rot90(x=Tensor([4, 4, 0],"float64"), )
[cuda error] paddle.Tensor.rot90(x=Tensor([4, 4, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.826726 GPU 1 69606 test begin: paddle.Tensor.rot90(x=Tensor([4, 4, 4, 0],"float64"), )
[cuda error] paddle.Tensor.rot90(x=Tensor([4, 4, 4, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.845278 GPU 1 69617 test begin: paddle.Tensor.rot90(x=Tensor([4, 4, 4, 0],"float64"), k=-1, axes=list[1,2,], )
[cuda error] paddle.Tensor.rot90(x=Tensor([4, 4, 4, 0],"float64"), k=-1, axes=list[1,2,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.855643 GPU 1 69603 test begin: paddle.Tensor.rot90(x=Tensor([4, 4, 4, 0],"float64"), k=-1, axes=tuple(2,3,), )
[cuda error] paddle.Tensor.rot90(x=Tensor([4, 4, 4, 0],"float64"), k=-1, axes=tuple(2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:41.866174 GPU 1 69629 test begin: paddle.Tensor.std(Tensor([0, 1, 36],"float32"), axis=-1, keepdim=True, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0521 22:07:42.184952 69629 dygraph_functions.cc:85067] got different data type, run type promotion automatically, this may cause data type been changed.
W0521 22:07:42.188149 69629 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.std(Tensor([0, 1, 36],"float32"), axis=-1, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:41.874011 GPU 1 69621 test begin: paddle.Tensor.std(Tensor([0, 1, 45],"float32"), axis=-1, keepdim=True, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0521 22:07:42.067394 69621 dygraph_functions.cc:85067] got different data type, run type promotion automatically, this may cause data type been changed.
W0521 22:07:42.074921 69621 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.std(Tensor([0, 1, 45],"float32"), axis=-1, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:41.874236 GPU 1 69600 test begin: paddle.Tensor.std(Tensor([0, 1024, 8],"float32"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0521 22:07:42.278985 69600 dygraph_functions.cc:85067] got different data type, run type promotion automatically, this may cause data type been changed.
[accuracy error] paddle.Tensor.std(Tensor([0, 1024, 8],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array(0., dtype=float32)
 DESIRED: array(nan, dtype=float32)

2025-05-21 22:07:41.896900 GPU 1 69609 test begin: paddle.Tensor.std(Tensor([0, 1024, 8],"float64"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0521 22:07:42.089746 69609 dygraph_functions.cc:85067] got different data type, run type promotion automatically, this may cause data type been changed.
[accuracy error] paddle.Tensor.std(Tensor([0, 1024, 8],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array(0.)
 DESIRED: array(nan)

2025-05-21 22:07:41.911168 GPU 1 69612 test begin: paddle.Tensor.std(Tensor([1, 0, 36],"float32"), axis=-1, keepdim=True, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0521 22:07:42.101178 69612 dygraph_functions.cc:85067] got different data type, run type promotion automatically, this may cause data type been changed.
W0521 22:07:42.108770 69612 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.std(Tensor([1, 0, 36],"float32"), axis=-1, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:41.966000 GPU 1 69608 test begin: paddle.Tensor.std(Tensor([1, 0, 45],"float32"), axis=-1, keepdim=True, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0521 22:07:42.237018 69608 dygraph_functions.cc:85067] got different data type, run type promotion automatically, this may cause data type been changed.
W0521 22:07:42.240127 69608 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.std(Tensor([1, 0, 45],"float32"), axis=-1, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:41.968873 GPU 1 69598 test begin: paddle.Tensor.std(Tensor([1, 1, 0],"float32"), axis=-1, keepdim=True, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0521 22:07:42.214084 69598 dygraph_functions.cc:85067] got different data type, run type promotion automatically, this may cause data type been changed.
[accuracy error] paddle.Tensor.std(Tensor([1, 1, 0],"float32"), axis=-1, keepdim=True, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array([[[0.]]], dtype=float32)
 DESIRED: array([[[nan]]], dtype=float32)

2025-05-21 22:07:42.039803 GPU 1 69602 test begin: paddle.Tensor.std(Tensor([1024, 0, 8],"float32"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0521 22:07:42.336278 69602 dygraph_functions.cc:85067] got different data type, run type promotion automatically, this may cause data type been changed.
[accuracy error] paddle.Tensor.std(Tensor([1024, 0, 8],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array(0., dtype=float32)
 DESIRED: array(nan, dtype=float32)

2025-05-21 22:07:42.067939 GPU 1 69603 test begin: paddle.Tensor.std(Tensor([1024, 0, 8],"float64"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0521 22:07:42.184844 69603 dygraph_functions.cc:85067] got different data type, run type promotion automatically, this may cause data type been changed.
[accuracy error] paddle.Tensor.std(Tensor([1024, 0, 8],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array(0.)
 DESIRED: array(nan)

2025-05-21 22:07:42.075880 GPU 1 69621 test begin: paddle.Tensor.std(Tensor([1024, 1024, 0],"float32"), )
[accuracy error] paddle.Tensor.std(Tensor([1024, 1024, 0],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array(0., dtype=float32)
 DESIRED: array(nan, dtype=float32)

2025-05-21 22:07:42.090697 GPU 1 69606 test begin: paddle.Tensor.std(Tensor([1024, 1024, 0],"float64"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0521 22:07:42.251296 69606 dygraph_functions.cc:85067] got different data type, run type promotion automatically, this may cause data type been changed.
[accuracy error] paddle.Tensor.std(Tensor([1024, 1024, 0],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array(0.)
 DESIRED: array(nan)

2025-05-21 22:07:42.095431 GPU 1 69599 test begin: paddle.Tensor.topk(Tensor([0, 1000],"float32"), 5, 1, True, True, )
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.topk(Tensor([0, 1000],"float32"), 5, 1, True, True, ) 
 (InvalidArgument) x has only 0 element, can not find 5 top values.
  [Hint: Expected x.numel() >= k, but received x.numel():0 < k:5.] (at ../paddle/phi/kernels/gpu/top_k_kernel.cu:80)


2025-05-21 22:07:42.098259 GPU 1 69609 test begin: paddle.Tensor.tril(Tensor([0, 2, 2],"float32"), -1, )
[cuda error] paddle.Tensor.tril(Tensor([0, 2, 2],"float32"), -1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:42.110699 GPU 1 69612 test begin: paddle.Tensor.tril(Tensor([0, 2],"float32"), -1, )
[cuda error] paddle.Tensor.tril(Tensor([0, 2],"float32"), -1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:42.128053 GPU 1 69596 test begin: paddle.Tensor.tril(Tensor([1, 0, 2],"float32"), -1, )
[cuda error] paddle.Tensor.tril(Tensor([1, 0, 2],"float32"), -1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:42.136604 GPU 1 69611 test begin: paddle.Tensor.tril(Tensor([1, 2, 0],"float32"), -1, )
[cuda error] paddle.Tensor.tril(Tensor([1, 2, 0],"float32"), -1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:42.158762 GPU 1 69619 test begin: paddle.Tensor.tril(Tensor([2, 0, 2],"float32"), -1, )
[cuda error] paddle.Tensor.tril(Tensor([2, 0, 2],"float32"), -1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:42.164549 GPU 1 69617 test begin: paddle.Tensor.tril(Tensor([2, 0],"float32"), -1, )
[cuda error] paddle.Tensor.tril(Tensor([2, 0],"float32"), -1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:42.187210 GPU 1 69603 test begin: paddle.Tensor.tril(Tensor([2, 2, 0],"float32"), -1, )
[cuda error] paddle.Tensor.tril(Tensor([2, 2, 0],"float32"), -1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:42.189847 GPU 1 69629 test begin: paddle.Tensor.var(Tensor([0, 2, 3],"float32"), axis=0, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
[accuracy error] paddle.Tensor.var(Tensor([0, 2, 3],"float32"), axis=0, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array([[0., 0., 0.],
       [0., 0., 0.]], dtype=float32)
 DESIRED: array([[nan, nan, nan],
       [nan, nan, nan]], dtype=float32)

2025-05-21 22:07:42.216564 GPU 1 69621 test begin: paddle.Tensor.var(Tensor([0, 2, 3],"float64"), axis=0, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
[accuracy error] paddle.Tensor.var(Tensor([0, 2, 3],"float64"), axis=0, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array([[0., 0., 0.],
       [0., 0., 0.]])
 DESIRED: array([[nan, nan, nan],
       [nan, nan, nan]])

2025-05-21 22:07:42.218907 GPU 1 69598 test begin: paddle.Tensor.var(Tensor([0, 4],"float64"), axis=0, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
[accuracy error] paddle.Tensor.var(Tensor([0, 4],"float64"), axis=0, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array([0., 0., 0., 0.])
 DESIRED: array([nan, nan, nan, nan])

2025-05-21 22:07:42.241512 GPU 1 69599 test begin: paddle.Tensor.var(Tensor([0, 784],"float32"), axis=0, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0521 22:07:42.393524 69599 dygraph_functions.cc:85067] got different data type, run type promotion automatically, this may cause data type been changed.
[accuracy error] paddle.Tensor.var(Tensor([0, 784],"float32"), axis=0, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,...
 DESIRED: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,...

2025-05-21 22:07:42.241817 GPU 1 69608 test begin: paddle.Tensor.var(Tensor([0],"float32"), axis=0, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
[accuracy error] paddle.Tensor.var(Tensor([0],"float32"), axis=0, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array(0., dtype=float32)
 DESIRED: array(nan, dtype=float32)

2025-05-21 22:07:42.247344 GPU 1 69609 test begin: paddle.Tensor.var(Tensor([0],"float64"), axis=0, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
[accuracy error] paddle.Tensor.var(Tensor([0],"float64"), axis=0, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array(0.)
 DESIRED: array(nan)

2025-05-21 22:07:42.249262 GPU 1 69612 test begin: paddle.Tensor.var(Tensor([1000, 0],"float32"), axis=0, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0521 22:07:42.405994 69612 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.var(Tensor([1000, 0],"float32"), axis=0, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.260160 GPU 1 69606 test begin: paddle.Tensor.var(Tensor([10000, 0, 3],"float32"), axis=0, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0521 22:07:42.414544 69606 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.var(Tensor([10000, 0, 3],"float32"), axis=0, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.279707 GPU 1 69596 test begin: paddle.Tensor.var(Tensor([10000, 0, 3],"float64"), axis=0, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0521 22:07:42.432593 69596 dygraph_functions.cc:85067] got different data type, run type promotion automatically, this may cause data type been changed.
W0521 22:07:42.435634 69596 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.var(Tensor([10000, 0, 3],"float64"), axis=0, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.281914 GPU 1 69600 test begin: paddle.Tensor.var(Tensor([10000, 2, 0],"float32"), axis=0, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0521 22:07:42.594606 69600 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.var(Tensor([10000, 2, 0],"float32"), axis=0, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.299438 GPU 1 69603 test begin: paddle.Tensor.var(Tensor([10000, 2, 0],"float64"), axis=0, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0521 22:07:42.415472 69603 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.var(Tensor([10000, 2, 0],"float64"), axis=0, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.333174 GPU 1 69616 test begin: paddle.Tensor.var(Tensor([100000, 0],"float64"), axis=0, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0521 22:07:42.630971 69616 dygraph_functions.cc:85067] got different data type, run type promotion automatically, this may cause data type been changed.
W0521 22:07:42.633922 69616 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.var(Tensor([100000, 0],"float64"), axis=0, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.344019 GPU 1 69611 test begin: paddle.addmm(input=Tensor([1, 1],"float64"), x=Tensor([0, 4],"float64"), y=Tensor([4, 5],"float64"), beta=-3.3, alpha=3.3, )
[paddle error] paddle.addmm(input=Tensor([1, 1],"float64"), x=Tensor([0, 4],"float64"), y=Tensor([4, 5],"float64"), beta=-3.3, alpha=3.3, ) 
 (PreconditionNotMet) The Input variable 'x' has not been initialized. You may need to confirm if you put exe.run(startup_program) after optimizer.minimize function.
  [Hint: Expected product(x_dims) != 0, but received product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/ternary.cc:109)


2025-05-21 22:07:42.345802 GPU 1 69602 test begin: paddle.addmm(input=Tensor([1, 1],"float64"), x=Tensor([5, 4],"float64"), y=Tensor([4, 0],"float64"), beta=-3.3, alpha=3.3, )
[paddle error] paddle.addmm(input=Tensor([1, 1],"float64"), x=Tensor([5, 4],"float64"), y=Tensor([4, 0],"float64"), beta=-3.3, alpha=3.3, ) 
 (PreconditionNotMet) The Input variable 'y' has not been initialized. You may need to confirm if you put exe.run(startup_program) after optimizer.minimize function.
  [Hint: Expected product(y_dims) != 0, but received product(y_dims):0 == 0:0.] (at ../paddle/phi/infermeta/ternary.cc:117)


2025-05-21 22:07:42.346904 GPU 1 69617 test begin: paddle.addmm(input=Tensor([5, 1],"float64"), x=Tensor([5, 4],"float64"), y=Tensor([4, 0],"float64"), beta=-3.3, alpha=3.3, )
[paddle error] paddle.addmm(input=Tensor([5, 1],"float64"), x=Tensor([5, 4],"float64"), y=Tensor([4, 0],"float64"), beta=-3.3, alpha=3.3, ) 
 (PreconditionNotMet) The Input variable 'y' has not been initialized. You may need to confirm if you put exe.run(startup_program) after optimizer.minimize function.
  [Hint: Expected product(y_dims) != 0, but received product(y_dims):0 == 0:0.] (at ../paddle/phi/infermeta/ternary.cc:117)


2025-05-21 22:07:42.348292 GPU 1 69621 test begin: paddle.amax(Tensor([0, 10, 10],"float32"), axis=list[-1,-2,], keepdim=False, )
[paddle error] paddle.amax(Tensor([0, 10, 10],"float32"), axis=list[-1,-2,], keepdim=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.395851 GPU 1 69619 test begin: paddle.amax(Tensor([0, 2, 4, 5],"float32"), axis=-1, keepdim=True, )
[paddle error] paddle.amax(Tensor([0, 2, 4, 5],"float32"), axis=-1, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.397471 GPU 1 69629 test begin: paddle.amax(Tensor([0, 2, 5, 4],"float32"), axis=2, keepdim=True, )
[paddle error] paddle.amax(Tensor([0, 2, 5, 4],"float32"), axis=2, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.406648 GPU 1 69609 test begin: paddle.amax(Tensor([0, 2, 5, 4],"float32"), axis=tuple(1,2,), keepdim=True, )
[paddle error] paddle.amax(Tensor([0, 2, 5, 4],"float32"), axis=tuple(1,2,), keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.407119 GPU 1 69612 test begin: paddle.amax(Tensor([0, 4],"float64"), 1, True, )
[paddle error] paddle.amax(Tensor([0, 4],"float64"), 1, True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.408127 GPU 1 69599 test begin: paddle.amax(Tensor([10, 0, 10],"float32"), axis=list[-1,0,], keepdim=False, )
[paddle error] paddle.amax(Tensor([10, 0, 10],"float32"), axis=list[-1,0,], keepdim=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.415369 GPU 1 69606 test begin: paddle.amax(Tensor([10, 10, 0],"float32"), axis=list[0,1,], keepdim=False, )
[paddle error] paddle.amax(Tensor([10, 10, 0],"float32"), axis=list[0,1,], keepdim=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.416236 GPU 1 69603 test begin: paddle.amax(Tensor([2, 0],"float64"), 0, False, )
[paddle error] paddle.amax(Tensor([2, 0],"float64"), 0, False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.417785 GPU 1 69604 test begin: paddle.amax(Tensor([2, 2, 0],"int32"), tuple(0,1,), False, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.amax(Tensor([2, 2, 0],"int32"), tuple(0,1,), False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.418157 GPU 1 69618 test begin: paddle.amax(Tensor([3, 0, 4, 5],"float32"), axis=-1, keepdim=True, )
[paddle error] paddle.amax(Tensor([3, 0, 4, 5],"float32"), axis=-1, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.420640 GPU 1 69615 test begin: paddle.amax(Tensor([3, 0, 5, 4],"float32"), axis=2, keepdim=True, )
[paddle error] paddle.amax(Tensor([3, 0, 5, 4],"float32"), axis=2, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.429615 GPU 1 69601 test begin: paddle.amax(Tensor([3, 2, 0, 5],"float32"), axis=-1, keepdim=True, )
[paddle error] paddle.amax(Tensor([3, 2, 0, 5],"float32"), axis=-1, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.437069 GPU 1 69596 test begin: paddle.amax(Tensor([3, 2, 5, 0],"float32"), axis=2, keepdim=True, )
[paddle error] paddle.amax(Tensor([3, 2, 5, 0],"float32"), axis=2, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.437700 GPU 1 69607 test begin: paddle.amax(Tensor([3, 2, 5, 0],"float32"), axis=tuple(1,2,), keepdim=True, )
[paddle error] paddle.amax(Tensor([3, 2, 5, 0],"float32"), axis=tuple(1,2,), keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.458264 GPU 1 69598 test begin: paddle.amin(Tensor([0, 10, 10],"float32"), axis=list[-1,-2,], keepdim=False, )
[paddle error] paddle.amin(Tensor([0, 10, 10],"float32"), axis=list[-1,-2,], keepdim=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.462439 GPU 1 69621 test begin: paddle.amin(Tensor([0, 2, 4, 5],"float32"), axis=-1, keepdim=True, )
[paddle error] paddle.amin(Tensor([0, 2, 4, 5],"float32"), axis=-1, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.497565 GPU 1 69605 test begin: paddle.amin(Tensor([0, 2, 5, 4],"float32"), axis=2, keepdim=True, )
[paddle error] paddle.amin(Tensor([0, 2, 5, 4],"float32"), axis=2, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.514243 GPU 1 69617 test begin: paddle.amin(Tensor([0, 2, 5, 4],"float32"), axis=tuple(1,2,), keepdim=True, )
[paddle error] paddle.amin(Tensor([0, 2, 5, 4],"float32"), axis=tuple(1,2,), keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.527108 GPU 1 69603 test begin: paddle.amin(Tensor([0, 4],"float64"), 1, True, )
[paddle error] paddle.amin(Tensor([0, 4],"float64"), 1, True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.529869 GPU 1 69610 test begin: paddle.amin(Tensor([10, 0, 10],"float32"), axis=list[-1,0,], keepdim=False, )
[paddle error] paddle.amin(Tensor([10, 0, 10],"float32"), axis=list[-1,0,], keepdim=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.543443 GPU 1 69606 test begin: paddle.amin(Tensor([10, 10, 0],"float32"), axis=list[0,1,], keepdim=False, )
[paddle error] paddle.amin(Tensor([10, 10, 0],"float32"), axis=list[0,1,], keepdim=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.548730 GPU 1 69611 test begin: paddle.amin(Tensor([2, 0],"float64"), 0, False, )
[paddle error] paddle.amin(Tensor([2, 0],"float64"), 0, False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.549338 GPU 1 69608 test begin: paddle.amin(Tensor([2, 2, 0],"int32"), tuple(0,1,), False, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.amin(Tensor([2, 2, 0],"int32"), tuple(0,1,), False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.558927 GPU 1 69609 test begin: paddle.amin(Tensor([3, 0, 4, 5],"float32"), axis=-1, keepdim=True, )
[paddle error] paddle.amin(Tensor([3, 0, 4, 5],"float32"), axis=-1, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.559433 GPU 1 69599 test begin: paddle.amin(Tensor([3, 0, 5, 4],"float32"), axis=2, keepdim=True, )
[paddle error] paddle.amin(Tensor([3, 0, 5, 4],"float32"), axis=2, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.572993 GPU 1 69621 test begin: paddle.amin(Tensor([3, 2, 0, 5],"float32"), axis=-1, keepdim=True, )
[paddle error] paddle.amin(Tensor([3, 2, 0, 5],"float32"), axis=-1, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.581567 GPU 1 69629 test begin: paddle.amin(Tensor([3, 2, 5, 0],"float32"), axis=2, keepdim=True, )
[paddle error] paddle.amin(Tensor([3, 2, 5, 0],"float32"), axis=2, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.582485 GPU 1 69618 test begin: paddle.amin(Tensor([3, 2, 5, 0],"float32"), axis=tuple(1,2,), keepdim=True, )
[paddle error] paddle.amin(Tensor([3, 2, 5, 0],"float32"), axis=tuple(1,2,), keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:42.584038 GPU 1 69614 test begin: paddle.angle(Tensor([0, 3],"complex128"), )
[cuda error] paddle.angle(Tensor([0, 3],"complex128"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:42.584864 GPU 1 69596 test begin: paddle.angle(Tensor([2, 0],"complex128"), )
[cuda error] paddle.angle(Tensor([2, 0],"complex128"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:42.587549 GPU 1 69612 test begin: paddle.argmax(Tensor([0, 1000],"float32"), axis=1, )
[paddle error] paddle.argmax(Tensor([0, 1000],"float32"), axis=1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.596305 GPU 1 69600 test begin: paddle.argmax(Tensor([0, 100],"float32"), axis=-1, )
[paddle error] paddle.argmax(Tensor([0, 100],"float32"), axis=-1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.625495 GPU 1 69619 test begin: paddle.argmax(Tensor([0, 1024, 50304],"float16"), -1, )
[paddle error] paddle.argmax(Tensor([0, 1024, 50304],"float16"), -1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.633993 GPU 1 69601 test begin: paddle.argmax(Tensor([0, 10],"float32"), axis=-1, keepdim=True, )
[paddle error] paddle.argmax(Tensor([0, 10],"float32"), axis=-1, keepdim=True, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.635635 GPU 1 69616 test begin: paddle.argmax(Tensor([0, 10],"float32"), axis=1, )
[paddle error] paddle.argmax(Tensor([0, 10],"float32"), axis=1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.637307 GPU 1 69603 test begin: paddle.argmax(Tensor([0, 2, 4, 16, 2],"float32"), axis=-1, )
[paddle error] paddle.argmax(Tensor([0, 2, 4, 16, 2],"float32"), axis=-1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.637457 GPU 1 69602 test begin: paddle.argmax(Tensor([0, 256],"float32"), axis=-1, )
[paddle error] paddle.argmax(Tensor([0, 256],"float32"), axis=-1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.678899 GPU 1 69598 test begin: paddle.argmax(Tensor([0, 3, 4],"float64"), axis=-1, keepdim=True, )
[paddle error] paddle.argmax(Tensor([0, 3, 4],"float64"), axis=-1, keepdim=True, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.681867 GPU 1 69621 test begin: paddle.argmax(Tensor([0, 32, 64],"float16"), axis=1, )
[paddle error] paddle.argmax(Tensor([0, 32, 64],"float16"), axis=1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.692577 GPU 1 69606 test begin: paddle.argmax(Tensor([0, 32, 64],"float32"), axis=1, )
[paddle error] paddle.argmax(Tensor([0, 32, 64],"float32"), axis=1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.694038 GPU 1 69618 test begin: paddle.argmax(Tensor([0, 7, 99],"float32"), axis=-1, )
[paddle error] paddle.argmax(Tensor([0, 7, 99],"float32"), axis=-1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.702638 GPU 1 69604 test begin: paddle.argmax(Tensor([0, 8, 14, 12],"float32"), axis=1, keepdim=True, )
[paddle error] paddle.argmax(Tensor([0, 8, 14, 12],"float32"), axis=1, keepdim=True, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.707981 GPU 1 69609 test begin: paddle.argmax(Tensor([1, 8, 0, 12],"float32"), axis=1, keepdim=True, )
[paddle error] paddle.argmax(Tensor([1, 8, 0, 12],"float32"), axis=1, keepdim=True, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.713223 GPU 1 69611 test begin: paddle.argmax(Tensor([1, 8, 14, 0],"float32"), axis=1, keepdim=True, )
[paddle error] paddle.argmax(Tensor([1, 8, 14, 0],"float32"), axis=1, keepdim=True, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.721926 GPU 1 69599 test begin: paddle.argmax(Tensor([12988, 32, 0],"float16"), axis=1, )
[paddle error] paddle.argmax(Tensor([12988, 32, 0],"float16"), axis=1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.729230 GPU 1 69596 test begin: paddle.argmax(Tensor([12988, 32, 0],"float32"), axis=1, )
[paddle error] paddle.argmax(Tensor([12988, 32, 0],"float32"), axis=1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.732588 GPU 1 69612 test begin: paddle.argmax(Tensor([13, 0, 4, 16, 2],"float32"), axis=-1, )
[paddle error] paddle.argmax(Tensor([13, 0, 4, 16, 2],"float32"), axis=-1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.743797 GPU 1 69601 test begin: paddle.argmax(Tensor([13, 0, 99],"float32"), axis=-1, )
[paddle error] paddle.argmax(Tensor([13, 0, 99],"float32"), axis=-1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.747576 GPU 1 69603 test begin: paddle.argmax(Tensor([13, 2, 0, 16, 2],"float32"), axis=-1, )
[paddle error] paddle.argmax(Tensor([13, 2, 0, 16, 2],"float32"), axis=-1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.748205 GPU 1 69615 test begin: paddle.argmax(Tensor([13, 2, 4, 0, 2],"float32"), axis=-1, )
[paddle error] paddle.argmax(Tensor([13, 2, 4, 0, 2],"float32"), axis=-1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.749329 GPU 1 69614 test begin: paddle.argmax(Tensor([16, 0, 50304],"float16"), -1, )
[paddle error] paddle.argmax(Tensor([16, 0, 50304],"float16"), -1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.755733 GPU 1 69629 test begin: paddle.argmax(Tensor([2, 0, 4],"float64"), axis=-1, keepdim=True, )
[paddle error] paddle.argmax(Tensor([2, 0, 4],"float64"), axis=-1, keepdim=True, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.770674 GPU 1 69602 test begin: paddle.argmax(Tensor([3, 0, 3, 3, 3, 3],"float64"), axis=0, )
[paddle error] paddle.argmax(Tensor([3, 0, 3, 3, 3, 3],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.774579 GPU 1 69607 test begin: paddle.argmax(Tensor([3, 3, 0, 3, 3, 3],"float64"), axis=0, )
[paddle error] paddle.argmax(Tensor([3, 3, 0, 3, 3, 3],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.790829 GPU 1 69621 test begin: paddle.argmax(Tensor([3, 3, 3, 0, 3, 3],"float64"), axis=0, )
[paddle error] paddle.argmax(Tensor([3, 3, 3, 0, 3, 3],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.791136 GPU 1 69610 test begin: paddle.argmax(Tensor([3, 3, 3, 3, 0, 3],"float64"), axis=0, )
[paddle error] paddle.argmax(Tensor([3, 3, 3, 3, 0, 3],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.800845 GPU 1 69616 test begin: paddle.argmax(Tensor([3, 3, 3, 3, 3, 0],"float64"), axis=0, )
[paddle error] paddle.argmax(Tensor([3, 3, 3, 3, 3, 0],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.804937 GPU 1 69618 test begin: paddle.argmax(Tensor([4, 0, 4, 4, 4],"float64"), axis=0, )
[paddle error] paddle.argmax(Tensor([4, 0, 4, 4, 4],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.806108 GPU 1 69617 test begin: paddle.argmax(Tensor([4, 4, 0, 4, 4],"float64"), axis=0, )
[paddle error] paddle.argmax(Tensor([4, 4, 0, 4, 4],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.843202 GPU 1 69606 test begin: paddle.argmax(Tensor([4, 4, 4, 0, 4],"float64"), axis=0, )
[paddle error] paddle.argmax(Tensor([4, 4, 4, 0, 4],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.845579 GPU 1 69608 test begin: paddle.argmax(Tensor([4, 4, 4, 4, 0],"float64"), axis=0, )
[paddle error] paddle.argmax(Tensor([4, 4, 4, 4, 0],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.846417 GPU 1 69619 test begin: paddle.argmax(Tensor([5, 0, 5, 5],"float64"), axis=0, )
[paddle error] paddle.argmax(Tensor([5, 0, 5, 5],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.855806 GPU 1 69601 test begin: paddle.argmax(Tensor([5, 5, 0, 5],"float64"), axis=0, )
[paddle error] paddle.argmax(Tensor([5, 5, 0, 5],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.857439 GPU 1 69603 test begin: paddle.argmax(Tensor([5, 5, 5, 0],"float64"), axis=0, )
[paddle error] paddle.argmax(Tensor([5, 5, 5, 0],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.858837 GPU 1 69614 test begin: paddle.argmax(x=Tensor([0, 3, 4],"float64"), axis=1, keepdim=False, )
[paddle error] paddle.argmax(x=Tensor([0, 3, 4],"float64"), axis=1, keepdim=False, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.859244 GPU 1 69609 test begin: paddle.argmax(x=Tensor([0, 3],"int64"), axis=-1, )
[paddle error] paddle.argmax(x=Tensor([0, 3],"int64"), axis=-1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.865973 GPU 1 69599 test begin: paddle.argmax(x=Tensor([3, 0],"int64"), axis=-2, )
[paddle error] paddle.argmax(x=Tensor([3, 0],"int64"), axis=-2, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.873498 GPU 1 69596 test begin: paddle.argmax(x=Tensor([3, 3, 0],"float64"), axis=1, keepdim=False, )
[paddle error] paddle.argmax(x=Tensor([3, 3, 0],"float64"), axis=1, keepdim=False, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.874831 GPU 1 69612 test begin: paddle.argmin(Tensor([0, 10],"float32"), axis=-1, )
[paddle error] paddle.argmin(Tensor([0, 10],"float32"), axis=-1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.878338 GPU 1 69629 test begin: paddle.argmin(Tensor([0, 10],"float32"), axis=-1, keepdim=True, )
[paddle error] paddle.argmin(Tensor([0, 10],"float32"), axis=-1, keepdim=True, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.884984 GPU 1 69602 test begin: paddle.argmin(Tensor([0, 10],"float32"), axis=1, )
[paddle error] paddle.argmin(Tensor([0, 10],"float32"), axis=1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.885930 GPU 1 69605 test begin: paddle.argmin(Tensor([3, 0, 3, 3, 3, 3],"float64"), axis=0, )
[paddle error] paddle.argmin(Tensor([3, 0, 3, 3, 3, 3],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.895765 GPU 1 69598 test begin: paddle.argmin(Tensor([3, 3, 0, 3, 3, 3],"float64"), axis=0, )
[paddle error] paddle.argmin(Tensor([3, 3, 0, 3, 3, 3],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.899760 GPU 1 69621 test begin: paddle.argmin(Tensor([3, 3, 3, 0, 3, 3],"float64"), axis=0, )
[paddle error] paddle.argmin(Tensor([3, 3, 3, 0, 3, 3],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.904805 GPU 1 69611 test begin: paddle.argmin(Tensor([3, 3, 3, 3, 0, 3],"float64"), axis=0, )
[paddle error] paddle.argmin(Tensor([3, 3, 3, 3, 0, 3],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.910274 GPU 1 69615 test begin: paddle.argmin(Tensor([3, 3, 3, 3, 3, 0],"float64"), axis=0, )
[paddle error] paddle.argmin(Tensor([3, 3, 3, 3, 3, 0],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.911280 GPU 1 69600 test begin: paddle.argmin(Tensor([4, 0, 4, 4, 4],"float64"), axis=0, )
[paddle error] paddle.argmin(Tensor([4, 0, 4, 4, 4],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.914138 GPU 1 69618 test begin: paddle.argmin(Tensor([4, 4, 0, 4, 4],"float64"), axis=0, )
[paddle error] paddle.argmin(Tensor([4, 4, 0, 4, 4],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.937719 GPU 1 69604 test begin: paddle.argmin(Tensor([4, 4, 4, 0, 4],"float64"), axis=0, )
[paddle error] paddle.argmin(Tensor([4, 4, 4, 0, 4],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.948839 GPU 1 69613 test begin: paddle.argmin(Tensor([4, 4, 4, 4, 0],"float64"), axis=0, )
[paddle error] paddle.argmin(Tensor([4, 4, 4, 4, 0],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.960684 GPU 1 69616 test begin: paddle.argmin(Tensor([5, 0, 5, 5],"float64"), axis=0, )
[paddle error] paddle.argmin(Tensor([5, 0, 5, 5],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.963474 GPU 1 69601 test begin: paddle.argmin(Tensor([5, 5, 0, 5],"float64"), axis=0, )
[paddle error] paddle.argmin(Tensor([5, 5, 0, 5],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.966767 GPU 1 69603 test begin: paddle.argmin(Tensor([5, 5, 5, 0],"float64"), axis=0, )
[paddle error] paddle.argmin(Tensor([5, 5, 5, 0],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.972393 GPU 1 69606 test begin: paddle.argmin(x=Tensor([0, 3, 4],"float64"), axis=1, keepdim=False, )
[paddle error] paddle.argmin(x=Tensor([0, 3, 4],"float64"), axis=1, keepdim=False, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.973282 GPU 1 69614 test begin: paddle.argmin(x=Tensor([0, 3],"int64"), axis=-1, )
[paddle error] paddle.argmin(x=Tensor([0, 3],"int64"), axis=-1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.996256 GPU 1 69629 test begin: paddle.argmin(x=Tensor([3, 0],"int64"), axis=-2, )
[paddle error] paddle.argmin(x=Tensor([3, 0],"int64"), axis=-2, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:42.999772 GPU 1 69602 test begin: paddle.argmin(x=Tensor([3, 3, 0],"float64"), axis=1, keepdim=False, )
[paddle error] paddle.argmin(x=Tensor([3, 3, 0],"float64"), axis=1, keepdim=False, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/arg_min_max_kernel.cu:226)


2025-05-21 22:07:43.000050 GPU 1 69612 test begin: paddle.atan2(Tensor([0, 17],"float64"), Tensor([0, 17],"float64"), )
[cuda error] paddle.atan2(Tensor([0, 17],"float64"), Tensor([0, 17],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.000897 GPU 1 69610 test begin: paddle.atan2(Tensor([0, 222, 333],"float64"), Tensor([222, 333],"float64"), )
[cuda error] paddle.atan2(Tensor([0, 222, 333],"float64"), Tensor([222, 333],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.004122 GPU 1 69609 test begin: paddle.atan2(Tensor([0, 3, 2],"float16"), Tensor([0, 3, 2],"float32"), )
W0521 22:07:43.122958 69609 dygraph_functions.cc:6780] got different data type, run type promotion automatically, this may cause data type been changed.
[cuda error] paddle.atan2(Tensor([0, 3, 2],"float16"), Tensor([0, 3, 2],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.007357 GPU 1 69596 test begin: paddle.atan2(Tensor([0, 3, 2],"float16"), Tensor([0, 3, 2],"float64"), )
W0521 22:07:43.139820 69596 dygraph_functions.cc:6780] got different data type, run type promotion automatically, this may cause data type been changed.
[cuda error] paddle.atan2(Tensor([0, 3, 2],"float16"), Tensor([0, 3, 2],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.008463 GPU 1 69621 test begin: paddle.atan2(Tensor([100],"float64"), Tensor([0, 100],"float64"), )
[cuda error] paddle.atan2(Tensor([100],"float64"), Tensor([0, 100],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.014469 GPU 1 69599 test begin: paddle.atan2(Tensor([11, 0],"float64"), Tensor([11, 0],"float64"), )
[cuda error] paddle.atan2(Tensor([11, 0],"float64"), Tensor([11, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.020414 GPU 1 69618 test begin: paddle.atan2(Tensor([4, 0, 2],"float16"), Tensor([4, 0, 2],"float32"), )
W0521 22:07:43.127458 69618 dygraph_functions.cc:6780] got different data type, run type promotion automatically, this may cause data type been changed.
[cuda error] paddle.atan2(Tensor([4, 0, 2],"float16"), Tensor([4, 0, 2],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.033581 GPU 1 69615 test begin: paddle.atan2(Tensor([4, 0, 2],"float16"), Tensor([4, 0, 2],"float64"), )
W0521 22:07:43.157413 69615 dygraph_functions.cc:6780] got different data type, run type promotion automatically, this may cause data type been changed.
[cuda error] paddle.atan2(Tensor([4, 0, 2],"float16"), Tensor([4, 0, 2],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.058229 GPU 1 69607 test begin: paddle.atan2(Tensor([4, 3, 0],"float16"), Tensor([4, 3, 0],"float32"), )
W0521 22:07:43.332090 69607 dygraph_functions.cc:6780] got different data type, run type promotion automatically, this may cause data type been changed.
[cuda error] paddle.atan2(Tensor([4, 3, 0],"float16"), Tensor([4, 3, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.068112 GPU 1 69619 test begin: paddle.atan2(Tensor([4, 3, 0],"float16"), Tensor([4, 3, 0],"float64"), )
W0521 22:07:43.306282 69619 dygraph_functions.cc:6780] got different data type, run type promotion automatically, this may cause data type been changed.
[cuda error] paddle.atan2(Tensor([4, 3, 0],"float16"), Tensor([4, 3, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.070413 GPU 1 69601 test begin: paddle.atan2(x=Tensor([0, 6, 6, 6, 6],"float64"), y=Tensor([0, 6, 6, 6, 6],"float64"), )
[cuda error] paddle.atan2(x=Tensor([0, 6, 6, 6, 6],"float64"), y=Tensor([0, 6, 6, 6, 6],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.070845 GPU 1 69611 test begin: paddle.atan2(x=Tensor([0, 6, 6, 6],"float64"), y=Tensor([0, 6, 6, 6],"float64"), )
[cuda error] paddle.atan2(x=Tensor([0, 6, 6, 6],"float64"), y=Tensor([0, 6, 6, 6],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.078330 GPU 1 69603 test begin: paddle.atan2(x=Tensor([0, 6, 6],"float64"), y=Tensor([0, 6, 6],"float64"), )
[cuda error] paddle.atan2(x=Tensor([0, 6, 6],"float64"), y=Tensor([0, 6, 6],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.087795 GPU 1 69606 test begin: paddle.atan2(x=Tensor([0, 6],"float16"), y=Tensor([0, 6],"float16"), )
[cuda error] paddle.atan2(x=Tensor([0, 6],"float16"), y=Tensor([0, 6],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.089365 GPU 1 69614 test begin: paddle.atan2(x=Tensor([0, 6],"float32"), y=Tensor([0, 6],"float32"), )
[cuda error] paddle.atan2(x=Tensor([0, 6],"float32"), y=Tensor([0, 6],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.091325 GPU 1 69616 test begin: paddle.atan2(x=Tensor([3, 0, 6, 6, 6],"float64"), y=Tensor([3, 0, 6, 6, 6],"float64"), )
[cuda error] paddle.atan2(x=Tensor([3, 0, 6, 6, 6],"float64"), y=Tensor([3, 0, 6, 6, 6],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.108167 GPU 1 69629 test begin: paddle.atan2(x=Tensor([3, 6, 0, 6, 6],"float64"), y=Tensor([3, 6, 0, 6, 6],"float64"), )
[cuda error] paddle.atan2(x=Tensor([3, 6, 0, 6, 6],"float64"), y=Tensor([3, 6, 0, 6, 6],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.112491 GPU 1 69602 test begin: paddle.atan2(x=Tensor([3, 6, 6, 0, 6],"float64"), y=Tensor([3, 6, 6, 0, 6],"float64"), )
[cuda error] paddle.atan2(x=Tensor([3, 6, 6, 0, 6],"float64"), y=Tensor([3, 6, 6, 0, 6],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.113240 GPU 1 69608 test begin: paddle.atan2(x=Tensor([3, 6, 6, 6, 0],"float64"), y=Tensor([3, 6, 6, 6, 0],"float64"), )
[cuda error] paddle.atan2(x=Tensor([3, 6, 6, 6, 0],"float64"), y=Tensor([3, 6, 6, 6, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.119907 GPU 1 69621 test begin: paddle.atan2(x=Tensor([6, 0, 6, 6],"float64"), y=Tensor([6, 0, 6, 6],"float64"), )
[cuda error] paddle.atan2(x=Tensor([6, 0, 6, 6],"float64"), y=Tensor([6, 0, 6, 6],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.125115 GPU 1 69617 test begin: paddle.atan2(x=Tensor([6, 0, 6],"float64"), y=Tensor([6, 0, 6],"float64"), )
[cuda error] paddle.atan2(x=Tensor([6, 0, 6],"float64"), y=Tensor([6, 0, 6],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.125271 GPU 1 69609 test begin: paddle.atan2(x=Tensor([6, 0],"float16"), y=Tensor([6, 0],"float16"), )
[cuda error] paddle.atan2(x=Tensor([6, 0],"float16"), y=Tensor([6, 0],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.129823 GPU 1 69618 test begin: paddle.atan2(x=Tensor([6, 0],"float32"), y=Tensor([6, 0],"float32"), )
[cuda error] paddle.atan2(x=Tensor([6, 0],"float32"), y=Tensor([6, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.129924 GPU 1 69599 test begin: paddle.atan2(x=Tensor([6, 6, 0, 6],"float64"), y=Tensor([6, 6, 0, 6],"float64"), )
[cuda error] paddle.atan2(x=Tensor([6, 6, 0, 6],"float64"), y=Tensor([6, 6, 0, 6],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.130356 GPU 1 69598 test begin: paddle.atan2(x=Tensor([6, 6, 0],"float64"), y=Tensor([6, 6, 0],"float64"), )
[cuda error] paddle.atan2(x=Tensor([6, 6, 0],"float64"), y=Tensor([6, 6, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.134343 GPU 1 69604 test begin: paddle.atan2(x=Tensor([6, 6, 6, 0],"float64"), y=Tensor([6, 6, 6, 0],"float64"), )
[cuda error] paddle.atan2(x=Tensor([6, 6, 6, 0],"float64"), y=Tensor([6, 6, 6, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.142087 GPU 1 69596 test begin: paddle.bmm(Tensor([0, 300, 128],"float32"), Tensor([0, 128, 30976],"float32"), )
W0521 22:07:43.390399 69596 backward.cc:437] While running Node (BmmGradNode) raises an EnforceNotMet exception
[paddle error] paddle.bmm(Tensor([0, 300, 128],"float32"), Tensor([0, 128, 30976],"float32"), ) 
 (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 15859712, memory's size is 0.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):15859712 > memory_size():0.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)


2025-05-21 22:07:43.160336 GPU 1 69615 test begin: paddle.bmm(Tensor([0, 300, 128],"float32"), Tensor([0, 128, 33856],"float32"), )
W0521 22:07:43.358767 69615 backward.cc:437] While running Node (BmmGradNode) raises an EnforceNotMet exception
[paddle error] paddle.bmm(Tensor([0, 300, 128],"float32"), Tensor([0, 128, 33856],"float32"), ) 
 (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 17334272, memory's size is 0.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):17334272 > memory_size():0.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)


2025-05-21 22:07:43.166886 GPU 1 69605 test begin: paddle.bmm(Tensor([1, 300, 128],"float32"), Tensor([1, 128, 0],"float32"), )
W0521 22:07:43.547106 69605 backward.cc:437] While running Node (BmmGradNode) raises an EnforceNotMet exception
[paddle error] paddle.bmm(Tensor([1, 300, 128],"float32"), Tensor([1, 128, 0],"float32"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:76)


2025-05-21 22:07:43.167732 GPU 1 69613 test begin: paddle.bmm(x=Tensor([0, 2, 3],"float32"), y=Tensor([0, 3, 2],"float32"), )
W0521 22:07:43.388042 69613 backward.cc:437] While running Node (BmmGradNode) raises an EnforceNotMet exception
[paddle error] paddle.bmm(x=Tensor([0, 2, 3],"float32"), y=Tensor([0, 3, 2],"float32"), ) 
 (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 24, memory's size is 0.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):24 > memory_size():0.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)


2025-05-21 22:07:43.182942 GPU 1 69601 test begin: paddle.bmm(x=Tensor([0, 2, 3],"float64"), y=Tensor([0, 3, 2],"float64"), )
W0521 22:07:43.304608 69601 backward.cc:437] While running Node (BmmGradNode) raises an EnforceNotMet exception
[paddle error] paddle.bmm(x=Tensor([0, 2, 3],"float64"), y=Tensor([0, 3, 2],"float64"), ) 
 (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 48, memory's size is 0.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):48 > memory_size():0.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)


2025-05-21 22:07:43.200979 GPU 1 69612 test begin: paddle.bmm(x=Tensor([2, 2, 3],"float32"), y=Tensor([2, 3, 0],"float32"), )
W0521 22:07:44.729084 69612 backward.cc:437] While running Node (BmmGradNode) raises an EnforceNotMet exception
[paddle error] paddle.bmm(x=Tensor([2, 2, 3],"float32"), y=Tensor([2, 3, 0],"float32"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:76)


2025-05-21 22:07:43.202403 GPU 1 69603 test begin: paddle.bmm(x=Tensor([2, 2, 3],"float64"), y=Tensor([2, 3, 0],"float64"), )
W0521 22:07:43.394066 69603 backward.cc:437] While running Node (BmmGradNode) raises an EnforceNotMet exception
[paddle error] paddle.bmm(x=Tensor([2, 2, 3],"float64"), y=Tensor([2, 3, 0],"float64"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:206)

 ** On entry to DgemmStridedBatched parameter number 8 had an illegal value

2025-05-21 22:07:43.205945 GPU 1 69606 test begin: paddle.bucketize(Tensor([0, 4],"float64"), Tensor([4],"float64"), )
[cuda error] paddle.bucketize(Tensor([0, 4],"float64"), Tensor([4],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.206727 GPU 1 69614 test begin: paddle.bucketize(Tensor([0, 4],"float64"), Tensor([4],"float64"), out_int32=True, )
[cuda error] paddle.bucketize(Tensor([0, 4],"float64"), Tensor([4],"float64"), out_int32=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.228662 GPU 1 69629 test begin: paddle.bucketize(Tensor([0, 4],"float64"), Tensor([4],"float64"), right=True, )
[cuda error] paddle.bucketize(Tensor([0, 4],"float64"), Tensor([4],"float64"), right=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.229954 GPU 1 69600 test begin: paddle.bucketize(Tensor([2, 0],"float64"), Tensor([4],"float64"), )
[cuda error] paddle.bucketize(Tensor([2, 0],"float64"), Tensor([4],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.229957 GPU 1 69621 test begin: paddle.bucketize(Tensor([2, 0],"float64"), Tensor([4],"float64"), out_int32=True, )
[cuda error] paddle.bucketize(Tensor([2, 0],"float64"), Tensor([4],"float64"), out_int32=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.230369 GPU 1 69611 test begin: paddle.bucketize(Tensor([2, 0],"float64"), Tensor([4],"float64"), right=True, )
[cuda error] paddle.bucketize(Tensor([2, 0],"float64"), Tensor([4],"float64"), right=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.233646 GPU 1 69616 test begin: paddle.column_stack(list[Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),], )
[Pass] paddle.column_stack(list[Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),], )

2025-05-21 22:07:43.238934 GPU 1 69618 test begin: paddle.column_stack(list[Tensor([0],"float64"),], )
[Pass] paddle.column_stack(list[Tensor([0],"float64"),], )

2025-05-21 22:07:43.256157 GPU 1 69602 test begin: paddle.complex(Tensor([0, 10],"float64"), Tensor([0, 10],"float64"), )
[Pass] paddle.complex(Tensor([0, 10],"float64"), Tensor([0, 10],"float64"), )

2025-05-21 22:07:43.270843 GPU 1 69599 test begin: paddle.complex(Tensor([0, 3, 4],"float32"), Tensor([0, 3, 4],"float32"), )
[Pass] paddle.complex(Tensor([0, 3, 4],"float32"), Tensor([0, 3, 4],"float32"), )

2025-05-21 22:07:43.274866 GPU 1 69609 test begin: paddle.complex(Tensor([0, 3],"float32"), Tensor([0, 3],"float32"), )
[Pass] paddle.complex(Tensor([0, 3],"float32"), Tensor([0, 3],"float32"), )

2025-05-21 22:07:43.305299 GPU 1 69601 test begin: paddle.complex(Tensor([0],"float32"), Tensor([0],"float32"), )
[Pass] paddle.complex(Tensor([0],"float32"), Tensor([0],"float32"), )

2025-05-21 22:07:43.335175 GPU 1 69607 test begin: paddle.complex(Tensor([0],"float64"), Tensor([0],"float64"), )
[Pass] paddle.complex(Tensor([0],"float64"), Tensor([0],"float64"), )

2025-05-21 22:07:43.360260 GPU 1 69615 test begin: paddle.complex(Tensor([10, 0],"float64"), Tensor([10, 0],"float64"), )
[Pass] paddle.complex(Tensor([10, 0],"float64"), Tensor([10, 0],"float64"), )

2025-05-21 22:07:43.381602 GPU 1 69604 test begin: paddle.complex(Tensor([2, 0, 4],"float32"), Tensor([2, 0, 4],"float32"), )
[Pass] paddle.complex(Tensor([2, 0, 4],"float32"), Tensor([2, 0, 4],"float32"), )

2025-05-21 22:07:43.388879 GPU 1 69613 test begin: paddle.complex(Tensor([2, 0],"float32"), Tensor([2, 0],"float32"), )
[Pass] paddle.complex(Tensor([2, 0],"float32"), Tensor([2, 0],"float32"), )

2025-05-21 22:07:43.390514 GPU 1 69610 test begin: paddle.complex(Tensor([2, 3, 0],"float32"), Tensor([2, 3, 0],"float32"), )
[Pass] paddle.complex(Tensor([2, 3, 0],"float32"), Tensor([2, 3, 0],"float32"), )

2025-05-21 22:07:43.390782 GPU 1 69598 test begin: paddle.complex(real=Tensor([0, 2, 3],"float32"), imag=Tensor([0, 2, 3],"float32"), )
[Pass] paddle.complex(real=Tensor([0, 2, 3],"float32"), imag=Tensor([0, 2, 3],"float32"), )

2025-05-21 22:07:43.391427 GPU 1 69596 test begin: paddle.complex(real=Tensor([0, 2, 3],"float64"), imag=Tensor([0, 2, 3],"float64"), )
[Pass] paddle.complex(real=Tensor([0, 2, 3],"float64"), imag=Tensor([0, 2, 3],"float64"), )

2025-05-21 22:07:43.393978 GPU 1 69614 test begin: paddle.complex(real=Tensor([0, 2],"float32"), imag=Tensor([0, 2],"float32"), )
[Pass] paddle.complex(real=Tensor([0, 2],"float32"), imag=Tensor([0, 2],"float32"), )

2025-05-21 22:07:43.394425 GPU 1 69619 test begin: paddle.complex(real=Tensor([0, 2],"float64"), imag=Tensor([0, 2],"float64"), )
[Pass] paddle.complex(real=Tensor([0, 2],"float64"), imag=Tensor([0, 2],"float64"), )

2025-05-21 22:07:43.394835 GPU 1 69606 test begin: paddle.complex(real=Tensor([0],"float32"), imag=Tensor([0],"float32"), )
[Pass] paddle.complex(real=Tensor([0],"float32"), imag=Tensor([0],"float32"), )

2025-05-21 22:07:43.394869 GPU 1 69603 test begin: paddle.complex(real=Tensor([0],"float64"), imag=Tensor([0],"float64"), )
[Pass] paddle.complex(real=Tensor([0],"float64"), imag=Tensor([0],"float64"), )

2025-05-21 22:07:43.396205 GPU 1 69608 test begin: paddle.complex(real=Tensor([3, 0],"float32"), imag=Tensor([3, 0],"float32"), )
[Pass] paddle.complex(real=Tensor([3, 0],"float32"), imag=Tensor([3, 0],"float32"), )

2025-05-21 22:07:43.491882 GPU 1 69618 test begin: paddle.complex(real=Tensor([3, 0],"float64"), imag=Tensor([3, 0],"float64"), )
[Pass] paddle.complex(real=Tensor([3, 0],"float64"), imag=Tensor([3, 0],"float64"), )

2025-05-21 22:07:43.496353 GPU 1 69602 test begin: paddle.complex(real=Tensor([9, 0, 3],"float32"), imag=Tensor([9, 0, 3],"float32"), )
[Pass] paddle.complex(real=Tensor([9, 0, 3],"float32"), imag=Tensor([9, 0, 3],"float32"), )

2025-05-21 22:07:43.496533 GPU 1 69601 test begin: paddle.complex(real=Tensor([9, 0, 3],"float64"), imag=Tensor([9, 0, 3],"float64"), )
[Pass] paddle.complex(real=Tensor([9, 0, 3],"float64"), imag=Tensor([9, 0, 3],"float64"), )

2025-05-21 22:07:43.507657 GPU 1 69599 test begin: paddle.complex(real=Tensor([9, 2, 0],"float32"), imag=Tensor([9, 2, 0],"float32"), )
[Pass] paddle.complex(real=Tensor([9, 2, 0],"float32"), imag=Tensor([9, 2, 0],"float32"), )

2025-05-21 22:07:43.510234 GPU 1 69609 test begin: paddle.complex(real=Tensor([9, 2, 0],"float64"), imag=Tensor([9, 2, 0],"float64"), )
[Pass] paddle.complex(real=Tensor([9, 2, 0],"float64"), imag=Tensor([9, 2, 0],"float64"), )

2025-05-21 22:07:43.528892 GPU 1 69610 test begin: paddle.cross(x=Tensor([0, 3, 3],"float64"), y=Tensor([0, 3, 3],"float64"), axis=1, )
[cuda error] paddle.cross(x=Tensor([0, 3, 3],"float64"), y=Tensor([0, 3, 3],"float64"), axis=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.539189 GPU 1 69607 test begin: paddle.cross(x=Tensor([0, 3, 3],"float64"), y=Tensor([0, 3, 3],"float64"), axis=2, )
[cuda error] paddle.cross(x=Tensor([0, 3, 3],"float64"), y=Tensor([0, 3, 3],"float64"), axis=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.541181 GPU 1 69596 test begin: paddle.cross(x=Tensor([0, 3],"float32"), y=Tensor([0, 3],"float32"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: Using torch.cross without specifying the dim arg is deprecated.
Please either pass the dim explicitly or simply use torch.linalg.cross.
The default value of dim will change to agree with that of linalg.cross in a future release. (Triggered internally at /pytorch/aten/src/ATen/native/Cross.cpp:62.)
  return func(*args, **kwargs)
[cuda error] paddle.cross(x=Tensor([0, 3],"float32"), y=Tensor([0, 3],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.544044 GPU 1 69617 test begin: paddle.cross(x=Tensor([0, 3],"float64"), y=Tensor([0, 3],"float64"), axis=-1, )
[cuda error] paddle.cross(x=Tensor([0, 3],"float64"), y=Tensor([0, 3],"float64"), axis=-1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.548290 GPU 1 69605 test begin: paddle.cross(x=Tensor([0, 3],"float64"), y=Tensor([0, 3],"float64"), axis=1, )
[cuda error] paddle.cross(x=Tensor([0, 3],"float64"), y=Tensor([0, 3],"float64"), axis=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.573685 GPU 1 69615 test begin: paddle.cross(x=Tensor([3, 0, 3],"float64"), y=Tensor([3, 0, 3],"float64"), axis=0, )
[cuda error] paddle.cross(x=Tensor([3, 0, 3],"float64"), y=Tensor([3, 0, 3],"float64"), axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.584387 GPU 1 69616 test begin: paddle.cross(x=Tensor([3, 0, 3],"float64"), y=Tensor([3, 0, 3],"float64"), axis=2, )
[cuda error] paddle.cross(x=Tensor([3, 0, 3],"float64"), y=Tensor([3, 0, 3],"float64"), axis=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.609344 GPU 1 69598 test begin: paddle.cross(x=Tensor([3, 0],"float32"), y=Tensor([3, 0],"float32"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: Using torch.cross without specifying the dim arg is deprecated.
Please either pass the dim explicitly or simply use torch.linalg.cross.
The default value of dim will change to agree with that of linalg.cross in a future release. (Triggered internally at /pytorch/aten/src/ATen/native/Cross.cpp:62.)
  return func(*args, **kwargs)
[cuda error] paddle.cross(x=Tensor([3, 0],"float32"), y=Tensor([3, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.648893 GPU 1 69618 test begin: paddle.cross(x=Tensor([3, 0],"float64"), y=Tensor([3, 0],"float64"), axis=0, )
[cuda error] paddle.cross(x=Tensor([3, 0],"float64"), y=Tensor([3, 0],"float64"), axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.651980 GPU 1 69603 test begin: paddle.cross(x=Tensor([3, 3, 0],"float64"), y=Tensor([3, 3, 0],"float64"), axis=0, )
[cuda error] paddle.cross(x=Tensor([3, 3, 0],"float64"), y=Tensor([3, 3, 0],"float64"), axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.653714 GPU 1 69599 test begin: paddle.cross(x=Tensor([3, 3, 0],"float64"), y=Tensor([3, 3, 0],"float64"), axis=1, )
[cuda error] paddle.cross(x=Tensor([3, 3, 0],"float64"), y=Tensor([3, 3, 0],"float64"), axis=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.654600 GPU 1 69606 test begin: paddle.cumsum(Tensor([0, 10],"int64"), 1, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.cumsum(Tensor([0, 10],"int64"), 1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.658181 GPU 1 69602 test begin: paddle.cumsum(Tensor([0, 1],"int64"), axis=-1, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.cumsum(Tensor([0, 1],"int64"), axis=-1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.659693 GPU 1 69609 test begin: paddle.cumsum(Tensor([0, 2, 4],"float32"), axis=1, )
[cuda error] paddle.cumsum(Tensor([0, 2, 4],"float32"), axis=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.666388 GPU 1 69601 test begin: paddle.cumsum(Tensor([0, 20],"int64"), axis=1, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.cumsum(Tensor([0, 20],"int64"), axis=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.666571 GPU 1 69608 test begin: paddle.cumsum(Tensor([1, 0],"float32"), axis=0, )
[cuda error] paddle.cumsum(Tensor([1, 0],"float32"), axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.676640 GPU 1 69610 test begin: paddle.cumsum(Tensor([3, 0],"int64"), axis=-2, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.cumsum(Tensor([3, 0],"int64"), axis=-2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.692924 GPU 1 69604 test begin: paddle.cumsum(Tensor([3, 2, 0],"float32"), axis=1, )
[cuda error] paddle.cumsum(Tensor([3, 2, 0],"float32"), axis=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.697325 GPU 1 69611 test begin: paddle.cumsum(x=Tensor([0, 16, 96, 32],"float64"), axis=2, )
[cuda error] paddle.cumsum(x=Tensor([0, 16, 96, 32],"float64"), axis=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.737766 GPU 1 69613 test begin: paddle.cumsum(x=Tensor([0, 2, 1, 3],"float64"), axis=3, )
[cuda error] paddle.cumsum(x=Tensor([0, 2, 1, 3],"float64"), axis=3, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.802288 GPU 1 69601 test begin: paddle.cumsum(x=Tensor([1, 0, 1, 3],"float64"), axis=-4, )
[cuda error] paddle.cumsum(x=Tensor([1, 0, 1, 3],"float64"), axis=-4, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.810537 GPU 1 69608 test begin: paddle.cumsum(x=Tensor([1, 0, 1, 3],"float64"), axis=3, )
[cuda error] paddle.cumsum(x=Tensor([1, 0, 1, 3],"float64"), axis=3, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.811639 GPU 1 69614 test begin: paddle.cumsum(x=Tensor([1, 0, 96, 32],"float64"), axis=2, )
[cuda error] paddle.cumsum(x=Tensor([1, 0, 96, 32],"float64"), axis=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.813151 GPU 1 69596 test begin: paddle.cumsum(x=Tensor([1, 16, 96, 0],"float64"), axis=2, )
[cuda error] paddle.cumsum(x=Tensor([1, 16, 96, 0],"float64"), axis=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.821011 GPU 1 69607 test begin: paddle.cumsum(x=Tensor([1, 2, 0, 3],"float64"), axis=-4, )
[cuda error] paddle.cumsum(x=Tensor([1, 2, 0, 3],"float64"), axis=-4, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.835544 GPU 1 69604 test begin: paddle.cumsum(x=Tensor([1, 2, 0, 3],"float64"), axis=3, )
[cuda error] paddle.cumsum(x=Tensor([1, 2, 0, 3],"float64"), axis=3, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.862311 GPU 1 69621 test begin: paddle.cumsum(x=Tensor([1, 2, 1, 0],"float64"), axis=-4, )
[cuda error] paddle.cumsum(x=Tensor([1, 2, 1, 0],"float64"), axis=-4, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:43.866437 GPU 1 69611 test begin: paddle.cumulative_trapezoid(y=Tensor([0, 4],"float16"), x=Tensor([0, 4],"float16"), )
[paddle error] paddle.cumulative_trapezoid(y=Tensor([0, 4],"float16"), x=Tensor([0, 4],"float16"), ) 
 (PreconditionNotMet) Tensor not initialized yet when DenseTensor::place() is called.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:62)


2025-05-21 22:07:43.971891 GPU 1 69603 test begin: paddle.cumulative_trapezoid(y=Tensor([4, 0],"float16"), x=Tensor([4, 0],"float16"), )
[paddle error] paddle.cumulative_trapezoid(y=Tensor([4, 0],"float16"), x=Tensor([4, 0],"float16"), ) 
 (PreconditionNotMet) Tensor not initialized yet when DenseTensor::place() is called.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:62)


2025-05-21 22:07:43.972683 GPU 1 69618 test begin: paddle.diag(Tensor([0, 10],"float32"), offset=-1, )
Warning: The core code of paddle.diag is too complex.
[paddle error] paddle.diag(Tensor([0, 10],"float32"), offset=-1, ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-05-21 22:07:43.977551 GPU 1 69599 test begin: paddle.diag(Tensor([10, 0],"float32"), offset=1, )
Warning: The core code of paddle.diag is too complex.
[paddle error] paddle.diag(Tensor([10, 0],"float32"), offset=1, ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-05-21 22:07:43.979674 GPU 1 69610 test begin: paddle.diag(x=Tensor([0, 3],"float64"), offset=-1, )
Warning: The core code of paddle.diag is too complex.
[paddle error] paddle.diag(x=Tensor([0, 3],"float64"), offset=-1, ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-05-21 22:07:43.981537 GPU 1 69614 test begin: paddle.diag(x=Tensor([2, 0],"float64"), offset=2, )
Warning: The core code of paddle.diag is too complex.
[paddle error] paddle.diag(x=Tensor([2, 0],"float64"), offset=2, ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-05-21 22:07:44.001676 GPU 1 69606 test begin: paddle.diag(x=Tensor([3, 0],"float64"), offset=1, )
Warning: The core code of paddle.diag is too complex.
[paddle error] paddle.diag(x=Tensor([3, 0],"float64"), offset=1, ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-05-21 22:07:44.010684 GPU 1 69596 test begin: paddle.diag_embed(Tensor([0, 12],"float64"), )
[cuda error] paddle.diag_embed(Tensor([0, 12],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:44.016558 GPU 1 69609 test begin: paddle.diag_embed(Tensor([0, 3, 12],"float64"), )
[cuda error] paddle.diag_embed(Tensor([0, 3, 12],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:44.020798 GPU 1 69605 test begin: paddle.diag_embed(Tensor([0],"float64"), )
[cuda error] paddle.diag_embed(Tensor([0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:44.028975 GPU 1 69600 test begin: paddle.diag_embed(Tensor([1, 0],"float64"), )
[cuda error] paddle.diag_embed(Tensor([1, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:44.030010 GPU 1 69629 test begin: paddle.diag_embed(Tensor([2, 0, 12],"float64"), )
[cuda error] paddle.diag_embed(Tensor([2, 0, 12],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:44.067010 GPU 1 69621 test begin: paddle.diag_embed(Tensor([2, 3, 0],"float64"), )
[cuda error] paddle.diag_embed(Tensor([2, 3, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:44.068956 GPU 1 69601 test begin: paddle.diagonal(Tensor([0, 2, 2],"float32"), offset=0, axis1=-1, axis2=-2, )
W0521 22:07:44.303944 69601 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(Tensor([0, 2, 2],"float32"), offset=0, axis1=-1, axis2=-2, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.071367 GPU 1 69616 test begin: paddle.diagonal(Tensor([0, 3, 4],"float32"), )
W0521 22:07:44.399101 69616 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(Tensor([0, 3, 4],"float32"), ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.080523 GPU 1 69608 test begin: paddle.diagonal(Tensor([0, 3, 4],"float32"), offset=0, axis1=1, axis2=2, )
W0521 22:07:44.352715 69608 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(Tensor([0, 3, 4],"float32"), offset=0, axis1=1, axis2=2, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.085755 GPU 1 69602 test begin: paddle.diagonal(Tensor([0, 3, 4],"float32"), offset=0, axis1=2, axis2=1, )
W0521 22:07:44.353389 69602 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(Tensor([0, 3, 4],"float32"), offset=0, axis1=2, axis2=1, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.091700 GPU 1 69607 test begin: paddle.diagonal(Tensor([0, 3, 4],"float32"), offset=1, axis1=0, axis2=1, )
W0521 22:07:44.353703 69607 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(Tensor([0, 3, 4],"float32"), offset=1, axis1=0, axis2=1, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.106906 GPU 1 69598 test begin: paddle.diagonal(Tensor([1, 0, 2],"float32"), offset=0, axis1=-1, axis2=-2, )
W0521 22:07:44.519224 69598 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(Tensor([1, 0, 2],"float32"), offset=0, axis1=-1, axis2=-2, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.113231 GPU 1 69613 test begin: paddle.diagonal(Tensor([1, 2, 0],"float32"), offset=0, axis1=-1, axis2=-2, )
W0521 22:07:44.388427 69613 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(Tensor([1, 2, 0],"float32"), offset=0, axis1=-1, axis2=-2, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.143814 GPU 1 69615 test begin: paddle.diagonal(Tensor([10, 0, 4],"float32"), )
[paddle error] paddle.diagonal(Tensor([10, 0, 4],"float32"), ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)

W0521 22:07:44.525514 69615 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception

2025-05-21 22:07:44.151669 GPU 1 69596 test begin: paddle.diagonal(Tensor([10, 0, 4],"float32"), offset=0, axis1=1, axis2=2, )
W0521 22:07:44.490084 69596 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(Tensor([10, 0, 4],"float32"), offset=0, axis1=1, axis2=2, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.152410 GPU 1 69603 test begin: paddle.diagonal(Tensor([10, 0, 4],"float32"), offset=0, axis1=2, axis2=1, )
W0521 22:07:44.520105 69603 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(Tensor([10, 0, 4],"float32"), offset=0, axis1=2, axis2=1, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.156960 GPU 1 69610 test begin: paddle.diagonal(Tensor([10, 0, 4],"float32"), offset=1, axis1=0, axis2=1, )
W0521 22:07:44.521158 69610 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(Tensor([10, 0, 4],"float32"), offset=1, axis1=0, axis2=1, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.161305 GPU 1 69599 test begin: paddle.diagonal(Tensor([10, 3, 0],"float32"), )
W0521 22:07:44.520761 69599 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(Tensor([10, 3, 0],"float32"), ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.173923 GPU 1 69604 test begin: paddle.diagonal(Tensor([10, 3, 0],"float32"), offset=0, axis1=1, axis2=2, )
W0521 22:07:44.521762 69604 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(Tensor([10, 3, 0],"float32"), offset=0, axis1=1, axis2=2, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.194708 GPU 1 69600 test begin: paddle.diagonal(Tensor([10, 3, 0],"float32"), offset=0, axis1=2, axis2=1, )
W0521 22:07:44.451551 69600 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(Tensor([10, 3, 0],"float32"), offset=0, axis1=2, axis2=1, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.195737 GPU 1 69609 test begin: paddle.diagonal(Tensor([10, 3, 0],"float32"), offset=1, axis1=0, axis2=1, )
[cuda error] paddle.diagonal(Tensor([10, 3, 0],"float32"), offset=1, axis1=0, axis2=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:44.196876 GPU 1 69605 test begin: paddle.diagonal(x=Tensor([0, 6, 6, 2, 2],"float64"), )
W0521 22:07:44.480726 69605 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([0, 6, 6, 2, 2],"float64"), ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.232583 GPU 1 69606 test begin: paddle.diagonal(x=Tensor([0, 6, 6, 2, 2],"float64"), axis1=-1, axis2=2, )
W0521 22:07:44.583575 69606 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([0, 6, 6, 2, 2],"float64"), axis1=-1, axis2=2, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.249165 GPU 1 69618 test begin: paddle.diagonal(x=Tensor([0, 6, 6, 2, 2],"float64"), axis1=0, axis2=3, )
W0521 22:07:44.584036 69618 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([0, 6, 6, 2, 2],"float64"), axis1=0, axis2=3, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.251012 GPU 1 69614 test begin: paddle.diagonal(x=Tensor([0, 6, 6, 2, 2],"float64"), axis1=2, axis2=3, )
[paddle error] paddle.diagonal(x=Tensor([0, 6, 6, 2, 2],"float64"), axis1=2, axis2=3, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)

W0521 22:07:44.657406 69614 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception

2025-05-21 22:07:44.304573 GPU 1 69601 test begin: paddle.diagonal(x=Tensor([0, 6, 6, 2, 2],"float64"), axis1=3, axis2=4, )
W0521 22:07:44.622800 69601 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([0, 6, 6, 2, 2],"float64"), axis1=3, axis2=4, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.350089 GPU 1 69619 test begin: paddle.diagonal(x=Tensor([0, 6, 6, 2, 2],"float64"), axis1=4, axis2=2, )
W0521 22:07:44.763051 69619 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([0, 6, 6, 2, 2],"float64"), axis1=4, axis2=2, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.352768 GPU 1 69617 test begin: paddle.diagonal(x=Tensor([0, 6, 6, 6],"float64"), )
W0521 22:07:44.842221 69617 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([0, 6, 6, 6],"float64"), ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.353412 GPU 1 69608 test begin: paddle.diagonal(x=Tensor([0, 6, 6],"float64"), )
W0521 22:07:44.634173 69608 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([0, 6, 6],"float64"), ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.354035 GPU 1 69602 test begin: paddle.diagonal(x=Tensor([0, 6],"float32"), )
W0521 22:07:44.656268 69602 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([0, 6],"float32"), ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.354350 GPU 1 69607 test begin: paddle.diagonal(x=Tensor([0, 6],"float64"), offset=-1, )
W0521 22:07:44.662273 69607 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([0, 6],"float64"), offset=-1, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.355578 GPU 1 69621 test begin: paddle.diagonal(x=Tensor([0, 6],"float64"), offset=1, )
W0521 22:07:44.668467 69621 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([0, 6],"float64"), offset=1, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.389202 GPU 1 69613 test begin: paddle.diagonal(x=Tensor([6, 0, 6, 2, 2],"float64"), )
W0521 22:07:44.740633 69613 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([6, 0, 6, 2, 2],"float64"), ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.399851 GPU 1 69616 test begin: paddle.diagonal(x=Tensor([6, 0, 6, 2, 2],"float64"), axis1=-1, axis2=2, )
W0521 22:07:44.752696 69616 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([6, 0, 6, 2, 2],"float64"), axis1=-1, axis2=2, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.452205 GPU 1 69600 test begin: paddle.diagonal(x=Tensor([6, 0, 6, 2, 2],"float64"), axis1=0, axis2=3, )
W0521 22:07:44.639811 69600 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([6, 0, 6, 2, 2],"float64"), axis1=0, axis2=3, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.482087 GPU 1 69605 test begin: paddle.diagonal(x=Tensor([6, 0, 6, 2, 2],"float64"), axis1=2, axis2=3, )
W0521 22:07:44.717613 69605 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([6, 0, 6, 2, 2],"float64"), axis1=2, axis2=3, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.485859 GPU 1 69609 test begin: paddle.diagonal(x=Tensor([6, 0, 6, 2, 2],"float64"), axis1=3, axis2=4, )
W0521 22:07:44.764724 69609 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([6, 0, 6, 2, 2],"float64"), axis1=3, axis2=4, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.491080 GPU 1 69596 test begin: paddle.diagonal(x=Tensor([6, 0, 6, 2, 2],"float64"), axis1=4, axis2=2, )
W0521 22:07:44.683653 69596 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([6, 0, 6, 2, 2],"float64"), axis1=4, axis2=2, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.520038 GPU 1 69598 test begin: paddle.diagonal(x=Tensor([6, 0, 6, 6],"float64"), )
W0521 22:07:44.770663 69598 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([6, 0, 6, 6],"float64"), ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.520900 GPU 1 69603 test begin: paddle.diagonal(x=Tensor([6, 0, 6],"float64"), )
W0521 22:07:44.701603 69603 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([6, 0, 6],"float64"), ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.521664 GPU 1 69599 test begin: paddle.diagonal(x=Tensor([6, 0],"float32"), )
W0521 22:07:44.687705 69599 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([6, 0],"float32"), ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.522128 GPU 1 69610 test begin: paddle.diagonal(x=Tensor([6, 0],"float64"), offset=-1, )
W0521 22:07:44.775635 69610 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([6, 0],"float64"), offset=-1, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.522695 GPU 1 69604 test begin: paddle.diagonal(x=Tensor([6, 0],"float64"), offset=1, )
W0521 22:07:44.691558 69604 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([6, 0],"float64"), offset=1, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.522995 GPU 1 69629 test begin: paddle.diagonal(x=Tensor([6, 6, 0, 2, 2],"float64"), )
W0521 22:07:44.695547 69629 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([6, 6, 0, 2, 2],"float64"), ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.527130 GPU 1 69615 test begin: paddle.diagonal(x=Tensor([6, 6, 0, 2, 2],"float64"), axis1=-1, axis2=2, )
W0521 22:07:44.716213 69615 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([6, 6, 0, 2, 2],"float64"), axis1=-1, axis2=2, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.528296 GPU 1 69611 test begin: paddle.diagonal(x=Tensor([6, 6, 0, 2, 2],"float64"), axis1=0, axis2=3, )
W0521 22:07:44.728677 69611 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([6, 6, 0, 2, 2],"float64"), axis1=0, axis2=3, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.584615 GPU 1 69606 test begin: paddle.diagonal(x=Tensor([6, 6, 0, 2, 2],"float64"), axis1=2, axis2=3, )
W0521 22:07:44.837996 69606 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([6, 6, 0, 2, 2],"float64"), axis1=2, axis2=3, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.584924 GPU 1 69618 test begin: paddle.diagonal(x=Tensor([6, 6, 0, 2, 2],"float64"), axis1=3, axis2=4, )
W0521 22:07:44.823009 69618 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([6, 6, 0, 2, 2],"float64"), axis1=3, axis2=4, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.623527 GPU 1 69601 test begin: paddle.diagonal(x=Tensor([6, 6, 0, 2, 2],"float64"), axis1=4, axis2=2, )
W0521 22:07:44.735342 69601 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([6, 6, 0, 2, 2],"float64"), axis1=4, axis2=2, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.634856 GPU 1 69608 test begin: paddle.diagonal(x=Tensor([6, 6, 0, 6],"float64"), )
W0521 22:07:44.745399 69608 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([6, 6, 0, 6],"float64"), ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.641667 GPU 1 69600 test begin: paddle.diagonal(x=Tensor([6, 6, 0],"float64"), )
W0521 22:07:44.830444 69600 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([6, 6, 0],"float64"), ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.657145 GPU 1 69602 test begin: paddle.diagonal(x=Tensor([6, 6, 6, 0, 2],"float64"), )
W0521 22:07:44.775283 69602 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([6, 6, 6, 0, 2],"float64"), ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.658874 GPU 1 69614 test begin: paddle.diagonal(x=Tensor([6, 6, 6, 0, 2],"float64"), axis1=-1, axis2=2, )
W0521 22:07:44.967998 69614 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([6, 6, 6, 0, 2],"float64"), axis1=-1, axis2=2, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.662939 GPU 1 69607 test begin: paddle.diagonal(x=Tensor([6, 6, 6, 0, 2],"float64"), axis1=0, axis2=3, )
W0521 22:07:44.799238 69607 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([6, 6, 6, 0, 2],"float64"), axis1=0, axis2=3, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.669276 GPU 1 69621 test begin: paddle.diagonal(x=Tensor([6, 6, 6, 0, 2],"float64"), axis1=2, axis2=3, )
W0521 22:07:44.812685 69621 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([6, 6, 6, 0, 2],"float64"), axis1=2, axis2=3, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.684625 GPU 1 69596 test begin: paddle.diagonal(x=Tensor([6, 6, 6, 0, 2],"float64"), axis1=3, axis2=4, )
W0521 22:07:44.841830 69596 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([6, 6, 6, 0, 2],"float64"), axis1=3, axis2=4, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.688509 GPU 1 69599 test begin: paddle.diagonal(x=Tensor([6, 6, 6, 0, 2],"float64"), axis1=4, axis2=2, )
W0521 22:07:44.854759 69599 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([6, 6, 6, 0, 2],"float64"), axis1=4, axis2=2, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.692301 GPU 1 69604 test begin: paddle.diagonal(x=Tensor([6, 6, 6, 0],"float64"), )
W0521 22:07:44.852478 69604 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([6, 6, 6, 0],"float64"), ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.696326 GPU 1 69629 test begin: paddle.diagonal(x=Tensor([6, 6, 6, 2, 0],"float64"), )
W0521 22:07:44.825066 69629 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([6, 6, 6, 2, 0],"float64"), ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.702367 GPU 1 69603 test begin: paddle.diagonal(x=Tensor([6, 6, 6, 2, 0],"float64"), axis1=-1, axis2=2, )
W0521 22:07:44.816736 69603 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([6, 6, 6, 2, 0],"float64"), axis1=-1, axis2=2, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.717747 GPU 1 69615 test begin: paddle.diagonal(x=Tensor([6, 6, 6, 2, 0],"float64"), axis1=0, axis2=3, )
W0521 22:07:44.890547 69615 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([6, 6, 6, 2, 0],"float64"), axis1=0, axis2=3, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.719199 GPU 1 69605 test begin: paddle.diagonal(x=Tensor([6, 6, 6, 2, 0],"float64"), axis1=2, axis2=3, )
W0521 22:07:44.903334 69605 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([6, 6, 6, 2, 0],"float64"), axis1=2, axis2=3, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.729893 GPU 1 69611 test begin: paddle.diagonal(x=Tensor([6, 6, 6, 2, 0],"float64"), axis1=3, axis2=4, )
W0521 22:07:44.950831 69611 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([6, 6, 6, 2, 0],"float64"), axis1=3, axis2=4, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.730318 GPU 1 69612 test begin: paddle.diagonal(x=Tensor([6, 6, 6, 2, 0],"float64"), axis1=4, axis2=2, )
W0521 22:07:44.920224 69612 backward.cc:437] While running Node (DiagonalGradNode) raises an EnforceNotMet exception
[paddle error] paddle.diagonal(x=Tensor([6, 6, 6, 2, 0],"float64"), axis1=4, axis2=2, ) 
 (InvalidArgument) StridedCopyKernel's out tensor must complete mutable data before call kernel.
  [Hint: output_data should not be null.] (at ../paddle/phi/kernels/gpu/strided_copy_kernel.cu:1296)


2025-05-21 22:07:44.736077 GPU 1 69601 test begin: paddle.digamma(Tensor([0, 10, 10, 2],"float64"), )
[cuda error] paddle.digamma(Tensor([0, 10, 10, 2],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:44.741432 GPU 1 69613 test begin: paddle.digamma(Tensor([0, 2, 2],"float32"), )
[cuda error] paddle.digamma(Tensor([0, 2, 2],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:44.746007 GPU 1 69608 test begin: paddle.digamma(Tensor([0, 2],"float32"), )
[cuda error] paddle.digamma(Tensor([0, 2],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:44.753555 GPU 1 69616 test begin: paddle.digamma(Tensor([0],"float32"), )
[cuda error] paddle.digamma(Tensor([0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:44.763858 GPU 1 69619 test begin: paddle.digamma(Tensor([1, 0, 2],"float32"), )
[cuda error] paddle.digamma(Tensor([1, 0, 2],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:44.765711 GPU 1 69609 test begin: paddle.digamma(Tensor([1, 0],"float32"), )
[cuda error] paddle.digamma(Tensor([1, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:44.771490 GPU 1 69598 test begin: paddle.digamma(Tensor([1, 2, 0],"float32"), )
[cuda error] paddle.digamma(Tensor([1, 2, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:44.775917 GPU 1 69602 test begin: paddle.digamma(Tensor([10, 0, 10, 2],"float64"), )
[cuda error] paddle.digamma(Tensor([10, 0, 10, 2],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:44.777444 GPU 1 69610 test begin: paddle.digamma(Tensor([10, 10, 0, 2],"float64"), )
[cuda error] paddle.digamma(Tensor([10, 10, 0, 2],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:44.799979 GPU 1 69607 test begin: paddle.digamma(Tensor([10, 10, 10, 0],"float64"), )
[cuda error] paddle.digamma(Tensor([10, 10, 10, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:44.813632 GPU 1 69621 test begin: paddle.digamma(x=Tensor([0, 3],"float32"), )
[cuda error] paddle.digamma(x=Tensor([0, 3],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:44.817445 GPU 1 69603 test begin: paddle.digamma(x=Tensor([0, 6, 6, 6, 6],"float64"), )
[cuda error] paddle.digamma(x=Tensor([0, 6, 6, 6, 6],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:44.823845 GPU 1 69618 test begin: paddle.digamma(x=Tensor([0, 6, 6, 6],"float64"), )
[cuda error] paddle.digamma(x=Tensor([0, 6, 6, 6],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:44.825798 GPU 1 69629 test begin: paddle.digamma(x=Tensor([0, 6, 6],"float64"), )
[cuda error] paddle.digamma(x=Tensor([0, 6, 6],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:44.831244 GPU 1 69600 test begin: paddle.digamma(x=Tensor([3, 0, 6, 6, 6],"float64"), )
[cuda error] paddle.digamma(x=Tensor([3, 0, 6, 6, 6],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:44.838896 GPU 1 69606 test begin: paddle.digamma(x=Tensor([3, 0],"float32"), )
[cuda error] paddle.digamma(x=Tensor([3, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:44.843061 GPU 1 69596 test begin: paddle.digamma(x=Tensor([3, 6, 0, 6, 6],"float64"), )
[cuda error] paddle.digamma(x=Tensor([3, 6, 0, 6, 6],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:44.845323 GPU 1 69601 test begin: paddle.digamma(x=Tensor([3, 6, 6, 0, 6],"float64"), )
[cuda error] paddle.digamma(x=Tensor([3, 6, 6, 0, 6],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:44.850701 GPU 1 69617 test begin: paddle.digamma(x=Tensor([3, 6, 6, 6, 0],"float64"), )
[cuda error] paddle.digamma(x=Tensor([3, 6, 6, 6, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:44.853190 GPU 1 69604 test begin: paddle.digamma(x=Tensor([6, 0, 6, 6],"float64"), )
[cuda error] paddle.digamma(x=Tensor([6, 0, 6, 6],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:44.855989 GPU 1 69599 test begin: paddle.digamma(x=Tensor([6, 0, 6],"float64"), )
[cuda error] paddle.digamma(x=Tensor([6, 0, 6],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:44.856395 GPU 1 69608 test begin: paddle.digamma(x=Tensor([6, 6, 0, 6],"float64"), )
[cuda error] paddle.digamma(x=Tensor([6, 6, 0, 6],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:44.888062 GPU 1 69602 test begin: paddle.digamma(x=Tensor([6, 6, 0],"float64"), )
[cuda error] paddle.digamma(x=Tensor([6, 6, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:44.892120 GPU 1 69615 test begin: paddle.digamma(x=Tensor([6, 6, 6, 0],"float64"), )
[cuda error] paddle.digamma(x=Tensor([6, 6, 6, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:44.905070 GPU 1 69605 test begin: paddle.dist(Tensor([0, 2, 3, 2],"float32"), Tensor([0, 1, 3, 1],"float32"), 2, )
[paddle error] paddle.dist(Tensor([0, 2, 3, 2],"float32"), Tensor([0, 1, 3, 1],"float32"), 2, ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [0, 2, 3, 2].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-05-21 22:07:44.921778 GPU 1 69612 test begin: paddle.dist(Tensor([0, 2, 3, 2],"float32"), Tensor([1, 1, 3, 1],"float32"), 2, )
[paddle error] paddle.dist(Tensor([0, 2, 3, 2],"float32"), Tensor([1, 1, 3, 1],"float32"), 2, ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [0, 2, 3, 2].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-05-21 22:07:44.935293 GPU 1 69603 test begin: paddle.dist(Tensor([0, 2],"float32"), Tensor([0, 2],"float32"), 0, )
Expected a proper Tensor but got None (or an undefined Tensor in C++) for argument #0 'self'
[paddle error] paddle.dist(Tensor([0, 2],"float32"), Tensor([0, 2],"float32"), 0, ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [0, 2].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-05-21 22:07:44.942616 GPU 1 69629 test begin: paddle.dist(Tensor([2, 0, 3, 2],"float32"), Tensor([1, 0, 3, 1],"float32"), 2, )
[paddle error] paddle.dist(Tensor([2, 0, 3, 2],"float32"), Tensor([1, 0, 3, 1],"float32"), 2, ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [2, 0, 3, 2].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-05-21 22:07:44.947467 GPU 1 69607 test begin: paddle.dist(Tensor([2, 0, 3, 2],"float32"), Tensor([1, 1, 3, 1],"float32"), 2, )
[paddle error] paddle.dist(Tensor([2, 0, 3, 2],"float32"), Tensor([1, 1, 3, 1],"float32"), 2, ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [2, 0, 3, 2].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-05-21 22:07:44.948019 GPU 1 69610 test begin: paddle.dist(Tensor([2, 0],"float32"), Tensor([2, 0],"float32"), 0, )
Expected a proper Tensor but got None (or an undefined Tensor in C++) for argument #0 'self'
[paddle error] paddle.dist(Tensor([2, 0],"float32"), Tensor([2, 0],"float32"), 0, ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [2, 0].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-05-21 22:07:44.952436 GPU 1 69611 test begin: paddle.dist(Tensor([2, 2, 0, 2],"float32"), Tensor([1, 1, 0, 1],"float32"), 2, )
[paddle error] paddle.dist(Tensor([2, 2, 0, 2],"float32"), Tensor([1, 1, 0, 1],"float32"), 2, ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [2, 2, 0, 2].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-05-21 22:07:44.954271 GPU 1 69601 test begin: paddle.dist(Tensor([2, 2, 3, 0],"float32"), Tensor([1, 1, 3, 0],"float32"), 2, )
[paddle error] paddle.dist(Tensor([2, 2, 3, 0],"float32"), Tensor([1, 1, 3, 0],"float32"), 2, ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [2, 2, 3, 0].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-05-21 22:07:44.957975 GPU 1 69613 test begin: paddle.dist(Tensor([2, 2, 3, 0],"float32"), Tensor([1, 1, 3, 1],"float32"), 2, )
[paddle error] paddle.dist(Tensor([2, 2, 3, 0],"float32"), Tensor([1, 1, 3, 1],"float32"), 2, ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [2, 2, 3, 0].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-05-21 22:07:44.960742 GPU 1 69621 test begin: paddle.dist(x=Tensor([0, 1, 1, 4, 4],"float64"), y=Tensor([0, 8, 7, 1, 4],"float64"), )
[paddle error] paddle.dist(x=Tensor([0, 1, 1, 4, 4],"float64"), y=Tensor([0, 8, 7, 1, 4],"float64"), ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [0, 1, 1, 4, 4].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-05-21 22:07:44.966718 GPU 1 69608 test begin: paddle.dist(x=Tensor([0, 1, 4, 4],"float64"), y=Tensor([7, 1, 4],"float64"), )
[paddle error] paddle.dist(x=Tensor([0, 1, 4, 4],"float64"), y=Tensor([7, 1, 4],"float64"), ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [0, 1, 4, 4].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-05-21 22:07:44.969570 GPU 1 69614 test begin: paddle.dist(x=Tensor([0, 2],"float64"), y=Tensor([0, 2],"float64"), p=0, )
Expected a proper Tensor but got None (or an undefined Tensor in C++) for argument #0 'self'
[paddle error] paddle.dist(x=Tensor([0, 2],"float64"), y=Tensor([0, 2],"float64"), p=0, ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [0, 2].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-05-21 22:07:44.973609 GPU 1 69600 test begin: paddle.dist(x=Tensor([0, 4, 1, 3],"float64"), y=Tensor([4, 3, 1],"float64"), p=7, )
[paddle error] paddle.dist(x=Tensor([0, 4, 1, 3],"float64"), y=Tensor([4, 3, 1],"float64"), p=7, ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [0, 4, 1, 3].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-05-21 22:07:44.982463 GPU 1 69616 test begin: paddle.dist(x=Tensor([0, 4],"float32"), y=Tensor([0, 4],"float32"), )
[paddle error] paddle.dist(x=Tensor([0, 4],"float32"), y=Tensor([0, 4],"float32"), ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [0, 4].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-05-21 22:07:44.995019 GPU 1 69596 test begin: paddle.dist(x=Tensor([0, 4],"float64"), y=Tensor([0, 4],"float64"), p=1, )
[paddle error] paddle.dist(x=Tensor([0, 4],"float64"), y=Tensor([0, 4],"float64"), p=1, ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [0, 4].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-05-21 22:07:44.998216 GPU 1 69619 test begin: paddle.dist(x=Tensor([0],"float64"), y=Tensor([0],"float64"), )
[paddle error] paddle.dist(x=Tensor([0],"float64"), y=Tensor([0],"float64"), ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [0].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-05-21 22:07:45.001738 GPU 1 69598 test begin: paddle.dist(x=Tensor([10],"float64"), y=Tensor([0, 10],"float64"), )
[paddle error] paddle.dist(x=Tensor([10],"float64"), y=Tensor([0, 10],"float64"), ) 
 (InvalidArgument) The Input(Y) has not been initialized properly. The shape of Input(Y) = [0, 10].
  [Hint: Expected common::product(y_dims) != 0, but received common::product(y_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1377)


2025-05-21 22:07:45.001822 GPU 1 69618 test begin: paddle.dist(x=Tensor([10],"float64"), y=Tensor([0, 10],"float64"), p=4, )
[paddle error] paddle.dist(x=Tensor([10],"float64"), y=Tensor([0, 10],"float64"), p=4, ) 
 (InvalidArgument) The Input(Y) has not been initialized properly. The shape of Input(Y) = [0, 10].
  [Hint: Expected common::product(y_dims) != 0, but received common::product(y_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1377)


2025-05-21 22:07:45.004781 GPU 1 69609 test begin: paddle.dist(x=Tensor([2, 0, 1, 4, 4],"float64"), y=Tensor([2, 0, 7, 1, 4],"float64"), )
[paddle error] paddle.dist(x=Tensor([2, 0, 1, 4, 4],"float64"), y=Tensor([2, 0, 7, 1, 4],"float64"), ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [2, 0, 1, 4, 4].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-05-21 22:07:45.005391 GPU 1 69602 test begin: paddle.dist(x=Tensor([2, 0],"float64"), y=Tensor([2, 0],"float64"), p=0, )
Expected a proper Tensor but got None (or an undefined Tensor in C++) for argument #0 'self'
[paddle error] paddle.dist(x=Tensor([2, 0],"float64"), y=Tensor([2, 0],"float64"), p=0, ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [2, 0].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-05-21 22:07:45.011196 GPU 1 69604 test begin: paddle.dist(x=Tensor([2, 1, 0, 4, 4],"float64"), y=Tensor([2, 8, 0, 1, 4],"float64"), )
[paddle error] paddle.dist(x=Tensor([2, 1, 0, 4, 4],"float64"), y=Tensor([2, 8, 0, 1, 4],"float64"), ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [2, 1, 0, 4, 4].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-05-21 22:07:45.015497 GPU 1 69599 test begin: paddle.dist(x=Tensor([2, 1, 0, 4],"float64"), y=Tensor([7, 1, 4],"float64"), )
[paddle error] paddle.dist(x=Tensor([2, 1, 0, 4],"float64"), y=Tensor([7, 1, 4],"float64"), ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [2, 1, 0, 4].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-05-21 22:07:45.029097 GPU 1 69606 test begin: paddle.dist(x=Tensor([2, 1, 1, 0, 4],"float64"), y=Tensor([2, 8, 7, 0, 4],"float64"), )
[paddle error] paddle.dist(x=Tensor([2, 1, 1, 0, 4],"float64"), y=Tensor([2, 8, 7, 0, 4],"float64"), ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [2, 1, 1, 0, 4].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-05-21 22:07:45.047299 GPU 1 69603 test begin: paddle.dist(x=Tensor([2, 1, 1, 0, 4],"float64"), y=Tensor([2, 8, 7, 1, 4],"float64"), )
[paddle error] paddle.dist(x=Tensor([2, 1, 1, 0, 4],"float64"), y=Tensor([2, 8, 7, 1, 4],"float64"), ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [2, 1, 1, 0, 4].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-05-21 22:07:45.060279 GPU 1 69615 test begin: paddle.dist(x=Tensor([2, 1, 1, 4, 0],"float64"), y=Tensor([2, 8, 7, 1, 0],"float64"), )
[paddle error] paddle.dist(x=Tensor([2, 1, 1, 4, 0],"float64"), y=Tensor([2, 8, 7, 1, 0],"float64"), ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [2, 1, 1, 4, 0].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-05-21 22:07:45.065551 GPU 1 69612 test begin: paddle.dist(x=Tensor([2, 1, 1, 4, 4],"float64"), y=Tensor([2, 0, 7, 1, 4],"float64"), )
[paddle error] paddle.dist(x=Tensor([2, 1, 1, 4, 4],"float64"), y=Tensor([2, 0, 7, 1, 4],"float64"), ) 
 (InvalidArgument) The Input(Y) has not been initialized properly. The shape of Input(Y) = [2, 0, 7, 1, 4].
  [Hint: Expected common::product(y_dims) != 0, but received common::product(y_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1377)


2025-05-21 22:07:45.069555 GPU 1 69601 test begin: paddle.dist(x=Tensor([2, 1, 1, 4, 4],"float64"), y=Tensor([2, 8, 0, 1, 4],"float64"), )
[paddle error] paddle.dist(x=Tensor([2, 1, 1, 4, 4],"float64"), y=Tensor([2, 8, 0, 1, 4],"float64"), ) 
 (InvalidArgument) The Input(Y) has not been initialized properly. The shape of Input(Y) = [2, 8, 0, 1, 4].
  [Hint: Expected common::product(y_dims) != 0, but received common::product(y_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1377)


2025-05-21 22:07:45.069693 GPU 1 69629 test begin: paddle.dist(x=Tensor([2, 1, 4, 4],"float64"), y=Tensor([0, 1, 4],"float64"), )
[paddle error] paddle.dist(x=Tensor([2, 1, 4, 4],"float64"), y=Tensor([0, 1, 4],"float64"), ) 
 (InvalidArgument) The Input(Y) has not been initialized properly. The shape of Input(Y) = [0, 1, 4].
  [Hint: Expected common::product(y_dims) != 0, but received common::product(y_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1377)


2025-05-21 22:07:45.082511 GPU 1 69605 test begin: paddle.dist(x=Tensor([2, 4, 1, 0],"float64"), y=Tensor([4, 3, 1],"float64"), p=7, )
[paddle error] paddle.dist(x=Tensor([2, 4, 1, 0],"float64"), y=Tensor([4, 3, 1],"float64"), p=7, ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [2, 4, 1, 0].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-05-21 22:07:45.082678 GPU 1 69608 test begin: paddle.dist(x=Tensor([2, 4, 1, 3],"float64"), y=Tensor([4, 0, 1],"float64"), p=7, )
[paddle error] paddle.dist(x=Tensor([2, 4, 1, 3],"float64"), y=Tensor([4, 0, 1],"float64"), p=7, ) 
 (InvalidArgument) The Input(Y) has not been initialized properly. The shape of Input(Y) = [4, 0, 1].
  [Hint: Expected common::product(y_dims) != 0, but received common::product(y_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1377)


2025-05-21 22:07:45.086986 GPU 1 69607 test begin: paddle.dist(x=Tensor([4, 0],"float32"), y=Tensor([4, 0],"float32"), )
[paddle error] paddle.dist(x=Tensor([4, 0],"float32"), y=Tensor([4, 0],"float32"), ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [4, 0].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-05-21 22:07:45.102186 GPU 1 69621 test begin: paddle.dist(x=Tensor([4, 0],"float64"), y=Tensor([4, 0],"float64"), p=1, )
[paddle error] paddle.dist(x=Tensor([4, 0],"float64"), y=Tensor([4, 0],"float64"), p=1, ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [4, 0].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-05-21 22:07:45.105732 GPU 1 69617 test begin: paddle.dstack(list[Tensor([0, 1],"float64"),Tensor([0, 1],"float64"),Tensor([0, 1],"float64"),], )
[Pass] paddle.dstack(list[Tensor([0, 1],"float64"),Tensor([0, 1],"float64"),Tensor([0, 1],"float64"),], )

2025-05-21 22:07:45.106664 GPU 1 69610 test begin: paddle.dstack(list[Tensor([0, 1],"float64"),], )
[Pass] paddle.dstack(list[Tensor([0, 1],"float64"),], )

2025-05-21 22:07:45.107724 GPU 1 69600 test begin: paddle.dstack(list[Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),], )
[Pass] paddle.dstack(list[Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),], )

2025-05-21 22:07:45.117691 GPU 1 69596 test begin: paddle.dstack(list[Tensor([0],"float64"),], )
[Pass] paddle.dstack(list[Tensor([0],"float64"),], )

2025-05-21 22:07:45.119496 GPU 1 69602 test begin: paddle.dstack(list[Tensor([1, 0],"float64"),Tensor([1, 0],"float64"),Tensor([1, 0],"float64"),], )
[Pass] paddle.dstack(list[Tensor([1, 0],"float64"),Tensor([1, 0],"float64"),Tensor([1, 0],"float64"),], )

2025-05-21 22:07:45.159531 GPU 1 69603 test begin: paddle.dstack(list[Tensor([1, 0],"float64"),], )
[Pass] paddle.dstack(list[Tensor([1, 0],"float64"),], )

2025-05-21 22:07:45.163498 GPU 1 69611 test begin: paddle.fft.fft2(x=Tensor([3, 3, 2, 0],"complex128"), s=tuple(1,2,), )
[Pass] paddle.fft.fft2(x=Tensor([3, 3, 2, 0],"complex128"), s=tuple(1,2,), )

2025-05-21 22:07:45.163909 GPU 1 69606 test begin: paddle.fft.fftn(Tensor([3, 3, 2, 0],"complex128"), tuple(1,2,), tuple(-2,-1,), "backward", None, )
[Pass] paddle.fft.fftn(Tensor([3, 3, 2, 0],"complex128"), tuple(1,2,), tuple(-2,-1,), "backward", None, )

2025-05-21 22:07:45.170318 GPU 1 69599 test begin: paddle.fft.fftn(x=Tensor([4, 0, 6, 2],"float64"), s=list[2,4,], axes=tuple(0,1,), )
[Pass] paddle.fft.fftn(x=Tensor([4, 0, 6, 2],"float64"), s=list[2,4,], axes=tuple(0,1,), )

2025-05-21 22:07:45.184731 GPU 1 69604 test begin: paddle.fft.fftn(x=Tensor([4, 0, 6],"float64"), s=list[2,4,], )
[Pass] paddle.fft.fftn(x=Tensor([4, 0, 6],"float64"), s=list[2,4,], )

2025-05-21 22:07:45.184924 GPU 1 69601 test begin: paddle.fft.fftn(x=Tensor([4, 4, 0],"float64"), s=list[2,4,], )
[Pass] paddle.fft.fftn(x=Tensor([4, 4, 0],"float64"), s=list[2,4,], )

2025-05-21 22:07:45.185251 GPU 1 69613 test begin: paddle.fft.fftshift(x=Tensor([0, 4, 2],"float64"), )
[cuda error] paddle.fft.fftshift(x=Tensor([0, 4, 2],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.194850 GPU 1 69608 test begin: paddle.fft.fftshift(x=Tensor([0, 5, 4, 4],"complex128"), axes=3, )
[cuda error] paddle.fft.fftshift(x=Tensor([0, 5, 4, 4],"complex128"), axes=3, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.214308 GPU 1 69616 test begin: paddle.fft.fftshift(x=Tensor([0, 5, 4, 4],"complex128"), axes=tuple(1,3,), )
[cuda error] paddle.fft.fftshift(x=Tensor([0, 5, 4, 4],"complex128"), axes=tuple(1,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.214387 GPU 1 69621 test begin: paddle.fft.fftshift(x=Tensor([0],"float32"), )
[cuda error] paddle.fft.fftshift(x=Tensor([0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.221134 GPU 1 69618 test begin: paddle.fft.fftshift(x=Tensor([2, 0, 2],"float64"), )
[cuda error] paddle.fft.fftshift(x=Tensor([2, 0, 2],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.224196 GPU 1 69607 test begin: paddle.fft.fftshift(x=Tensor([2, 4, 0],"float64"), )
[cuda error] paddle.fft.fftshift(x=Tensor([2, 4, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.230113 GPU 1 69602 test begin: paddle.fft.fftshift(x=Tensor([4, 0, 4, 4],"complex128"), )
[cuda error] paddle.fft.fftshift(x=Tensor([4, 0, 4, 4],"complex128"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.234017 GPU 1 69612 test begin: paddle.fft.fftshift(x=Tensor([4, 0, 4, 4],"complex128"), axes=3, )
[cuda error] paddle.fft.fftshift(x=Tensor([4, 0, 4, 4],"complex128"), axes=3, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.236952 GPU 1 69598 test begin: paddle.fft.fftshift(x=Tensor([4, 0, 4, 4],"complex128"), axes=tuple(1,3,), )
[cuda error] paddle.fft.fftshift(x=Tensor([4, 0, 4, 4],"complex128"), axes=tuple(1,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.238723 GPU 1 69619 test begin: paddle.fft.fftshift(x=Tensor([4, 5, 0, 4],"complex128"), )
[cuda error] paddle.fft.fftshift(x=Tensor([4, 5, 0, 4],"complex128"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.241453 GPU 1 69629 test begin: paddle.fft.fftshift(x=Tensor([4, 5, 0, 4],"complex128"), axes=3, )
[cuda error] paddle.fft.fftshift(x=Tensor([4, 5, 0, 4],"complex128"), axes=3, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.242176 GPU 1 69605 test begin: paddle.fft.fftshift(x=Tensor([4, 5, 0, 4],"complex128"), axes=tuple(1,3,), )
[cuda error] paddle.fft.fftshift(x=Tensor([4, 5, 0, 4],"complex128"), axes=tuple(1,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.262694 GPU 1 69609 test begin: paddle.fft.fftshift(x=Tensor([4, 5, 4, 0],"complex128"), )
[cuda error] paddle.fft.fftshift(x=Tensor([4, 5, 4, 0],"complex128"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.267996 GPU 1 69600 test begin: paddle.fft.fftshift(x=Tensor([4, 5, 4, 0],"complex128"), axes=3, )
[cuda error] paddle.fft.fftshift(x=Tensor([4, 5, 4, 0],"complex128"), axes=3, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.268717 GPU 1 69615 test begin: paddle.fft.fftshift(x=Tensor([4, 5, 4, 0],"complex128"), axes=tuple(1,3,), )
[cuda error] paddle.fft.fftshift(x=Tensor([4, 5, 4, 0],"complex128"), axes=tuple(1,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.270825 GPU 1 69614 test begin: paddle.fft.ifft2(x=Tensor([3, 3, 2, 0],"complex128"), s=tuple(1,2,), )
[Pass] paddle.fft.ifft2(x=Tensor([3, 3, 2, 0],"complex128"), s=tuple(1,2,), )

2025-05-21 22:07:45.271447 GPU 1 69603 test begin: paddle.fft.ifftn(Tensor([3, 3, 2, 0],"complex128"), tuple(1,2,), tuple(-2,-1,), "backward", None, )
[Pass] paddle.fft.ifftn(Tensor([3, 3, 2, 0],"complex128"), tuple(1,2,), tuple(-2,-1,), "backward", None, )

2025-05-21 22:07:45.272741 GPU 1 69610 test begin: paddle.fft.ifftn(x=Tensor([4, 0, 6, 2],"float64"), s=list[2,4,], axes=tuple(0,1,), )
[Pass] paddle.fft.ifftn(x=Tensor([4, 0, 6, 2],"float64"), s=list[2,4,], axes=tuple(0,1,), )

2025-05-21 22:07:45.283736 GPU 1 69596 test begin: paddle.fft.ifftn(x=Tensor([4, 0, 6],"float64"), s=list[2,4,], )
[Pass] paddle.fft.ifftn(x=Tensor([4, 0, 6],"float64"), s=list[2,4,], )

2025-05-21 22:07:45.319116 GPU 1 69608 test begin: paddle.fft.ifftn(x=Tensor([4, 4, 0],"float64"), s=list[2,4,], )
[Pass] paddle.fft.ifftn(x=Tensor([4, 4, 0],"float64"), s=list[2,4,], )

2025-05-21 22:07:45.328598 GPU 1 69621 test begin: paddle.fft.ifftshift(x=Tensor([0, 4, 2],"float64"), )
[cuda error] paddle.fft.ifftshift(x=Tensor([0, 4, 2],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.346662 GPU 1 69602 test begin: paddle.fft.ifftshift(x=Tensor([0, 5, 4, 4],"complex128"), )
[cuda error] paddle.fft.ifftshift(x=Tensor([0, 5, 4, 4],"complex128"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.364199 GPU 1 69607 test begin: paddle.fft.ifftshift(x=Tensor([0, 5, 4, 4],"complex128"), axes=3, )
[cuda error] paddle.fft.ifftshift(x=Tensor([0, 5, 4, 4],"complex128"), axes=3, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.365451 GPU 1 69617 test begin: paddle.fft.ifftshift(x=Tensor([0, 5, 4, 4],"complex128"), axes=tuple(0,3,), )
[cuda error] paddle.fft.ifftshift(x=Tensor([0, 5, 4, 4],"complex128"), axes=tuple(0,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.377517 GPU 1 69600 test begin: paddle.fft.ifftshift(x=Tensor([0],"float32"), )
[cuda error] paddle.fft.ifftshift(x=Tensor([0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.416324 GPU 1 69601 test begin: paddle.fft.ifftshift(x=Tensor([2, 0, 2],"float64"), )
[cuda error] paddle.fft.ifftshift(x=Tensor([2, 0, 2],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.445330 GPU 1 69621 test begin: paddle.fft.ifftshift(x=Tensor([2, 4, 0],"float64"), )
[cuda error] paddle.fft.ifftshift(x=Tensor([2, 4, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.449732 GPU 1 69606 test begin: paddle.fft.ifftshift(x=Tensor([4, 0, 4, 4],"complex128"), )
[cuda error] paddle.fft.ifftshift(x=Tensor([4, 0, 4, 4],"complex128"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.454127 GPU 1 69604 test begin: paddle.fft.ifftshift(x=Tensor([4, 0, 4, 4],"complex128"), axes=3, )
[cuda error] paddle.fft.ifftshift(x=Tensor([4, 0, 4, 4],"complex128"), axes=3, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.457134 GPU 1 69616 test begin: paddle.fft.ifftshift(x=Tensor([4, 0, 4, 4],"complex128"), axes=tuple(0,3,), )
[cuda error] paddle.fft.ifftshift(x=Tensor([4, 0, 4, 4],"complex128"), axes=tuple(0,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.457446 GPU 1 69618 test begin: paddle.fft.ifftshift(x=Tensor([4, 5, 0, 4],"complex128"), )
[cuda error] paddle.fft.ifftshift(x=Tensor([4, 5, 0, 4],"complex128"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.458968 GPU 1 69605 test begin: paddle.fft.ifftshift(x=Tensor([4, 5, 0, 4],"complex128"), axes=3, )
[cuda error] paddle.fft.ifftshift(x=Tensor([4, 5, 0, 4],"complex128"), axes=3, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.462333 GPU 1 69602 test begin: paddle.fft.ifftshift(x=Tensor([4, 5, 0, 4],"complex128"), axes=tuple(0,3,), )
[cuda error] paddle.fft.ifftshift(x=Tensor([4, 5, 0, 4],"complex128"), axes=tuple(0,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.467911 GPU 1 69612 test begin: paddle.fft.ifftshift(x=Tensor([4, 5, 4, 0],"complex128"), )
[cuda error] paddle.fft.ifftshift(x=Tensor([4, 5, 4, 0],"complex128"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.469691 GPU 1 69613 test begin: paddle.fft.ifftshift(x=Tensor([4, 5, 4, 0],"complex128"), axes=3, )
[cuda error] paddle.fft.ifftshift(x=Tensor([4, 5, 4, 0],"complex128"), axes=3, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.473879 GPU 1 69608 test begin: paddle.fft.ifftshift(x=Tensor([4, 5, 4, 0],"complex128"), axes=tuple(0,3,), )
[cuda error] paddle.fft.ifftshift(x=Tensor([4, 5, 4, 0],"complex128"), axes=tuple(0,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.475578 GPU 1 69603 test begin: paddle.fft.ihfft2(x=Tensor([0, 3, 3],"float64"), s=tuple(1,2,), axes=tuple(0,2,), )
[Pass] paddle.fft.ihfft2(x=Tensor([0, 3, 3],"float64"), s=tuple(1,2,), axes=tuple(0,2,), )

2025-05-21 22:07:45.477843 GPU 1 69611 test begin: paddle.fft.ihfft2(x=Tensor([0, 3, 3],"float64"), s=tuple(1,2,), axes=tuple(0,2,), norm="forward", )
[Pass] paddle.fft.ihfft2(x=Tensor([0, 3, 3],"float64"), s=tuple(1,2,), axes=tuple(0,2,), norm="forward", )

2025-05-21 22:07:45.484431 GPU 1 69619 test begin: paddle.fft.ihfft2(x=Tensor([0, 3, 3],"float64"), s=tuple(1,2,), axes=tuple(0,2,), norm="ortho", )
[Pass] paddle.fft.ihfft2(x=Tensor([0, 3, 3],"float64"), s=tuple(1,2,), axes=tuple(0,2,), norm="ortho", )

2025-05-21 22:07:45.485124 GPU 1 69598 test begin: paddle.fft.ihfft2(x=Tensor([4, 0, 3],"float64"), s=tuple(1,2,), )
[Pass] paddle.fft.ihfft2(x=Tensor([4, 0, 3],"float64"), s=tuple(1,2,), )

2025-05-21 22:07:45.488480 GPU 1 69615 test begin: paddle.fft.ihfft2(x=Tensor([4, 3, 0],"float64"), s=tuple(1,2,), )
[Pass] paddle.fft.ihfft2(x=Tensor([4, 3, 0],"float64"), s=tuple(1,2,), )

2025-05-21 22:07:45.490508 GPU 1 69600 test begin: paddle.fft.ihfft2(x=Tensor([4, 3, 0],"float64"), s=tuple(1,2,), axes=tuple(0,2,), )
[Pass] paddle.fft.ihfft2(x=Tensor([4, 3, 0],"float64"), s=tuple(1,2,), axes=tuple(0,2,), )

2025-05-21 22:07:45.492806 GPU 1 69599 test begin: paddle.fft.ihfft2(x=Tensor([4, 3, 0],"float64"), s=tuple(1,2,), axes=tuple(0,2,), norm="forward", )
[Pass] paddle.fft.ihfft2(x=Tensor([4, 3, 0],"float64"), s=tuple(1,2,), axes=tuple(0,2,), norm="forward", )

2025-05-21 22:07:45.503705 GPU 1 69609 test begin: paddle.fft.ihfft2(x=Tensor([4, 3, 0],"float64"), s=tuple(1,2,), axes=tuple(0,2,), norm="ortho", )
[Pass] paddle.fft.ihfft2(x=Tensor([4, 3, 0],"float64"), s=tuple(1,2,), axes=tuple(0,2,), norm="ortho", )

2025-05-21 22:07:45.511731 GPU 1 69607 test begin: paddle.fft.ihfftn(Tensor([0, 3, 3],"float64"), tuple(1,2,), tuple(0,2,), "backward", None, )
[Pass] paddle.fft.ihfftn(Tensor([0, 3, 3],"float64"), tuple(1,2,), tuple(0,2,), "backward", None, )

2025-05-21 22:07:45.528470 GPU 1 69601 test begin: paddle.fft.ihfftn(Tensor([0, 3, 3],"float64"), tuple(1,2,), tuple(0,2,), "forward", None, )
[Pass] paddle.fft.ihfftn(Tensor([0, 3, 3],"float64"), tuple(1,2,), tuple(0,2,), "forward", None, )

2025-05-21 22:07:45.538340 GPU 1 69596 test begin: paddle.fft.ihfftn(Tensor([0, 3, 3],"float64"), tuple(1,2,), tuple(0,2,), "ortho", None, )
[Pass] paddle.fft.ihfftn(Tensor([0, 3, 3],"float64"), tuple(1,2,), tuple(0,2,), "ortho", None, )

2025-05-21 22:07:45.561577 GPU 1 69621 test begin: paddle.fft.ihfftn(Tensor([4, 0, 3],"float64"), tuple(1,2,), tuple(-2,-1,), "backward", None, )
[Pass] paddle.fft.ihfftn(Tensor([4, 0, 3],"float64"), tuple(1,2,), tuple(-2,-1,), "backward", None, )

2025-05-21 22:07:45.574712 GPU 1 69602 test begin: paddle.fft.ihfftn(Tensor([4, 3, 0],"float64"), tuple(1,2,), tuple(-2,-1,), "backward", None, )
[Pass] paddle.fft.ihfftn(Tensor([4, 3, 0],"float64"), tuple(1,2,), tuple(-2,-1,), "backward", None, )

2025-05-21 22:07:45.575690 GPU 1 69610 test begin: paddle.fft.ihfftn(Tensor([4, 3, 0],"float64"), tuple(1,2,), tuple(0,2,), "backward", None, )
[Pass] paddle.fft.ihfftn(Tensor([4, 3, 0],"float64"), tuple(1,2,), tuple(0,2,), "backward", None, )

2025-05-21 22:07:45.585100 GPU 1 69608 test begin: paddle.fft.ihfftn(Tensor([4, 3, 0],"float64"), tuple(1,2,), tuple(0,2,), "forward", None, )
[Pass] paddle.fft.ihfftn(Tensor([4, 3, 0],"float64"), tuple(1,2,), tuple(0,2,), "forward", None, )

2025-05-21 22:07:45.595006 GPU 1 69603 test begin: paddle.fft.ihfftn(Tensor([4, 3, 0],"float64"), tuple(1,2,), tuple(0,2,), "ortho", None, )
[Pass] paddle.fft.ihfftn(Tensor([4, 3, 0],"float64"), tuple(1,2,), tuple(0,2,), "ortho", None, )

2025-05-21 22:07:45.620878 GPU 1 69604 test begin: paddle.fft.ihfftn(x=Tensor([4, 3, 0],"float64"), s=tuple(1,2,), )
[Pass] paddle.fft.ihfftn(x=Tensor([4, 3, 0],"float64"), s=tuple(1,2,), )

2025-05-21 22:07:45.628783 GPU 1 69606 test begin: paddle.fft.ihfftn(x=Tensor([4, 3, 0],"float64"), s=tuple(1,2,), axes=tuple(0,2,), )
[Pass] paddle.fft.ihfftn(x=Tensor([4, 3, 0],"float64"), s=tuple(1,2,), axes=tuple(0,2,), )

2025-05-21 22:07:45.640627 GPU 1 69612 test begin: paddle.fft.ihfftn(x=Tensor([4, 3, 0],"float64"), s=tuple(1,2,), axes=tuple(0,2,), norm="forward", )
[Pass] paddle.fft.ihfftn(x=Tensor([4, 3, 0],"float64"), s=tuple(1,2,), axes=tuple(0,2,), norm="forward", )

2025-05-21 22:07:45.651959 GPU 1 69629 test begin: paddle.fft.ihfftn(x=Tensor([4, 3, 0],"float64"), s=tuple(1,2,), axes=tuple(0,2,), norm="ortho", )
[Pass] paddle.fft.ihfftn(x=Tensor([4, 3, 0],"float64"), s=tuple(1,2,), axes=tuple(0,2,), norm="ortho", )

2025-05-21 22:07:45.681565 GPU 1 69605 test begin: paddle.fft.rfft2(x=Tensor([2, 2, 0],"float64"), s=list[1,2,], )
[Pass] paddle.fft.rfft2(x=Tensor([2, 2, 0],"float64"), s=list[1,2,], )

2025-05-21 22:07:45.698651 GPU 1 69611 test begin: paddle.fft.rfft2(x=Tensor([2, 2, 0],"float64"), s=list[1,2,], norm="backward", )
[Pass] paddle.fft.rfft2(x=Tensor([2, 2, 0],"float64"), s=list[1,2,], norm="backward", )

2025-05-21 22:07:45.702362 GPU 1 69617 test begin: paddle.fft.rfft2(x=Tensor([2, 2, 0],"float64"), s=list[1,2,], norm="forward", )
[Pass] paddle.fft.rfft2(x=Tensor([2, 2, 0],"float64"), s=list[1,2,], norm="forward", )

2025-05-21 22:07:45.711722 GPU 1 69601 test begin: paddle.fft.rfft2(x=Tensor([2, 2, 0],"float64"), s=list[1,2,], norm="ortho", )
[Pass] paddle.fft.rfft2(x=Tensor([2, 2, 0],"float64"), s=list[1,2,], norm="ortho", )

2025-05-21 22:07:45.711886 GPU 1 69603 test begin: paddle.fft.rfftn(Tensor([2, 2, 0],"float64"), list[1,2,], None, "ortho", None, )
[Pass] paddle.fft.rfftn(Tensor([2, 2, 0],"float64"), list[1,2,], None, "ortho", None, )

2025-05-21 22:07:45.712766 GPU 1 69600 test begin: paddle.fft.rfftn(Tensor([2, 2, 0],"float64"), list[1,2,], tuple(-2,-1,), "backward", None, )
[Pass] paddle.fft.rfftn(Tensor([2, 2, 0],"float64"), list[1,2,], tuple(-2,-1,), "backward", None, )

2025-05-21 22:07:45.718168 GPU 1 69613 test begin: paddle.fft.rfftn(Tensor([2, 2, 0],"float64"), list[1,2,], tuple(-2,-1,), "forward", None, )
[Pass] paddle.fft.rfftn(Tensor([2, 2, 0],"float64"), list[1,2,], tuple(-2,-1,), "forward", None, )

2025-05-21 22:07:45.727962 GPU 1 69616 test begin: paddle.fft.rfftn(Tensor([2, 2, 0],"float64"), list[1,2,], tuple(-2,-1,), "ortho", None, )
[Pass] paddle.fft.rfftn(Tensor([2, 2, 0],"float64"), list[1,2,], tuple(-2,-1,), "ortho", None, )

2025-05-21 22:07:45.738177 GPU 1 69618 test begin: paddle.flip(Tensor([0, 2, 2],"float32"), list[0,1,], )
[cuda error] paddle.flip(Tensor([0, 2, 2],"float32"), list[0,1,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.743877 GPU 1 69602 test begin: paddle.flip(Tensor([0, 2],"float32"), tuple(-2,-1,), )
[cuda error] paddle.flip(Tensor([0, 2],"float32"), tuple(-2,-1,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.744923 GPU 1 69599 test begin: paddle.flip(Tensor([0, 3],"float32"), list[0,], )
[cuda error] paddle.flip(Tensor([0, 3],"float32"), list[0,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.747582 GPU 1 69607 test begin: paddle.flip(Tensor([0, 4],"float32"), list[0,1,], )
[cuda error] paddle.flip(Tensor([0, 4],"float32"), list[0,1,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.752384 GPU 1 69608 test begin: paddle.flip(Tensor([0, 8, 224, 224],"float32"), axis=list[3,], )
[cuda error] paddle.flip(Tensor([0, 8, 224, 224],"float32"), axis=list[3,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.751800 GPU 1 69621 test begin: paddle.flip(Tensor([0],"int32"), axis=list[0,], )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.flip(Tensor([0],"int32"), axis=list[0,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.795385 GPU 1 69596 test begin: paddle.flip(Tensor([2, 0],"float32"), list[0,], )
[cuda error] paddle.flip(Tensor([2, 0],"float32"), list[0,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.799519 GPU 1 69614 test begin: paddle.flip(Tensor([2, 0],"float32"), tuple(-2,-1,), )
[cuda error] paddle.flip(Tensor([2, 0],"float32"), tuple(-2,-1,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.811458 GPU 1 69609 test begin: paddle.flip(Tensor([3, 0, 224, 224],"float32"), axis=list[3,], )
[cuda error] paddle.flip(Tensor([3, 0, 224, 224],"float32"), axis=list[3,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.832785 GPU 1 69615 test begin: paddle.flip(Tensor([3, 0, 2],"float32"), list[0,1,], )
[cuda error] paddle.flip(Tensor([3, 0, 2],"float32"), list[0,1,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.836517 GPU 1 69598 test begin: paddle.flip(Tensor([3, 2, 0],"float32"), list[0,1,], )
[cuda error] paddle.flip(Tensor([3, 2, 0],"float32"), list[0,1,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.844006 GPU 1 69606 test begin: paddle.flip(Tensor([3, 8, 0, 224],"float32"), axis=list[3,], )
[cuda error] paddle.flip(Tensor([3, 8, 0, 224],"float32"), axis=list[3,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.848367 GPU 1 69619 test begin: paddle.flip(Tensor([3, 8, 224, 0],"float32"), axis=list[3,], )
[cuda error] paddle.flip(Tensor([3, 8, 224, 0],"float32"), axis=list[3,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.848549 GPU 1 69602 test begin: paddle.flip(Tensor([4, 0],"float32"), list[0,1,], )
[cuda error] paddle.flip(Tensor([4, 0],"float32"), list[0,1,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.860021 GPU 1 69610 test begin: paddle.flip(x=Tensor([0, 3, 3, 3, 3, 3],"float64"), axis=list[-1,0,3,4,2,], )
[cuda error] paddle.flip(x=Tensor([0, 3, 3, 3, 3, 3],"float64"), axis=list[-1,0,3,4,2,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.894667 GPU 1 69604 test begin: paddle.flip(x=Tensor([0, 3, 3],"bool"), axis=list[0,], )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.flip(x=Tensor([0, 3, 3],"bool"), axis=list[0,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.903119 GPU 1 69611 test begin: paddle.flip(x=Tensor([0, 3, 3],"float64"), axis=list[-1,0,1,], )
[cuda error] paddle.flip(x=Tensor([0, 3, 3],"float64"), axis=list[-1,0,1,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.935657 GPU 1 69612 test begin: paddle.flip(x=Tensor([0, 3, 3],"float64"), axis=list[0,1,2,], )
[cuda error] paddle.flip(x=Tensor([0, 3, 3],"float64"), axis=list[0,1,2,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.938414 GPU 1 69599 test begin: paddle.flip(x=Tensor([3, 0, 3, 3, 3, 3],"float64"), axis=list[-1,0,3,4,2,], )
[cuda error] paddle.flip(x=Tensor([3, 0, 3, 3, 3, 3],"float64"), axis=list[-1,0,3,4,2,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.947871 GPU 1 69605 test begin: paddle.flip(x=Tensor([3, 0, 3],"bool"), axis=list[0,], )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.flip(x=Tensor([3, 0, 3],"bool"), axis=list[0,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.953611 GPU 1 69602 test begin: paddle.flip(x=Tensor([3, 0, 3],"float64"), axis=list[-1,0,1,], )
[cuda error] paddle.flip(x=Tensor([3, 0, 3],"float64"), axis=list[-1,0,1,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.954172 GPU 1 69596 test begin: paddle.flip(x=Tensor([3, 0, 3],"float64"), axis=list[0,1,2,], )
[cuda error] paddle.flip(x=Tensor([3, 0, 3],"float64"), axis=list[0,1,2,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.959971 GPU 1 69618 test begin: paddle.flip(x=Tensor([3, 3, 0, 3, 3, 3],"float64"), axis=list[-1,0,3,4,2,], )
[cuda error] paddle.flip(x=Tensor([3, 3, 0, 3, 3, 3],"float64"), axis=list[-1,0,3,4,2,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.975880 GPU 1 69609 test begin: paddle.flip(x=Tensor([3, 3, 0],"bool"), axis=list[0,], )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.flip(x=Tensor([3, 3, 0],"bool"), axis=list[0,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:45.986580 GPU 1 69606 test begin: paddle.flip(x=Tensor([3, 3, 0],"float64"), axis=list[-1,0,1,], )
[cuda error] paddle.flip(x=Tensor([3, 3, 0],"float64"), axis=list[-1,0,1,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:46.006977 GPU 1 69615 test begin: paddle.flip(x=Tensor([3, 3, 0],"float64"), axis=list[0,1,2,], )
[cuda error] paddle.flip(x=Tensor([3, 3, 0],"float64"), axis=list[0,1,2,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:46.007561 GPU 1 69607 test begin: paddle.flip(x=Tensor([3, 3, 3, 0, 3, 3],"float64"), axis=list[-1,0,3,4,2,], )
[cuda error] paddle.flip(x=Tensor([3, 3, 3, 0, 3, 3],"float64"), axis=list[-1,0,3,4,2,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:46.020766 GPU 1 69610 test begin: paddle.flip(x=Tensor([3, 3, 3, 3, 0, 3],"float64"), axis=list[-1,0,3,4,2,], )
[cuda error] paddle.flip(x=Tensor([3, 3, 3, 3, 0, 3],"float64"), axis=list[-1,0,3,4,2,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:46.024107 GPU 1 69621 test begin: paddle.flip(x=Tensor([3, 3, 3, 3, 3, 0],"float64"), axis=list[-1,0,3,4,2,], )
[cuda error] paddle.flip(x=Tensor([3, 3, 3, 3, 3, 0],"float64"), axis=list[-1,0,3,4,2,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:46.041384 GPU 1 69608 test begin: paddle.fmax(Tensor([0, 15],"float32"), Tensor([0, 15],"float32"), )
[cuda error] paddle.fmax(Tensor([0, 15],"float32"), Tensor([0, 15],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:46.046809 GPU 1 69611 test begin: paddle.fmax(Tensor([0, 15],"float32"), Tensor([15],"float32"), )
[cuda error] paddle.fmax(Tensor([0, 15],"float32"), Tensor([15],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:46.056257 GPU 1 69598 test begin: paddle.fmax(Tensor([0, 200, 40],"float32"), Tensor([0, 200, 40],"float32"), )
[cuda error] paddle.fmax(Tensor([0, 200, 40],"float32"), Tensor([0, 200, 40],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:46.060120 GPU 1 69605 test begin: paddle.fmax(Tensor([10, 0],"float32"), Tensor([10, 0],"float32"), )
[cuda error] paddle.fmax(Tensor([10, 0],"float32"), Tensor([10, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:46.061763 GPU 1 69614 test begin: paddle.fmax(Tensor([30, 0, 40],"float32"), Tensor([30, 0, 40],"float32"), )
[cuda error] paddle.fmax(Tensor([30, 0, 40],"float32"), Tensor([30, 0, 40],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:46.064463 GPU 1 69619 test begin: paddle.fmax(Tensor([30, 200, 0],"float32"), Tensor([30, 200, 0],"float32"), )
[cuda error] paddle.fmax(Tensor([30, 200, 0],"float32"), Tensor([30, 200, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:46.069294 GPU 1 69602 test begin: paddle.fmin(Tensor([0, 15],"float32"), Tensor([0, 15],"float32"), )
[cuda error] paddle.fmin(Tensor([0, 15],"float32"), Tensor([0, 15],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:46.079814 GPU 1 69596 test begin: paddle.fmin(Tensor([0, 15],"float32"), Tensor([15],"float32"), )
[cuda error] paddle.fmin(Tensor([0, 15],"float32"), Tensor([15],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:46.080295 GPU 1 69604 test begin: paddle.fmin(Tensor([0, 200, 40],"float32"), Tensor([0, 200, 40],"float32"), )
[cuda error] paddle.fmin(Tensor([0, 200, 40],"float32"), Tensor([0, 200, 40],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:46.082718 GPU 1 69612 test begin: paddle.fmin(Tensor([10, 0],"float32"), Tensor([10, 0],"float32"), )
[cuda error] paddle.fmin(Tensor([10, 0],"float32"), Tensor([10, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:46.086903 GPU 1 69599 test begin: paddle.fmin(Tensor([30, 0, 40],"float32"), Tensor([30, 0, 40],"float32"), )
[cuda error] paddle.fmin(Tensor([30, 0, 40],"float32"), Tensor([30, 0, 40],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:46.099206 GPU 1 69606 test begin: paddle.fmin(Tensor([30, 200, 0],"float32"), Tensor([30, 200, 0],"float32"), )
[cuda error] paddle.fmin(Tensor([30, 200, 0],"float32"), Tensor([30, 200, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:46.131225 GPU 1 69609 test begin: paddle.frac(Tensor([0, 20, 1],"float32"), )
[cuda error] paddle.frac(Tensor([0, 20, 1],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:46.148415 GPU 1 69615 test begin: paddle.frac(Tensor([0, 3],"float32"), )
[cuda error] paddle.frac(Tensor([0, 3],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:46.159995 GPU 1 69607 test begin: paddle.frac(Tensor([10, 0, 1],"float32"), )
[cuda error] paddle.frac(Tensor([10, 0, 1],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:46.190002 GPU 1 69618 test begin: paddle.frac(Tensor([10, 20, 0],"float32"), )
[cuda error] paddle.frac(Tensor([10, 20, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:46.284297 GPU 1 69602 test begin: paddle.frac(Tensor([2, 0],"float32"), )
[cuda error] paddle.frac(Tensor([2, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:46.286536 GPU 1 69605 test begin: paddle.imag(Tensor([0, 10, 10, 20],"complex128"), )
[Pass] paddle.imag(Tensor([0, 10, 10, 20],"complex128"), )

2025-05-21 22:07:46.287666 GPU 1 69606 test begin: paddle.imag(Tensor([0, 3],"complex128"), )
[Pass] paddle.imag(Tensor([0, 3],"complex128"), )

2025-05-21 22:07:46.288406 GPU 1 69609 test begin: paddle.imag(Tensor([10, 0, 10, 20],"complex128"), )
[Pass] paddle.imag(Tensor([10, 0, 10, 20],"complex128"), )

2025-05-21 22:07:46.292635 GPU 1 69612 test begin: paddle.imag(Tensor([10, 10, 0, 20],"complex128"), )
[Pass] paddle.imag(Tensor([10, 10, 0, 20],"complex128"), )

2025-05-21 22:07:46.293319 GPU 1 69599 test begin: paddle.imag(Tensor([10, 10, 10, 0],"complex128"), )
[Pass] paddle.imag(Tensor([10, 10, 10, 0],"complex128"), )

2025-05-21 22:07:46.300334 GPU 1 69608 test begin: paddle.imag(Tensor([2, 0],"complex128"), )
[Pass] paddle.imag(Tensor([2, 0],"complex128"), )

2025-05-21 22:07:46.304905 GPU 1 69621 test begin: paddle.imag(x=Tensor([0, 10],"complex64"), )
[Pass] paddle.imag(x=Tensor([0, 10],"complex64"), )

2025-05-21 22:07:46.305419 GPU 1 69607 test begin: paddle.imag(x=Tensor([1, 0],"complex64"), )
[Pass] paddle.imag(x=Tensor([1, 0],"complex64"), )

2025-05-21 22:07:46.314522 GPU 1 69615 test begin: paddle.inner(Tensor([5, 10, 10],"complex128"), Tensor([0, 10],"complex128"), )
W0521 22:07:46.821389 69615 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.inner(Tensor([5, 10, 10],"complex128"), Tensor([0, 10],"complex128"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:958)


2025-05-21 22:07:46.329976 GPU 1 69611 test begin: paddle.inner(Tensor([5, 10, 10],"float64"), Tensor([0, 10],"float64"), )
W0521 22:07:50.440623 69611 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.inner(Tensor([5, 10, 10],"float64"), Tensor([0, 10],"float64"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:07:46.330927 GPU 1 69596 test begin: paddle.inner(x=Tensor([0],"float64"), y=Tensor([0],"float64"), )
[paddle error] paddle.inner(x=Tensor([0],"float64"), y=Tensor([0],"float64"), ) 
 (InvalidArgument) can not reshape 0 to -1, 0, because the unspecified dimension 0 can be any number and is ambiguous
  [Hint: Expected unk_dim_idx == -1, but received unk_dim_idx:0 != -1:-1.] (at ../paddle/phi/infermeta/unary.cc:2209)


2025-05-21 22:07:46.332358 GPU 1 69604 test begin: paddle.inner(x=Tensor([2, 5, 3, 0],"float64"), y=Tensor([3, 2, 5, 0],"float64"), )
[paddle error] paddle.inner(x=Tensor([2, 5, 3, 0],"float64"), y=Tensor([3, 2, 5, 0],"float64"), ) 
 (InvalidArgument) can not reshape 2, 5, 3, 0 to -1, 0, because the unspecified dimension 0 can be any number and is ambiguous
  [Hint: Expected unk_dim_idx == -1, but received unk_dim_idx:0 != -1:-1.] (at ../paddle/phi/infermeta/unary.cc:2209)


2025-05-21 22:07:46.381395 GPU 1 69598 test begin: paddle.inner(x=Tensor([2, 5, 3, 4],"float64"), y=Tensor([0, 2, 5, 4],"float64"), )
W0521 22:07:46.984712 69598 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.inner(x=Tensor([2, 5, 3, 4],"float64"), y=Tensor([0, 2, 5, 4],"float64"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:07:46.390205 GPU 1 69619 test begin: paddle.inner(x=Tensor([2, 5, 3, 4],"float64"), y=Tensor([3, 0, 5, 4],"float64"), )
W0521 22:07:50.574406 69619 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.inner(x=Tensor([2, 5, 3, 4],"float64"), y=Tensor([3, 0, 5, 4],"float64"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:07:46.401986 GPU 1 69614 test begin: paddle.inner(x=Tensor([2, 5, 3, 4],"float64"), y=Tensor([3, 2, 0, 4],"float64"), )
W0521 22:07:46.986310 69614 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.inner(x=Tensor([2, 5, 3, 4],"float64"), y=Tensor([3, 2, 0, 4],"float64"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:07:46.431251 GPU 1 69608 test begin: paddle.inner(x=Tensor([3, 0],"float64"), y=Tensor([5, 0],"float64"), )
[paddle error] paddle.inner(x=Tensor([3, 0],"float64"), y=Tensor([5, 0],"float64"), ) 
 (InvalidArgument) can not reshape 3, 0 to -1, 0, because the unspecified dimension 0 can be any number and is ambiguous
  [Hint: Expected unk_dim_idx == -1, but received unk_dim_idx:0 != -1:-1.] (at ../paddle/phi/infermeta/unary.cc:2209)


2025-05-21 22:07:46.433112 GPU 1 69602 test begin: paddle.inner(x=Tensor([3, 4],"float64"), y=Tensor([0, 2, 4],"float64"), )
W0521 22:07:47.690734 69602 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.inner(x=Tensor([3, 4],"float64"), y=Tensor([0, 2, 4],"float64"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:07:46.434005 GPU 1 69610 test begin: paddle.inner(x=Tensor([3, 4],"float64"), y=Tensor([0, 2, 5, 4],"float64"), )
W0521 22:07:46.821480 69610 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.inner(x=Tensor([3, 4],"float64"), y=Tensor([0, 2, 5, 4],"float64"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:07:46.435467 GPU 1 69612 test begin: paddle.inner(x=Tensor([3, 4],"float64"), y=Tensor([0, 4],"float64"), )
W0521 22:07:46.983139 69612 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.inner(x=Tensor([3, 4],"float64"), y=Tensor([0, 4],"float64"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:07:46.435645 GPU 1 69605 test begin: paddle.inner(x=Tensor([3, 4],"float64"), y=Tensor([3, 0, 4],"float64"), )
W0521 22:07:46.821292 69605 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.inner(x=Tensor([3, 4],"float64"), y=Tensor([3, 0, 4],"float64"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:07:46.436437 GPU 1 69609 test begin: paddle.inner(x=Tensor([3, 4],"float64"), y=Tensor([3, 0, 5, 4],"float64"), )
W0521 22:07:47.718185 69609 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.inner(x=Tensor([3, 4],"float64"), y=Tensor([3, 0, 5, 4],"float64"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:07:46.436602 GPU 1 69599 test begin: paddle.inner(x=Tensor([3, 4],"float64"), y=Tensor([3, 2, 0, 4],"float64"), )
W0521 22:07:47.684727 69599 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.inner(x=Tensor([3, 4],"float64"), y=Tensor([3, 2, 0, 4],"float64"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:07:46.441480 GPU 1 69621 test begin: paddle.inner(x=Tensor([4, 0],"float32"), y=Tensor([4, 0],"float32"), )
[paddle error] paddle.inner(x=Tensor([4, 0],"float32"), y=Tensor([4, 0],"float32"), ) 
 (InvalidArgument) can not reshape 4, 0 to -1, 0, because the unspecified dimension 0 can be any number and is ambiguous
  [Hint: Expected unk_dim_idx == -1, but received unk_dim_idx:0 != -1:-1.] (at ../paddle/phi/infermeta/unary.cc:2209)


2025-05-21 22:07:46.443137 GPU 1 69606 test begin: paddle.inner(x=Tensor([4, 4],"float32"), y=Tensor([0, 4],"float32"), )
W0521 22:07:47.681360 69606 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.inner(x=Tensor([4, 4],"float32"), y=Tensor([0, 4],"float32"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:40)


2025-05-21 22:07:46.455502 GPU 1 69607 test begin: paddle.inner(x=Tensor([5, 3, 0],"float64"), y=Tensor([2, 5, 0],"float64"), )
[paddle error] paddle.inner(x=Tensor([5, 3, 0],"float64"), y=Tensor([2, 5, 0],"float64"), ) 
 (InvalidArgument) can not reshape 5, 3, 0 to -1, 0, because the unspecified dimension 0 can be any number and is ambiguous
  [Hint: Expected unk_dim_idx == -1, but received unk_dim_idx:0 != -1:-1.] (at ../paddle/phi/infermeta/unary.cc:2209)


2025-05-21 22:07:46.486885 GPU 1 69618 test begin: paddle.inner(x=Tensor([5, 3, 4],"float64"), y=Tensor([0, 5, 4],"float64"), )
W0521 22:07:46.985886 69618 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.inner(x=Tensor([5, 3, 4],"float64"), y=Tensor([0, 5, 4],"float64"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:07:46.489877 GPU 1 69616 test begin: paddle.inner(x=Tensor([5, 3, 4],"float64"), y=Tensor([2, 0, 4],"float64"), )
W0521 22:07:47.371527 69616 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.inner(x=Tensor([5, 3, 4],"float64"), y=Tensor([2, 0, 4],"float64"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:07:46.490461 GPU 1 69617 test begin: paddle.isclose(Tensor([0, 10],"float64"), Tensor([0, 10],"float64"), rtol=1e-05, atol=1e-08, )
[Pass] paddle.isclose(Tensor([0, 10],"float64"), Tensor([0, 10],"float64"), rtol=1e-05, atol=1e-08, )

2025-05-21 22:07:46.670421 GPU 1 69603 test begin: paddle.isclose(Tensor([10, 0],"float64"), Tensor([10, 0],"float64"), rtol=1e-05, atol=1e-08, )
[Pass] paddle.isclose(Tensor([10, 0],"float64"), Tensor([10, 0],"float64"), rtol=1e-05, atol=1e-08, )

2025-05-21 22:07:46.670753 GPU 1 69613 test begin: paddle.isclose(x=Tensor([0, 4, 5],"float64"), y=Tensor([0, 4, 5],"float64"), )
[Pass] paddle.isclose(x=Tensor([0, 4, 5],"float64"), y=Tensor([0, 4, 5],"float64"), )

2025-05-21 22:07:46.816253 GPU 1 69608 test begin: paddle.isclose(x=Tensor([0],"float32"), y=Tensor([0],"float32"), )
[Pass] paddle.isclose(x=Tensor([0],"float32"), y=Tensor([0],"float32"), )

2025-05-21 22:07:46.817858 GPU 1 69600 test begin: paddle.isclose(x=Tensor([0],"float64"), y=Tensor([0],"float64"), )
[Pass] paddle.isclose(x=Tensor([0],"float64"), y=Tensor([0],"float64"), )

2025-05-21 22:07:46.818553 GPU 1 69604 test begin: paddle.isclose(x=Tensor([3, 0, 5],"float64"), y=Tensor([3, 0, 5],"float64"), )
[Pass] paddle.isclose(x=Tensor([3, 0, 5],"float64"), y=Tensor([3, 0, 5],"float64"), )

2025-05-21 22:07:46.818718 GPU 1 69607 test begin: paddle.isclose(x=Tensor([3, 4, 0],"float64"), y=Tensor([3, 4, 0],"float64"), )
[Pass] paddle.isclose(x=Tensor([3, 4, 0],"float64"), y=Tensor([3, 4, 0],"float64"), )

2025-05-21 22:07:46.819611 GPU 1 69601 test begin: paddle.isfinite(Tensor([0, 17, 10],"int32"), )
[cuda error] paddle.isfinite(Tensor([0, 17, 10],"int32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:46.820214 GPU 1 69629 test begin: paddle.isfinite(Tensor([0, 17, 5, 6, 7],"float16"), )
[cuda error] paddle.isfinite(Tensor([0, 17, 5, 6, 7],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:46.822213 GPU 1 69605 test begin: paddle.isfinite(Tensor([0, 17],"float32"), )
[cuda error] paddle.isfinite(Tensor([0, 17],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:46.822319 GPU 1 69615 test begin: paddle.isfinite(Tensor([0, 280, 376, 25, 3],"float32"), )
[cuda error] paddle.isfinite(Tensor([0, 280, 376, 25, 3],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:46.822775 GPU 1 69610 test begin: paddle.isfinite(Tensor([0, 3, 4, 5],"float64"), )
[cuda error] paddle.isfinite(Tensor([0, 3, 4, 5],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:46.921061 GPU 1 69608 test begin: paddle.isfinite(Tensor([0, 94, 311],"float32"), )
[cuda error] paddle.isfinite(Tensor([0, 94, 311],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:46.955651 GPU 1 69603 test begin: paddle.isfinite(Tensor([0],"int64"), )
[cuda error] paddle.isfinite(Tensor([0],"int64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:46.983975 GPU 1 69612 test begin: paddle.isfinite(Tensor([11, 0, 10],"int32"), )
[cuda error] paddle.isfinite(Tensor([11, 0, 10],"int32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:46.985455 GPU 1 69598 test begin: paddle.isfinite(Tensor([11, 0],"float32"), )
[cuda error] paddle.isfinite(Tensor([11, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:46.986755 GPU 1 69618 test begin: paddle.isfinite(Tensor([11, 17, 0],"int32"), )
[cuda error] paddle.isfinite(Tensor([11, 17, 0],"int32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:46.987615 GPU 1 69614 test begin: paddle.isfinite(Tensor([2, 0, 4, 5],"float64"), )
[cuda error] paddle.isfinite(Tensor([2, 0, 4, 5],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.010036 GPU 1 69617 test begin: paddle.isfinite(Tensor([2, 3, 0, 5],"float64"), )
[cuda error] paddle.isfinite(Tensor([2, 3, 0, 5],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.023653 GPU 1 69613 test begin: paddle.isfinite(Tensor([2, 3, 4, 0],"float64"), )
[cuda error] paddle.isfinite(Tensor([2, 3, 4, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.081048 GPU 1 69608 test begin: paddle.isfinite(Tensor([4, 0, 311],"float32"), )
[cuda error] paddle.isfinite(Tensor([4, 0, 311],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.082552 GPU 1 69603 test begin: paddle.isfinite(Tensor([4, 0, 376, 25, 3],"float32"), )
[cuda error] paddle.isfinite(Tensor([4, 0, 376, 25, 3],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.086196 GPU 1 69605 test begin: paddle.isfinite(Tensor([4, 280, 0, 25, 3],"float32"), )
[cuda error] paddle.isfinite(Tensor([4, 280, 0, 25, 3],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.137824 GPU 1 69596 test begin: paddle.isfinite(Tensor([4, 280, 376, 0, 3],"float32"), )
[cuda error] paddle.isfinite(Tensor([4, 280, 376, 0, 3],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.139662 GPU 1 69621 test begin: paddle.isfinite(Tensor([4, 280, 376, 25, 0],"float32"), )
[cuda error] paddle.isfinite(Tensor([4, 280, 376, 25, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.253654 GPU 1 69610 test begin: paddle.isfinite(Tensor([4, 94, 0],"float32"), )
[cuda error] paddle.isfinite(Tensor([4, 94, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.258125 GPU 1 69600 test begin: paddle.isfinite(Tensor([8, 0, 5, 6, 7],"float16"), )
[cuda error] paddle.isfinite(Tensor([8, 0, 5, 6, 7],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.258643 GPU 1 69601 test begin: paddle.isfinite(Tensor([8, 17, 0, 6, 7],"float16"), )
[cuda error] paddle.isfinite(Tensor([8, 17, 0, 6, 7],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.261423 GPU 1 69607 test begin: paddle.isfinite(Tensor([8, 17, 5, 0, 7],"float16"), )
[cuda error] paddle.isfinite(Tensor([8, 17, 5, 0, 7],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.263860 GPU 1 69615 test begin: paddle.isfinite(Tensor([8, 17, 5, 6, 0],"float16"), )
[cuda error] paddle.isfinite(Tensor([8, 17, 5, 6, 0],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.282763 GPU 1 69604 test begin: paddle.isfinite(x=Tensor([0],"float64"), )
[cuda error] paddle.isfinite(x=Tensor([0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.372482 GPU 1 69616 test begin: paddle.isin(Tensor([0, 8],"float16"), Tensor([0, 3],"float16"), False, False, )
[cuda error] paddle.isin(Tensor([0, 8],"float16"), Tensor([0, 3],"float16"), False, False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.443726 GPU 1 69629 test begin: paddle.isin(Tensor([0, 8],"float16"), Tensor([0, 3],"float16"), False, True, )
[cuda error] paddle.isin(Tensor([0, 8],"float16"), Tensor([0, 3],"float16"), False, True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.445029 GPU 1 69614 test begin: paddle.isin(Tensor([0, 8],"float16"), Tensor([2, 3],"float16"), False, False, )
[cuda error] paddle.isin(Tensor([0, 8],"float16"), Tensor([2, 3],"float16"), False, False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.454803 GPU 1 69605 test begin: paddle.isin(Tensor([0, 8],"float16"), Tensor([2, 3],"float16"), False, True, )
[cuda error] paddle.isin(Tensor([0, 8],"float16"), Tensor([2, 3],"float16"), False, True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.474897 GPU 1 69621 test begin: paddle.isin(Tensor([0, 8],"float32"), Tensor([0, 3],"float32"), False, False, )
[cuda error] paddle.isin(Tensor([0, 8],"float32"), Tensor([0, 3],"float32"), False, False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.501104 GPU 1 69596 test begin: paddle.isin(Tensor([0, 8],"float32"), Tensor([0, 3],"float32"), False, True, )
[cuda error] paddle.isin(Tensor([0, 8],"float32"), Tensor([0, 3],"float32"), False, True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.509941 GPU 1 69618 test begin: paddle.isin(Tensor([0, 8],"float32"), Tensor([2, 3],"float32"), False, False, )
[cuda error] paddle.isin(Tensor([0, 8],"float32"), Tensor([2, 3],"float32"), False, False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.526593 GPU 1 69612 test begin: paddle.isin(Tensor([0, 8],"float32"), Tensor([2, 3],"float32"), False, True, )
[cuda error] paddle.isin(Tensor([0, 8],"float32"), Tensor([2, 3],"float32"), False, True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.530557 GPU 1 69598 test begin: paddle.isin(Tensor([4, 0],"float16"), Tensor([2, 0],"float16"), False, False, )
[cuda error] paddle.isin(Tensor([4, 0],"float16"), Tensor([2, 0],"float16"), False, False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.558244 GPU 1 69610 test begin: paddle.isin(Tensor([4, 0],"float16"), Tensor([2, 0],"float16"), False, True, )
[cuda error] paddle.isin(Tensor([4, 0],"float16"), Tensor([2, 0],"float16"), False, True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.566737 GPU 1 69614 test begin: paddle.isin(Tensor([4, 0],"float16"), Tensor([2, 3],"float16"), False, False, )
[cuda error] paddle.isin(Tensor([4, 0],"float16"), Tensor([2, 3],"float16"), False, False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.568499 GPU 1 69617 test begin: paddle.isin(Tensor([4, 0],"float16"), Tensor([2, 3],"float16"), False, True, )
[cuda error] paddle.isin(Tensor([4, 0],"float16"), Tensor([2, 3],"float16"), False, True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.578733 GPU 1 69615 test begin: paddle.isin(Tensor([4, 0],"float32"), Tensor([2, 0],"float32"), False, False, )
[cuda error] paddle.isin(Tensor([4, 0],"float32"), Tensor([2, 0],"float32"), False, False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.582786 GPU 1 69613 test begin: paddle.isin(Tensor([4, 0],"float32"), Tensor([2, 0],"float32"), False, True, )
[cuda error] paddle.isin(Tensor([4, 0],"float32"), Tensor([2, 0],"float32"), False, True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.584624 GPU 1 69608 test begin: paddle.isin(Tensor([4, 0],"float32"), Tensor([2, 3],"float32"), False, False, )
[cuda error] paddle.isin(Tensor([4, 0],"float32"), Tensor([2, 3],"float32"), False, False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.587036 GPU 1 69621 test begin: paddle.isin(Tensor([4, 0],"float32"), Tensor([2, 3],"float32"), False, True, )
[cuda error] paddle.isin(Tensor([4, 0],"float32"), Tensor([2, 3],"float32"), False, True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.605474 GPU 1 69605 test begin: paddle.isinf(Tensor([0, 12],"float32"), )
[cuda error] paddle.isinf(Tensor([0, 12],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.611086 GPU 1 69616 test begin: paddle.isinf(Tensor([0, 12],"float64"), )
[cuda error] paddle.isinf(Tensor([0, 12],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.630575 GPU 1 69603 test begin: paddle.isinf(Tensor([0, 17, 10],"int16"), )
[cuda error] paddle.isinf(Tensor([0, 17, 10],"int16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.648891 GPU 1 69596 test begin: paddle.isinf(Tensor([0, 17, 10],"int32"), )
[cuda error] paddle.isinf(Tensor([0, 17, 10],"int32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.669014 GPU 1 69618 test begin: paddle.isinf(Tensor([0, 17, 5, 6, 7],"float16"), )
[cuda error] paddle.isinf(Tensor([0, 17, 5, 6, 7],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.679739 GPU 1 69600 test begin: paddle.isinf(Tensor([0, 3, 4, 5],"float64"), )
[cuda error] paddle.isinf(Tensor([0, 3, 4, 5],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.682272 GPU 1 69606 test begin: paddle.isinf(Tensor([0, 3, 4, 5],"int8"), )
[cuda error] paddle.isinf(Tensor([0, 3, 4, 5],"int8"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.684705 GPU 1 69601 test begin: paddle.isinf(Tensor([0],"int64"), )
[cuda error] paddle.isinf(Tensor([0],"int64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.685582 GPU 1 69599 test begin: paddle.isinf(Tensor([0],"uint8"), )
[cuda error] paddle.isinf(Tensor([0],"uint8"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.691740 GPU 1 69614 test begin: paddle.isinf(Tensor([10, 0],"float32"), )
[cuda error] paddle.isinf(Tensor([10, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.691937 GPU 1 69602 test begin: paddle.isinf(Tensor([10, 0],"float64"), )
[cuda error] paddle.isinf(Tensor([10, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.696192 GPU 1 69621 test begin: paddle.isinf(Tensor([11, 0, 10],"int16"), )
[cuda error] paddle.isinf(Tensor([11, 0, 10],"int16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.702988 GPU 1 69604 test begin: paddle.isinf(Tensor([11, 0, 10],"int32"), )
[cuda error] paddle.isinf(Tensor([11, 0, 10],"int32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.716188 GPU 1 69610 test begin: paddle.isinf(Tensor([11, 17, 0],"int16"), )
[cuda error] paddle.isinf(Tensor([11, 17, 0],"int16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.719346 GPU 1 69609 test begin: paddle.isinf(Tensor([11, 17, 0],"int32"), )
[cuda error] paddle.isinf(Tensor([11, 17, 0],"int32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.722062 GPU 1 69607 test begin: paddle.isinf(Tensor([2, 0, 4, 5],"float64"), )
[cuda error] paddle.isinf(Tensor([2, 0, 4, 5],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.728016 GPU 1 69605 test begin: paddle.isinf(Tensor([2, 0, 4, 5],"int8"), )
[cuda error] paddle.isinf(Tensor([2, 0, 4, 5],"int8"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.747475 GPU 1 69615 test begin: paddle.isinf(Tensor([2, 3, 0, 5],"float64"), )
[cuda error] paddle.isinf(Tensor([2, 3, 0, 5],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.760565 GPU 1 69596 test begin: paddle.isinf(Tensor([2, 3, 0, 5],"int8"), )
[cuda error] paddle.isinf(Tensor([2, 3, 0, 5],"int8"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.761178 GPU 1 69629 test begin: paddle.isinf(Tensor([2, 3, 4, 0],"float64"), )
[cuda error] paddle.isinf(Tensor([2, 3, 4, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.766084 GPU 1 69598 test begin: paddle.isinf(Tensor([2, 3, 4, 0],"int8"), )
[cuda error] paddle.isinf(Tensor([2, 3, 4, 0],"int8"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.766356 GPU 1 69612 test begin: paddle.isinf(Tensor([8, 0, 5, 6, 7],"float16"), )
[cuda error] paddle.isinf(Tensor([8, 0, 5, 6, 7],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.787237 GPU 1 69617 test begin: paddle.isinf(Tensor([8, 17, 0, 6, 7],"float16"), )
[cuda error] paddle.isinf(Tensor([8, 17, 0, 6, 7],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.792300 GPU 1 69621 test begin: paddle.isinf(Tensor([8, 17, 5, 0, 7],"float16"), )
[cuda error] paddle.isinf(Tensor([8, 17, 5, 0, 7],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.801085 GPU 1 69606 test begin: paddle.isinf(Tensor([8, 17, 5, 6, 0],"float16"), )
[cuda error] paddle.isinf(Tensor([8, 17, 5, 6, 0],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.803441 GPU 1 69599 test begin: paddle.isinf(x=Tensor([0],"float64"), )
[cuda error] paddle.isinf(x=Tensor([0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.809054 GPU 1 69613 test begin: paddle.isnan(Tensor([0, 17, 10],"int32"), )
[cuda error] paddle.isnan(Tensor([0, 17, 10],"int32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.810811 GPU 1 69614 test begin: paddle.isnan(Tensor([0, 17, 5, 6, 7],"float16"), )
[cuda error] paddle.isnan(Tensor([0, 17, 5, 6, 7],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.832846 GPU 1 69618 test begin: paddle.isnan(Tensor([0, 17],"float32"), )
[cuda error] paddle.isnan(Tensor([0, 17],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.832918 GPU 1 69616 test begin: paddle.isnan(Tensor([0, 3, 4, 5],"float32"), )
[cuda error] paddle.isnan(Tensor([0, 3, 4, 5],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.852649 GPU 1 69605 test begin: paddle.isnan(Tensor([0, 3, 4, 5],"float64"), )
[cuda error] paddle.isnan(Tensor([0, 3, 4, 5],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.865654 GPU 1 69610 test begin: paddle.isnan(Tensor([0, 512],"float16"), )
[cuda error] paddle.isnan(Tensor([0, 512],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.867148 GPU 1 69609 test begin: paddle.isnan(Tensor([0, 64, 16],"float32"), )
[cuda error] paddle.isnan(Tensor([0, 64, 16],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.891144 GPU 1 69603 test begin: paddle.isnan(Tensor([0],"float16"), )
[cuda error] paddle.isnan(Tensor([0],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.896638 GPU 1 69621 test begin: paddle.isnan(Tensor([0],"float32"), )
[cuda error] paddle.isnan(Tensor([0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.902414 GPU 1 69596 test begin: paddle.isnan(Tensor([1024, 0],"float16"), )
[cuda error] paddle.isnan(Tensor([1024, 0],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.911676 GPU 1 69615 test begin: paddle.isnan(Tensor([11, 0, 10],"int32"), )
[cuda error] paddle.isnan(Tensor([11, 0, 10],"int32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.918712 GPU 1 69602 test begin: paddle.isnan(Tensor([11, 0],"float32"), )
[cuda error] paddle.isnan(Tensor([11, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.924170 GPU 1 69608 test begin: paddle.isnan(Tensor([11, 17, 0],"int32"), )
[cuda error] paddle.isnan(Tensor([11, 17, 0],"int32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.926748 GPU 1 69614 test begin: paddle.isnan(Tensor([14, 0, 16],"float32"), )
[cuda error] paddle.isnan(Tensor([14, 0, 16],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.927555 GPU 1 69600 test begin: paddle.isnan(Tensor([14, 64, 0],"float32"), )
[cuda error] paddle.isnan(Tensor([14, 64, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.945159 GPU 1 69604 test begin: paddle.isnan(Tensor([2, 0, 4, 5],"float32"), )
[cuda error] paddle.isnan(Tensor([2, 0, 4, 5],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.947955 GPU 1 69612 test begin: paddle.isnan(Tensor([2, 0, 4, 5],"float64"), )
[cuda error] paddle.isnan(Tensor([2, 0, 4, 5],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.954120 GPU 1 69606 test begin: paddle.isnan(Tensor([2, 3, 0, 5],"float32"), )
[cuda error] paddle.isnan(Tensor([2, 3, 0, 5],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.955691 GPU 1 69607 test begin: paddle.isnan(Tensor([2, 3, 0, 5],"float64"), )
[cuda error] paddle.isnan(Tensor([2, 3, 0, 5],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.957759 GPU 1 69599 test begin: paddle.isnan(Tensor([2, 3, 4, 0],"float32"), )
[cuda error] paddle.isnan(Tensor([2, 3, 4, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.972496 GPU 1 69601 test begin: paddle.isnan(Tensor([2, 3, 4, 0],"float64"), )
[cuda error] paddle.isnan(Tensor([2, 3, 4, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.993686 GPU 1 69605 test begin: paddle.isnan(Tensor([8, 0, 5, 6, 7],"float16"), )
[cuda error] paddle.isnan(Tensor([8, 0, 5, 6, 7],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.996669 GPU 1 69617 test begin: paddle.isnan(Tensor([8, 17, 0, 6, 7],"float16"), )
[cuda error] paddle.isnan(Tensor([8, 17, 0, 6, 7],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:47.999065 GPU 1 69609 test begin: paddle.isnan(Tensor([8, 17, 5, 0, 7],"float16"), )
[cuda error] paddle.isnan(Tensor([8, 17, 5, 0, 7],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.003156 GPU 1 69618 test begin: paddle.isnan(Tensor([8, 17, 5, 6, 0],"float16"), )
[cuda error] paddle.isnan(Tensor([8, 17, 5, 6, 0],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.016591 GPU 1 69596 test begin: paddle.isnan(x=Tensor([0],"float64"), )
[cuda error] paddle.isnan(x=Tensor([0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.028110 GPU 1 69610 test begin: paddle.isneginf(Tensor([0, 17, 10],"int16"), )
[cuda error] paddle.isneginf(Tensor([0, 17, 10],"int16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.034702 GPU 1 69613 test begin: paddle.isneginf(Tensor([0, 17, 10],"int32"), )
[cuda error] paddle.isneginf(Tensor([0, 17, 10],"int32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.038762 GPU 1 69621 test begin: paddle.isneginf(Tensor([0, 17, 5, 6, 7],"float16"), )
[cuda error] paddle.isneginf(Tensor([0, 17, 5, 6, 7],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.041027 GPU 1 69614 test begin: paddle.isneginf(Tensor([0, 17],"float32"), )
[cuda error] paddle.isneginf(Tensor([0, 17],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.075938 GPU 1 69598 test begin: paddle.isneginf(Tensor([0, 3, 4, 5],"float64"), )
[cuda error] paddle.isneginf(Tensor([0, 3, 4, 5],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.079012 GPU 1 69615 test begin: paddle.isneginf(Tensor([0, 3, 4, 5],"int8"), )
[cuda error] paddle.isneginf(Tensor([0, 3, 4, 5],"int8"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.104472 GPU 1 69616 test begin: paddle.isneginf(Tensor([0],"int64"), )
[cuda error] paddle.isneginf(Tensor([0],"int64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.105224 GPU 1 69629 test begin: paddle.isneginf(Tensor([0],"uint8"), )
[cuda error] paddle.isneginf(Tensor([0],"uint8"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.106246 GPU 1 69612 test begin: paddle.isneginf(Tensor([11, 0, 10],"int16"), )
[cuda error] paddle.isneginf(Tensor([11, 0, 10],"int16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.109708 GPU 1 69606 test begin: paddle.isneginf(Tensor([11, 0, 10],"int32"), )
[cuda error] paddle.isneginf(Tensor([11, 0, 10],"int32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.114738 GPU 1 69599 test begin: paddle.isneginf(Tensor([11, 0],"float32"), )
[cuda error] paddle.isneginf(Tensor([11, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.115885 GPU 1 69605 test begin: paddle.isneginf(Tensor([11, 17, 0],"int16"), )
[cuda error] paddle.isneginf(Tensor([11, 17, 0],"int16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.116292 GPU 1 69609 test begin: paddle.isneginf(Tensor([11, 17, 0],"int32"), )
[cuda error] paddle.isneginf(Tensor([11, 17, 0],"int32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.129445 GPU 1 69607 test begin: paddle.isneginf(Tensor([2, 0, 4, 5],"float64"), )
[cuda error] paddle.isneginf(Tensor([2, 0, 4, 5],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.132491 GPU 1 69596 test begin: paddle.isneginf(Tensor([2, 0, 4, 5],"int8"), )
[cuda error] paddle.isneginf(Tensor([2, 0, 4, 5],"int8"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.144892 GPU 1 69601 test begin: paddle.isneginf(Tensor([2, 3, 0, 5],"float64"), )
[cuda error] paddle.isneginf(Tensor([2, 3, 0, 5],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.157505 GPU 1 69617 test begin: paddle.isneginf(Tensor([2, 3, 0, 5],"int8"), )
[cuda error] paddle.isneginf(Tensor([2, 3, 0, 5],"int8"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.163801 GPU 1 69618 test begin: paddle.isneginf(Tensor([2, 3, 4, 0],"float64"), )
[cuda error] paddle.isneginf(Tensor([2, 3, 4, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.164614 GPU 1 69610 test begin: paddle.isneginf(Tensor([2, 3, 4, 0],"int8"), )
[cuda error] paddle.isneginf(Tensor([2, 3, 4, 0],"int8"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.172759 GPU 1 69602 test begin: paddle.isneginf(Tensor([8, 0, 5, 6, 7],"float16"), )
[cuda error] paddle.isneginf(Tensor([8, 0, 5, 6, 7],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.177718 GPU 1 69608 test begin: paddle.isneginf(Tensor([8, 17, 0, 6, 7],"float16"), )
[cuda error] paddle.isneginf(Tensor([8, 17, 0, 6, 7],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.182723 GPU 1 69621 test begin: paddle.isneginf(Tensor([8, 17, 5, 0, 7],"float16"), )
[cuda error] paddle.isneginf(Tensor([8, 17, 5, 0, 7],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.186145 GPU 1 69614 test begin: paddle.isneginf(Tensor([8, 17, 5, 6, 0],"float16"), )
[cuda error] paddle.isneginf(Tensor([8, 17, 5, 6, 0],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.191420 GPU 1 69600 test begin: paddle.isposinf(Tensor([0, 17, 10],"int16"), )
[cuda error] paddle.isposinf(Tensor([0, 17, 10],"int16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.213972 GPU 1 69603 test begin: paddle.isposinf(Tensor([0, 17, 10],"int32"), )
[cuda error] paddle.isposinf(Tensor([0, 17, 10],"int32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.244776 GPU 1 69609 test begin: paddle.isposinf(Tensor([0, 17, 5, 6, 7],"float16"), )
[cuda error] paddle.isposinf(Tensor([0, 17, 5, 6, 7],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.254643 GPU 1 69615 test begin: paddle.isposinf(Tensor([0, 17],"float32"), )
[cuda error] paddle.isposinf(Tensor([0, 17],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.260452 GPU 1 69596 test begin: paddle.isposinf(Tensor([0, 3, 4, 5],"float64"), )
[cuda error] paddle.isposinf(Tensor([0, 3, 4, 5],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.265425 GPU 1 69612 test begin: paddle.isposinf(Tensor([0, 3, 4, 5],"int8"), )
[cuda error] paddle.isposinf(Tensor([0, 3, 4, 5],"int8"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.266131 GPU 1 69606 test begin: paddle.isposinf(Tensor([0],"int64"), )
[cuda error] paddle.isposinf(Tensor([0],"int64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.266998 GPU 1 69598 test begin: paddle.isposinf(Tensor([0],"uint8"), )
[cuda error] paddle.isposinf(Tensor([0],"uint8"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.270998 GPU 1 69599 test begin: paddle.isposinf(Tensor([11, 0, 10],"int16"), )
[cuda error] paddle.isposinf(Tensor([11, 0, 10],"int16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.272752 GPU 1 69605 test begin: paddle.isposinf(Tensor([11, 0, 10],"int32"), )
[cuda error] paddle.isposinf(Tensor([11, 0, 10],"int32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.281301 GPU 1 69613 test begin: paddle.isposinf(Tensor([11, 0],"float32"), )
[cuda error] paddle.isposinf(Tensor([11, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.284325 GPU 1 69607 test begin: paddle.isposinf(Tensor([11, 17, 0],"int16"), )
[cuda error] paddle.isposinf(Tensor([11, 17, 0],"int16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.288474 GPU 1 69601 test begin: paddle.isposinf(Tensor([11, 17, 0],"int32"), )
[cuda error] paddle.isposinf(Tensor([11, 17, 0],"int32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.288569 GPU 1 69610 test begin: paddle.isposinf(Tensor([2, 0, 4, 5],"float64"), )
[cuda error] paddle.isposinf(Tensor([2, 0, 4, 5],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.295620 GPU 1 69604 test begin: paddle.isposinf(Tensor([2, 0, 4, 5],"int8"), )
[cuda error] paddle.isposinf(Tensor([2, 0, 4, 5],"int8"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.316365 GPU 1 69602 test begin: paddle.isposinf(Tensor([2, 3, 0, 5],"float64"), )
[cuda error] paddle.isposinf(Tensor([2, 3, 0, 5],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.317619 GPU 1 69617 test begin: paddle.isposinf(Tensor([2, 3, 0, 5],"int8"), )
[cuda error] paddle.isposinf(Tensor([2, 3, 0, 5],"int8"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.326750 GPU 1 69621 test begin: paddle.isposinf(Tensor([2, 3, 4, 0],"float64"), )
[cuda error] paddle.isposinf(Tensor([2, 3, 4, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.327324 GPU 1 69616 test begin: paddle.isposinf(Tensor([2, 3, 4, 0],"int8"), )
[cuda error] paddle.isposinf(Tensor([2, 3, 4, 0],"int8"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.338526 GPU 1 69618 test begin: paddle.isposinf(Tensor([8, 0, 5, 6, 7],"float16"), )
[cuda error] paddle.isposinf(Tensor([8, 0, 5, 6, 7],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.359808 GPU 1 69614 test begin: paddle.isposinf(Tensor([8, 17, 0, 6, 7],"float16"), )
[cuda error] paddle.isposinf(Tensor([8, 17, 0, 6, 7],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.374853 GPU 1 69609 test begin: paddle.isposinf(Tensor([8, 17, 5, 0, 7],"float16"), )
[cuda error] paddle.isposinf(Tensor([8, 17, 5, 0, 7],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.374911 GPU 1 69596 test begin: paddle.isposinf(Tensor([8, 17, 5, 6, 0],"float16"), )
[cuda error] paddle.isposinf(Tensor([8, 17, 5, 6, 0],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.376328 GPU 1 69600 test begin: paddle.kron(Tensor([0, 10],"float32"), Tensor([5, 5, 4, 3, 2],"float32"), )
[cuda error] paddle.kron(Tensor([0, 10],"float32"), Tensor([5, 5, 4, 3, 2],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.391385 GPU 1 69605 test begin: paddle.kron(Tensor([0, 10],"float32"), Tensor([5, 5, 4],"float32"), )
[cuda error] paddle.kron(Tensor([0, 10],"float32"), Tensor([5, 5, 4],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.392063 GPU 1 69612 test begin: paddle.kron(Tensor([0, 10],"float64"), Tensor([0, 10],"float64"), )
[cuda error] paddle.kron(Tensor([0, 10],"float64"), Tensor([0, 10],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.410502 GPU 1 69610 test begin: paddle.kron(Tensor([0, 10],"float64"), Tensor([10, 10],"float64"), )
[cuda error] paddle.kron(Tensor([0, 10],"float64"), Tensor([10, 10],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.412754 GPU 1 69598 test begin: paddle.kron(Tensor([0, 2],"complex128"), Tensor([2, 2, 3],"float64"), )
[cuda error] paddle.kron(Tensor([0, 2],"complex128"), Tensor([2, 2, 3],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.422326 GPU 1 69606 test begin: paddle.kron(Tensor([0, 5, 4, 3, 5, 6],"float32"), Tensor([3, 5, 4],"float32"), )
[cuda error] paddle.kron(Tensor([0, 5, 4, 3, 5, 6],"float32"), Tensor([3, 5, 4],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.425756 GPU 1 69615 test begin: paddle.kron(Tensor([0, 8],"float16"), Tensor([0, 8],"float16"), )
[cuda error] paddle.kron(Tensor([0, 8],"float16"), Tensor([0, 8],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.427725 GPU 1 69599 test begin: paddle.kron(Tensor([0, 8],"float16"), Tensor([16, 8],"float16"), )
[cuda error] paddle.kron(Tensor([0, 8],"float16"), Tensor([16, 8],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.427939 GPU 1 69604 test begin: paddle.kron(Tensor([10, 0],"float32"), Tensor([5, 5, 4, 3, 2],"float32"), )
[cuda error] paddle.kron(Tensor([10, 0],"float32"), Tensor([5, 5, 4, 3, 2],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.435691 GPU 1 69602 test begin: paddle.kron(Tensor([10, 0],"float32"), Tensor([5, 5, 4],"float32"), )
[cuda error] paddle.kron(Tensor([10, 0],"float32"), Tensor([5, 5, 4],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.436367 GPU 1 69607 test begin: paddle.kron(Tensor([10, 0],"float64"), Tensor([10, 0],"float64"), )
[cuda error] paddle.kron(Tensor([10, 0],"float64"), Tensor([10, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.442816 GPU 1 69617 test begin: paddle.kron(Tensor([10, 0],"float64"), Tensor([10, 10],"float64"), )
[cuda error] paddle.kron(Tensor([10, 0],"float64"), Tensor([10, 10],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.445801 GPU 1 69601 test begin: paddle.kron(Tensor([10, 10],"float32"), Tensor([0, 5, 4, 3, 2],"float32"), )
[cuda error] paddle.kron(Tensor([10, 10],"float32"), Tensor([0, 5, 4, 3, 2],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.471089 GPU 1 69621 test begin: paddle.kron(Tensor([10, 10],"float32"), Tensor([0, 5, 4],"float32"), )
[cuda error] paddle.kron(Tensor([10, 10],"float32"), Tensor([0, 5, 4],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.473424 GPU 1 69618 test begin: paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 0, 4, 3, 2],"float32"), )
[cuda error] paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 0, 4, 3, 2],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.473609 GPU 1 69603 test begin: paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 0, 4],"float32"), )
[cuda error] paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 0, 4],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.473990 GPU 1 69629 test begin: paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 5, 0, 3, 2],"float32"), )
[cuda error] paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 5, 0, 3, 2],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.488715 GPU 1 69596 test begin: paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 5, 0],"float32"), )
[cuda error] paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 5, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.495713 GPU 1 69609 test begin: paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 5, 4, 0, 2],"float32"), )
[cuda error] paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 5, 4, 0, 2],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.505350 GPU 1 69614 test begin: paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 5, 4, 3, 0],"float32"), )
[cuda error] paddle.kron(Tensor([10, 10],"float32"), Tensor([5, 5, 4, 3, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.509858 GPU 1 69612 test begin: paddle.kron(Tensor([10, 10],"float64"), Tensor([0, 10],"float64"), )
[cuda error] paddle.kron(Tensor([10, 10],"float64"), Tensor([0, 10],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.514676 GPU 1 69605 test begin: paddle.kron(Tensor([10, 10],"float64"), Tensor([10, 0],"float64"), )
[cuda error] paddle.kron(Tensor([10, 10],"float64"), Tensor([10, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.537863 GPU 1 69610 test begin: paddle.kron(Tensor([12, 0],"float16"), Tensor([16, 0],"float16"), )
[cuda error] paddle.kron(Tensor([12, 0],"float16"), Tensor([16, 0],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.538071 GPU 1 69608 test begin: paddle.kron(Tensor([12, 0],"float16"), Tensor([16, 8],"float16"), )
[cuda error] paddle.kron(Tensor([12, 0],"float16"), Tensor([16, 8],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.538732 GPU 1 69600 test begin: paddle.kron(Tensor([12, 8],"float16"), Tensor([0, 8],"float16"), )
[cuda error] paddle.kron(Tensor([12, 8],"float16"), Tensor([0, 8],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.546271 GPU 1 69616 test begin: paddle.kron(Tensor([12, 8],"float16"), Tensor([16, 0],"float16"), )
[cuda error] paddle.kron(Tensor([12, 8],"float16"), Tensor([16, 0],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.582708 GPU 1 69613 test begin: paddle.kron(Tensor([2, 0],"complex128"), Tensor([2, 2, 3],"float64"), )
[cuda error] paddle.kron(Tensor([2, 0],"complex128"), Tensor([2, 2, 3],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.588520 GPU 1 69607 test begin: paddle.kron(Tensor([2, 2],"complex128"), Tensor([0, 2, 3],"float64"), )
[paddle error] paddle.kron(Tensor([2, 2],"complex128"), Tensor([0, 2, 3],"float64"), ) 
 (InvalidArgument) The type of data we are trying to retrieve (complex128) does not match the type of data (float64) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():11 != phi::CppTypeToDataType<T>::Type():13.] (at ../paddle/phi/core/dense_tensor.cc:153)


2025-05-21 22:07:48.592149 GPU 1 69615 test begin: paddle.kron(Tensor([2, 2],"complex128"), Tensor([2, 0, 3],"float64"), )
[paddle error] paddle.kron(Tensor([2, 2],"complex128"), Tensor([2, 0, 3],"float64"), ) 
 (InvalidArgument) The type of data we are trying to retrieve (complex128) does not match the type of data (float64) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():11 != phi::CppTypeToDataType<T>::Type():13.] (at ../paddle/phi/core/dense_tensor.cc:153)


2025-05-21 22:07:48.601828 GPU 1 69601 test begin: paddle.kron(Tensor([2, 2],"complex128"), Tensor([2, 2, 0],"float64"), )
[paddle error] paddle.kron(Tensor([2, 2],"complex128"), Tensor([2, 2, 0],"float64"), ) 
 (InvalidArgument) The type of data we are trying to retrieve (complex128) does not match the type of data (float64) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():11 != phi::CppTypeToDataType<T>::Type():13.] (at ../paddle/phi/core/dense_tensor.cc:153)


2025-05-21 22:07:48.602508 GPU 1 69604 test begin: paddle.kron(Tensor([5, 0, 4, 3, 5, 6],"float32"), Tensor([3, 5, 4],"float32"), )
[cuda error] paddle.kron(Tensor([5, 0, 4, 3, 5, 6],"float32"), Tensor([3, 5, 4],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.603163 GPU 1 69598 test begin: paddle.kron(Tensor([5, 5, 0, 3, 5, 6],"float32"), Tensor([3, 5, 4],"float32"), )
[cuda error] paddle.kron(Tensor([5, 5, 0, 3, 5, 6],"float32"), Tensor([3, 5, 4],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.603250 GPU 1 69602 test begin: paddle.kron(Tensor([5, 5, 4, 0, 5, 6],"float32"), Tensor([3, 5, 4],"float32"), )
[cuda error] paddle.kron(Tensor([5, 5, 4, 0, 5, 6],"float32"), Tensor([3, 5, 4],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.603499 GPU 1 69617 test begin: paddle.kron(Tensor([5, 5, 4, 3, 0, 6],"float32"), Tensor([3, 5, 4],"float32"), )
[cuda error] paddle.kron(Tensor([5, 5, 4, 3, 0, 6],"float32"), Tensor([3, 5, 4],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.607562 GPU 1 69606 test begin: paddle.kron(Tensor([5, 5, 4, 3, 5, 0],"float32"), Tensor([3, 5, 4],"float32"), )
[cuda error] paddle.kron(Tensor([5, 5, 4, 3, 5, 0],"float32"), Tensor([3, 5, 4],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.607702 GPU 1 69599 test begin: paddle.kron(Tensor([5, 5, 4, 3, 5, 6],"float32"), Tensor([0, 5, 4],"float32"), )
[cuda error] paddle.kron(Tensor([5, 5, 4, 3, 5, 6],"float32"), Tensor([0, 5, 4],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.611655 GPU 1 69596 test begin: paddle.kron(Tensor([5, 5, 4, 3, 5, 6],"float32"), Tensor([3, 0, 4],"float32"), )
[cuda error] paddle.kron(Tensor([5, 5, 4, 3, 5, 6],"float32"), Tensor([3, 0, 4],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.636997 GPU 1 69621 test begin: paddle.kron(Tensor([5, 5, 4, 3, 5, 6],"float32"), Tensor([3, 5, 0],"float32"), )
[cuda error] paddle.kron(Tensor([5, 5, 4, 3, 5, 6],"float32"), Tensor([3, 5, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.640639 GPU 1 69605 test begin: paddle.kron(x=Tensor([0, 2],"float64"), y=Tensor([0, 3],"float64"), )
[cuda error] paddle.kron(x=Tensor([0, 2],"float64"), y=Tensor([0, 3],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.654669 GPU 1 69610 test begin: paddle.kron(x=Tensor([0, 2],"float64"), y=Tensor([3, 3, 2],"float64"), )
[cuda error] paddle.kron(x=Tensor([0, 2],"float64"), y=Tensor([3, 3, 2],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.754920 GPU 1 69605 test begin: paddle.kron(x=Tensor([0, 2],"float64"), y=Tensor([3, 3],"float64"), )
[cuda error] paddle.kron(x=Tensor([0, 2],"float64"), y=Tensor([3, 3],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.814018 GPU 1 69609 test begin: paddle.kron(x=Tensor([0, 3],"float32"), y=Tensor([0, 3],"float32"), )
[cuda error] paddle.kron(x=Tensor([0, 3],"float32"), y=Tensor([0, 3],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.823978 GPU 1 69617 test begin: paddle.kron(x=Tensor([0, 3],"float32"), y=Tensor([3, 3],"float32"), )
[cuda error] paddle.kron(x=Tensor([0, 3],"float32"), y=Tensor([3, 3],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.824327 GPU 1 69600 test begin: paddle.kron(x=Tensor([0],"float64"), y=Tensor([3, 3],"float64"), )
[cuda error] paddle.kron(x=Tensor([0],"float64"), y=Tensor([3, 3],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.825081 GPU 1 69612 test begin: paddle.kron(x=Tensor([1],"float64"), y=Tensor([0, 3],"float64"), )
[cuda error] paddle.kron(x=Tensor([1],"float64"), y=Tensor([0, 3],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.833013 GPU 1 69596 test begin: paddle.kron(x=Tensor([1],"float64"), y=Tensor([3, 0],"float64"), )
[cuda error] paddle.kron(x=Tensor([1],"float64"), y=Tensor([3, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.834075 GPU 1 69618 test begin: paddle.kron(x=Tensor([2, 0],"float32"), y=Tensor([3, 0],"float32"), )
[cuda error] paddle.kron(x=Tensor([2, 0],"float32"), y=Tensor([3, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.834499 GPU 1 69601 test begin: paddle.kron(x=Tensor([2, 0],"float32"), y=Tensor([3, 3],"float32"), )
[cuda error] paddle.kron(x=Tensor([2, 0],"float32"), y=Tensor([3, 3],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.834559 GPU 1 69607 test begin: paddle.kron(x=Tensor([2, 0],"float64"), y=Tensor([3, 0],"float64"), )
[cuda error] paddle.kron(x=Tensor([2, 0],"float64"), y=Tensor([3, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.834787 GPU 1 69604 test begin: paddle.kron(x=Tensor([2, 0],"float64"), y=Tensor([3, 3, 2],"float64"), )
[cuda error] paddle.kron(x=Tensor([2, 0],"float64"), y=Tensor([3, 3, 2],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.835274 GPU 1 69603 test begin: paddle.kron(x=Tensor([2, 0],"float64"), y=Tensor([3, 3],"float64"), )
[cuda error] paddle.kron(x=Tensor([2, 0],"float64"), y=Tensor([3, 3],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.835391 GPU 1 69608 test begin: paddle.kron(x=Tensor([2, 2],"float64"), y=Tensor([0, 3, 2],"float64"), )
[cuda error] paddle.kron(x=Tensor([2, 2],"float64"), y=Tensor([0, 3, 2],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.835708 GPU 1 69606 test begin: paddle.kron(x=Tensor([2, 2],"float64"), y=Tensor([0, 3],"float64"), )
[cuda error] paddle.kron(x=Tensor([2, 2],"float64"), y=Tensor([0, 3],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.835818 GPU 1 69615 test begin: paddle.kron(x=Tensor([2, 2],"float64"), y=Tensor([3, 0, 2],"float64"), )
[cuda error] paddle.kron(x=Tensor([2, 2],"float64"), y=Tensor([3, 0, 2],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.836430 GPU 1 69616 test begin: paddle.kron(x=Tensor([2, 2],"float64"), y=Tensor([3, 0],"float64"), )
[cuda error] paddle.kron(x=Tensor([2, 2],"float64"), y=Tensor([3, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.836535 GPU 1 69614 test begin: paddle.kron(x=Tensor([2, 2],"float64"), y=Tensor([3, 3, 0],"float64"), )
[cuda error] paddle.kron(x=Tensor([2, 2],"float64"), y=Tensor([3, 3, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.836620 GPU 1 69621 test begin: paddle.kron(x=Tensor([2, 3],"float32"), y=Tensor([0, 3],"float32"), )
[cuda error] paddle.kron(x=Tensor([2, 3],"float32"), y=Tensor([0, 3],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.836777 GPU 1 69599 test begin: paddle.kron(x=Tensor([2, 3],"float32"), y=Tensor([3, 0],"float32"), )
[cuda error] paddle.kron(x=Tensor([2, 3],"float32"), y=Tensor([3, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:48.930973 GPU 1 69609 test begin: paddle.lerp(Tensor([0, 1, 1, 1],"float32"), Tensor([0, 3, 8, 8],"float32"), 0.3, )
[paddle error] paddle.lerp(Tensor([0, 1, 1, 1],"float32"), Tensor([0, 3, 8, 8],"float32"), 0.3, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:48.967626 GPU 1 69602 test begin: paddle.lerp(Tensor([0, 1, 1],"float32"), Tensor([0, 28, 28],"float32"), 0.36, )
[paddle error] paddle.lerp(Tensor([0, 1, 1],"float32"), Tensor([0, 28, 28],"float32"), 0.36, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:48.970469 GPU 1 69598 test begin: paddle.lerp(Tensor([0, 1, 1],"float32"), Tensor([0, 8, 8],"float32"), 0.3, )
[paddle error] paddle.lerp(Tensor([0, 1, 1],"float32"), Tensor([0, 8, 8],"float32"), 0.3, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:48.993715 GPU 1 69629 test begin: paddle.lerp(Tensor([0, 1, 8, 8],"float32"), Tensor([0, 3, 8, 8],"float32"), 1.1, )
[paddle error] paddle.lerp(Tensor([0, 1, 8, 8],"float32"), Tensor([0, 3, 8, 8],"float32"), 1.1, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:48.998626 GPU 1 69613 test begin: paddle.lerp(Tensor([0, 1],"float32"), Tensor([0, 1],"float32"), Tensor([0, 1],"float32"), )
[paddle error] paddle.lerp(Tensor([0, 1],"float32"), Tensor([0, 1],"float32"), Tensor([0, 1],"float32"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.009233 GPU 1 69610 test begin: paddle.lerp(Tensor([0, 28, 28],"float32"), Tensor([0, 28, 28],"float32"), 1.0, )
[paddle error] paddle.lerp(Tensor([0, 28, 28],"float32"), Tensor([0, 28, 28],"float32"), 1.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.121102 GPU 1 69609 test begin: paddle.lerp(Tensor([0, 28, 28],"float32"), Tensor([0, 28, 28],"float32"), 1.2, )
[paddle error] paddle.lerp(Tensor([0, 28, 28],"float32"), Tensor([0, 28, 28],"float32"), 1.2, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.124483 GPU 1 69607 test begin: paddle.lerp(Tensor([0, 3, 3],"float32"), Tensor([0, 3, 3],"float32"), Tensor([0, 3, 3],"float32"), )
[paddle error] paddle.lerp(Tensor([0, 3, 3],"float32"), Tensor([0, 3, 3],"float32"), Tensor([0, 3, 3],"float32"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.164023 GPU 1 69605 test begin: paddle.lerp(Tensor([0, 3, 3],"float32"), Tensor([1, 3, 3],"float32"), Tensor([1, 3, 3],"float32"), )
[paddle error] paddle.lerp(Tensor([0, 3, 3],"float32"), Tensor([1, 3, 3],"float32"), Tensor([1, 3, 3],"float32"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.165839 GPU 1 69608 test begin: paddle.lerp(Tensor([0, 3, 3],"float64"), Tensor([0, 3, 3],"float64"), Tensor([0, 3, 3],"float64"), )
[paddle error] paddle.lerp(Tensor([0, 3, 3],"float64"), Tensor([0, 3, 3],"float64"), Tensor([0, 3, 3],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.172284 GPU 1 69596 test begin: paddle.lerp(Tensor([0, 3, 3],"float64"), Tensor([1, 3, 3],"float64"), Tensor([1, 3, 3],"float64"), )
[paddle error] paddle.lerp(Tensor([0, 3, 3],"float64"), Tensor([1, 3, 3],"float64"), Tensor([1, 3, 3],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.172366 GPU 1 69604 test begin: paddle.lerp(Tensor([0, 3, 8, 8],"float32"), Tensor([0, 3, 8, 8],"float32"), 2.1, )
[paddle error] paddle.lerp(Tensor([0, 3, 8, 8],"float32"), Tensor([0, 3, 8, 8],"float32"), 2.1, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.172657 GPU 1 69617 test begin: paddle.lerp(Tensor([0, 3],"float64"), Tensor([0, 3],"float64"), Tensor([0, 3],"float64"), )
[paddle error] paddle.lerp(Tensor([0, 3],"float64"), Tensor([0, 3],"float64"), Tensor([0, 3],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.202126 GPU 1 69598 test begin: paddle.lerp(Tensor([0, 3],"float64"), Tensor([1, 3],"float64"), Tensor([1, 3],"float64"), )
[paddle error] paddle.lerp(Tensor([0, 3],"float64"), Tensor([1, 3],"float64"), Tensor([1, 3],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.209591 GPU 1 69618 test begin: paddle.lerp(Tensor([0, 6, 3, 1, 2, 5],"float64"), Tensor([0, 6, 3, 1, 2, 5],"float64"), Tensor([0, 6, 3, 1, 2, 5],"float64"), )
[paddle error] paddle.lerp(Tensor([0, 6, 3, 1, 2, 5],"float64"), Tensor([0, 6, 3, 1, 2, 5],"float64"), Tensor([0, 6, 3, 1, 2, 5],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.238092 GPU 1 69602 test begin: paddle.lerp(Tensor([0, 6, 3, 4, 1, 5],"float64"), Tensor([0, 6, 3, 4, 1, 5],"float64"), Tensor([0, 6, 3, 4, 1, 5],"float64"), )
[paddle error] paddle.lerp(Tensor([0, 6, 3, 4, 1, 5],"float64"), Tensor([0, 6, 3, 4, 1, 5],"float64"), Tensor([0, 6, 3, 4, 1, 5],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.256402 GPU 1 69613 test begin: paddle.lerp(Tensor([0, 8, 8],"float32"), Tensor([0, 8, 8],"float32"), 1.1, )
[paddle error] paddle.lerp(Tensor([0, 8, 8],"float32"), Tensor([0, 8, 8],"float32"), 1.1, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.258148 GPU 1 69629 test begin: paddle.lerp(Tensor([0, 8, 8],"float32"), Tensor([0, 8, 8],"float32"), 2.1, )
[paddle error] paddle.lerp(Tensor([0, 8, 8],"float32"), Tensor([0, 8, 8],"float32"), 2.1, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.274685 GPU 1 69607 test begin: paddle.lerp(Tensor([0],"float32"), Tensor([0],"float32"), Tensor([0],"float32"), )
[paddle error] paddle.lerp(Tensor([0],"float32"), Tensor([0],"float32"), Tensor([0],"float32"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.275303 GPU 1 69609 test begin: paddle.lerp(Tensor([0],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), )
[paddle error] paddle.lerp(Tensor([0],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.291931 GPU 1 69610 test begin: paddle.lerp(Tensor([0],"float64"), Tensor([0],"float64"), Tensor([0],"float64"), )
[paddle error] paddle.lerp(Tensor([0],"float64"), Tensor([0],"float64"), Tensor([0],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.332147 GPU 1 69612 test begin: paddle.lerp(Tensor([0],"float64"), Tensor([1],"float64"), Tensor([1],"float64"), )
[paddle error] paddle.lerp(Tensor([0],"float64"), Tensor([1],"float64"), Tensor([1],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.333217 GPU 1 69599 test begin: paddle.lerp(Tensor([1, 0, 1],"float32"), Tensor([3, 0, 28],"float32"), 0.36, )
[paddle error] paddle.lerp(Tensor([1, 0, 1],"float32"), Tensor([3, 0, 28],"float32"), 0.36, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.334234 GPU 1 69616 test begin: paddle.lerp(Tensor([1, 0, 1],"float32"), Tensor([3, 0, 8],"float32"), 0.3, )
[paddle error] paddle.lerp(Tensor([1, 0, 1],"float32"), Tensor([3, 0, 8],"float32"), 0.3, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.335338 GPU 1 69615 test begin: paddle.lerp(Tensor([1, 0, 28],"float32"), Tensor([3, 0, 28],"float32"), 1.0, )
[paddle error] paddle.lerp(Tensor([1, 0, 28],"float32"), Tensor([3, 0, 28],"float32"), 1.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.335446 GPU 1 69621 test begin: paddle.lerp(Tensor([1, 0, 3],"float32"), Tensor([1, 0, 3],"float32"), Tensor([1, 0, 3],"float32"), )
[paddle error] paddle.lerp(Tensor([1, 0, 3],"float32"), Tensor([1, 0, 3],"float32"), Tensor([1, 0, 3],"float32"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.345030 GPU 1 69600 test begin: paddle.lerp(Tensor([1, 0, 3],"float64"), Tensor([1, 0, 3],"float64"), Tensor([1, 0, 3],"float64"), )
[paddle error] paddle.lerp(Tensor([1, 0, 3],"float64"), Tensor([1, 0, 3],"float64"), Tensor([1, 0, 3],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.346484 GPU 1 69601 test begin: paddle.lerp(Tensor([1, 0, 8],"float32"), Tensor([3, 0, 8],"float32"), 1.1, )
[paddle error] paddle.lerp(Tensor([1, 0, 8],"float32"), Tensor([3, 0, 8],"float32"), 1.1, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.346600 GPU 1 69603 test begin: paddle.lerp(Tensor([1, 0],"float64"), Tensor([1, 0],"float64"), Tensor([1, 0],"float64"), )
[paddle error] paddle.lerp(Tensor([1, 0],"float64"), Tensor([1, 0],"float64"), Tensor([1, 0],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.346929 GPU 1 69606 test begin: paddle.lerp(Tensor([1, 1, 0],"float32"), Tensor([3, 28, 0],"float32"), 0.36, )
[paddle error] paddle.lerp(Tensor([1, 1, 0],"float32"), Tensor([3, 28, 0],"float32"), 0.36, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.454806 GPU 1 69607 test begin: paddle.lerp(Tensor([1, 1, 0],"float32"), Tensor([3, 8, 0],"float32"), 0.3, )
[paddle error] paddle.lerp(Tensor([1, 1, 0],"float32"), Tensor([3, 8, 0],"float32"), 0.3, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.458765 GPU 1 69599 test begin: paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([0, 28, 28],"float32"), 0.36, )
[paddle error] paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([0, 28, 28],"float32"), 0.36, ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:55)


2025-05-21 22:07:49.459343 GPU 1 69610 test begin: paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([0, 8, 8],"float32"), 0.3, )
[paddle error] paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([0, 8, 8],"float32"), 0.3, ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:55)


2025-05-21 22:07:49.469858 GPU 1 69617 test begin: paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 0, 28],"float32"), 0.36, )
[paddle error] paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 0, 28],"float32"), 0.36, ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:55)


2025-05-21 22:07:49.480307 GPU 1 69608 test begin: paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 0, 8],"float32"), 0.3, )
[paddle error] paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 0, 8],"float32"), 0.3, ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:55)


2025-05-21 22:07:49.484015 GPU 1 69604 test begin: paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 28, 0],"float32"), 0.36, )
[paddle error] paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 28, 0],"float32"), 0.36, ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:55)


2025-05-21 22:07:49.488056 GPU 1 69615 test begin: paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 8, 0],"float32"), 0.3, )
[paddle error] paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 8, 0],"float32"), 0.3, ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:55)


2025-05-21 22:07:49.498409 GPU 1 69614 test begin: paddle.lerp(Tensor([1, 28, 0],"float32"), Tensor([3, 28, 0],"float32"), 1.0, )
[paddle error] paddle.lerp(Tensor([1, 28, 0],"float32"), Tensor([3, 28, 0],"float32"), 1.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.503628 GPU 1 69612 test begin: paddle.lerp(Tensor([1, 28, 28],"float32"), Tensor([0, 28, 28],"float32"), 1.0, )
[paddle error] paddle.lerp(Tensor([1, 28, 28],"float32"), Tensor([0, 28, 28],"float32"), 1.0, ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:55)


2025-05-21 22:07:49.503877 GPU 1 69596 test begin: paddle.lerp(Tensor([1, 3, 0],"float32"), Tensor([1, 3, 0],"float32"), Tensor([1, 3, 0],"float32"), )
[paddle error] paddle.lerp(Tensor([1, 3, 0],"float32"), Tensor([1, 3, 0],"float32"), Tensor([1, 3, 0],"float32"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.504630 GPU 1 69605 test begin: paddle.lerp(Tensor([1, 3, 0],"float64"), Tensor([1, 3, 0],"float64"), Tensor([1, 3, 0],"float64"), )
[paddle error] paddle.lerp(Tensor([1, 3, 0],"float64"), Tensor([1, 3, 0],"float64"), Tensor([1, 3, 0],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.508088 GPU 1 69616 test begin: paddle.lerp(Tensor([1, 3, 3],"float32"), Tensor([0, 3, 3],"float32"), Tensor([1, 3, 3],"float32"), )
[paddle error] paddle.lerp(Tensor([1, 3, 3],"float32"), Tensor([0, 3, 3],"float32"), Tensor([1, 3, 3],"float32"), ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:55)


2025-05-21 22:07:49.539039 GPU 1 69613 test begin: paddle.lerp(Tensor([1, 3, 3],"float32"), Tensor([1, 3, 3],"float32"), Tensor([0, 3, 3],"float32"), )
[cuda error] paddle.lerp(Tensor([1, 3, 3],"float32"), Tensor([1, 3, 3],"float32"), Tensor([0, 3, 3],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:49.572129 GPU 1 69621 test begin: paddle.lerp(Tensor([1, 3, 3],"float64"), Tensor([0, 3, 3],"float64"), Tensor([1, 3, 3],"float64"), )
[paddle error] paddle.lerp(Tensor([1, 3, 3],"float64"), Tensor([0, 3, 3],"float64"), Tensor([1, 3, 3],"float64"), ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:55)


2025-05-21 22:07:49.610988 GPU 1 69629 test begin: paddle.lerp(Tensor([1, 3, 3],"float64"), Tensor([1, 3, 3],"float64"), Tensor([0, 3, 3],"float64"), )
[cuda error] paddle.lerp(Tensor([1, 3, 3],"float64"), Tensor([1, 3, 3],"float64"), Tensor([0, 3, 3],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:49.619687 GPU 1 69618 test begin: paddle.lerp(Tensor([1, 3],"float64"), Tensor([0, 3],"float64"), Tensor([1, 3],"float64"), )
[paddle error] paddle.lerp(Tensor([1, 3],"float64"), Tensor([0, 3],"float64"), Tensor([1, 3],"float64"), ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:55)


2025-05-21 22:07:49.627195 GPU 1 69606 test begin: paddle.lerp(Tensor([1, 3],"float64"), Tensor([1, 3],"float64"), Tensor([0, 3],"float64"), )
[cuda error] paddle.lerp(Tensor([1, 3],"float64"), Tensor([1, 3],"float64"), Tensor([0, 3],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:49.645263 GPU 1 69607 test begin: paddle.lerp(Tensor([1, 8, 0],"float32"), Tensor([3, 8, 0],"float32"), 1.1, )
[paddle error] paddle.lerp(Tensor([1, 8, 0],"float32"), Tensor([3, 8, 0],"float32"), 1.1, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.670564 GPU 1 69598 test begin: paddle.lerp(Tensor([1, 8, 8],"float32"), Tensor([0, 8, 8],"float32"), 1.1, )
[paddle error] paddle.lerp(Tensor([1, 8, 8],"float32"), Tensor([0, 8, 8],"float32"), 1.1, ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:55)


2025-05-21 22:07:49.672552 GPU 1 69602 test begin: paddle.lerp(Tensor([10, 1, 0, 5, 5],"float32"), Tensor([10, 5, 1, 5, 5],"float32"), Tensor([1],"float32"), )
[paddle error] paddle.lerp(Tensor([10, 1, 0, 5, 5],"float32"), Tensor([10, 5, 1, 5, 5],"float32"), Tensor([1],"float32"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.681722 GPU 1 69609 test begin: paddle.lerp(Tensor([10, 1, 10, 5, 5],"float32"), Tensor([10, 0, 1, 5, 5],"float32"), Tensor([1],"float32"), )
[paddle error] paddle.lerp(Tensor([10, 1, 10, 5, 5],"float32"), Tensor([10, 0, 1, 5, 5],"float32"), Tensor([1],"float32"), ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:55)


2025-05-21 22:07:49.734113 GPU 1 69603 test begin: paddle.lerp(Tensor([10, 5, 10, 1, 0],"float32"), Tensor([10, 5, 10, 5, 1],"float32"), Tensor([1],"float32"), )
[paddle error] paddle.lerp(Tensor([10, 5, 10, 1, 0],"float32"), Tensor([10, 5, 10, 5, 1],"float32"), Tensor([1],"float32"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.742513 GPU 1 69614 test begin: paddle.lerp(Tensor([10, 5, 10, 1, 5],"float32"), Tensor([10, 5, 10, 0, 1],"float32"), Tensor([1],"float32"), )
[paddle error] paddle.lerp(Tensor([10, 5, 10, 1, 5],"float32"), Tensor([10, 5, 10, 0, 1],"float32"), Tensor([1],"float32"), ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:55)


2025-05-21 22:07:49.769837 GPU 1 69600 test begin: paddle.lerp(Tensor([1],"float32"), Tensor([0],"float32"), Tensor([1],"float32"), )
[paddle error] paddle.lerp(Tensor([1],"float32"), Tensor([0],"float32"), Tensor([1],"float32"), ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:55)


2025-05-21 22:07:49.776480 GPU 1 69601 test begin: paddle.lerp(Tensor([1],"float32"), Tensor([1],"float32"), Tensor([0],"float32"), )
[cuda error] paddle.lerp(Tensor([1],"float32"), Tensor([1],"float32"), Tensor([0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:49.803222 GPU 1 69596 test begin: paddle.lerp(Tensor([1],"float64"), Tensor([0],"float64"), Tensor([1],"float64"), )
[paddle error] paddle.lerp(Tensor([1],"float64"), Tensor([0],"float64"), Tensor([1],"float64"), ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:55)


2025-05-21 22:07:49.816875 GPU 1 69605 test begin: paddle.lerp(Tensor([1],"float64"), Tensor([1],"float64"), Tensor([0],"float64"), )
[cuda error] paddle.lerp(Tensor([1],"float64"), Tensor([1],"float64"), Tensor([0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:49.853125 GPU 1 69599 test begin: paddle.lerp(Tensor([2, 0, 1, 1],"float32"), Tensor([2, 0, 8, 8],"float32"), 0.3, )
[paddle error] paddle.lerp(Tensor([2, 0, 1, 1],"float32"), Tensor([2, 0, 8, 8],"float32"), 0.3, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.853598 GPU 1 69615 test begin: paddle.lerp(Tensor([2, 0, 5],"float32"), Tensor([3, 2, 1, 5],"float32"), 0.5, )
[paddle error] paddle.lerp(Tensor([2, 0, 5],"float32"), Tensor([3, 2, 1, 5],"float32"), 0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.853842 GPU 1 69617 test begin: paddle.lerp(Tensor([2, 0, 8, 8],"float32"), Tensor([2, 0, 8, 8],"float32"), 1.1, )
[paddle error] paddle.lerp(Tensor([2, 0, 8, 8],"float32"), Tensor([2, 0, 8, 8],"float32"), 1.1, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.854544 GPU 1 69608 test begin: paddle.lerp(Tensor([2, 0, 8, 8],"float32"), Tensor([2, 0, 8, 8],"float32"), 2.1, )
[paddle error] paddle.lerp(Tensor([2, 0, 8, 8],"float32"), Tensor([2, 0, 8, 8],"float32"), 2.1, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.854626 GPU 1 69612 test begin: paddle.lerp(Tensor([2, 0],"float32"), Tensor([2, 0],"float32"), Tensor([2, 0],"float32"), )
[paddle error] paddle.lerp(Tensor([2, 0],"float32"), Tensor([2, 0],"float32"), Tensor([2, 0],"float32"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.857844 GPU 1 69618 test begin: paddle.lerp(Tensor([2, 0],"float32"), Tensor([2, 1],"float32"), Tensor([2, 1],"float32"), )
[paddle error] paddle.lerp(Tensor([2, 0],"float32"), Tensor([2, 1],"float32"), Tensor([2, 1],"float32"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.857965 GPU 1 69610 test begin: paddle.lerp(Tensor([2, 1, 0, 1],"float32"), Tensor([2, 3, 0, 8],"float32"), 0.3, )
[paddle error] paddle.lerp(Tensor([2, 1, 0, 1],"float32"), Tensor([2, 3, 0, 8],"float32"), 0.3, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.859800 GPU 1 69604 test begin: paddle.lerp(Tensor([2, 1, 0, 8],"float32"), Tensor([2, 3, 0, 8],"float32"), 1.1, )
[paddle error] paddle.lerp(Tensor([2, 1, 0, 8],"float32"), Tensor([2, 3, 0, 8],"float32"), 1.1, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.863409 GPU 1 69606 test begin: paddle.lerp(Tensor([2, 1, 1, 0],"float32"), Tensor([2, 3, 8, 0],"float32"), 0.3, )
[paddle error] paddle.lerp(Tensor([2, 1, 1, 0],"float32"), Tensor([2, 3, 8, 0],"float32"), 0.3, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.959023 GPU 1 69607 test begin: paddle.lerp(Tensor([2, 1, 1, 1],"float32"), Tensor([2, 0, 8, 8],"float32"), 0.3, )
[paddle error] paddle.lerp(Tensor([2, 1, 1, 1],"float32"), Tensor([2, 0, 8, 8],"float32"), 0.3, ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:55)


2025-05-21 22:07:49.973250 GPU 1 69599 test begin: paddle.lerp(Tensor([2, 1, 1, 1],"float32"), Tensor([2, 3, 0, 8],"float32"), 0.3, )
[paddle error] paddle.lerp(Tensor([2, 1, 1, 1],"float32"), Tensor([2, 3, 0, 8],"float32"), 0.3, ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:55)


2025-05-21 22:07:49.979280 GPU 1 69612 test begin: paddle.lerp(Tensor([2, 1, 1, 1],"float32"), Tensor([2, 3, 8, 0],"float32"), 0.3, )
[paddle error] paddle.lerp(Tensor([2, 1, 1, 1],"float32"), Tensor([2, 3, 8, 0],"float32"), 0.3, ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:55)


2025-05-21 22:07:49.979755 GPU 1 69617 test begin: paddle.lerp(Tensor([2, 1, 8, 0],"float32"), Tensor([2, 3, 8, 0],"float32"), 1.1, )
[paddle error] paddle.lerp(Tensor([2, 1, 8, 0],"float32"), Tensor([2, 3, 8, 0],"float32"), 1.1, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:49.985791 GPU 1 69608 test begin: paddle.lerp(Tensor([2, 1, 8, 8],"float32"), Tensor([2, 0, 8, 8],"float32"), 1.1, )
[paddle error] paddle.lerp(Tensor([2, 1, 8, 8],"float32"), Tensor([2, 0, 8, 8],"float32"), 1.1, ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:55)


2025-05-21 22:07:49.988594 GPU 1 69610 test begin: paddle.lerp(Tensor([2, 1],"float32"), Tensor([2, 0],"float32"), Tensor([2, 1],"float32"), )
[paddle error] paddle.lerp(Tensor([2, 1],"float32"), Tensor([2, 0],"float32"), Tensor([2, 1],"float32"), ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:55)


2025-05-21 22:07:50.022975 GPU 1 69616 test begin: paddle.lerp(Tensor([2, 1],"float32"), Tensor([2, 1],"float32"), Tensor([2, 0],"float32"), )
[cuda error] paddle.lerp(Tensor([2, 1],"float32"), Tensor([2, 1],"float32"), Tensor([2, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:50.032773 GPU 1 69596 test begin: paddle.lerp(Tensor([2, 2, 5],"float32"), Tensor([0, 2, 1, 5],"float32"), 0.5, )
[paddle error] paddle.lerp(Tensor([2, 2, 5],"float32"), Tensor([0, 2, 1, 5],"float32"), 0.5, ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:55)


2025-05-21 22:07:50.033564 GPU 1 69621 test begin: paddle.lerp(Tensor([2, 3, 0, 8],"float32"), Tensor([2, 3, 0, 8],"float32"), 2.1, )
[paddle error] paddle.lerp(Tensor([2, 3, 0, 8],"float32"), Tensor([2, 3, 0, 8],"float32"), 2.1, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.034056 GPU 1 69598 test begin: paddle.lerp(Tensor([2, 3, 8, 0],"float32"), Tensor([2, 3, 8, 0],"float32"), 2.1, )
[paddle error] paddle.lerp(Tensor([2, 3, 8, 0],"float32"), Tensor([2, 3, 8, 0],"float32"), 2.1, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.035751 GPU 1 69613 test begin: paddle.lerp(Tensor([2, 5],"float32"), Tensor([2, 2, 5],"float32"), Tensor([0, 2, 2, 5],"float32"), )
[cuda error] paddle.lerp(Tensor([2, 5],"float32"), Tensor([2, 2, 5],"float32"), Tensor([0, 2, 2, 5],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:50.037335 GPU 1 69605 test begin: paddle.lerp(Tensor([3, 0, 28],"float32"), Tensor([3, 0, 28],"float32"), 1.2, )
[paddle error] paddle.lerp(Tensor([3, 0, 28],"float32"), Tensor([3, 0, 28],"float32"), 1.2, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.037584 GPU 1 69629 test begin: paddle.lerp(Tensor([3, 0, 3, 1, 2, 5],"float64"), Tensor([3, 0, 3, 1, 2, 5],"float64"), Tensor([3, 0, 3, 1, 2, 5],"float64"), )
[paddle error] paddle.lerp(Tensor([3, 0, 3, 1, 2, 5],"float64"), Tensor([3, 0, 3, 1, 2, 5],"float64"), Tensor([3, 0, 3, 1, 2, 5],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.041360 GPU 1 69609 test begin: paddle.lerp(Tensor([3, 0, 3, 4, 1, 5],"float64"), Tensor([3, 0, 3, 4, 1, 5],"float64"), Tensor([3, 0, 3, 4, 1, 5],"float64"), )
[paddle error] paddle.lerp(Tensor([3, 0, 3, 4, 1, 5],"float64"), Tensor([3, 0, 3, 4, 1, 5],"float64"), Tensor([3, 0, 3, 4, 1, 5],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.045444 GPU 1 69615 test begin: paddle.lerp(Tensor([3, 0, 8],"float32"), Tensor([3, 0, 8],"float32"), 2.1, )
[paddle error] paddle.lerp(Tensor([3, 0, 8],"float32"), Tensor([3, 0, 8],"float32"), 2.1, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.048191 GPU 1 69602 test begin: paddle.lerp(Tensor([3, 28, 0],"float32"), Tensor([3, 28, 0],"float32"), 1.2, )
[paddle error] paddle.lerp(Tensor([3, 28, 0],"float32"), Tensor([3, 28, 0],"float32"), 1.2, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.094445 GPU 1 69600 test begin: paddle.lerp(Tensor([3, 6, 0, 1, 2, 5],"float64"), Tensor([3, 6, 0, 1, 2, 5],"float64"), Tensor([3, 6, 0, 1, 2, 5],"float64"), )
[paddle error] paddle.lerp(Tensor([3, 6, 0, 1, 2, 5],"float64"), Tensor([3, 6, 0, 1, 2, 5],"float64"), Tensor([3, 6, 0, 1, 2, 5],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.106919 GPU 1 69603 test begin: paddle.lerp(Tensor([3, 6, 0, 4, 1, 5],"float64"), Tensor([3, 6, 0, 4, 1, 5],"float64"), Tensor([3, 6, 0, 4, 1, 5],"float64"), )
[paddle error] paddle.lerp(Tensor([3, 6, 0, 4, 1, 5],"float64"), Tensor([3, 6, 0, 4, 1, 5],"float64"), Tensor([3, 6, 0, 4, 1, 5],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.171927 GPU 1 69601 test begin: paddle.lerp(Tensor([3, 6, 3, 0, 1, 5],"float64"), Tensor([3, 6, 3, 0, 1, 5],"float64"), Tensor([3, 6, 3, 0, 1, 5],"float64"), )
[paddle error] paddle.lerp(Tensor([3, 6, 3, 0, 1, 5],"float64"), Tensor([3, 6, 3, 0, 1, 5],"float64"), Tensor([3, 6, 3, 0, 1, 5],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.183847 GPU 1 69606 test begin: paddle.lerp(Tensor([3, 6, 3, 0, 2, 5],"float64"), Tensor([3, 6, 3, 0, 2, 5],"float64"), Tensor([3, 6, 3, 0, 2, 5],"float64"), )
[paddle error] paddle.lerp(Tensor([3, 6, 3, 0, 2, 5],"float64"), Tensor([3, 6, 3, 0, 2, 5],"float64"), Tensor([3, 6, 3, 0, 2, 5],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.192918 GPU 1 69596 test begin: paddle.lerp(Tensor([3, 6, 3, 0, 2, 5],"float64"), Tensor([3, 6, 3, 1, 2, 5],"float64"), Tensor([3, 6, 3, 1, 2, 5],"float64"), )
[paddle error] paddle.lerp(Tensor([3, 6, 3, 0, 2, 5],"float64"), Tensor([3, 6, 3, 1, 2, 5],"float64"), Tensor([3, 6, 3, 1, 2, 5],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.197309 GPU 1 69599 test begin: paddle.lerp(Tensor([3, 6, 3, 1, 0, 5],"float64"), Tensor([3, 6, 3, 1, 0, 5],"float64"), Tensor([3, 6, 3, 1, 0, 5],"float64"), )
[paddle error] paddle.lerp(Tensor([3, 6, 3, 1, 0, 5],"float64"), Tensor([3, 6, 3, 1, 0, 5],"float64"), Tensor([3, 6, 3, 1, 0, 5],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.198107 GPU 1 69617 test begin: paddle.lerp(Tensor([3, 6, 3, 1, 2, 0],"float64"), Tensor([3, 6, 3, 1, 2, 0],"float64"), Tensor([3, 6, 3, 1, 2, 0],"float64"), )
[paddle error] paddle.lerp(Tensor([3, 6, 3, 1, 2, 0],"float64"), Tensor([3, 6, 3, 1, 2, 0],"float64"), Tensor([3, 6, 3, 1, 2, 0],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.202040 GPU 1 69604 test begin: paddle.lerp(Tensor([3, 6, 3, 1, 2, 5],"float64"), Tensor([3, 6, 3, 0, 2, 5],"float64"), Tensor([3, 6, 3, 1, 2, 5],"float64"), )
[paddle error] paddle.lerp(Tensor([3, 6, 3, 1, 2, 5],"float64"), Tensor([3, 6, 3, 0, 2, 5],"float64"), Tensor([3, 6, 3, 1, 2, 5],"float64"), ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:55)


2025-05-21 22:07:50.203083 GPU 1 69605 test begin: paddle.lerp(Tensor([3, 6, 3, 1, 2, 5],"float64"), Tensor([3, 6, 3, 1, 2, 5],"float64"), Tensor([3, 6, 3, 0, 2, 5],"float64"), )
[cuda error] paddle.lerp(Tensor([3, 6, 3, 1, 2, 5],"float64"), Tensor([3, 6, 3, 1, 2, 5],"float64"), Tensor([3, 6, 3, 0, 2, 5],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:50.205319 GPU 1 69607 test begin: paddle.lerp(Tensor([3, 6, 3, 4, 0, 5],"float64"), Tensor([3, 6, 3, 4, 0, 5],"float64"), Tensor([3, 6, 3, 4, 0, 5],"float64"), )
[paddle error] paddle.lerp(Tensor([3, 6, 3, 4, 0, 5],"float64"), Tensor([3, 6, 3, 4, 0, 5],"float64"), Tensor([3, 6, 3, 4, 0, 5],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.210644 GPU 1 69610 test begin: paddle.lerp(Tensor([3, 6, 3, 4, 0, 5],"float64"), Tensor([3, 6, 3, 4, 1, 5],"float64"), Tensor([3, 6, 3, 4, 1, 5],"float64"), )
[paddle error] paddle.lerp(Tensor([3, 6, 3, 4, 0, 5],"float64"), Tensor([3, 6, 3, 4, 1, 5],"float64"), Tensor([3, 6, 3, 4, 1, 5],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.213651 GPU 1 69608 test begin: paddle.lerp(Tensor([3, 6, 3, 4, 1, 0],"float64"), Tensor([3, 6, 3, 4, 1, 0],"float64"), Tensor([3, 6, 3, 4, 1, 0],"float64"), )
[paddle error] paddle.lerp(Tensor([3, 6, 3, 4, 1, 0],"float64"), Tensor([3, 6, 3, 4, 1, 0],"float64"), Tensor([3, 6, 3, 4, 1, 0],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.214806 GPU 1 69616 test begin: paddle.lerp(Tensor([3, 6, 3, 4, 1, 5],"float64"), Tensor([3, 6, 3, 4, 0, 5],"float64"), Tensor([3, 6, 3, 4, 1, 5],"float64"), )
[paddle error] paddle.lerp(Tensor([3, 6, 3, 4, 1, 5],"float64"), Tensor([3, 6, 3, 4, 0, 5],"float64"), Tensor([3, 6, 3, 4, 1, 5],"float64"), ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:55)


2025-05-21 22:07:50.217288 GPU 1 69609 test begin: paddle.lerp(Tensor([3, 6, 3, 4, 1, 5],"float64"), Tensor([3, 6, 3, 4, 1, 5],"float64"), Tensor([3, 6, 3, 4, 0, 5],"float64"), )
[cuda error] paddle.lerp(Tensor([3, 6, 3, 4, 1, 5],"float64"), Tensor([3, 6, 3, 4, 1, 5],"float64"), Tensor([3, 6, 3, 4, 0, 5],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:50.238818 GPU 1 69615 test begin: paddle.lerp(Tensor([3, 8, 0],"float32"), Tensor([3, 8, 0],"float32"), 2.1, )
[paddle error] paddle.lerp(Tensor([3, 8, 0],"float32"), Tensor([3, 8, 0],"float32"), 2.1, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.221510 GPU 1 69612 test begin: paddle.lerp(x=Tensor([0, 5, 4, 3],"float64"), y=Tensor([0, 5, 4, 3],"float64"), weight=0.0, )
[paddle error] paddle.lerp(x=Tensor([0, 5, 4, 3],"float64"), y=Tensor([0, 5, 4, 3],"float64"), weight=0.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.226473 GPU 1 69614 test begin: paddle.lerp(x=Tensor([0, 5, 4, 3],"float64"), y=Tensor([0, 5, 4, 3],"float64"), weight=0.5, )
[paddle error] paddle.lerp(x=Tensor([0, 5, 4, 3],"float64"), y=Tensor([0, 5, 4, 3],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.248569 GPU 1 69621 test begin: paddle.lerp(x=Tensor([0, 5, 4, 3],"float64"), y=Tensor([0, 5, 4, 3],"float64"), weight=1.0, )
[paddle error] paddle.lerp(x=Tensor([0, 5, 4, 3],"float64"), y=Tensor([0, 5, 4, 3],"float64"), weight=1.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.330593 GPU 1 69606 test begin: paddle.lerp(x=Tensor([0, 5, 4],"float64"), y=Tensor([0, 5, 4],"float64"), weight=0.5, )
[paddle error] paddle.lerp(x=Tensor([0, 5, 4],"float64"), y=Tensor([0, 5, 4],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.337834 GPU 1 69613 test begin: paddle.lerp(x=Tensor([0, 5],"float64"), y=Tensor([0, 5],"float64"), weight=0.5, )
[paddle error] paddle.lerp(x=Tensor([0, 5],"float64"), y=Tensor([0, 5],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.352288 GPU 1 69598 test begin: paddle.lerp(x=Tensor([0, 5],"float64"), y=Tensor([1],"float64"), weight=0.2, )
[paddle error] paddle.lerp(x=Tensor([0, 5],"float64"), y=Tensor([1],"float64"), weight=0.2, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.352729 GPU 1 69596 test begin: paddle.lerp(x=Tensor([0],"float32"), y=Tensor([0],"float32"), weight=0.5, )
[paddle error] paddle.lerp(x=Tensor([0],"float32"), y=Tensor([0],"float32"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.355122 GPU 1 69599 test begin: paddle.lerp(x=Tensor([0],"float64"), y=Tensor([0],"float64"), weight=0.5, )
[paddle error] paddle.lerp(x=Tensor([0],"float64"), y=Tensor([0],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.361573 GPU 1 69607 test begin: paddle.lerp(x=Tensor([4, 0, 4, 3],"float64"), y=Tensor([4, 0, 4, 3],"float64"), weight=0.0, )
[paddle error] paddle.lerp(x=Tensor([4, 0, 4, 3],"float64"), y=Tensor([4, 0, 4, 3],"float64"), weight=0.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.369691 GPU 1 69610 test begin: paddle.lerp(x=Tensor([4, 0, 4, 3],"float64"), y=Tensor([4, 0, 4, 3],"float64"), weight=0.5, )
[paddle error] paddle.lerp(x=Tensor([4, 0, 4, 3],"float64"), y=Tensor([4, 0, 4, 3],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.373909 GPU 1 69605 test begin: paddle.lerp(x=Tensor([4, 0, 4, 3],"float64"), y=Tensor([4, 0, 4, 3],"float64"), weight=1.0, )
[paddle error] paddle.lerp(x=Tensor([4, 0, 4, 3],"float64"), y=Tensor([4, 0, 4, 3],"float64"), weight=1.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.374899 GPU 1 69608 test begin: paddle.lerp(x=Tensor([4, 0, 4],"float64"), y=Tensor([4, 0, 4],"float64"), weight=0.5, )
[paddle error] paddle.lerp(x=Tensor([4, 0, 4],"float64"), y=Tensor([4, 0, 4],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.381303 GPU 1 69621 test begin: paddle.lerp(x=Tensor([4, 0],"float64"), y=Tensor([1],"float64"), weight=0.2, )
[paddle error] paddle.lerp(x=Tensor([4, 0],"float64"), y=Tensor([1],"float64"), weight=0.2, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.397887 GPU 1 69616 test begin: paddle.lerp(x=Tensor([4, 0],"float64"), y=Tensor([4, 0],"float64"), weight=0.5, )
[paddle error] paddle.lerp(x=Tensor([4, 0],"float64"), y=Tensor([4, 0],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.400549 GPU 1 69617 test begin: paddle.lerp(x=Tensor([4, 5, 0, 3],"float64"), y=Tensor([4, 5, 0, 3],"float64"), weight=0.0, )
[paddle error] paddle.lerp(x=Tensor([4, 5, 0, 3],"float64"), y=Tensor([4, 5, 0, 3],"float64"), weight=0.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.402804 GPU 1 69602 test begin: paddle.lerp(x=Tensor([4, 5, 0, 3],"float64"), y=Tensor([4, 5, 0, 3],"float64"), weight=0.5, )
[paddle error] paddle.lerp(x=Tensor([4, 5, 0, 3],"float64"), y=Tensor([4, 5, 0, 3],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.403537 GPU 1 69615 test begin: paddle.lerp(x=Tensor([4, 5, 0, 3],"float64"), y=Tensor([4, 5, 0, 3],"float64"), weight=1.0, )
[paddle error] paddle.lerp(x=Tensor([4, 5, 0, 3],"float64"), y=Tensor([4, 5, 0, 3],"float64"), weight=1.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.404709 GPU 1 69612 test begin: paddle.lerp(x=Tensor([4, 5, 0],"float64"), y=Tensor([4, 5, 0],"float64"), weight=0.5, )
[paddle error] paddle.lerp(x=Tensor([4, 5, 0],"float64"), y=Tensor([4, 5, 0],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.408541 GPU 1 69618 test begin: paddle.lerp(x=Tensor([4, 5, 4, 0],"float64"), y=Tensor([4, 5, 4, 0],"float64"), weight=0.0, )
[paddle error] paddle.lerp(x=Tensor([4, 5, 4, 0],"float64"), y=Tensor([4, 5, 4, 0],"float64"), weight=0.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.412555 GPU 1 69604 test begin: paddle.lerp(x=Tensor([4, 5, 4, 0],"float64"), y=Tensor([4, 5, 4, 0],"float64"), weight=0.5, )
[paddle error] paddle.lerp(x=Tensor([4, 5, 4, 0],"float64"), y=Tensor([4, 5, 4, 0],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.413409 GPU 1 69609 test begin: paddle.lerp(x=Tensor([4, 5, 4, 0],"float64"), y=Tensor([4, 5, 4, 0],"float64"), weight=1.0, )
[paddle error] paddle.lerp(x=Tensor([4, 5, 4, 0],"float64"), y=Tensor([4, 5, 4, 0],"float64"), weight=1.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/gpu/lerp_kernel.cu:50)


2025-05-21 22:07:50.413753 GPU 1 69600 test begin: paddle.lgamma(Tensor([0, 1, 1, 1],"float32"), )
[cuda error] paddle.lgamma(Tensor([0, 1, 1, 1],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:50.441942 GPU 1 69611 test begin: paddle.lgamma(Tensor([0, 1, 1],"float32"), )
[cuda error] paddle.lgamma(Tensor([0, 1, 1],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:50.448597 GPU 1 69603 test begin: paddle.lgamma(Tensor([0, 10, 10, 2],"float64"), )
[cuda error] paddle.lgamma(Tensor([0, 10, 10, 2],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:50.479080 GPU 1 69629 test begin: paddle.lgamma(Tensor([0, 1],"float32"), )
[cuda error] paddle.lgamma(Tensor([0, 1],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:50.480972 GPU 1 69621 test begin: paddle.lgamma(Tensor([0, 2, 2],"float32"), )
[cuda error] paddle.lgamma(Tensor([0, 2, 2],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:50.506613 GPU 1 69601 test begin: paddle.lgamma(Tensor([0, 2],"float32"), )
[cuda error] paddle.lgamma(Tensor([0, 2],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:50.517744 GPU 1 69599 test begin: paddle.lgamma(Tensor([0],"float32"), )
[cuda error] paddle.lgamma(Tensor([0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:50.519310 GPU 1 69607 test begin: paddle.lgamma(Tensor([0],"float64"), )
[cuda error] paddle.lgamma(Tensor([0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:50.521989 GPU 1 69606 test begin: paddle.lgamma(Tensor([1, 0, 2],"float32"), )
[cuda error] paddle.lgamma(Tensor([1, 0, 2],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:50.530757 GPU 1 69596 test begin: paddle.lgamma(Tensor([1, 0],"float32"), )
[cuda error] paddle.lgamma(Tensor([1, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:50.531179 GPU 1 69610 test begin: paddle.lgamma(Tensor([1, 2, 0],"float32"), )
[cuda error] paddle.lgamma(Tensor([1, 2, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:50.537796 GPU 1 69605 test begin: paddle.lgamma(Tensor([10, 0, 1, 1],"float32"), )
[cuda error] paddle.lgamma(Tensor([10, 0, 1, 1],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:50.541081 GPU 1 69608 test begin: paddle.lgamma(Tensor([10, 0, 10, 2],"float64"), )
[cuda error] paddle.lgamma(Tensor([10, 0, 10, 2],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:50.553925 GPU 1 69615 test begin: paddle.lgamma(Tensor([10, 0, 1],"float32"), )
[cuda error] paddle.lgamma(Tensor([10, 0, 1],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:50.562874 GPU 1 69612 test begin: paddle.lgamma(Tensor([10, 1, 0, 1],"float32"), )
[cuda error] paddle.lgamma(Tensor([10, 1, 0, 1],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:50.576352 GPU 1 69617 test begin: paddle.lgamma(Tensor([10, 1, 0],"float32"), )
[cuda error] paddle.lgamma(Tensor([10, 1, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:50.577552 GPU 1 69619 test begin: paddle.lgamma(Tensor([10, 1, 1, 0],"float32"), )
[cuda error] paddle.lgamma(Tensor([10, 1, 1, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:50.577521 GPU 1 69621 test begin: paddle.lgamma(Tensor([10, 10, 0, 2],"float64"), )
[cuda error] paddle.lgamma(Tensor([10, 10, 0, 2],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:50.577685 GPU 1 69611 test begin: paddle.lgamma(Tensor([10, 10, 10, 0],"float64"), )
[cuda error] paddle.lgamma(Tensor([10, 10, 10, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:50.582943 GPU 1 69609 test begin: paddle.lgamma(x=Tensor([0, 3],"float32"), )
[cuda error] paddle.lgamma(x=Tensor([0, 3],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:50.602082 GPU 1 69616 test begin: paddle.lgamma(x=Tensor([0, 3],"float64"), )
[cuda error] paddle.lgamma(x=Tensor([0, 3],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:50.610399 GPU 1 69604 test begin: paddle.lgamma(x=Tensor([0, 6, 6],"float64"), )
[cuda error] paddle.lgamma(x=Tensor([0, 6, 6],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:50.623898 GPU 1 69613 test begin: paddle.lgamma(x=Tensor([3, 0],"float32"), )
[cuda error] paddle.lgamma(x=Tensor([3, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:50.644471 GPU 1 69599 test begin: paddle.lgamma(x=Tensor([3, 0],"float64"), )
[cuda error] paddle.lgamma(x=Tensor([3, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:50.651886 GPU 1 69606 test begin: paddle.lgamma(x=Tensor([6, 0, 6],"float64"), )
[cuda error] paddle.lgamma(x=Tensor([6, 0, 6],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:50.653666 GPU 1 69614 test begin: paddle.lgamma(x=Tensor([6, 6, 0],"float64"), )
[cuda error] paddle.lgamma(x=Tensor([6, 6, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:50.665589 GPU 1 69598 test begin: paddle.linalg.cholesky_solve(Tensor([0, 30, 2],"float64"), Tensor([0, 30, 30],"float64"), upper=True, )
[paddle error] paddle.linalg.cholesky_solve(Tensor([0, 30, 2],"float64"), Tensor([0, 30, 30],"float64"), upper=True, ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:50.666008 GPU 1 69610 test begin: paddle.linalg.cholesky_solve(Tensor([1, 30, 0],"float64"), Tensor([2, 30, 30],"float64"), upper=True, )
[paddle error] paddle.linalg.cholesky_solve(Tensor([1, 30, 0],"float64"), Tensor([2, 30, 30],"float64"), upper=True, ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:50.674900 GPU 1 69621 test begin: paddle.linalg.cholesky_solve(Tensor([1, 30, 2],"float64"), Tensor([0, 30, 30],"float64"), upper=True, )
[paddle error] paddle.linalg.cholesky_solve(Tensor([1, 30, 2],"float64"), Tensor([0, 30, 30],"float64"), upper=True, ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:50.678989 GPU 1 69607 test begin: paddle.linalg.cholesky_solve(Tensor([20, 0],"float64"), Tensor([20, 20],"float64"), upper=True, )
[paddle error] paddle.linalg.cholesky_solve(Tensor([20, 0],"float64"), Tensor([20, 20],"float64"), upper=True, ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:50.679220 GPU 1 69596 test begin: paddle.linalg.cholesky_solve(x=Tensor([0, 2, 4, 3],"float64"), y=Tensor([0, 2, 4, 4],"float64"), )
[paddle error] paddle.linalg.cholesky_solve(x=Tensor([0, 2, 4, 3],"float64"), y=Tensor([0, 2, 4, 4],"float64"), ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:50.698179 GPU 1 69605 test begin: paddle.linalg.cholesky_solve(x=Tensor([0, 2, 4, 3],"float64"), y=Tensor([0, 2, 4, 4],"float64"), upper=True, )
[paddle error] paddle.linalg.cholesky_solve(x=Tensor([0, 2, 4, 3],"float64"), y=Tensor([0, 2, 4, 4],"float64"), upper=True, ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:50.698707 GPU 1 69617 test begin: paddle.linalg.cholesky_solve(x=Tensor([0, 4, 3],"float64"), y=Tensor([0, 4, 4],"float64"), )
[paddle error] paddle.linalg.cholesky_solve(x=Tensor([0, 4, 3],"float64"), y=Tensor([0, 4, 4],"float64"), ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:50.699437 GPU 1 69611 test begin: paddle.linalg.cholesky_solve(x=Tensor([4, 0],"float32"), y=Tensor([4, 4],"float32"), )
[paddle error] paddle.linalg.cholesky_solve(x=Tensor([4, 0],"float32"), y=Tensor([4, 4],"float32"), ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:50.699675 GPU 1 69615 test begin: paddle.linalg.cholesky_solve(x=Tensor([4, 0],"float64"), y=Tensor([4, 4],"float64"), )
[paddle error] paddle.linalg.cholesky_solve(x=Tensor([4, 0],"float64"), y=Tensor([4, 4],"float64"), ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:50.705218 GPU 1 69608 test begin: paddle.linalg.cholesky_solve(x=Tensor([5, 0, 4, 3],"float64"), y=Tensor([5, 0, 4, 4],"float64"), )
[paddle error] paddle.linalg.cholesky_solve(x=Tensor([5, 0, 4, 3],"float64"), y=Tensor([5, 0, 4, 4],"float64"), ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:50.712241 GPU 1 69609 test begin: paddle.linalg.cholesky_solve(x=Tensor([5, 0, 4, 3],"float64"), y=Tensor([5, 0, 4, 4],"float64"), upper=True, )
[paddle error] paddle.linalg.cholesky_solve(x=Tensor([5, 0, 4, 3],"float64"), y=Tensor([5, 0, 4, 4],"float64"), upper=True, ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:50.714453 GPU 1 69602 test begin: paddle.linalg.cholesky_solve(x=Tensor([5, 2, 4, 0],"float64"), y=Tensor([5, 2, 4, 4],"float64"), )
[paddle error] paddle.linalg.cholesky_solve(x=Tensor([5, 2, 4, 0],"float64"), y=Tensor([5, 2, 4, 4],"float64"), ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:50.719652 GPU 1 69612 test begin: paddle.linalg.cholesky_solve(x=Tensor([5, 2, 4, 0],"float64"), y=Tensor([5, 2, 4, 4],"float64"), upper=True, )
[paddle error] paddle.linalg.cholesky_solve(x=Tensor([5, 2, 4, 0],"float64"), y=Tensor([5, 2, 4, 4],"float64"), upper=True, ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:50.735461 GPU 1 69600 test begin: paddle.linalg.cholesky_solve(x=Tensor([5, 4, 0],"float64"), y=Tensor([5, 4, 4],"float64"), )
[paddle error] paddle.linalg.cholesky_solve(x=Tensor([5, 4, 0],"float64"), y=Tensor([5, 4, 4],"float64"), ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:50.746043 GPU 1 69603 test begin: paddle.linalg.cond(Tensor([0, 3],"float32"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([0, 3],"float32"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [0, 3], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-05-21 22:07:50.771263 GPU 1 69604 test begin: paddle.linalg.cond(Tensor([0, 3],"float32"), p=-1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([0, 3],"float32"), p=-1, ) 
 only support p is -1 when input is a square matrix or batches of square matrices

2025-05-21 22:07:50.773153 GPU 1 69599 test begin: paddle.linalg.cond(Tensor([0, 3],"float32"), p=1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([0, 3],"float32"), p=1, ) 
 only support p is 1 when input is a square matrix or batches of square matrices

2025-05-21 22:07:50.789023 GPU 1 69618 test begin: paddle.linalg.cond(Tensor([0, 3],"float32"), p=2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([0, 3],"float32"), p=2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [0, 3], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-05-21 22:07:50.795503 GPU 1 69616 test begin: paddle.linalg.cond(Tensor([0, 3],"float32"), p=math.inf, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([0, 3],"float32"), p=math.inf, ) 
 only support p is inf when input is a square matrix or batches of square matrices

2025-05-21 22:07:50.796496 GPU 1 69606 test begin: paddle.linalg.cond(Tensor([0, 5],"float32"), -1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([0, 5],"float32"), -1, ) 
 only support p is -1 when input is a square matrix or batches of square matrices

2025-05-21 22:07:50.813158 GPU 1 69619 test begin: paddle.linalg.cond(Tensor([0, 5],"float32"), -2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([0, 5],"float32"), -2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [0, 5], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-05-21 22:07:50.819538 GPU 1 69621 test begin: paddle.linalg.cond(Tensor([0, 5],"float32"), -math.inf, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([0, 5],"float32"), -math.inf, ) 
 only support p is -inf when input is a square matrix or batches of square matrices

2025-05-21 22:07:50.828193 GPU 1 69601 test begin: paddle.linalg.cond(Tensor([0, 5],"float32"), 1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([0, 5],"float32"), 1, ) 
 only support p is 1 when input is a square matrix or batches of square matrices

2025-05-21 22:07:50.837233 GPU 1 69629 test begin: paddle.linalg.cond(Tensor([0, 5],"float32"), 2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([0, 5],"float32"), 2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [0, 5], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-05-21 22:07:50.870555 GPU 1 69613 test begin: paddle.linalg.cond(Tensor([0, 5],"float32"), None, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([0, 5],"float32"), None, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [0, 5], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-05-21 22:07:50.876501 GPU 1 69609 test begin: paddle.linalg.cond(Tensor([0, 5],"float32"), math.inf, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([0, 5],"float32"), math.inf, ) 
 only support p is inf when input is a square matrix or batches of square matrices

2025-05-21 22:07:50.886231 GPU 1 69612 test begin: paddle.linalg.cond(Tensor([0, 7],"float64"), -2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([0, 7],"float64"), -2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [0, 7], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-05-21 22:07:50.936397 GPU 1 69599 test begin: paddle.linalg.cond(Tensor([0, 7],"float64"), 2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([0, 7],"float64"), 2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [0, 7], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-05-21 22:07:50.945766 GPU 1 69621 test begin: paddle.linalg.cond(Tensor([0, 7],"float64"), None, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([0, 7],"float64"), None, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [0, 7], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-05-21 22:07:50.950687 GPU 1 69606 test begin: paddle.linalg.cond(Tensor([2, 4, 0, 3],"float32"), -1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([2, 4, 0, 3],"float32"), -1, ) 
 only support p is -1 when input is a square matrix or batches of square matrices

2025-05-21 22:07:50.960356 GPU 1 69604 test begin: paddle.linalg.cond(Tensor([2, 4, 0, 3],"float32"), -2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([2, 4, 0, 3],"float32"), -2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [2, 4, 0, 3], X's size = 0, 'shape' is [2, 4], the capacity of 'shape' is 8.
  [Hint: Expected capacity == in_size, but received capacity:8 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-05-21 22:07:50.963073 GPU 1 69601 test begin: paddle.linalg.cond(Tensor([2, 4, 0, 3],"float32"), -math.inf, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([2, 4, 0, 3],"float32"), -math.inf, ) 
 only support p is -inf when input is a square matrix or batches of square matrices

2025-05-21 22:07:50.996279 GPU 1 69616 test begin: paddle.linalg.cond(Tensor([2, 4, 0, 3],"float32"), 1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([2, 4, 0, 3],"float32"), 1, ) 
 only support p is 1 when input is a square matrix or batches of square matrices

2025-05-21 22:07:50.997350 GPU 1 69598 test begin: paddle.linalg.cond(Tensor([2, 4, 0, 3],"float32"), 2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([2, 4, 0, 3],"float32"), 2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [2, 4, 0, 3], X's size = 0, 'shape' is [2, 4], the capacity of 'shape' is 8.
  [Hint: Expected capacity == in_size, but received capacity:8 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-05-21 22:07:51.008441 GPU 1 69614 test begin: paddle.linalg.cond(Tensor([2, 4, 0, 3],"float32"), None, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([2, 4, 0, 3],"float32"), None, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [2, 4, 0, 3], X's size = 0, 'shape' is [2, 4], the capacity of 'shape' is 8.
  [Hint: Expected capacity == in_size, but received capacity:8 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-05-21 22:07:51.013565 GPU 1 69619 test begin: paddle.linalg.cond(Tensor([2, 4, 0, 3],"float32"), math.inf, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([2, 4, 0, 3],"float32"), math.inf, ) 
 only support p is inf when input is a square matrix or batches of square matrices

2025-05-21 22:07:51.044837 GPU 1 69609 test begin: paddle.linalg.cond(Tensor([2, 4, 3, 0],"float32"), -1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([2, 4, 3, 0],"float32"), -1, ) 
 only support p is -1 when input is a square matrix or batches of square matrices

2025-05-21 22:07:51.050214 GPU 1 69603 test begin: paddle.linalg.cond(Tensor([2, 4, 3, 0],"float32"), -2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([2, 4, 3, 0],"float32"), -2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [2, 4, 3, 0], X's size = 0, 'shape' is [2, 4], the capacity of 'shape' is 8.
  [Hint: Expected capacity == in_size, but received capacity:8 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-05-21 22:07:51.057344 GPU 1 69612 test begin: paddle.linalg.cond(Tensor([2, 4, 3, 0],"float32"), -math.inf, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([2, 4, 3, 0],"float32"), -math.inf, ) 
 only support p is -inf when input is a square matrix or batches of square matrices

2025-05-21 22:07:51.064117 GPU 1 69602 test begin: paddle.linalg.cond(Tensor([2, 4, 3, 0],"float32"), 1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([2, 4, 3, 0],"float32"), 1, ) 
 only support p is 1 when input is a square matrix or batches of square matrices

2025-05-21 22:07:51.064267 GPU 1 69600 test begin: paddle.linalg.cond(Tensor([2, 4, 3, 0],"float32"), 2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([2, 4, 3, 0],"float32"), 2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [2, 4, 3, 0], X's size = 0, 'shape' is [2, 4], the capacity of 'shape' is 8.
  [Hint: Expected capacity == in_size, but received capacity:8 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-05-21 22:07:51.088860 GPU 1 69621 test begin: paddle.linalg.cond(Tensor([2, 4, 3, 0],"float32"), None, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([2, 4, 3, 0],"float32"), None, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [2, 4, 3, 0], X's size = 0, 'shape' is [2, 4], the capacity of 'shape' is 8.
  [Hint: Expected capacity == in_size, but received capacity:8 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-05-21 22:07:51.106329 GPU 1 69601 test begin: paddle.linalg.cond(Tensor([2, 4, 3, 0],"float32"), math.inf, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([2, 4, 3, 0],"float32"), math.inf, ) 
 only support p is inf when input is a square matrix or batches of square matrices

2025-05-21 22:07:51.106765 GPU 1 69599 test begin: paddle.linalg.cond(Tensor([3, 0],"float32"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([3, 0],"float32"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [3, 0], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-05-21 22:07:51.106854 GPU 1 69606 test begin: paddle.linalg.cond(Tensor([3, 0],"float32"), p=-1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([3, 0],"float32"), p=-1, ) 
 only support p is -1 when input is a square matrix or batches of square matrices

2025-05-21 22:07:51.148678 GPU 1 69618 test begin: paddle.linalg.cond(Tensor([3, 0],"float32"), p=1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([3, 0],"float32"), p=1, ) 
 only support p is 1 when input is a square matrix or batches of square matrices

2025-05-21 22:07:51.156255 GPU 1 69604 test begin: paddle.linalg.cond(Tensor([3, 0],"float32"), p=2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([3, 0],"float32"), p=2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [3, 0], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-05-21 22:07:51.168842 GPU 1 69613 test begin: paddle.linalg.cond(Tensor([3, 0],"float32"), p=math.inf, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([3, 0],"float32"), p=math.inf, ) 
 only support p is inf when input is a square matrix or batches of square matrices

2025-05-21 22:07:51.205843 GPU 1 69609 test begin: paddle.linalg.cond(Tensor([5, 0],"float32"), -1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([5, 0],"float32"), -1, ) 
 only support p is -1 when input is a square matrix or batches of square matrices

2025-05-21 22:07:51.212881 GPU 1 69612 test begin: paddle.linalg.cond(Tensor([5, 0],"float32"), -2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([5, 0],"float32"), -2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [5, 0], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-05-21 22:07:51.219333 GPU 1 69616 test begin: paddle.linalg.cond(Tensor([5, 0],"float32"), -math.inf, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([5, 0],"float32"), -math.inf, ) 
 only support p is -inf when input is a square matrix or batches of square matrices

2025-05-21 22:07:51.226094 GPU 1 69619 test begin: paddle.linalg.cond(Tensor([5, 0],"float32"), 1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([5, 0],"float32"), 1, ) 
 only support p is 1 when input is a square matrix or batches of square matrices

2025-05-21 22:07:51.243206 GPU 1 69629 test begin: paddle.linalg.cond(Tensor([5, 0],"float32"), 2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([5, 0],"float32"), 2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [5, 0], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-05-21 22:07:51.247487 GPU 1 69601 test begin: paddle.linalg.cond(Tensor([5, 0],"float32"), None, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([5, 0],"float32"), None, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [5, 0], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-05-21 22:07:51.264945 GPU 1 69606 test begin: paddle.linalg.cond(Tensor([5, 0],"float32"), math.inf, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([5, 0],"float32"), math.inf, ) 
 only support p is inf when input is a square matrix or batches of square matrices

2025-05-21 22:07:51.271851 GPU 1 69599 test begin: paddle.linalg.cond(Tensor([9, 0],"float64"), -2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([9, 0],"float64"), -2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [9, 0], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-05-21 22:07:51.288594 GPU 1 69621 test begin: paddle.linalg.cond(Tensor([9, 0],"float64"), 2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([9, 0],"float64"), 2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [9, 0], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-05-21 22:07:51.301789 GPU 1 69604 test begin: paddle.linalg.cond(Tensor([9, 0],"float64"), None, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([9, 0],"float64"), None, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [9, 0], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-05-21 22:07:51.340083 GPU 1 69612 test begin: paddle.linalg.cond(x=Tensor([0, 3],"float32"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([0, 3],"float32"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [0, 3], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-05-21 22:07:51.346634 GPU 1 69609 test begin: paddle.linalg.cond(x=Tensor([0, 3],"float64"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([0, 3],"float64"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [0, 3], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-05-21 22:07:51.352198 GPU 1 69601 test begin: paddle.linalg.cond(x=Tensor([0, 4],"float64"), p=-2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([0, 4],"float64"), p=-2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [0, 4], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-05-21 22:07:51.355794 GPU 1 69602 test begin: paddle.linalg.cond(x=Tensor([0, 4],"float64"), p=1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([0, 4],"float64"), p=1, ) 
 only support p is 1 when input is a square matrix or batches of square matrices

2025-05-21 22:07:51.357234 GPU 1 69608 test begin: paddle.linalg.cond(x=Tensor([3, 0],"float32"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([3, 0],"float32"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [3, 0], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-05-21 22:07:51.364764 GPU 1 69598 test begin: paddle.linalg.cond(x=Tensor([3, 0],"float64"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([3, 0],"float64"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [3, 0], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-05-21 22:07:51.365050 GPU 1 69614 test begin: paddle.linalg.cond(x=Tensor([4, 0],"float64"), p=-2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([4, 0],"float64"), p=-2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [4, 0], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-05-21 22:07:51.388156 GPU 1 69621 test begin: paddle.linalg.cond(x=Tensor([4, 0],"float64"), p=1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([4, 0],"float64"), p=1, ) 
 only support p is 1 when input is a square matrix or batches of square matrices

2025-05-21 22:07:51.391971 GPU 1 69600 test begin: paddle.linalg.cond(x=Tensor([4, 2, 0, 4],"float64"), p=-1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([4, 2, 0, 4],"float64"), p=-1, ) 
 only support p is -1 when input is a square matrix or batches of square matrices

2025-05-21 22:07:51.421038 GPU 1 69619 test begin: paddle.linalg.cond(x=Tensor([4, 2, 0, 4],"float64"), p=-math.inf, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([4, 2, 0, 4],"float64"), p=-math.inf, ) 
 only support p is -inf when input is a square matrix or batches of square matrices

2025-05-21 22:07:51.444686 GPU 1 69599 test begin: paddle.linalg.cond(x=Tensor([4, 2, 0, 4],"float64"), p=math.inf, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([4, 2, 0, 4],"float64"), p=math.inf, ) 
 only support p is inf when input is a square matrix or batches of square matrices

2025-05-21 22:07:51.444936 GPU 1 69603 test begin: paddle.linalg.cond(x=Tensor([4, 2, 4, 0],"float64"), p=-1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([4, 2, 4, 0],"float64"), p=-1, ) 
 only support p is -1 when input is a square matrix or batches of square matrices

2025-05-21 22:07:51.445844 GPU 1 69606 test begin: paddle.linalg.cond(x=Tensor([4, 2, 4, 0],"float64"), p=-math.inf, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([4, 2, 4, 0],"float64"), p=-math.inf, ) 
 only support p is -inf when input is a square matrix or batches of square matrices

2025-05-21 22:07:51.446430 GPU 1 69613 test begin: paddle.linalg.cond(x=Tensor([4, 2, 4, 0],"float64"), p=math.inf, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([4, 2, 4, 0],"float64"), p=math.inf, ) 
 only support p is inf when input is a square matrix or batches of square matrices

2025-05-21 22:07:51.454393 GPU 1 69616 test begin: paddle.linalg.cond(x=Tensor([6, 0],"float64"), p=-2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([6, 0],"float64"), p=-2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [6, 0], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-05-21 22:07:51.459158 GPU 1 69612 test begin: paddle.linalg.cond(x=Tensor([6, 2, 4, 0, 4],"float64"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([6, 2, 4, 0, 4],"float64"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [6, 2, 4, 0, 4], X's size = 0, 'shape' is [6, 2, 4], the capacity of 'shape' is 48.
  [Hint: Expected capacity == in_size, but received capacity:48 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-05-21 22:07:51.466825 GPU 1 69609 test begin: paddle.linalg.cond(x=Tensor([6, 2, 4, 3, 0],"float64"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([6, 2, 4, 3, 0],"float64"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [6, 2, 4, 3, 0], X's size = 0, 'shape' is [6, 2, 4], the capacity of 'shape' is 48.
  [Hint: Expected capacity == in_size, but received capacity:48 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-05-21 22:07:51.498634 GPU 1 69604 test begin: paddle.linalg.cov(Tensor([0, 4],"float32"), )
W0521 22:07:52.022989 69604 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.linalg.cov(Tensor([0, 4],"float32"), ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:51.499146 GPU 1 69618 test begin: paddle.linalg.cov(Tensor([0],"float32"), )
 ** On entry to DGEMM  parameter number 8 had an illegal value
 ** On entry to DGEMM  parameter number 8 had an illegal value
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: cov(): degrees of freedom is <= 0. Correction should be strictly less than the number of observations. (Triggered internally at /pytorch/aten/src/ATen/native/Correlation.cpp:116.)
  return func(*args, **kwargs)
[accuracy error] paddle.linalg.cov(Tensor([0],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array(-inf, dtype=float32)
 DESIRED: array(nan, dtype=float32)

2025-05-21 22:07:51.657888 GPU 1 69608 test begin: paddle.linalg.cov(Tensor([3, 0],"float32"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: cov(): degrees of freedom is <= 0. Correction should be strictly less than the number of observations. (Triggered internally at /pytorch/aten/src/ATen/native/Correlation.cpp:116.)
  return func(*args, **kwargs)
[accuracy error] paddle.linalg.cov(Tensor([3, 0],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array([[-inf,  nan,  nan],
       [ nan,  nan,  nan],
       [ nan,  nan,  nan]], dtype=float32)
 DESIRED: array([[nan, nan, nan],
       [nan, nan, nan],
       [nan, nan, nan]], dtype=float32)

2025-05-21 22:07:51.668199 GPU 1 69600 test begin: paddle.linalg.cov(x=Tensor([0, 12],"float64"), )
W0521 22:07:51.853093 69600 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.linalg.cov(x=Tensor([0, 12],"float64"), ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:51.668720 GPU 1 69614 test begin: paddle.linalg.cov(x=Tensor([0, 2],"float32"), )
W0521 22:07:52.019727 69614 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.linalg.cov(x=Tensor([0, 2],"float32"), ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:51.668831 GPU 1 69621 test begin: paddle.linalg.cov(x=Tensor([4, 0],"float32"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: cov(): degrees of freedom is <= 0. Correction should be strictly less than the number of observations. (Triggered internally at /pytorch/aten/src/ATen/native/Correlation.cpp:116.)
  return func(*args, **kwargs)
[accuracy error] paddle.linalg.cov(x=Tensor([4, 0],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array([[-inf,  inf, -inf,  inf],
       [-inf, -inf, -inf,  inf],
       [-inf,  inf, -inf,  inf],
       [ inf, -inf,  inf, -inf]], dtype=float32)
 DESIRED: array([[nan, nan, nan, nan],
       [nan, nan, nan, nan],
       [nan, nan, nan, nan],
       [nan, nan, nan, nan]], dtype=float32)

2025-05-21 22:07:51.668977 GPU 1 69601 test begin: paddle.linalg.cov(x=Tensor([4, 0],"float64"), )
 ** On entry to DGEMM  parameter number 8 had an illegal value
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: cov(): degrees of freedom is <= 0. Correction should be strictly less than the number of observations. (Triggered internally at /pytorch/aten/src/ATen/native/Correlation.cpp:116.)
  return func(*args, **kwargs)
[accuracy error] paddle.linalg.cov(x=Tensor([4, 0],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array([[-inf,  inf,  nan,  inf],
       [ inf,  inf,  inf,  nan],
       [ inf,  nan, -inf,  nan],
       [-inf,  nan, -inf,  nan]])
 DESIRED: array([[nan, nan, nan, nan],
       [nan, nan, nan, nan],
       [nan, nan, nan, nan],
       [nan, nan, nan, nan]])

2025-05-21 22:07:51.677225 GPU 1 69606 test begin: paddle.linalg.det(Tensor([0, 1, 4, 3, 6, 6],"complex64"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[cuda error] paddle.linalg.det(Tensor([0, 1, 4, 3, 6, 6],"complex64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:51.682568 GPU 1 69599 test begin: paddle.linalg.det(Tensor([0, 3, 5, 5],"complex128"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[cuda error] paddle.linalg.det(Tensor([0, 3, 5, 5],"complex128"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:51.682754 GPU 1 69629 test begin: paddle.linalg.det(Tensor([2, 0, 4, 3, 6, 6],"complex64"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[cuda error] paddle.linalg.det(Tensor([2, 0, 4, 3, 6, 6],"complex64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:51.683388 GPU 1 69609 test begin: paddle.linalg.det(Tensor([2, 1, 0, 3, 6, 6],"complex64"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[cuda error] paddle.linalg.det(Tensor([2, 1, 0, 3, 6, 6],"complex64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:51.683539 GPU 1 69619 test begin: paddle.linalg.det(Tensor([2, 1, 4, 0, 6, 6],"complex64"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[cuda error] paddle.linalg.det(Tensor([2, 1, 4, 0, 6, 6],"complex64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:51.683600 GPU 1 69612 test begin: paddle.linalg.det(Tensor([3, 0, 5, 5],"complex128"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[cuda error] paddle.linalg.det(Tensor([3, 0, 5, 5],"complex128"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:51.683743 GPU 1 69603 test begin: paddle.linalg.lstsq(Tensor([0, 10],"float64"), Tensor([0, 8],"float64"), rcond=1e-15, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([0, 10],"float64"), Tensor([0, 8],"float64"), rcond=1e-15, driver="gels", ) 
 (InvalidArgument) C++ Slice Operation Not Support End < Start
  [Hint: Expected ed > st, but received ed:0 <= st:0.] (at ../paddle/phi/kernels/funcs/slice.h:93)


2025-05-21 22:07:51.684429 GPU 1 69602 test begin: paddle.linalg.lstsq(Tensor([0, 2, 8],"float32"), Tensor([0, 2, 15],"float32"), rcond=None, driver="gels", )
 ** On entry to DGEMM  parameter number 8 had an illegal value
[paddle error] paddle.linalg.lstsq(Tensor([0, 2, 8],"float32"), Tensor([0, 2, 15],"float32"), rcond=None, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:51.684542 GPU 1 69598 test begin: paddle.linalg.lstsq(Tensor([0, 5],"float32"), Tensor([0, 8],"float32"), rcond=None, driver="gels", )
 ** On entry to DGEMM  parameter number 8 had an illegal value
 ** On entry to DGEMM  parameter number 8 had an illegal value
[paddle error] paddle.linalg.lstsq(Tensor([0, 5],"float32"), Tensor([0, 8],"float32"), rcond=None, driver="gels", ) 
 (InvalidArgument) C++ Slice Operation Not Support End < Start
  [Hint: Expected ed > st, but received ed:0 <= st:0.] (at ../paddle/phi/kernels/funcs/slice.h:93)


2025-05-21 22:07:51.684659 GPU 1 69616 test begin: paddle.linalg.lstsq(Tensor([0, 7, 3],"float64"), Tensor([0, 7, 6],"float64"), rcond=1e-15, driver="gels", )
 ** On entry to DGEMM  parameter number 8 had an illegal value
 ** On entry to DGEMM  parameter number 8 had an illegal value
[paddle error] paddle.linalg.lstsq(Tensor([0, 7, 3],"float64"), Tensor([0, 7, 6],"float64"), rcond=1e-15, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:51.832678 GPU 1 69613 test begin: paddle.linalg.lstsq(Tensor([0, 8, 6],"float64"), Tensor([0, 8, 10],"float64"), rcond=1e-15, driver="gels", )
 ** On entry to DGEMM  parameter number 8 had an illegal value
[paddle error] paddle.linalg.lstsq(Tensor([0, 8, 6],"float64"), Tensor([0, 8, 10],"float64"), rcond=1e-15, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:51.854013 GPU 1 69600 test begin: paddle.linalg.lstsq(Tensor([0, 9],"float32"), Tensor([0, 5],"float32"), rcond=1e-15, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([0, 9],"float32"), Tensor([0, 5],"float32"), rcond=1e-15, driver="gels", ) 
 (InvalidArgument) C++ Slice Operation Not Support End < Start
  [Hint: Expected ed > st, but received ed:0 <= st:0.] (at ../paddle/phi/kernels/funcs/slice.h:93)


2025-05-21 22:07:52.017037 GPU 1 69606 test begin: paddle.linalg.lstsq(Tensor([10, 0, 3],"float64"), Tensor([10, 0, 6],"float64"), rcond=1e-15, driver="gels", )
 ** On entry to SGEMM  parameter number 8 had an illegal value
[paddle error] paddle.linalg.lstsq(Tensor([10, 0, 3],"float64"), Tensor([10, 0, 6],"float64"), rcond=1e-15, driver="gels", ) 
 (InvalidArgument) C++ Slice Operation Not Support End < Start
  [Hint: Expected ed > st, but received ed:0 <= st:0.] (at ../paddle/phi/kernels/funcs/slice.h:93)


2025-05-21 22:07:52.018073 GPU 1 69609 test begin: paddle.linalg.lstsq(Tensor([10, 0, 6],"float64"), Tensor([10, 0, 10],"float64"), rcond=1e-15, driver="gels", )
 ** On entry to DGEMM  parameter number 8 had an illegal value
[paddle error] paddle.linalg.lstsq(Tensor([10, 0, 6],"float64"), Tensor([10, 0, 10],"float64"), rcond=1e-15, driver="gels", ) 
 (InvalidArgument) C++ Slice Operation Not Support End < Start
  [Hint: Expected ed > st, but received ed:0 <= st:0.] (at ../paddle/phi/kernels/funcs/slice.h:93)


2025-05-21 22:07:52.018627 GPU 1 69612 test begin: paddle.linalg.lstsq(Tensor([10, 0],"float32"), Tensor([10, 0],"float32"), rcond=None, driver="gels", )
 ** On entry to SgemmStridedBatched parameter number 8 had an illegal value
 ** On entry to DGEMM  parameter number 8 had an illegal value
[paddle error] paddle.linalg.lstsq(Tensor([10, 0],"float32"), Tensor([10, 0],"float32"), rcond=None, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:52.020193 GPU 1 69599 test begin: paddle.linalg.lstsq(Tensor([10, 0],"float32"), Tensor([10, 8],"float32"), rcond=None, driver="gels", )
 ** On entry to DGEMM  parameter number 8 had an illegal value
[paddle error] paddle.linalg.lstsq(Tensor([10, 0],"float32"), Tensor([10, 8],"float32"), rcond=None, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:52.021405 GPU 1 69614 test begin: paddle.linalg.lstsq(Tensor([10, 5],"float32"), Tensor([10, 0],"float32"), rcond=None, driver="gels", )
 ** On entry to DGEMM  parameter number 8 had an illegal value
 ** On entry to DGEMM  parameter number 8 had an illegal value
[paddle error] paddle.linalg.lstsq(Tensor([10, 5],"float32"), Tensor([10, 0],"float32"), rcond=None, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:52.022694 GPU 1 69608 test begin: paddle.linalg.lstsq(Tensor([10, 7, 0],"float64"), Tensor([10, 7, 0],"float64"), rcond=1e-15, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([10, 7, 0],"float64"), Tensor([10, 7, 0],"float64"), rcond=1e-15, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:52.023287 GPU 1 69619 test begin: paddle.linalg.lstsq(Tensor([10, 7, 0],"float64"), Tensor([10, 7, 6],"float64"), rcond=1e-15, driver="gels", )
 ** On entry to DGEMM  parameter number 8 had an illegal value
[paddle error] paddle.linalg.lstsq(Tensor([10, 7, 0],"float64"), Tensor([10, 7, 6],"float64"), rcond=1e-15, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:52.025316 GPU 1 69604 test begin: paddle.linalg.lstsq(Tensor([10, 7, 3],"float64"), Tensor([10, 7, 0],"float64"), rcond=1e-15, driver="gels", )
 ** On entry to DGEMM  parameter number 8 had an illegal value
[paddle error] paddle.linalg.lstsq(Tensor([10, 7, 3],"float64"), Tensor([10, 7, 0],"float64"), rcond=1e-15, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:52.025868 GPU 1 69618 test begin: paddle.linalg.lstsq(Tensor([10, 8, 0],"float64"), Tensor([10, 8, 0],"float64"), rcond=1e-15, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([10, 8, 0],"float64"), Tensor([10, 8, 0],"float64"), rcond=1e-15, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:52.028378 GPU 1 69621 test begin: paddle.linalg.lstsq(Tensor([10, 8, 0],"float64"), Tensor([10, 8, 10],"float64"), rcond=1e-15, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([10, 8, 0],"float64"), Tensor([10, 8, 10],"float64"), rcond=1e-15, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:52.211417 GPU 1 69601 test begin: paddle.linalg.lstsq(Tensor([10, 8, 6],"float64"), Tensor([10, 8, 0],"float64"), rcond=1e-15, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([10, 8, 6],"float64"), Tensor([10, 8, 0],"float64"), rcond=1e-15, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:52.382921 GPU 1 69608 test begin: paddle.linalg.lstsq(Tensor([3, 0, 8],"float32"), Tensor([3, 0, 15],"float32"), rcond=None, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([3, 0, 8],"float32"), Tensor([3, 0, 15],"float32"), rcond=None, driver="gels", ) 
 (InvalidArgument) C++ Slice Operation Not Support End < Start
  [Hint: Expected ed > st, but received ed:0 <= st:0.] (at ../paddle/phi/kernels/funcs/slice.h:93)


2025-05-21 22:07:52.934881 GPU 1 69621 test begin: paddle.linalg.lstsq(Tensor([3, 2, 0],"float32"), Tensor([3, 2, 0],"float32"), rcond=None, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([3, 2, 0],"float32"), Tensor([3, 2, 0],"float32"), rcond=None, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:53.061067 GPU 1 69621 test begin: paddle.linalg.lstsq(Tensor([3, 2, 0],"float32"), Tensor([3, 2, 15],"float32"), rcond=None, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([3, 2, 0],"float32"), Tensor([3, 2, 15],"float32"), rcond=None, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:53.081643 GPU 1 69608 test begin: paddle.linalg.lstsq(Tensor([3, 2, 8],"float32"), Tensor([3, 2, 0],"float32"), rcond=None, driver="gels", )
[accuracy error] paddle.linalg.lstsq(Tensor([3, 2, 8],"float32"), Tensor([3, 2, 0],"float32"), rcond=None, driver="gels", ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (3, 8, 2, 0), (3, 8, 0) mismatch)
 ACTUAL: array([], shape=(3, 8, 2, 0), dtype=float32)
 DESIRED: array([], shape=(3, 8, 0), dtype=float32)

2025-05-21 22:07:53.131232 GPU 1 69599 test begin: paddle.linalg.lstsq(Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), rcond=1e-15, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), rcond=1e-15, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:53.181249 GPU 1 69621 test begin: paddle.linalg.lstsq(Tensor([5, 0],"float64"), Tensor([5, 8],"float64"), rcond=1e-15, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([5, 0],"float64"), Tensor([5, 8],"float64"), rcond=1e-15, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:53.214009 GPU 1 69615 test begin: paddle.linalg.lstsq(Tensor([9, 0],"float32"), Tensor([9, 0],"float32"), rcond=1e-15, driver="gels", )
 ** On entry to DGEMM  parameter number 8 had an illegal value
 ** On entry to GEMM_EX  parameter number 9 had an illegal value
[paddle error] paddle.linalg.lstsq(Tensor([9, 0],"float32"), Tensor([9, 0],"float32"), rcond=1e-15, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:53.261872 GPU 1 69599 test begin: paddle.linalg.lstsq(Tensor([9, 0],"float32"), Tensor([9, 5],"float32"), rcond=1e-15, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([9, 0],"float32"), Tensor([9, 5],"float32"), rcond=1e-15, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:53.403458 GPU 1 69599 test begin: paddle.linalg.lstsq(Tensor([9, 9],"float32"), Tensor([9, 0],"float32"), rcond=1e-15, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([9, 9],"float32"), Tensor([9, 0],"float32"), rcond=1e-15, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-05-21 22:07:53.406636 GPU 1 69611 test begin: paddle.linalg.matrix_norm(x=Tensor([0, 3, 4, 5],"float64"), p=-2, axis=list[1,2,], keepdim=False, )
[paddle error] paddle.linalg.matrix_norm(x=Tensor([0, 3, 4, 5],"float64"), p=-2, axis=list[1,2,], keepdim=False, ) 
 (InvalidArgument) Zero-size tensor to reduction operation minimum which has no identity.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/reduce_min_kernel.cc:30)


2025-05-21 22:07:53.455769 GPU 1 69615 test begin: paddle.linalg.matrix_norm(x=Tensor([0, 3, 4, 5],"float64"), p=-2, axis=list[1,2,], keepdim=True, )
[paddle error] paddle.linalg.matrix_norm(x=Tensor([0, 3, 4, 5],"float64"), p=-2, axis=list[1,2,], keepdim=True, ) 
 (InvalidArgument) Zero-size tensor to reduction operation minimum which has no identity.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/reduce_min_kernel.cc:30)


2025-05-21 22:07:53.459122 GPU 1 69607 test begin: paddle.linalg.matrix_norm(x=Tensor([0, 3, 4],"float64"), p="fro", axis=list[0,1,], keepdim=False, )
[Pass] paddle.linalg.matrix_norm(x=Tensor([0, 3, 4],"float64"), p="fro", axis=list[0,1,], keepdim=False, )

2025-05-21 22:07:53.474893 GPU 1 69610 test begin: paddle.linalg.matrix_norm(x=Tensor([0, 3, 4],"float64"), p="fro", axis=list[0,1,], keepdim=True, )
[Pass] paddle.linalg.matrix_norm(x=Tensor([0, 3, 4],"float64"), p="fro", axis=list[0,1,], keepdim=True, )

2025-05-21 22:07:53.528720 GPU 1 69611 test begin: paddle.linalg.matrix_norm(x=Tensor([0, 3, 4],"float64"), p="nuc", axis=list[0,1,], keepdim=False, )
[accuracy error] backward  paddle.linalg.matrix_norm(x=Tensor([0, 3, 4],"float64"), p="nuc", axis=list[0,1,], keepdim=False, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (0, 0, 4, 3), (0, 3, 4) mismatch)
 ACTUAL: array([], shape=(0, 0, 4, 3), dtype=float64)
 DESIRED: array([], shape=(0, 3, 4), dtype=float64)

2025-05-21 22:07:53.577595 GPU 1 69612 test begin: paddle.linalg.matrix_norm(x=Tensor([0, 3, 4],"float64"), p="nuc", axis=list[0,1,], keepdim=True, )
[accuracy error] backward  paddle.linalg.matrix_norm(x=Tensor([0, 3, 4],"float64"), p="nuc", axis=list[0,1,], keepdim=True, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (0, 0, 4, 3), (0, 3, 4) mismatch)
 ACTUAL: array([], shape=(0, 0, 4, 3), dtype=float64)
 DESIRED: array([], shape=(0, 3, 4), dtype=float64)

2025-05-21 22:07:53.577868 GPU 1 69599 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 0, 4],"float64"), p="fro", axis=list[0,1,], keepdim=False, )
[Pass] paddle.linalg.matrix_norm(x=Tensor([2, 0, 4],"float64"), p="fro", axis=list[0,1,], keepdim=False, )

2025-05-21 22:07:53.587098 GPU 1 69615 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 0, 4],"float64"), p="fro", axis=list[0,1,], keepdim=True, )
[Pass] paddle.linalg.matrix_norm(x=Tensor([2, 0, 4],"float64"), p="fro", axis=list[0,1,], keepdim=True, )

2025-05-21 22:07:53.590329 GPU 1 69602 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 0, 4],"float64"), p="nuc", axis=list[0,1,], keepdim=False, )
[accuracy error] backward  paddle.linalg.matrix_norm(x=Tensor([2, 0, 4],"float64"), p="nuc", axis=list[0,1,], keepdim=False, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (2, 0, 4, 0), (2, 0, 4) mismatch)
 ACTUAL: array([], shape=(2, 0, 4, 0), dtype=float64)
 DESIRED: array([], shape=(2, 0, 4), dtype=float64)

2025-05-21 22:07:53.594331 GPU 1 69598 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 0, 4],"float64"), p="nuc", axis=list[0,1,], keepdim=True, )
[accuracy error] backward  paddle.linalg.matrix_norm(x=Tensor([2, 0, 4],"float64"), p="nuc", axis=list[0,1,], keepdim=True, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (2, 0, 4, 0), (2, 0, 4) mismatch)
 ACTUAL: array([], shape=(2, 0, 4, 0), dtype=float64)
 DESIRED: array([], shape=(2, 0, 4), dtype=float64)

2025-05-21 22:07:53.594510 GPU 1 69603 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 3, 0],"float64"), p="fro", axis=list[0,1,], keepdim=False, )
[Pass] paddle.linalg.matrix_norm(x=Tensor([2, 3, 0],"float64"), p="fro", axis=list[0,1,], keepdim=False, )

2025-05-21 22:07:53.598379 GPU 1 69610 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 3, 0],"float64"), p="fro", axis=list[0,1,], keepdim=True, )
[Pass] paddle.linalg.matrix_norm(x=Tensor([2, 3, 0],"float64"), p="fro", axis=list[0,1,], keepdim=True, )

2025-05-21 22:07:53.610022 GPU 1 69609 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 3, 0],"float64"), p="nuc", axis=list[0,1,], keepdim=False, )
[accuracy error] backward  paddle.linalg.matrix_norm(x=Tensor([2, 3, 0],"float64"), p="nuc", axis=list[0,1,], keepdim=False, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (2, 2, 0, 3), (2, 3, 0) mismatch)
 ACTUAL: array([], shape=(2, 2, 0, 3), dtype=float64)
 DESIRED: array([], shape=(2, 3, 0), dtype=float64)

2025-05-21 22:07:53.610380 GPU 1 69606 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 3, 0],"float64"), p="nuc", axis=list[0,1,], keepdim=True, )
[accuracy error] backward  paddle.linalg.matrix_norm(x=Tensor([2, 3, 0],"float64"), p="nuc", axis=list[0,1,], keepdim=True, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (2, 2, 0, 3), (2, 3, 0) mismatch)
 ACTUAL: array([], shape=(2, 2, 0, 3), dtype=float64)
 DESIRED: array([], shape=(2, 3, 0), dtype=float64)

2025-05-21 22:07:53.628086 GPU 1 69604 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 3, 0],"float64"), p=-math.inf, axis=list[0,1,], keepdim=False, )
[paddle error] paddle.linalg.matrix_norm(x=Tensor([2, 3, 0],"float64"), p=-math.inf, axis=list[0,1,], keepdim=False, ) 
 (InvalidArgument) Zero-size tensor to reduction operation minimum which has no identity.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/reduce_min_kernel.cc:30)


2025-05-21 22:07:53.711826 GPU 1 69611 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 3, 0],"float64"), p=-math.inf, axis=list[0,1,], keepdim=True, )
[paddle error] paddle.linalg.matrix_norm(x=Tensor([2, 3, 0],"float64"), p=-math.inf, axis=list[0,1,], keepdim=True, ) 
 (InvalidArgument) Zero-size tensor to reduction operation minimum which has no identity.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/reduce_min_kernel.cc:30)


2025-05-21 22:07:53.719186 GPU 1 69607 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 3, 4, 0],"float64"), p=-2, axis=list[1,2,], keepdim=False, )
[paddle error] paddle.linalg.matrix_norm(x=Tensor([2, 3, 4, 0],"float64"), p=-2, axis=list[1,2,], keepdim=False, ) 
 (InvalidArgument) Zero-size tensor to reduction operation minimum which has no identity.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/reduce_min_kernel.cc:30)


2025-05-21 22:07:53.738345 GPU 1 69610 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 3, 4, 0],"float64"), p=-2, axis=list[1,2,], keepdim=True, )
[paddle error] paddle.linalg.matrix_norm(x=Tensor([2, 3, 4, 0],"float64"), p=-2, axis=list[1,2,], keepdim=True, ) 
 (InvalidArgument) Zero-size tensor to reduction operation minimum which has no identity.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/reduce_min_kernel.cc:30)


2025-05-21 22:07:53.739472 GPU 1 69600 test begin: paddle.linalg.matrix_power(x=Tensor([0, 2, 10, 10],"float64"), n=64, )
[Pass] paddle.linalg.matrix_power(x=Tensor([0, 2, 10, 10],"float64"), n=64, )

2025-05-21 22:07:53.742390 GPU 1 69606 test begin: paddle.linalg.matrix_power(x=Tensor([0, 2, 2, 7, 6, 1, 11, 4, 4],"float64"), n=3, )
[Pass] paddle.linalg.matrix_power(x=Tensor([0, 2, 2, 7, 6, 1, 11, 4, 4],"float64"), n=3, )

2025-05-21 22:07:53.744085 GPU 1 69615 test begin: paddle.linalg.matrix_power(x=Tensor([0, 2, 3, 2, 1, 32, 32],"float64"), n=-10, )
[Pass] paddle.linalg.matrix_power(x=Tensor([0, 2, 3, 2, 1, 32, 32],"float64"), n=-10, )

2025-05-21 22:07:53.749003 GPU 1 69612 test begin: paddle.linalg.matrix_power(x=Tensor([0, 2, 3, 2, 1, 32, 32],"float64"), n=-2, )
[Pass] paddle.linalg.matrix_power(x=Tensor([0, 2, 3, 2, 1, 32, 32],"float64"), n=-2, )

2025-05-21 22:07:53.753694 GPU 1 69609 test begin: paddle.linalg.matrix_power(x=Tensor([0, 2, 3, 2, 1, 32, 32],"float64"), n=10, )
[Pass] paddle.linalg.matrix_power(x=Tensor([0, 2, 3, 2, 1, 32, 32],"float64"), n=10, )

2025-05-21 22:07:53.755484 GPU 1 69596 test begin: paddle.linalg.matrix_power(x=Tensor([0, 2, 32, 32],"float64"), n=-10, )
[Pass] paddle.linalg.matrix_power(x=Tensor([0, 2, 32, 32],"float64"), n=-10, )

2025-05-21 22:07:53.758492 GPU 1 69618 test begin: paddle.linalg.matrix_power(x=Tensor([0, 2, 32, 32],"float64"), n=10, )
[Pass] paddle.linalg.matrix_power(x=Tensor([0, 2, 32, 32],"float64"), n=10, )

2025-05-21 22:07:53.773130 GPU 1 69604 test begin: paddle.linalg.matrix_power(x=Tensor([0, 2, 4, 4],"float64"), n=64, )
[Pass] paddle.linalg.matrix_power(x=Tensor([0, 2, 4, 4],"float64"), n=64, )

2025-05-21 22:07:53.796990 GPU 1 69599 test begin: paddle.linalg.matrix_power(x=Tensor([0, 2, 4, 4],"float64"), n=8, )
[Pass] paddle.linalg.matrix_power(x=Tensor([0, 2, 4, 4],"float64"), n=8, )

2025-05-21 22:07:53.800093 GPU 1 69601 test begin: paddle.linalg.matrix_power(x=Tensor([0, 4, 4],"float32"), n=3, )
[Pass] paddle.linalg.matrix_power(x=Tensor([0, 4, 4],"float32"), n=3, )

2025-05-21 22:07:53.801205 GPU 1 69602 test begin: paddle.linalg.matrix_power(x=Tensor([0, 4, 4],"float64"), n=3, )
[Pass] paddle.linalg.matrix_power(x=Tensor([0, 4, 4],"float64"), n=3, )

2025-05-21 22:07:53.803044 GPU 1 69608 test begin: paddle.linalg.matrix_power(x=Tensor([3, 0, 10, 10],"float64"), n=64, )
[Pass] paddle.linalg.matrix_power(x=Tensor([3, 0, 10, 10],"float64"), n=64, )

2025-05-21 22:07:53.804536 GPU 1 69605 test begin: paddle.linalg.matrix_power(x=Tensor([3, 0, 2, 7, 6, 1, 11, 4, 4],"float64"), n=3, )
[Pass] paddle.linalg.matrix_power(x=Tensor([3, 0, 2, 7, 6, 1, 11, 4, 4],"float64"), n=3, )

2025-05-21 22:07:53.827811 GPU 1 69621 test begin: paddle.linalg.matrix_power(x=Tensor([3, 0, 3, 2, 1, 32, 32],"float64"), n=-10, )
[Pass] paddle.linalg.matrix_power(x=Tensor([3, 0, 3, 2, 1, 32, 32],"float64"), n=-10, )

2025-05-21 22:07:53.829213 GPU 1 69611 test begin: paddle.linalg.matrix_power(x=Tensor([3, 0, 3, 2, 1, 32, 32],"float64"), n=-2, )
[Pass] paddle.linalg.matrix_power(x=Tensor([3, 0, 3, 2, 1, 32, 32],"float64"), n=-2, )

2025-05-21 22:07:53.837123 GPU 1 69603 test begin: paddle.linalg.matrix_power(x=Tensor([3, 0, 3, 2, 1, 32, 32],"float64"), n=10, )
[Pass] paddle.linalg.matrix_power(x=Tensor([3, 0, 3, 2, 1, 32, 32],"float64"), n=10, )

2025-05-21 22:07:53.848670 GPU 1 69600 test begin: paddle.linalg.matrix_power(x=Tensor([3, 0, 32, 32],"float64"), n=-10, )
[Pass] paddle.linalg.matrix_power(x=Tensor([3, 0, 32, 32],"float64"), n=-10, )

2025-05-21 22:07:53.864169 GPU 1 69606 test begin: paddle.linalg.matrix_power(x=Tensor([3, 0, 32, 32],"float64"), n=10, )
[Pass] paddle.linalg.matrix_power(x=Tensor([3, 0, 32, 32],"float64"), n=10, )

2025-05-21 22:07:53.876025 GPU 1 69607 test begin: paddle.linalg.matrix_power(x=Tensor([3, 0, 4, 4],"float64"), n=64, )
[Pass] paddle.linalg.matrix_power(x=Tensor([3, 0, 4, 4],"float64"), n=64, )

2025-05-21 22:07:53.882241 GPU 1 69618 test begin: paddle.linalg.matrix_power(x=Tensor([3, 0, 4, 4],"float64"), n=8, )
[Pass] paddle.linalg.matrix_power(x=Tensor([3, 0, 4, 4],"float64"), n=8, )

2025-05-21 22:07:53.883804 GPU 1 69609 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 0, 2, 1, 32, 32],"float64"), n=-10, )
[Pass] paddle.linalg.matrix_power(x=Tensor([3, 2, 0, 2, 1, 32, 32],"float64"), n=-10, )

2025-05-21 22:07:53.884855 GPU 1 69610 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 0, 2, 1, 32, 32],"float64"), n=-2, )
[Pass] paddle.linalg.matrix_power(x=Tensor([3, 2, 0, 2, 1, 32, 32],"float64"), n=-2, )

2025-05-21 22:07:53.889362 GPU 1 69596 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 0, 2, 1, 32, 32],"float64"), n=10, )
[Pass] paddle.linalg.matrix_power(x=Tensor([3, 2, 0, 2, 1, 32, 32],"float64"), n=10, )

2025-05-21 22:07:53.901203 GPU 1 69604 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 0, 7, 6, 1, 11, 4, 4],"float64"), n=3, )
[Pass] paddle.linalg.matrix_power(x=Tensor([3, 2, 0, 7, 6, 1, 11, 4, 4],"float64"), n=3, )

2025-05-21 22:07:53.904531 GPU 1 69598 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 2, 0, 6, 1, 11, 4, 4],"float64"), n=3, )
[Pass] paddle.linalg.matrix_power(x=Tensor([3, 2, 2, 0, 6, 1, 11, 4, 4],"float64"), n=3, )

2025-05-21 22:07:53.905341 GPU 1 69615 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 2, 7, 0, 1, 11, 4, 4],"float64"), n=3, )
[Pass] paddle.linalg.matrix_power(x=Tensor([3, 2, 2, 7, 0, 1, 11, 4, 4],"float64"), n=3, )

2025-05-21 22:07:53.913614 GPU 1 69602 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 2, 7, 6, 0, 11, 4, 4],"float64"), n=3, )
[Pass] paddle.linalg.matrix_power(x=Tensor([3, 2, 2, 7, 6, 0, 11, 4, 4],"float64"), n=3, )

2025-05-21 22:07:53.923837 GPU 1 69612 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 2, 7, 6, 1, 0, 4, 4],"float64"), n=3, )
[Pass] paddle.linalg.matrix_power(x=Tensor([3, 2, 2, 7, 6, 1, 0, 4, 4],"float64"), n=3, )

2025-05-21 22:07:53.925765 GPU 1 69601 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 0, 1, 32, 32],"float64"), n=-10, )
[Pass] paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 0, 1, 32, 32],"float64"), n=-10, )

2025-05-21 22:07:53.960502 GPU 1 69599 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 0, 1, 32, 32],"float64"), n=-2, )
[Pass] paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 0, 1, 32, 32],"float64"), n=-2, )

2025-05-21 22:07:53.960675 GPU 1 69619 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 0, 1, 32, 32],"float64"), n=10, )
[Pass] paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 0, 1, 32, 32],"float64"), n=10, )

2025-05-21 22:07:53.978654 GPU 1 69600 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 2, 0, 32, 32],"float64"), n=-10, )
[Pass] paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 2, 0, 32, 32],"float64"), n=-10, )

2025-05-21 22:07:53.984039 GPU 1 69608 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 2, 0, 32, 32],"float64"), n=-2, )
[Pass] paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 2, 0, 32, 32],"float64"), n=-2, )

2025-05-21 22:07:53.984752 GPU 1 69606 test begin: paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 2, 0, 32, 32],"float64"), n=10, )
[Pass] paddle.linalg.matrix_power(x=Tensor([3, 2, 3, 2, 0, 32, 32],"float64"), n=10, )

2025-05-21 22:07:54.004382 GPU 1 69618 test begin: paddle.linalg.matrix_rank(Tensor([0, 10],"float32"), )
[paddle error] paddle.linalg.matrix_rank(Tensor([0, 10],"float32"), ) 
 (InvalidArgument) The input Tensor x's shape[-2] should not be 0, but received 0, 10 now.
  [Hint: Expected rows != 0, but received rows:0 == 0:0.] (at ../paddle/phi/kernels/gpu/matrix_rank_tol_kernel.cu:639)


2025-05-21 22:07:54.007824 GPU 1 69596 test begin: paddle.linalg.matrix_rank(Tensor([0, 10],"float32"), hermitian=True, )
[paddle error] paddle.linalg.matrix_rank(Tensor([0, 10],"float32"), hermitian=True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:0 != cols:10.] (at ../paddle/phi/infermeta/unary.cc:2510)


2025-05-21 22:07:54.008728 GPU 1 69609 test begin: paddle.linalg.matrix_rank(Tensor([0, 10],"float32"), hermitian=True, atol=0.015, rtol=None, )
[paddle error] paddle.linalg.matrix_rank(Tensor([0, 10],"float32"), hermitian=True, atol=0.015, rtol=None, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:0 != cols:10.] (at ../paddle/phi/infermeta/binary.cc:3146)


2025-05-21 22:07:54.015323 GPU 1 69605 test begin: paddle.linalg.matrix_rank(Tensor([0, 10],"float32"), hermitian=True, atol=0.2, rtol=0.05, )
[paddle error] paddle.linalg.matrix_rank(Tensor([0, 10],"float32"), hermitian=True, atol=0.2, rtol=0.05, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:0 != cols:10.] (at ../paddle/phi/infermeta/binary.cc:3146)


2025-05-21 22:07:54.020519 GPU 1 69607 test begin: paddle.linalg.matrix_rank(Tensor([0, 10],"float32"), hermitian=True, atol=None, rtol=1.1, )
[paddle error] paddle.linalg.matrix_rank(Tensor([0, 10],"float32"), hermitian=True, atol=None, rtol=1.1, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:0 != cols:10.] (at ../paddle/phi/infermeta/binary.cc:3146)


2025-05-21 22:07:54.029878 GPU 1 69603 test begin: paddle.linalg.matrix_rank(Tensor([0, 10],"float32"), tol=0.1, )
[paddle error] paddle.linalg.matrix_rank(Tensor([0, 10],"float32"), tol=0.1, ) 
 (InvalidArgument) The input Tensor x's shape[-2] should not be 0, but received 0, 10 now.
  [Hint: Expected rows != 0, but received rows:0 == 0:0.] (at ../paddle/phi/kernels/gpu/matrix_rank_tol_kernel.cu:639)


2025-05-21 22:07:54.038693 GPU 1 69610 test begin: paddle.linalg.matrix_rank(Tensor([0, 10],"float32"), tol=Tensor([2],"float32"), )
[paddle error] paddle.linalg.matrix_rank(Tensor([0, 10],"float32"), tol=Tensor([2],"float32"), ) 
 (InvalidArgument) The input Tensor x's shape[-2] should not be 0, but received 0, 10 now.
  [Hint: Expected rows != 0, but received rows:0 == 0:0.] (at ../paddle/phi/kernels/gpu/matrix_rank_tol_kernel.cu:639)


2025-05-21 22:07:54.044436 GPU 1 69611 test begin: paddle.linalg.matrix_rank(Tensor([0, 1],"float64"), Tensor([0, 4],"float64"), False, )
[paddle error] paddle.linalg.matrix_rank(Tensor([0, 1],"float64"), Tensor([0, 4],"float64"), False, ) 
 (InvalidArgument) The input Tensor x's shape[-2] should not be 0, but received 0, 1 now.
  [Hint: Expected rows != 0, but received rows:0 == 0:0.] (at ../paddle/phi/kernels/gpu/matrix_rank_tol_kernel.cu:639)


2025-05-21 22:07:54.057802 GPU 1 69621 test begin: paddle.linalg.matrix_rank(Tensor([0, 1],"float64"), Tensor([1, 4],"float64"), False, )
[paddle error] paddle.linalg.matrix_rank(Tensor([0, 1],"float64"), Tensor([1, 4],"float64"), False, ) 
 (InvalidArgument) The input Tensor x's shape[-2] should not be 0, but received 0, 1 now.
  [Hint: Expected rows != 0, but received rows:0 == 0:0.] (at ../paddle/phi/kernels/gpu/matrix_rank_tol_kernel.cu:639)


2025-05-21 22:07:54.062534 GPU 1 69602 test begin: paddle.linalg.matrix_rank(Tensor([0, 200],"float64"), Tensor([0, 200],"float64"), True, )
[paddle error] paddle.linalg.matrix_rank(Tensor([0, 200],"float64"), Tensor([0, 200],"float64"), True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:0 != cols:200.] (at ../paddle/phi/infermeta/binary.cc:3146)


2025-05-21 22:07:54.070917 GPU 1 69615 test begin: paddle.linalg.matrix_rank(Tensor([0, 200],"float64"), Tensor([200, 200],"float64"), True, )
[paddle error] paddle.linalg.matrix_rank(Tensor([0, 200],"float64"), Tensor([200, 200],"float64"), True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:0 != cols:200.] (at ../paddle/phi/infermeta/binary.cc:3146)


2025-05-21 22:07:54.081346 GPU 1 69612 test begin: paddle.linalg.matrix_rank(Tensor([0, 3],"float32"), 0.1, True, )
[paddle error] paddle.linalg.matrix_rank(Tensor([0, 3],"float32"), 0.1, True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:0 != cols:3.] (at ../paddle/phi/infermeta/unary.cc:2510)


2025-05-21 22:07:54.088829 GPU 1 69599 test begin: paddle.linalg.matrix_rank(Tensor([0, 4, 5, 5],"float64"), hermitian=False, atol=Tensor([3, 4],"float64"), rtol=None, )
[paddle error] paddle.linalg.matrix_rank(Tensor([0, 4, 5, 5],"float64"), hermitian=False, atol=Tensor([3, 4],"float64"), rtol=None, ) 
 (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [0, 4] and the shape of Y = [3, 4]. Received [0] in X is not equal to [3] in Y at i:0.
  [Hint: Expected x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0) == true, but received x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0):0 != true:1.] (at ../paddle/phi/kernels/funcs/common_shape.h:72)


2025-05-21 22:07:54.102713 GPU 1 69606 test begin: paddle.linalg.matrix_rank(Tensor([0, 4, 5, 6],"float32"), Tensor([3, 4],"float32"), False, )
[paddle error] paddle.linalg.matrix_rank(Tensor([0, 4, 5, 6],"float32"), Tensor([3, 4],"float32"), False, ) 
 (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [0, 4] and the shape of Y = [3, 4]. Received [0] in X is not equal to [3] in Y at i:0.
  [Hint: Expected x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0) == true, but received x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0):0 != true:1.] (at ../paddle/phi/kernels/funcs/common_shape.h:72)


2025-05-21 22:07:54.114539 GPU 1 69618 test begin: paddle.linalg.matrix_rank(Tensor([0, 4, 7, 8],"float64"), Tensor([3, 4],"float32"), hermitian=False, )
[paddle error] paddle.linalg.matrix_rank(Tensor([0, 4, 7, 8],"float64"), Tensor([3, 4],"float32"), hermitian=False, ) 
 (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [0, 4] and the shape of Y = [3, 4]. Received [0] in X is not equal to [3] in Y at i:0.
  [Hint: Expected x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0) == true, but received x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0):0 != true:1.] (at ../paddle/phi/kernels/funcs/common_shape.h:72)


2025-05-21 22:07:54.119082 GPU 1 69598 test begin: paddle.linalg.matrix_rank(Tensor([0, 4, 7, 8],"float64"), hermitian=False, atol=Tensor([3, 1],"float32"), rtol=Tensor([3, 1],"float32"), )
[paddle error] paddle.linalg.matrix_rank(Tensor([0, 4, 7, 8],"float64"), hermitian=False, atol=Tensor([3, 1],"float32"), rtol=Tensor([3, 1],"float32"), ) 
 (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [0, 4] and the shape of Y = [3, 1]. Received [0] in X is not equal to [3] in Y at i:0.
  [Hint: Expected x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0) == true, but received x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0):0 != true:1.] (at ../paddle/phi/kernels/funcs/common_shape.h:72)


2025-05-21 22:07:54.122722 GPU 1 69596 test begin: paddle.linalg.matrix_rank(Tensor([0, 4, 7, 8],"float64"), hermitian=False, atol=Tensor([3, 4],"float32"), rtol=Tensor([3, 4],"float32"), )
[paddle error] paddle.linalg.matrix_rank(Tensor([0, 4, 7, 8],"float64"), hermitian=False, atol=Tensor([3, 4],"float32"), rtol=Tensor([3, 4],"float32"), ) 
 (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [0, 4] and the shape of Y = [3, 4]. Received [0] in X is not equal to [3] in Y at i:0.
  [Hint: Expected x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0) == true, but received x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0):0 != true:1.] (at ../paddle/phi/kernels/funcs/common_shape.h:72)


2025-05-21 22:07:54.125709 GPU 1 69609 test begin: paddle.linalg.matrix_rank(Tensor([10, 0],"float32"), )
[paddle error] paddle.linalg.matrix_rank(Tensor([10, 0],"float32"), ) 
 (InvalidArgument) The input Tensor x's shape[-1] should not be 0, but received 10, 0 now.
  [Hint: Expected cols != 0, but received cols:0 == 0:0.] (at ../paddle/phi/kernels/gpu/matrix_rank_tol_kernel.cu:645)


2025-05-21 22:07:54.129892 GPU 1 69614 test begin: paddle.linalg.matrix_rank(Tensor([10, 0],"float32"), hermitian=True, )
[paddle error] paddle.linalg.matrix_rank(Tensor([10, 0],"float32"), hermitian=True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:10 != cols:0.] (at ../paddle/phi/infermeta/unary.cc:2510)


2025-05-21 22:07:54.137111 GPU 1 69601 test begin: paddle.linalg.matrix_rank(Tensor([10, 0],"float32"), hermitian=True, atol=0.015, rtol=None, )
[paddle error] paddle.linalg.matrix_rank(Tensor([10, 0],"float32"), hermitian=True, atol=0.015, rtol=None, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:10 != cols:0.] (at ../paddle/phi/infermeta/binary.cc:3146)


2025-05-21 22:07:54.142431 GPU 1 69605 test begin: paddle.linalg.matrix_rank(Tensor([10, 0],"float32"), hermitian=True, atol=0.2, rtol=0.05, )
[paddle error] paddle.linalg.matrix_rank(Tensor([10, 0],"float32"), hermitian=True, atol=0.2, rtol=0.05, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:10 != cols:0.] (at ../paddle/phi/infermeta/binary.cc:3146)


2025-05-21 22:07:54.155277 GPU 1 69604 test begin: paddle.linalg.matrix_rank(Tensor([10, 0],"float32"), hermitian=True, atol=None, rtol=1.1, )
[paddle error] paddle.linalg.matrix_rank(Tensor([10, 0],"float32"), hermitian=True, atol=None, rtol=1.1, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:10 != cols:0.] (at ../paddle/phi/infermeta/binary.cc:3146)


2025-05-21 22:07:54.157129 GPU 1 69616 test begin: paddle.linalg.matrix_rank(Tensor([10, 0],"float32"), tol=0.1, )
[paddle error] paddle.linalg.matrix_rank(Tensor([10, 0],"float32"), tol=0.1, ) 
 (InvalidArgument) The input Tensor x's shape[-1] should not be 0, but received 10, 0 now.
  [Hint: Expected cols != 0, but received cols:0 == 0:0.] (at ../paddle/phi/kernels/gpu/matrix_rank_tol_kernel.cu:645)


2025-05-21 22:07:54.163566 GPU 1 69607 test begin: paddle.linalg.matrix_rank(Tensor([10, 0],"float32"), tol=Tensor([2],"float32"), )
[paddle error] paddle.linalg.matrix_rank(Tensor([10, 0],"float32"), tol=Tensor([2],"float32"), ) 
 (InvalidArgument) The input Tensor x's shape[-1] should not be 0, but received 10, 0 now.
  [Hint: Expected cols != 0, but received cols:0 == 0:0.] (at ../paddle/phi/kernels/gpu/matrix_rank_tol_kernel.cu:645)


2025-05-21 22:07:54.172458 GPU 1 69600 test begin: paddle.linalg.matrix_rank(Tensor([200, 0],"float64"), Tensor([200, 0],"float64"), True, )
[paddle error] paddle.linalg.matrix_rank(Tensor([200, 0],"float64"), Tensor([200, 0],"float64"), True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:200 != cols:0.] (at ../paddle/phi/infermeta/binary.cc:3146)


2025-05-21 22:07:54.181128 GPU 1 69603 test begin: paddle.linalg.matrix_rank(Tensor([200, 0],"float64"), Tensor([200, 200],"float64"), True, )
[paddle error] paddle.linalg.matrix_rank(Tensor([200, 0],"float64"), Tensor([200, 200],"float64"), True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:200 != cols:0.] (at ../paddle/phi/infermeta/binary.cc:3146)


2025-05-21 22:07:54.196204 GPU 1 69611 test begin: paddle.linalg.matrix_rank(Tensor([3, 0, 5, 5],"float64"), hermitian=False, atol=Tensor([3, 4],"float64"), rtol=None, )
[paddle error] paddle.linalg.matrix_rank(Tensor([3, 0, 5, 5],"float64"), hermitian=False, atol=Tensor([3, 4],"float64"), rtol=None, ) 
 (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [3, 0] and the shape of Y = [3, 4]. Received [0] in X is not equal to [4] in Y at i:1.
  [Hint: Expected x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0) == true, but received x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0):0 != true:1.] (at ../paddle/phi/kernels/funcs/common_shape.h:72)


2025-05-21 22:07:54.198027 GPU 1 69602 test begin: paddle.linalg.matrix_rank(Tensor([3, 0, 5, 6],"float32"), Tensor([3, 4],"float32"), False, )
[paddle error] paddle.linalg.matrix_rank(Tensor([3, 0, 5, 6],"float32"), Tensor([3, 4],"float32"), False, ) 
 (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [3, 0] and the shape of Y = [3, 4]. Received [0] in X is not equal to [4] in Y at i:1.
  [Hint: Expected x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0) == true, but received x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0):0 != true:1.] (at ../paddle/phi/kernels/funcs/common_shape.h:72)


2025-05-21 22:07:54.210906 GPU 1 69610 test begin: paddle.linalg.matrix_rank(Tensor([3, 0, 5],"float32"), )
[paddle error] paddle.linalg.matrix_rank(Tensor([3, 0, 5],"float32"), ) 
 (InvalidArgument) The input Tensor x's shape[-2] should not be 0, but received 3, 0, 5 now.
  [Hint: Expected rows != 0, but received rows:0 == 0:0.] (at ../paddle/phi/kernels/gpu/matrix_rank_tol_kernel.cu:639)


2025-05-21 22:07:54.216068 GPU 1 69599 test begin: paddle.linalg.matrix_rank(Tensor([3, 0, 5],"float32"), tol=0.1, )
[paddle error] paddle.linalg.matrix_rank(Tensor([3, 0, 5],"float32"), tol=0.1, ) 
 (InvalidArgument) The input Tensor x's shape[-2] should not be 0, but received 3, 0, 5 now.
  [Hint: Expected rows != 0, but received rows:0 == 0:0.] (at ../paddle/phi/kernels/gpu/matrix_rank_tol_kernel.cu:639)


2025-05-21 22:07:54.218456 GPU 1 69606 test begin: paddle.linalg.matrix_rank(Tensor([3, 0, 7, 8],"float64"), Tensor([3, 4],"float32"), hermitian=False, )
[paddle error] paddle.linalg.matrix_rank(Tensor([3, 0, 7, 8],"float64"), Tensor([3, 4],"float32"), hermitian=False, ) 
 (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [3, 0] and the shape of Y = [3, 4]. Received [0] in X is not equal to [4] in Y at i:1.
  [Hint: Expected x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0) == true, but received x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0):0 != true:1.] (at ../paddle/phi/kernels/funcs/common_shape.h:72)


2025-05-21 22:07:54.224154 GPU 1 69615 test begin: paddle.linalg.matrix_rank(Tensor([3, 0, 7, 8],"float64"), hermitian=False, atol=Tensor([3, 4],"float32"), rtol=Tensor([3, 4],"float32"), )
[paddle error] paddle.linalg.matrix_rank(Tensor([3, 0, 7, 8],"float64"), hermitian=False, atol=Tensor([3, 4],"float32"), rtol=Tensor([3, 4],"float32"), ) 
 (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [3, 0] and the shape of Y = [3, 4]. Received [0] in X is not equal to [4] in Y at i:1.
  [Hint: Expected x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0) == true, but received x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0):0 != true:1.] (at ../paddle/phi/kernels/funcs/common_shape.h:72)


2025-05-21 22:07:54.230699 GPU 1 69618 test begin: paddle.linalg.matrix_rank(Tensor([3, 0],"float32"), 0.1, True, )
[paddle error] paddle.linalg.matrix_rank(Tensor([3, 0],"float32"), 0.1, True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:3 != cols:0.] (at ../paddle/phi/infermeta/unary.cc:2510)


2025-05-21 22:07:54.237965 GPU 1 69596 test begin: paddle.linalg.matrix_rank(Tensor([3, 4, 0, 5],"float64"), hermitian=False, atol=Tensor([3, 4],"float64"), rtol=None, )
[paddle error] paddle.linalg.matrix_rank(Tensor([3, 4, 0, 5],"float64"), hermitian=False, atol=Tensor([3, 4],"float64"), rtol=None, ) 
 (InvalidArgument) The input Tensor x's shape[-2] should not be 0, but received 3, 4, 0, 5 now.
  [Hint: Expected rows != 0, but received rows:0 == 0:0.] (at ../paddle/phi/kernels/gpu/matrix_rank_tol_kernel.cu:775)


2025-05-21 22:07:54.244778 GPU 1 69612 test begin: paddle.linalg.matrix_rank(Tensor([3, 4, 0, 5],"float64"), hermitian=True, atol=0.5, rtol=None, )
[paddle error] paddle.linalg.matrix_rank(Tensor([3, 4, 0, 5],"float64"), hermitian=True, atol=0.5, rtol=None, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:0 != cols:5.] (at ../paddle/phi/infermeta/binary.cc:3146)


2025-05-21 22:07:54.245537 GPU 1 69609 test begin: paddle.linalg.matrix_rank(Tensor([3, 4, 0, 6],"float32"), Tensor([3, 4],"float32"), False, )
[paddle error] paddle.linalg.matrix_rank(Tensor([3, 4, 0, 6],"float32"), Tensor([3, 4],"float32"), False, ) 
 (InvalidArgument) The input Tensor x's shape[-2] should not be 0, but received 3, 4, 0, 6 now.
  [Hint: Expected rows != 0, but received rows:0 == 0:0.] (at ../paddle/phi/kernels/gpu/matrix_rank_tol_kernel.cu:639)


2025-05-21 22:07:54.245778 GPU 1 69614 test begin: paddle.linalg.matrix_rank(Tensor([3, 4, 0, 8],"float64"), 0.1, hermitian=False, )
[paddle error] paddle.linalg.matrix_rank(Tensor([3, 4, 0, 8],"float64"), 0.1, hermitian=False, ) 
 (InvalidArgument) The input Tensor x's shape[-2] should not be 0, but received 3, 4, 0, 8 now.
  [Hint: Expected rows != 0, but received rows:0 == 0:0.] (at ../paddle/phi/kernels/gpu/matrix_rank_tol_kernel.cu:639)


2025-05-21 22:07:54.260501 GPU 1 69621 test begin: paddle.linalg.matrix_rank(Tensor([3, 4, 0, 8],"float64"), Tensor([3, 4],"float32"), hermitian=False, )
[paddle error] paddle.linalg.matrix_rank(Tensor([3, 4, 0, 8],"float64"), Tensor([3, 4],"float32"), hermitian=False, ) 
 (InvalidArgument) The input Tensor x's shape[-2] should not be 0, but received 3, 4, 0, 8 now.
  [Hint: Expected rows != 0, but received rows:0 == 0:0.] (at ../paddle/phi/kernels/gpu/matrix_rank_tol_kernel.cu:639)


2025-05-21 22:07:54.260549 GPU 1 69605 test begin: paddle.linalg.matrix_rank(Tensor([3, 4, 0, 8],"float64"), hermitian=False, atol=Tensor([3, 1],"float32"), rtol=Tensor([3, 1],"float32"), )
[paddle error] paddle.linalg.matrix_rank(Tensor([3, 4, 0, 8],"float64"), hermitian=False, atol=Tensor([3, 1],"float32"), rtol=Tensor([3, 1],"float32"), ) 
 (InvalidArgument) The input Tensor x's shape[-2] should not be 0, but received 3, 4, 0, 8 now.
  [Hint: Expected rows != 0, but received rows:0 == 0:0.] (at ../paddle/phi/kernels/gpu/matrix_rank_tol_kernel.cu:775)


2025-05-21 22:07:54.260893 GPU 1 69619 test begin: paddle.linalg.matrix_rank(Tensor([3, 4, 0, 8],"float64"), hermitian=False, atol=Tensor([3, 4],"float32"), rtol=Tensor([3, 4],"float32"), )
[paddle error] paddle.linalg.matrix_rank(Tensor([3, 4, 0, 8],"float64"), hermitian=False, atol=Tensor([3, 4],"float32"), rtol=Tensor([3, 4],"float32"), ) 
 (InvalidArgument) The input Tensor x's shape[-2] should not be 0, but received 3, 4, 0, 8 now.
  [Hint: Expected rows != 0, but received rows:0 == 0:0.] (at ../paddle/phi/kernels/gpu/matrix_rank_tol_kernel.cu:775)


2025-05-21 22:07:54.265766 GPU 1 69613 test begin: paddle.linalg.matrix_rank(Tensor([3, 4, 0],"float32"), )
[paddle error] paddle.linalg.matrix_rank(Tensor([3, 4, 0],"float32"), ) 
 (InvalidArgument) The input Tensor x's shape[-1] should not be 0, but received 3, 4, 0 now.
  [Hint: Expected cols != 0, but received cols:0 == 0:0.] (at ../paddle/phi/kernels/gpu/matrix_rank_tol_kernel.cu:645)


2025-05-21 22:07:54.308140 GPU 1 69616 test begin: paddle.linalg.matrix_rank(Tensor([3, 4, 0],"float32"), tol=0.1, )
[paddle error] paddle.linalg.matrix_rank(Tensor([3, 4, 0],"float32"), tol=0.1, ) 
 (InvalidArgument) The input Tensor x's shape[-1] should not be 0, but received 3, 4, 0 now.
  [Hint: Expected cols != 0, but received cols:0 == 0:0.] (at ../paddle/phi/kernels/gpu/matrix_rank_tol_kernel.cu:645)


2025-05-21 22:07:54.311742 GPU 1 69608 test begin: paddle.linalg.matrix_rank(Tensor([3, 4, 5, 0],"float32"), Tensor([3, 4],"float32"), False, )
[paddle error] paddle.linalg.matrix_rank(Tensor([3, 4, 5, 0],"float32"), Tensor([3, 4],"float32"), False, ) 
 (InvalidArgument) The input Tensor x's shape[-1] should not be 0, but received 3, 4, 5, 0 now.
  [Hint: Expected cols != 0, but received cols:0 == 0:0.] (at ../paddle/phi/kernels/gpu/matrix_rank_tol_kernel.cu:645)


2025-05-21 22:07:54.317561 GPU 1 69611 test begin: paddle.linalg.matrix_rank(Tensor([3, 4, 5, 0],"float64"), hermitian=False, atol=Tensor([3, 4],"float64"), rtol=None, )
[paddle error] paddle.linalg.matrix_rank(Tensor([3, 4, 5, 0],"float64"), hermitian=False, atol=Tensor([3, 4],"float64"), rtol=None, ) 
 (InvalidArgument) The input Tensor x's shape[-1] should not be 0, but received 3, 4, 5, 0 now.
  [Hint: Expected cols != 0, but received cols:0 == 0:0.] (at ../paddle/phi/kernels/gpu/matrix_rank_tol_kernel.cu:781)


2025-05-21 22:07:54.325775 GPU 1 69598 test begin: paddle.linalg.matrix_rank(Tensor([3, 4, 5, 0],"float64"), hermitian=True, atol=0.5, rtol=None, )
[paddle error] paddle.linalg.matrix_rank(Tensor([3, 4, 5, 0],"float64"), hermitian=True, atol=0.5, rtol=None, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:5 != cols:0.] (at ../paddle/phi/infermeta/binary.cc:3146)


2025-05-21 22:07:54.479567 GPU 1 69599 test begin: paddle.linalg.matrix_rank(Tensor([3, 4, 7, 0],"float64"), 0.1, hermitian=False, )
[paddle error] paddle.linalg.matrix_rank(Tensor([3, 4, 7, 0],"float64"), 0.1, hermitian=False, ) 
 (InvalidArgument) The input Tensor x's shape[-1] should not be 0, but received 3, 4, 7, 0 now.
  [Hint: Expected cols != 0, but received cols:0 == 0:0.] (at ../paddle/phi/kernels/gpu/matrix_rank_tol_kernel.cu:645)


2025-05-21 22:07:54.479738 GPU 1 69603 test begin: paddle.linalg.matrix_rank(Tensor([3, 4, 7, 0],"float64"), Tensor([3, 4],"float32"), hermitian=False, )
[paddle error] paddle.linalg.matrix_rank(Tensor([3, 4, 7, 0],"float64"), Tensor([3, 4],"float32"), hermitian=False, ) 
 (InvalidArgument) The input Tensor x's shape[-1] should not be 0, but received 3, 4, 7, 0 now.
  [Hint: Expected cols != 0, but received cols:0 == 0:0.] (at ../paddle/phi/kernels/gpu/matrix_rank_tol_kernel.cu:645)


2025-05-21 22:07:54.480228 GPU 1 69610 test begin: paddle.linalg.matrix_rank(Tensor([3, 4, 7, 0],"float64"), hermitian=False, atol=Tensor([3, 1],"float32"), rtol=Tensor([3, 1],"float32"), )
[paddle error] paddle.linalg.matrix_rank(Tensor([3, 4, 7, 0],"float64"), hermitian=False, atol=Tensor([3, 1],"float32"), rtol=Tensor([3, 1],"float32"), ) 
 (InvalidArgument) The input Tensor x's shape[-1] should not be 0, but received 3, 4, 7, 0 now.
  [Hint: Expected cols != 0, but received cols:0 == 0:0.] (at ../paddle/phi/kernels/gpu/matrix_rank_tol_kernel.cu:781)


2025-05-21 22:07:54.480435 GPU 1 69606 test begin: paddle.linalg.matrix_rank(Tensor([3, 4, 7, 0],"float64"), hermitian=False, atol=Tensor([3, 4],"float32"), rtol=Tensor([3, 4],"float32"), )
[paddle error] paddle.linalg.matrix_rank(Tensor([3, 4, 7, 0],"float64"), hermitian=False, atol=Tensor([3, 4],"float32"), rtol=Tensor([3, 4],"float32"), ) 
 (InvalidArgument) The input Tensor x's shape[-1] should not be 0, but received 3, 4, 7, 0 now.
  [Hint: Expected cols != 0, but received cols:0 == 0:0.] (at ../paddle/phi/kernels/gpu/matrix_rank_tol_kernel.cu:781)


2025-05-21 22:07:54.480630 GPU 1 69601 test begin: paddle.linalg.matrix_rank(Tensor([5, 0],"float64"), Tensor([1, 0],"float64"), False, )
[paddle error] paddle.linalg.matrix_rank(Tensor([5, 0],"float64"), Tensor([1, 0],"float64"), False, ) 
 (InvalidArgument) The input Tensor x's shape[-1] should not be 0, but received 5, 0 now.
  [Hint: Expected cols != 0, but received cols:0 == 0:0.] (at ../paddle/phi/kernels/gpu/matrix_rank_tol_kernel.cu:645)


2025-05-21 22:07:54.481609 GPU 1 69600 test begin: paddle.linalg.matrix_rank(Tensor([5, 0],"float64"), Tensor([1, 4],"float64"), False, )
[paddle error] paddle.linalg.matrix_rank(Tensor([5, 0],"float64"), Tensor([1, 4],"float64"), False, ) 
 (InvalidArgument) The input Tensor x's shape[-1] should not be 0, but received 5, 0 now.
  [Hint: Expected cols != 0, but received cols:0 == 0:0.] (at ../paddle/phi/kernels/gpu/matrix_rank_tol_kernel.cu:645)


2025-05-21 22:07:54.482213 GPU 1 69602 test begin: paddle.linalg.matrix_rank(x=Tensor([0, 3, 4, 4],"float64"), tol=Tensor([2, 3],"float64"), hermitian=True, )
[paddle error] paddle.linalg.matrix_rank(x=Tensor([0, 3, 4, 4],"float64"), tol=Tensor([2, 3],"float64"), hermitian=True, ) 
 (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [0, 3] and the shape of Y = [2, 3]. Received [0] in X is not equal to [2] in Y at i:0.
  [Hint: Expected x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0) == true, but received x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0):0 != true:1.] (at ../paddle/phi/kernels/funcs/common_shape.h:72)


2025-05-21 22:07:54.482610 GPU 1 69596 test begin: paddle.linalg.matrix_rank(x=Tensor([0, 4, 4, 5],"float64"), tol=Tensor([2, 1],"float64"), hermitian=False, )
[paddle error] paddle.linalg.matrix_rank(x=Tensor([0, 4, 4, 5],"float64"), tol=Tensor([2, 1],"float64"), hermitian=False, ) 
 (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [0, 4] and the shape of Y = [2, 1]. Received [0] in X is not equal to [2] in Y at i:0.
  [Hint: Expected x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0) == true, but received x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0):0 != true:1.] (at ../paddle/phi/kernels/funcs/common_shape.h:72)


2025-05-21 22:07:54.483426 GPU 1 69612 test begin: paddle.linalg.matrix_rank(x=Tensor([0, 4],"float64"), tol=4.4, hermitian=True, )
[paddle error] paddle.linalg.matrix_rank(x=Tensor([0, 4],"float64"), tol=4.4, hermitian=True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:0 != cols:4.] (at ../paddle/phi/infermeta/unary.cc:2510)


2025-05-21 22:07:54.484015 GPU 1 69611 test begin: paddle.linalg.matrix_rank(x=Tensor([0, 4],"float64"), tol=Tensor([1],"float64"), hermitian=True, )
[paddle error] paddle.linalg.matrix_rank(x=Tensor([0, 4],"float64"), tol=Tensor([1],"float64"), hermitian=True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:0 != cols:4.] (at ../paddle/phi/infermeta/binary.cc:3146)


2025-05-21 22:07:54.484392 GPU 1 69607 test begin: paddle.linalg.matrix_rank(x=Tensor([0, 5],"float64"), tol=4.4, hermitian=False, )
[paddle error] paddle.linalg.matrix_rank(x=Tensor([0, 5],"float64"), tol=4.4, hermitian=False, ) 
 (InvalidArgument) The input Tensor x's shape[-2] should not be 0, but received 0, 5 now.
  [Hint: Expected rows != 0, but received rows:0 == 0:0.] (at ../paddle/phi/kernels/gpu/matrix_rank_tol_kernel.cu:639)


2025-05-21 22:07:54.484635 GPU 1 69609 test begin: paddle.linalg.matrix_rank(x=Tensor([2, 0, 4, 4],"float64"), tol=Tensor([2, 3],"float64"), hermitian=True, )
[paddle error] paddle.linalg.matrix_rank(x=Tensor([2, 0, 4, 4],"float64"), tol=Tensor([2, 3],"float64"), hermitian=True, ) 
 (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [2, 0] and the shape of Y = [2, 3]. Received [0] in X is not equal to [3] in Y at i:1.
  [Hint: Expected x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0) == true, but received x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0):0 != true:1.] (at ../paddle/phi/kernels/funcs/common_shape.h:72)


2025-05-21 22:07:54.485066 GPU 1 69618 test begin: paddle.linalg.matrix_rank(x=Tensor([2, 2, 0, 4],"float64"), tol=Tensor([1, 1],"float64"), hermitian=True, )
[paddle error] paddle.linalg.matrix_rank(x=Tensor([2, 2, 0, 4],"float64"), tol=Tensor([1, 1],"float64"), hermitian=True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:0 != cols:4.] (at ../paddle/phi/infermeta/binary.cc:3146)


2025-05-21 22:07:54.485211 GPU 1 69621 test begin: paddle.linalg.matrix_rank(x=Tensor([2, 2, 4, 0],"float64"), tol=Tensor([1, 1],"float64"), hermitian=True, )
[paddle error] paddle.linalg.matrix_rank(x=Tensor([2, 2, 4, 0],"float64"), tol=Tensor([1, 1],"float64"), hermitian=True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:4 != cols:0.] (at ../paddle/phi/infermeta/binary.cc:3146)


2025-05-21 22:07:54.485609 GPU 1 69616 test begin: paddle.linalg.matrix_rank(x=Tensor([2, 3, 0, 4],"float64"), tol=Tensor([1],"float64"), hermitian=True, )
[paddle error] paddle.linalg.matrix_rank(x=Tensor([2, 3, 0, 4],"float64"), tol=Tensor([1],"float64"), hermitian=True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:0 != cols:4.] (at ../paddle/phi/infermeta/binary.cc:3146)


2025-05-21 22:07:54.485797 GPU 1 69615 test begin: paddle.linalg.matrix_rank(x=Tensor([2, 3, 0, 4],"float64"), tol=Tensor([2, 3],"float64"), hermitian=True, )
[paddle error] paddle.linalg.matrix_rank(x=Tensor([2, 3, 0, 4],"float64"), tol=Tensor([2, 3],"float64"), hermitian=True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:0 != cols:4.] (at ../paddle/phi/infermeta/binary.cc:3146)


2025-05-21 22:07:54.486127 GPU 1 69604 test begin: paddle.linalg.matrix_rank(x=Tensor([2, 3, 4, 0],"float64"), tol=Tensor([1],"float64"), hermitian=True, )
[paddle error] paddle.linalg.matrix_rank(x=Tensor([2, 3, 4, 0],"float64"), tol=Tensor([1],"float64"), hermitian=True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:4 != cols:0.] (at ../paddle/phi/infermeta/binary.cc:3146)


2025-05-21 22:07:54.486251 GPU 1 69605 test begin: paddle.linalg.matrix_rank(x=Tensor([2, 3, 4, 0],"float64"), tol=Tensor([2, 3],"float64"), hermitian=True, )
[paddle error] paddle.linalg.matrix_rank(x=Tensor([2, 3, 4, 0],"float64"), tol=Tensor([2, 3],"float64"), hermitian=True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:4 != cols:0.] (at ../paddle/phi/infermeta/binary.cc:3146)


2025-05-21 22:07:54.486439 GPU 1 69614 test begin: paddle.linalg.matrix_rank(x=Tensor([2, 4, 0, 5],"float64"), tol=Tensor([2, 1],"float64"), hermitian=False, )
[paddle error] paddle.linalg.matrix_rank(x=Tensor([2, 4, 0, 5],"float64"), tol=Tensor([2, 1],"float64"), hermitian=False, ) 
 (InvalidArgument) The input Tensor x's shape[-2] should not be 0, but received 2, 4, 0, 5 now.
  [Hint: Expected rows != 0, but received rows:0 == 0:0.] (at ../paddle/phi/kernels/gpu/matrix_rank_tol_kernel.cu:639)


2025-05-21 22:07:54.486575 GPU 1 69619 test begin: paddle.linalg.matrix_rank(x=Tensor([2, 4, 4, 0],"float64"), tol=Tensor([2, 1],"float64"), hermitian=False, )
[paddle error] paddle.linalg.matrix_rank(x=Tensor([2, 4, 4, 0],"float64"), tol=Tensor([2, 1],"float64"), hermitian=False, ) 
 (InvalidArgument) The input Tensor x's shape[-1] should not be 0, but received 2, 4, 4, 0 now.
  [Hint: Expected cols != 0, but received cols:0 == 0:0.] (at ../paddle/phi/kernels/gpu/matrix_rank_tol_kernel.cu:645)


2025-05-21 22:07:54.631070 GPU 1 69613 test begin: paddle.linalg.matrix_rank(x=Tensor([4, 0],"float64"), tol=4.4, hermitian=False, )
[paddle error] paddle.linalg.matrix_rank(x=Tensor([4, 0],"float64"), tol=4.4, hermitian=False, ) 
 (InvalidArgument) The input Tensor x's shape[-1] should not be 0, but received 4, 0 now.
  [Hint: Expected cols != 0, but received cols:0 == 0:0.] (at ../paddle/phi/kernels/gpu/matrix_rank_tol_kernel.cu:645)


2025-05-21 22:07:54.635504 GPU 1 69608 test begin: paddle.linalg.matrix_rank(x=Tensor([4, 0],"float64"), tol=4.4, hermitian=True, )
[paddle error] paddle.linalg.matrix_rank(x=Tensor([4, 0],"float64"), tol=4.4, hermitian=True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:4 != cols:0.] (at ../paddle/phi/infermeta/unary.cc:2510)


2025-05-21 22:07:54.789200 GPU 1 69599 test begin: paddle.linalg.matrix_rank(x=Tensor([4, 0],"float64"), tol=Tensor([1],"float64"), hermitian=True, )
[paddle error] paddle.linalg.matrix_rank(x=Tensor([4, 0],"float64"), tol=Tensor([1],"float64"), hermitian=True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:4 != cols:0.] (at ../paddle/phi/infermeta/binary.cc:3146)


2025-05-21 22:07:54.791058 GPU 1 69596 test begin: paddle.linalg.multi_dot(list[Tensor([0],"float64"),Tensor([0],"float64"),], )
[paddle error] paddle.linalg.multi_dot(list[Tensor([0],"float64"),Tensor([0],"float64"),], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:07:54.792420 GPU 1 69612 test begin: paddle.linalg.multi_dot(list[Tensor([2, 10],"float64"),Tensor([10, 4],"float64"),Tensor([4, 0],"float64"),], )
[paddle error] paddle.linalg.multi_dot(list[Tensor([2, 10],"float64"),Tensor([10, 4],"float64"),Tensor([4, 0],"float64"),], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:07:54.792543 GPU 1 69611 test begin: paddle.linalg.multi_dot(list[Tensor([2, 4],"float64"),Tensor([4, 0],"float64"),], )
[paddle error] paddle.linalg.multi_dot(list[Tensor([2, 4],"float64"),Tensor([4, 0],"float64"),], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:07:54.793137 GPU 1 69603 test begin: paddle.linalg.multi_dot(list[Tensor([2, 8],"float16"),Tensor([8, 0],"float16"),], )
[paddle error] paddle.linalg.multi_dot(list[Tensor([2, 8],"float16"),Tensor([8, 0],"float16"),], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:426)


2025-05-21 22:07:54.793256 GPU 1 69615 test begin: paddle.linalg.multi_dot(list[Tensor([3, 4],"float64"),Tensor([4, 8],"float64"),Tensor([8, 0],"float64"),], )
[paddle error] paddle.linalg.multi_dot(list[Tensor([3, 4],"float64"),Tensor([4, 8],"float64"),Tensor([8, 0],"float64"),], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:07:54.793700 GPU 1 69606 test begin: paddle.linalg.multi_dot(list[Tensor([4],"float64"),Tensor([4, 0],"float64"),], )
[paddle error] paddle.linalg.multi_dot(list[Tensor([4],"float64"),Tensor([4, 0],"float64"),], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:07:54.793836 GPU 1 69610 test begin: paddle.linalg.multi_dot(list[Tensor([4],"float64"),Tensor([4, 3],"float64"),Tensor([3, 0],"float64"),], )
[paddle error] paddle.linalg.multi_dot(list[Tensor([4],"float64"),Tensor([4, 3],"float64"),Tensor([3, 0],"float64"),], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:07:54.794190 GPU 1 69600 test begin: paddle.linalg.multi_dot(list[Tensor([4],"float64"),Tensor([4, 3],"float64"),Tensor([3, 4],"float64"),Tensor([4, 0],"float64"),], )
[paddle error] paddle.linalg.multi_dot(list[Tensor([4],"float64"),Tensor([4, 3],"float64"),Tensor([3, 4],"float64"),Tensor([4, 0],"float64"),], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:07:54.949346 GPU 1 69609 test begin: paddle.linalg.multi_dot(list[Tensor([8, 6],"float64"),Tensor([6, 3],"float64"),Tensor([3, 4],"float64"),Tensor([4, 0],"float64"),], )
[paddle error] paddle.linalg.multi_dot(list[Tensor([8, 6],"float64"),Tensor([6, 3],"float64"),Tensor([3, 4],"float64"),Tensor([4, 0],"float64"),], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:07:54.949640 GPU 1 69598 test begin: paddle.linalg.norm(Tensor([0, 3, 4, 5],"float64"), p="fro", axis=list[1,2,], keepdim=False, )
[Pass] paddle.linalg.norm(Tensor([0, 3, 4, 5],"float64"), p="fro", axis=list[1,2,], keepdim=False, )

2025-05-21 22:07:54.953485 GPU 1 69602 test begin: paddle.linalg.norm(Tensor([0, 5, 5],"float32"), p="fro", axis=list[0,1,], keepdim=True, )
[Pass] paddle.linalg.norm(Tensor([0, 5, 5],"float32"), p="fro", axis=list[0,1,], keepdim=True, )

2025-05-21 22:07:54.962457 GPU 1 69613 test begin: paddle.linalg.norm(Tensor([2, 0, 4, 5],"float64"), p="fro", axis=list[1,2,], keepdim=False, )
[Pass] paddle.linalg.norm(Tensor([2, 0, 4, 5],"float64"), p="fro", axis=list[1,2,], keepdim=False, )

2025-05-21 22:07:54.969044 GPU 1 69599 test begin: paddle.linalg.norm(Tensor([2, 3, 0, 5],"float64"), p="fro", axis=list[1,2,], keepdim=False, )
[Pass] paddle.linalg.norm(Tensor([2, 3, 0, 5],"float64"), p="fro", axis=list[1,2,], keepdim=False, )

2025-05-21 22:07:54.969893 GPU 1 69616 test begin: paddle.linalg.norm(Tensor([2, 3, 4, 0],"float64"), p="fro", axis=list[1,2,], keepdim=False, )
[Pass] paddle.linalg.norm(Tensor([2, 3, 4, 0],"float64"), p="fro", axis=list[1,2,], keepdim=False, )

2025-05-21 22:07:54.969992 GPU 1 69601 test begin: paddle.linalg.norm(Tensor([5, 0, 5],"float32"), p="fro", axis=list[0,1,], keepdim=True, )
[Pass] paddle.linalg.norm(Tensor([5, 0, 5],"float32"), p="fro", axis=list[0,1,], keepdim=True, )

2025-05-21 22:07:54.970061 GPU 1 69605 test begin: paddle.linalg.norm(Tensor([5, 5, 0],"float32"), p="fro", axis=list[0,1,], keepdim=True, )
[Pass] paddle.linalg.norm(Tensor([5, 5, 0],"float32"), p="fro", axis=list[0,1,], keepdim=True, )

2025-05-21 22:07:54.970317 GPU 1 69608 test begin: paddle.linalg.norm(x=Tensor([0, 3, 3],"float64"), axis=list[1,2,], p=1, )
[paddle error] paddle.linalg.norm(x=Tensor([0, 3, 3],"float64"), axis=list[1,2,], p=1, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.064900 GPU 1 69598 test begin: paddle.linalg.norm(x=Tensor([0, 3, 3],"float64"), axis=list[1,2,], p=math.inf, )
[paddle error] paddle.linalg.norm(x=Tensor([0, 3, 3],"float64"), axis=list[1,2,], p=math.inf, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.126953 GPU 1 69607 test begin: paddle.linalg.norm(x=Tensor([2, 3, 0],"float64"), p=-math.inf, axis=list[0,1,], keepdim=False, )
[paddle error] paddle.linalg.norm(x=Tensor([2, 3, 0],"float64"), p=-math.inf, axis=list[0,1,], keepdim=False, ) 
 (InvalidArgument) Zero-size tensor to reduction operation minimum which has no identity.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/reduce_min_kernel.cc:30)


2025-05-21 22:07:55.127066 GPU 1 69604 test begin: paddle.linalg.norm(x=Tensor([2, 3, 0],"float64"), p=-math.inf, axis=list[0,1,], keepdim=True, )
[paddle error] paddle.linalg.norm(x=Tensor([2, 3, 0],"float64"), p=-math.inf, axis=list[0,1,], keepdim=True, ) 
 (InvalidArgument) Zero-size tensor to reduction operation minimum which has no identity.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/reduce_min_kernel.cc:30)


2025-05-21 22:07:55.127359 GPU 1 69619 test begin: paddle.linalg.norm(x=Tensor([2, 3, 0],"float64"), p=1, axis=list[0,1,], keepdim=False, )
[paddle error] paddle.linalg.norm(x=Tensor([2, 3, 0],"float64"), p=1, axis=list[0,1,], keepdim=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.128040 GPU 1 69621 test begin: paddle.linalg.norm(x=Tensor([2, 3, 0],"float64"), p=1, axis=list[0,1,], keepdim=True, )
[paddle error] paddle.linalg.norm(x=Tensor([2, 3, 0],"float64"), p=1, axis=list[0,1,], keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.132378 GPU 1 69618 test begin: paddle.linalg.norm(x=Tensor([2, 3, 0],"float64"), p=2, axis=list[0,1,], keepdim=False, )
[paddle error] paddle.linalg.norm(x=Tensor([2, 3, 0],"float64"), p=2, axis=list[0,1,], keepdim=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.133251 GPU 1 69614 test begin: paddle.linalg.norm(x=Tensor([2, 3, 0],"float64"), p=2, axis=list[0,1,], keepdim=True, )
[paddle error] paddle.linalg.norm(x=Tensor([2, 3, 0],"float64"), p=2, axis=list[0,1,], keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.133271 GPU 1 69611 test begin: paddle.linalg.norm(x=Tensor([2, 3, 0],"float64"), p=math.inf, axis=list[0,1,], keepdim=False, )
[paddle error] paddle.linalg.norm(x=Tensor([2, 3, 0],"float64"), p=math.inf, axis=list[0,1,], keepdim=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.134567 GPU 1 69612 test begin: paddle.linalg.norm(x=Tensor([2, 3, 0],"float64"), p=math.inf, axis=list[0,1,], keepdim=True, )
 ** On entry to DGEMM  parameter number 8 had an illegal value
[paddle error] paddle.linalg.norm(x=Tensor([2, 3, 0],"float64"), p=math.inf, axis=list[0,1,], keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.135009 GPU 1 69606 test begin: paddle.linalg.norm(x=Tensor([3, 0, 3],"float64"), axis=list[0,2,], p=1, )
 ** On entry to DGEMM  parameter number 8 had an illegal value
[paddle error] paddle.linalg.norm(x=Tensor([3, 0, 3],"float64"), axis=list[0,2,], p=1, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.135325 GPU 1 69615 test begin: paddle.linalg.norm(x=Tensor([3, 0, 3],"float64"), axis=list[0,2,], p=2, )
 ** On entry to DGEMM  parameter number 8 had an illegal value
[paddle error] paddle.linalg.norm(x=Tensor([3, 0, 3],"float64"), axis=list[0,2,], p=2, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.135862 GPU 1 69609 test begin: paddle.linalg.pinv(Tensor([0, 200, 300],"float64"), rcond=1e-15, hermitian=False, )
 ** On entry to DGEMM  parameter number 8 had an illegal value
[paddle error] paddle.linalg.pinv(Tensor([0, 200, 300],"float64"), rcond=1e-15, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.239684 GPU 1 69605 test begin: paddle.linalg.pinv(Tensor([0, 4, 5],"float64"), rcond=1e-15, hermitian=False, )
[paddle error] paddle.linalg.pinv(Tensor([0, 4, 5],"float64"), rcond=1e-15, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.242128 GPU 1 69598 test begin: paddle.linalg.pinv(Tensor([0, 4],"float64"), rcond=1e-15, hermitian=False, )
[paddle error] paddle.linalg.pinv(Tensor([0, 4],"float64"), rcond=1e-15, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.245317 GPU 1 69604 test begin: paddle.linalg.pinv(Tensor([0, 5, 5],"float64"), rcond=1e-10, hermitian=False, )
[paddle error] paddle.linalg.pinv(Tensor([0, 5, 5],"float64"), rcond=1e-10, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.252092 GPU 1 69608 test begin: paddle.linalg.pinv(Tensor([0, 5],"float64"), rcond=1e-15, hermitian=False, )
[paddle error] paddle.linalg.pinv(Tensor([0, 5],"float64"), rcond=1e-15, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.259628 GPU 1 69607 test begin: paddle.linalg.pinv(Tensor([0, 6, 5, 4],"float64"), rcond=1e-15, hermitian=False, )
[paddle error] paddle.linalg.pinv(Tensor([0, 6, 5, 4],"float64"), rcond=1e-15, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.282026 GPU 1 69619 test begin: paddle.linalg.pinv(Tensor([2, 0, 300],"float64"), rcond=1e-15, hermitian=False, )
[paddle error] paddle.linalg.pinv(Tensor([2, 0, 300],"float64"), rcond=1e-15, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.283664 GPU 1 69616 test begin: paddle.linalg.pinv(Tensor([2, 200, 0],"float64"), rcond=1e-15, hermitian=False, )
[paddle error] paddle.linalg.pinv(Tensor([2, 200, 0],"float64"), rcond=1e-15, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.288973 GPU 1 69596 test begin: paddle.linalg.pinv(Tensor([3, 0, 5, 4],"float64"), rcond=1e-15, hermitian=False, )
[paddle error] paddle.linalg.pinv(Tensor([3, 0, 5, 4],"float64"), rcond=1e-15, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.290336 GPU 1 69610 test begin: paddle.linalg.pinv(Tensor([3, 0, 5],"float64"), rcond=1e-10, hermitian=False, )
[paddle error] paddle.linalg.pinv(Tensor([3, 0, 5],"float64"), rcond=1e-10, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.292104 GPU 1 69603 test begin: paddle.linalg.pinv(Tensor([3, 0, 5],"float64"), rcond=1e-15, hermitian=False, )
 ** On entry to GEMM_EX  parameter number 9 had an illegal value
[paddle error] paddle.linalg.pinv(Tensor([3, 0, 5],"float64"), rcond=1e-15, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.293767 GPU 1 69599 test begin: paddle.linalg.pinv(Tensor([3, 4, 0],"float64"), rcond=1e-15, hermitian=False, )
[paddle error] paddle.linalg.pinv(Tensor([3, 4, 0],"float64"), rcond=1e-15, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.294111 GPU 1 69613 test begin: paddle.linalg.pinv(Tensor([3, 5, 0],"float64"), rcond=1e-10, hermitian=False, )
[paddle error] paddle.linalg.pinv(Tensor([3, 5, 0],"float64"), rcond=1e-10, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.296258 GPU 1 69602 test begin: paddle.linalg.pinv(Tensor([3, 6, 0, 4],"float64"), rcond=1e-15, hermitian=False, )
[paddle error] paddle.linalg.pinv(Tensor([3, 6, 0, 4],"float64"), rcond=1e-15, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.388286 GPU 1 69611 test begin: paddle.linalg.pinv(Tensor([3, 6, 5, 0],"float64"), rcond=1e-15, hermitian=False, )
[paddle error] paddle.linalg.pinv(Tensor([3, 6, 5, 0],"float64"), rcond=1e-15, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.405147 GPU 1 69621 test begin: paddle.linalg.pinv(Tensor([4, 0],"float64"), rcond=1e-15, hermitian=False, )
[paddle error] paddle.linalg.pinv(Tensor([4, 0],"float64"), rcond=1e-15, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.405920 GPU 1 69618 test begin: paddle.linalg.pinv(Tensor([5, 0],"float64"), rcond=1e-15, hermitian=False, )
[paddle error] paddle.linalg.pinv(Tensor([5, 0],"float64"), rcond=1e-15, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.457018 GPU 1 69601 test begin: paddle.linalg.pinv(x=Tensor([0, 2, 2],"float64"), rcond=5, hermitian=True, )
[paddle error] paddle.linalg.pinv(x=Tensor([0, 2, 2],"float64"), rcond=5, hermitian=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.538393 GPU 1 69614 test begin: paddle.linalg.pinv(x=Tensor([0, 4, 40],"float64"), )
[paddle error] paddle.linalg.pinv(x=Tensor([0, 4, 40],"float64"), ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.567427 GPU 1 69606 test begin: paddle.linalg.pinv(x=Tensor([0, 4, 40],"float64"), rcond=0.5, )
[paddle error] paddle.linalg.pinv(x=Tensor([0, 4, 40],"float64"), rcond=0.5, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.567522 GPU 1 69612 test begin: paddle.linalg.pinv(x=Tensor([0, 40],"float64"), )
[paddle error] paddle.linalg.pinv(x=Tensor([0, 40],"float64"), ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.577485 GPU 1 69615 test begin: paddle.linalg.pinv(x=Tensor([0, 4],"float32"), )
[paddle error] paddle.linalg.pinv(x=Tensor([0, 4],"float32"), ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.629907 GPU 1 69607 test begin: paddle.linalg.pinv(x=Tensor([2, 0, 40],"float64"), )
[paddle error] paddle.linalg.pinv(x=Tensor([2, 0, 40],"float64"), ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.630464 GPU 1 69608 test begin: paddle.linalg.pinv(x=Tensor([2, 0, 40],"float64"), rcond=0.5, )
[paddle error] paddle.linalg.pinv(x=Tensor([2, 0, 40],"float64"), rcond=0.5, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.630537 GPU 1 69604 test begin: paddle.linalg.pinv(x=Tensor([2, 0],"float64"), )
[paddle error] paddle.linalg.pinv(x=Tensor([2, 0],"float64"), ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.630643 GPU 1 69605 test begin: paddle.linalg.pinv(x=Tensor([2, 4, 0],"float64"), )
[paddle error] paddle.linalg.pinv(x=Tensor([2, 4, 0],"float64"), ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.630993 GPU 1 69598 test begin: paddle.linalg.pinv(x=Tensor([2, 4, 0],"float64"), rcond=0.5, )
[paddle error] paddle.linalg.pinv(x=Tensor([2, 4, 0],"float64"), rcond=0.5, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.631916 GPU 1 69609 test begin: paddle.linalg.pinv(x=Tensor([3, 0],"float32"), )
[paddle error] paddle.linalg.pinv(x=Tensor([3, 0],"float32"), ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.631984 GPU 1 69596 test begin: paddle.linalg.pinv(x=Tensor([4, 0, 2],"float64"), rcond=5, hermitian=True, )
[paddle error] paddle.linalg.pinv(x=Tensor([4, 0, 2],"float64"), rcond=5, hermitian=True, ) 
 (InvalidArgument) Eigh op is designed for square matrix, consequentlyinner-most 2 dimensions of Input(X) should be symmetric.But received X's shape[-2] = 0 and shape[-1] = 2.
  [Hint: Expected input_dim[rank - 2] == input_dim[rank - 1], but received input_dim[rank - 2]:0 != input_dim[rank - 1]:2.] (at ../paddle/phi/infermeta/unary.cc:1151)


2025-05-21 22:07:55.632105 GPU 1 69610 test begin: paddle.linalg.pinv(x=Tensor([4, 2, 0],"float64"), rcond=5, hermitian=True, )
[paddle error] paddle.linalg.pinv(x=Tensor([4, 2, 0],"float64"), rcond=5, hermitian=True, ) 
 (InvalidArgument) Eigh op is designed for square matrix, consequentlyinner-most 2 dimensions of Input(X) should be symmetric.But received X's shape[-2] = 2 and shape[-1] = 0.
  [Hint: Expected input_dim[rank - 2] == input_dim[rank - 1], but received input_dim[rank - 2]:2 != input_dim[rank - 1]:0.] (at ../paddle/phi/infermeta/unary.cc:1151)


2025-05-21 22:07:55.632507 GPU 1 69616 test begin: paddle.linalg.solve(Tensor([0, 3, 3],"float64"), Tensor([0, 3, 3],"float64"), )
W0521 22:07:55.773604 69616 backward.cc:437] While running Node (SolveGradNode) raises an EnforceNotMet exception
[paddle error] paddle.linalg.solve(Tensor([0, 3, 3],"float64"), Tensor([0, 3, 3],"float64"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:55.632730 GPU 1 69619 test begin: paddle.linalg.solve(Tensor([0, 3, 3],"float64"), Tensor([0, 3, 3],"float64"), left=False, )
W0521 22:07:55.785884 69619 backward.cc:437] While running Node (SolveGradNode) raises an EnforceNotMet exception
[paddle error] paddle.linalg.solve(Tensor([0, 3, 3],"float64"), Tensor([0, 3, 3],"float64"), left=False, ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:55.636811 GPU 1 69601 test begin: paddle.linalg.solve(Tensor([0, 3, 3],"float64"), Tensor([1, 3, 3],"float64"), )
W0521 22:07:55.854692 69601 backward.cc:437] While running Node (SolveGradNode) raises an EnforceNotMet exception
[paddle error] paddle.linalg.solve(Tensor([0, 3, 3],"float64"), Tensor([1, 3, 3],"float64"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:55.641031 GPU 1 69599 test begin: paddle.linalg.solve(Tensor([0, 3, 3],"float64"), Tensor([1, 3, 3],"float64"), left=False, )
W0521 22:07:55.808534 69599 backward.cc:437] While running Node (SolveGradNode) raises an EnforceNotMet exception
[paddle error] paddle.linalg.solve(Tensor([0, 3, 3],"float64"), Tensor([1, 3, 3],"float64"), left=False, ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:55.731620 GPU 1 69611 test begin: paddle.linalg.solve(Tensor([10, 10],"float32"), Tensor([0, 10],"float32"), left=False, )
 ** On entry to DGEMM  parameter number 8 had an illegal value
 ** On entry to DGEMM  parameter number 8 had an illegal value
W0521 22:07:55.943020 69611 backward.cc:437] While running Node (SolveGradNode) raises an EnforceNotMet exception
[paddle error] paddle.linalg.solve(Tensor([10, 10],"float32"), Tensor([0, 10],"float32"), left=False, ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:55.749428 GPU 1 69612 test begin: paddle.linalg.solve(Tensor([10, 10],"float32"), Tensor([10, 0],"float32"), )
W0521 22:07:55.869865 69612 backward.cc:437] While running Node (SolveGradNode) raises an EnforceNotMet exception
[paddle error] paddle.linalg.solve(Tensor([10, 10],"float32"), Tensor([10, 0],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:55.752743 GPU 1 69615 test begin: paddle.linalg.solve(Tensor([10, 10],"float64"), Tensor([0, 10],"float64"), left=False, )
[paddle error] paddle.linalg.solve(Tensor([10, 10],"float64"), Tensor([0, 10],"float64"), left=False, ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)

W0521 22:07:55.904454 69615 backward.cc:437] While running Node (SolveGradNode) raises an EnforceNotMet exception

2025-05-21 22:07:55.752933 GPU 1 69605 test begin: paddle.linalg.solve(Tensor([10, 10],"float64"), Tensor([10, 0],"float64"), )
 ** On entry to DGEMM  parameter number 8 had an illegal value
 ** On entry to SgemmStridedBatched parameter number 8 had an illegal value
 ** On entry to DGEMM  parameter number 8 had an illegal value
W0521 22:07:56.125308 69605 backward.cc:437] While running Node (SolveGradNode) raises an EnforceNotMet exception
[paddle error] paddle.linalg.solve(Tensor([10, 10],"float64"), Tensor([10, 0],"float64"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:55.758436 GPU 1 69609 test begin: paddle.linalg.solve(Tensor([2, 3, 3],"float64"), Tensor([1, 0, 3],"float64"), left=False, )
W0521 22:07:55.888257 69609 backward.cc:437] While running Node (SolveGradNode) raises an EnforceNotMet exception
[paddle error] paddle.linalg.solve(Tensor([2, 3, 3],"float64"), Tensor([1, 0, 3],"float64"), left=False, ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:55.758482 GPU 1 69604 test begin: paddle.linalg.solve(Tensor([2, 3, 3],"float64"), Tensor([1, 3, 0],"float64"), )
W0521 22:07:56.142191 69604 backward.cc:437] While running Node (SolveGradNode) raises an EnforceNotMet exception
[paddle error] paddle.linalg.solve(Tensor([2, 3, 3],"float64"), Tensor([1, 3, 0],"float64"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:55.765633 GPU 1 69618 test begin: paddle.linalg.solve(x=Tensor([0, 14, 14],"float64"), y=Tensor([0, 14, 2],"float64"), )
W0521 22:07:55.888325 69618 backward.cc:437] While running Node (SolveGradNode) raises an EnforceNotMet exception
[paddle error] paddle.linalg.solve(x=Tensor([0, 14, 14],"float64"), y=Tensor([0, 14, 2],"float64"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:55.766379 GPU 1 69614 test begin: paddle.linalg.solve(x=Tensor([14, 14],"float64"), y=Tensor([14, 0],"float64"), )
W0521 22:07:55.890250 69614 backward.cc:437] While running Node (SolveGradNode) raises an EnforceNotMet exception
[paddle error] paddle.linalg.solve(x=Tensor([14, 14],"float64"), y=Tensor([14, 0],"float64"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/gpu/expand_as_kernel.cu:46)


2025-05-21 22:07:55.774424 GPU 1 69616 test begin: paddle.linalg.solve(x=Tensor([4, 14, 14],"float64"), y=Tensor([4, 14, 0],"float64"), )
[torch error] paddle.linalg.solve(x=Tensor([4, 14, 14],"float64"), y=Tensor([4, 14, 0],"float64"), )
Traceback (most recent call last):
  File "/root/paddlejob/PaddleAPITest-dev/tester/accuracy.py", line 57, in test
    if not self.gen_torch_input():
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/root/paddlejob/PaddleAPITest-dev/tester/base.py", line 766, in gen_torch_input
    self.torch_kwargs[key] = arg_config.get_torch_tensor(self.api_config)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/paddlejob/PaddleAPITest-dev/tester/api_config/config_analyzer.py", line 1804, in get_torch_tensor
    self.torch_tensor = torch.tensor(
                        ^^^^^^^^^^^^^
  File "/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-05-21 22:07:55.786673 GPU 1 69619 test begin: paddle.linalg.svd_lowrank(Tensor([0, 17],"float64"), q=4, )
[torch error] paddle.linalg.svd_lowrank(Tensor([0, 17],"float64"), q=4, )
Traceback (most recent call last):
  File "/root/paddlejob/PaddleAPITest-dev/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/_lowrank.py", line 147, in svd_lowrank
    return _svd_lowrank(A, q=q, niter=niter, M=M)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/_lowrank.py", line 170, in _svd_lowrank
    Q = get_approximate_basis(A, q, niter=niter, M=M)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/_lowrank.py", line 70, in get_approximate_basis
    X = matmul(A, R)
        ^^^^^^^^^^^^
  File "/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/_linalg_utils.py", line 42, in matmul
    return torch.matmul(A, B)
           ^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


2025-05-21 22:07:55.790036 GPU 1 69610 test begin: paddle.linalg.svd_lowrank(Tensor([0, 4, 17],"float64"), q=4, )
[paddle error] paddle.linalg.svd_lowrank(Tensor([0, 4, 17],"float64"), q=4, ) 
 ([0, 4, 17, 4, 17, 4, 17, 4], 4)

2025-05-21 22:07:55.804630 GPU 1 69596 test begin: paddle.linalg.svd_lowrank(Tensor([1, 0, 17],"float64"), q=4, )
[paddle error] paddle.linalg.svd_lowrank(Tensor([1, 0, 17],"float64"), q=4, ) 
 q(=4) must be non-negative integer and not greater than min(m, n)=0

2025-05-21 22:07:55.807963 GPU 1 69607 test begin: paddle.linalg.svd_lowrank(Tensor([1, 4, 0],"float64"), q=4, )
[paddle error] paddle.linalg.svd_lowrank(Tensor([1, 4, 0],"float64"), q=4, ) 
 q(=4) must be non-negative integer and not greater than min(m, n)=0

2025-05-21 22:07:55.808051 GPU 1 69606 test begin: paddle.linalg.svd_lowrank(Tensor([4, 0],"float64"), q=4, )
[paddle error] paddle.linalg.svd_lowrank(Tensor([4, 0],"float64"), q=4, ) 
 q(=4) must be non-negative integer and not greater than min(m, n)=0

2025-05-21 22:07:55.808603 GPU 1 69621 test begin: paddle.linalg.vector_norm(x=Tensor([2, 3, 0],"float64"), p=math.inf, axis=list[0,1,], keepdim=False, )
[paddle error] paddle.linalg.vector_norm(x=Tensor([2, 3, 0],"float64"), p=math.inf, axis=list[0,1,], keepdim=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:55.809369 GPU 1 69599 test begin: paddle.linalg.vector_norm(x=Tensor([2, 3, 0],"float64"), p=math.inf, axis=list[0,1,], keepdim=True, )
[torch error] paddle.linalg.vector_norm(x=Tensor([2, 3, 0],"float64"), p=math.inf, axis=list[0,1,], keepdim=True, )
Traceback (most recent call last):
  File "/root/paddlejob/PaddleAPITest-dev/tester/accuracy.py", line 113, in test
    paddle.base.core.eager._for_test_check_cuda_error()
OSError: (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:55.828617 GPU 1 69602 test begin: paddle.logcumsumexp(Tensor([0, 10, 10],"float32"), axis=-1, )
[cuda error] paddle.logcumsumexp(Tensor([0, 10, 10],"float32"), axis=-1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:55.839051 GPU 1 69608 test begin: paddle.logcumsumexp(Tensor([0, 10, 10],"float32"), axis=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_logcumsumexp(_object*, _object*, _object*)
1   logcumsumexp_ad_func(paddle::Tensor const&, int, bool, bool, bool)
2   paddle::experimental::logcumsumexp(paddle::Tensor const&, int, bool, bool, bool)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836475 (unix time) try "date -d @1747836475" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f58c9a7cd3a) received by PID 69608 (TID 0x7f5970260740) from PID 18446744072797801786 ***]


2025-05-21 22:07:55.854351 GPU 1 69603 test begin: paddle.logcumsumexp(Tensor([0, 4],"float32"), axis=-1, )
[cuda error] paddle.logcumsumexp(Tensor([0, 4],"float32"), axis=-1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:55.854701 GPU 1 69598 test begin: paddle.logcumsumexp(Tensor([0, 4],"float32"), axis=-2, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_logcumsumexp(_object*, _object*, _object*)
1   logcumsumexp_ad_func(paddle::Tensor const&, int, bool, bool, bool)
2   paddle::experimental::logcumsumexp(paddle::Tensor const&, int, bool, bool, bool)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836475 (unix time) try "date -d @1747836475" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fdce7521d3a) received by PID 69598 (TID 0x7fdd8dd05740) from PID 18446744073295502650 ***]


2025-05-21 22:07:55.855663 GPU 1 69601 test begin: paddle.logcumsumexp(Tensor([0, 4],"float32"), axis=0, )
[torch error] paddle.logcumsumexp(Tensor([0, 4],"float32"), axis=0, )
Traceback (most recent call last):
  File "/root/paddlejob/PaddleAPITest-dev/tester/accuracy.py", line 113, in test
    paddle.base.core.eager._for_test_check_cuda_error()
OSError: (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:55.870677 GPU 1 69612 test begin: paddle.logcumsumexp(Tensor([10, 0, 10],"float32"), axis=-1, )
[cuda error] paddle.logcumsumexp(Tensor([10, 0, 10],"float32"), axis=-1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:55.889139 GPU 1 69618 test begin: paddle.logcumsumexp(Tensor([10, 0, 10],"float32"), axis=0, )
[torch error] paddle.logcumsumexp(Tensor([10, 0, 10],"float32"), axis=0, )
Traceback (most recent call last):
  File "/root/paddlejob/PaddleAPITest-dev/tester/accuracy.py", line 113, in test
    paddle.base.core.eager._for_test_check_cuda_error()
OSError: (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:55.889248 GPU 1 69609 test begin: paddle.logcumsumexp(Tensor([10, 10, 0],"float32"), axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_logcumsumexp(_object*, _object*, _object*)
1   logcumsumexp_ad_func(paddle::Tensor const&, int, bool, bool, bool)
2   paddle::experimental::logcumsumexp(paddle::Tensor const&, int, bool, bool, bool)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836476 (unix time) try "date -d @1747836476" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f470dee6146) received by PID 69609 (TID 0x7f47b46c9740) from PID 233726278 ***]


2025-05-21 22:07:55.891129 GPU 1 69613 test begin: paddle.logcumsumexp(Tensor([10, 10, 0],"float32"), axis=0, )
[cuda error] paddle.logcumsumexp(Tensor([10, 10, 0],"float32"), axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:55.891307 GPU 1 69614 test begin: paddle.logcumsumexp(Tensor([3, 0],"float32"), axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_logcumsumexp(_object*, _object*, _object*)
1   logcumsumexp_ad_func(paddle::Tensor const&, int, bool, bool, bool)
2   paddle::experimental::logcumsumexp(paddle::Tensor const&, int, bool, bool, bool)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836476 (unix time) try "date -d @1747836476" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f77fd67c146) received by PID 69614 (TID 0x7f78a3e5f740) from PID 18446744073666019654 ***]


2025-05-21 22:07:55.904750 GPU 1 69600 test begin: paddle.logcumsumexp(Tensor([3, 0],"float32"), axis=-2, )
 ** On entry to DGEMM  parameter number 8 had an illegal value
[cuda error] paddle.logcumsumexp(Tensor([3, 0],"float32"), axis=-2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:55.905410 GPU 1 69615 test begin: paddle.logcumsumexp(Tensor([3, 0],"float32"), axis=0, )
[cuda error] paddle.logcumsumexp(Tensor([3, 0],"float32"), axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:55.926055 GPU 1 69606 test begin: paddle.logsumexp(Tensor([0, 16, 4, 8],"float32"), axis=3, keepdim=True, )
[paddle error] paddle.logsumexp(Tensor([0, 16, 4, 8],"float32"), axis=3, keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:55.929471 GPU 1 69607 test begin: paddle.logsumexp(Tensor([0, 200, 40],"float32"), axis=-1, keepdim=False, )
[paddle error] paddle.logsumexp(Tensor([0, 200, 40],"float32"), axis=-1, keepdim=False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:55.943863 GPU 1 69611 test begin: paddle.logsumexp(Tensor([0, 200, 40],"float32"), axis=list[0,2,], keepdim=False, )
[paddle error] paddle.logsumexp(Tensor([0, 200, 40],"float32"), axis=list[0,2,], keepdim=False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:55.988148 GPU 1 69612 test begin: paddle.logsumexp(Tensor([0, 3, 4, 5],"float16"), list[-1,], False, )
[paddle error] paddle.logsumexp(Tensor([0, 3, 4, 5],"float16"), list[-1,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.016178 GPU 1 69603 test begin: paddle.logsumexp(Tensor([0, 3, 4, 5],"float32"), 2, False, )
[paddle error] paddle.logsumexp(Tensor([0, 3, 4, 5],"float32"), 2, False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.020609 GPU 1 69615 test begin: paddle.logsumexp(Tensor([0, 3, 4, 5],"float32"), list[-1,], False, )
[paddle error] paddle.logsumexp(Tensor([0, 3, 4, 5],"float32"), list[-1,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.026122 GPU 1 69621 test begin: paddle.logsumexp(Tensor([0, 3, 4, 5],"float32"), list[2,-3,], False, )
[paddle error] paddle.logsumexp(Tensor([0, 3, 4, 5],"float32"), list[2,-3,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.039150 GPU 1 69602 test begin: paddle.logsumexp(Tensor([0, 3, 4, 5],"float32"), tuple(0,1,-1,), False, )
[paddle error] paddle.logsumexp(Tensor([0, 3, 4, 5],"float32"), tuple(0,1,-1,), False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.043058 GPU 1 69606 test begin: paddle.logsumexp(Tensor([0, 3, 4, 5],"float64"), list[-1,], True, )
[paddle error] paddle.logsumexp(Tensor([0, 3, 4, 5],"float64"), list[-1,], True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.052348 GPU 1 69600 test begin: paddle.logsumexp(Tensor([0, 3, 4, 5],"float64"), list[0,-1,], False, )
[paddle error] paddle.logsumexp(Tensor([0, 3, 4, 5],"float64"), list[0,-1,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.052552 GPU 1 69607 test begin: paddle.logsumexp(Tensor([0, 3, 4, 5],"float64"), list[0,1,2,3,], False, )
[paddle error] paddle.logsumexp(Tensor([0, 3, 4, 5],"float64"), list[0,1,2,3,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.126463 GPU 1 69605 test begin: paddle.logsumexp(Tensor([0, 4, 16, 1],"float32"), axis=1, keepdim=True, )
[paddle error] paddle.logsumexp(Tensor([0, 4, 16, 1],"float32"), axis=1, keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.143085 GPU 1 69604 test begin: paddle.logsumexp(Tensor([0, 5, 6],"float64"), list[-1,], False, )
[paddle error] paddle.logsumexp(Tensor([0, 5, 6],"float64"), list[-1,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.146942 GPU 1 69596 test begin: paddle.logsumexp(Tensor([0, 60],"float32"), axis=1, )
[paddle error] paddle.logsumexp(Tensor([0, 60],"float32"), axis=1, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.147924 GPU 1 69612 test begin: paddle.logsumexp(Tensor([0, 8, 4, 8],"float32"), axis=3, keepdim=True, )
[paddle error] paddle.logsumexp(Tensor([0, 8, 4, 8],"float32"), axis=3, keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.149719 GPU 1 69610 test begin: paddle.logsumexp(Tensor([0],"float32"), axis=0, )
[paddle error] paddle.logsumexp(Tensor([0],"float32"), axis=0, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.165382 GPU 1 69629 test begin: paddle.logsumexp(Tensor([10, 0],"float32"), axis=1, )
[paddle error] paddle.logsumexp(Tensor([10, 0],"float32"), axis=1, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.166349 GPU 1 69606 test begin: paddle.logsumexp(Tensor([2, 0, 4, 5],"float16"), list[-1,], False, )
[paddle error] paddle.logsumexp(Tensor([2, 0, 4, 5],"float16"), list[-1,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.181649 GPU 1 69613 test begin: paddle.logsumexp(Tensor([2, 0, 4, 5],"float32"), 2, False, )
[paddle error] paddle.logsumexp(Tensor([2, 0, 4, 5],"float32"), 2, False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.184897 GPU 1 69607 test begin: paddle.logsumexp(Tensor([2, 0, 4, 5],"float32"), list[-1,], False, )
[paddle error] paddle.logsumexp(Tensor([2, 0, 4, 5],"float32"), list[-1,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.188878 GPU 1 69621 test begin: paddle.logsumexp(Tensor([2, 0, 4, 5],"float32"), list[2,-3,], False, )
[paddle error] paddle.logsumexp(Tensor([2, 0, 4, 5],"float32"), list[2,-3,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.193365 GPU 1 69600 test begin: paddle.logsumexp(Tensor([2, 0, 4, 5],"float32"), tuple(0,1,-1,), False, )
[paddle error] paddle.logsumexp(Tensor([2, 0, 4, 5],"float32"), tuple(0,1,-1,), False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.198352 GPU 1 69611 test begin: paddle.logsumexp(Tensor([2, 0, 4, 5],"float64"), list[-1,], True, )
[paddle error] paddle.logsumexp(Tensor([2, 0, 4, 5],"float64"), list[-1,], True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.206544 GPU 1 69603 test begin: paddle.logsumexp(Tensor([2, 0, 4, 5],"float64"), list[0,-1,], False, )
[paddle error] paddle.logsumexp(Tensor([2, 0, 4, 5],"float64"), list[0,-1,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.208268 GPU 1 69602 test begin: paddle.logsumexp(Tensor([2, 0, 4, 5],"float64"), list[0,1,2,3,], False, )
[paddle error] paddle.logsumexp(Tensor([2, 0, 4, 5],"float64"), list[0,1,2,3,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.212246 GPU 1 69615 test begin: paddle.logsumexp(Tensor([2, 0],"float32"), axis=1, )
[paddle error] paddle.logsumexp(Tensor([2, 0],"float32"), axis=1, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.269985 GPU 1 69596 test begin: paddle.logsumexp(Tensor([2, 3, 0, 5],"float16"), list[-1,], False, )
[paddle error] paddle.logsumexp(Tensor([2, 3, 0, 5],"float16"), list[-1,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.274103 GPU 1 69610 test begin: paddle.logsumexp(Tensor([2, 3, 0, 5],"float32"), 2, False, )
[paddle error] paddle.logsumexp(Tensor([2, 3, 0, 5],"float32"), 2, False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.283809 GPU 1 69605 test begin: paddle.logsumexp(Tensor([2, 3, 0, 5],"float32"), list[-1,], False, )
[paddle error] paddle.logsumexp(Tensor([2, 3, 0, 5],"float32"), list[-1,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.287006 GPU 1 69606 test begin: paddle.logsumexp(Tensor([2, 3, 0, 5],"float32"), list[2,-3,], False, )
[paddle error] paddle.logsumexp(Tensor([2, 3, 0, 5],"float32"), list[2,-3,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.299083 GPU 1 69621 test begin: paddle.logsumexp(Tensor([2, 3, 0, 5],"float32"), tuple(0,1,-1,), False, )
[paddle error] paddle.logsumexp(Tensor([2, 3, 0, 5],"float32"), tuple(0,1,-1,), False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.305105 GPU 1 69600 test begin: paddle.logsumexp(Tensor([2, 3, 0, 5],"float64"), list[-1,], True, )
[paddle error] paddle.logsumexp(Tensor([2, 3, 0, 5],"float64"), list[-1,], True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.311054 GPU 1 69607 test begin: paddle.logsumexp(Tensor([2, 3, 0, 5],"float64"), list[0,-1,], False, )
[paddle error] paddle.logsumexp(Tensor([2, 3, 0, 5],"float64"), list[0,-1,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.330491 GPU 1 69602 test begin: paddle.logsumexp(Tensor([2, 3, 0, 5],"float64"), list[0,1,2,3,], False, )
[paddle error] paddle.logsumexp(Tensor([2, 3, 0, 5],"float64"), list[0,1,2,3,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.336004 GPU 1 69617 test begin: paddle.logsumexp(Tensor([2, 3, 4, 0],"float16"), list[-1,], False, )
[paddle error] paddle.logsumexp(Tensor([2, 3, 4, 0],"float16"), list[-1,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.336677 GPU 1 69604 test begin: paddle.logsumexp(Tensor([2, 3, 4, 0],"float32"), 2, False, )
[paddle error] paddle.logsumexp(Tensor([2, 3, 4, 0],"float32"), 2, False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.339643 GPU 1 69611 test begin: paddle.logsumexp(Tensor([2, 3, 4, 0],"float32"), list[-1,], False, )
[paddle error] paddle.logsumexp(Tensor([2, 3, 4, 0],"float32"), list[-1,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.358780 GPU 1 69615 test begin: paddle.logsumexp(Tensor([2, 3, 4, 0],"float32"), list[2,-3,], False, )
[paddle error] paddle.logsumexp(Tensor([2, 3, 4, 0],"float32"), list[2,-3,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.390542 GPU 1 69612 test begin: paddle.logsumexp(Tensor([2, 3, 4, 0],"float32"), tuple(0,1,-1,), False, )
[paddle error] paddle.logsumexp(Tensor([2, 3, 4, 0],"float32"), tuple(0,1,-1,), False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.394124 GPU 1 69596 test begin: paddle.logsumexp(Tensor([2, 3, 4, 0],"float64"), list[-1,], True, )
[paddle error] paddle.logsumexp(Tensor([2, 3, 4, 0],"float64"), list[-1,], True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.396885 GPU 1 69610 test begin: paddle.logsumexp(Tensor([2, 3, 4, 0],"float64"), list[0,-1,], False, )
[paddle error] paddle.logsumexp(Tensor([2, 3, 4, 0],"float64"), list[0,-1,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.398771 GPU 1 69603 test begin: paddle.logsumexp(Tensor([2, 3, 4, 0],"float64"), list[0,1,2,3,], False, )
[paddle error] paddle.logsumexp(Tensor([2, 3, 4, 0],"float64"), list[0,1,2,3,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.407350 GPU 1 69606 test begin: paddle.logsumexp(Tensor([26, 0, 16, 1],"float32"), axis=1, keepdim=True, )
[paddle error] paddle.logsumexp(Tensor([26, 0, 16, 1],"float32"), axis=1, keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.429859 GPU 1 69607 test begin: paddle.logsumexp(Tensor([26, 0, 4, 8],"float32"), axis=3, keepdim=True, )
[paddle error] paddle.logsumexp(Tensor([26, 0, 4, 8],"float32"), axis=3, keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.436533 GPU 1 69600 test begin: paddle.logsumexp(Tensor([26, 16, 0, 8],"float32"), axis=3, keepdim=True, )
[paddle error] paddle.logsumexp(Tensor([26, 16, 0, 8],"float32"), axis=3, keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.438080 GPU 1 69605 test begin: paddle.logsumexp(Tensor([26, 16, 4, 0],"float32"), axis=3, keepdim=True, )
[paddle error] paddle.logsumexp(Tensor([26, 16, 4, 0],"float32"), axis=3, keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.439429 GPU 1 69621 test begin: paddle.logsumexp(Tensor([26, 4, 0, 1],"float32"), axis=1, keepdim=True, )
[paddle error] paddle.logsumexp(Tensor([26, 4, 0, 1],"float32"), axis=1, keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.442552 GPU 1 69613 test begin: paddle.logsumexp(Tensor([26, 4, 16, 0],"float32"), axis=1, keepdim=True, )
[paddle error] paddle.logsumexp(Tensor([26, 4, 16, 0],"float32"), axis=1, keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.461356 GPU 1 69611 test begin: paddle.logsumexp(Tensor([26, 8, 0, 8],"float32"), axis=3, keepdim=True, )
[paddle error] paddle.logsumexp(Tensor([26, 8, 0, 8],"float32"), axis=3, keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.461463 GPU 1 69617 test begin: paddle.logsumexp(Tensor([26, 8, 4, 0],"float32"), axis=3, keepdim=True, )
[paddle error] paddle.logsumexp(Tensor([26, 8, 4, 0],"float32"), axis=3, keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.478486 GPU 1 69602 test begin: paddle.logsumexp(Tensor([30, 0, 40],"float32"), axis=-1, keepdim=False, )
[paddle error] paddle.logsumexp(Tensor([30, 0, 40],"float32"), axis=-1, keepdim=False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.480577 GPU 1 69615 test begin: paddle.logsumexp(Tensor([30, 0, 40],"float32"), axis=list[0,2,], keepdim=False, )
[paddle error] paddle.logsumexp(Tensor([30, 0, 40],"float32"), axis=list[0,2,], keepdim=False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.484055 GPU 1 69604 test begin: paddle.logsumexp(Tensor([30, 200, 0],"float32"), axis=-1, keepdim=False, )
[paddle error] paddle.logsumexp(Tensor([30, 200, 0],"float32"), axis=-1, keepdim=False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.524286 GPU 1 69596 test begin: paddle.logsumexp(Tensor([30, 200, 0],"float32"), axis=list[0,2,], keepdim=False, )
[paddle error] paddle.logsumexp(Tensor([30, 200, 0],"float32"), axis=list[0,2,], keepdim=False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.525497 GPU 1 69629 test begin: paddle.logsumexp(Tensor([4, 0, 6],"float64"), list[-1,], False, )
[paddle error] paddle.logsumexp(Tensor([4, 0, 6],"float64"), list[-1,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.526177 GPU 1 69606 test begin: paddle.logsumexp(Tensor([4, 5, 0],"float64"), list[-1,], False, )
[paddle error] paddle.logsumexp(Tensor([4, 5, 0],"float64"), list[-1,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.549513 GPU 1 69607 test begin: paddle.logsumexp(x=Tensor([0, 3, 2],"float32"), axis=2, )
[paddle error] paddle.logsumexp(x=Tensor([0, 3, 2],"float32"), axis=2, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.577666 GPU 1 69612 test begin: paddle.logsumexp(x=Tensor([0, 3, 2],"float64"), axis=0, keepdim=True, )
[paddle error] paddle.logsumexp(x=Tensor([0, 3, 2],"float64"), axis=0, keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.577792 GPU 1 69610 test begin: paddle.logsumexp(x=Tensor([0, 3, 2],"float64"), axis=2, )
[paddle error] paddle.logsumexp(x=Tensor([0, 3, 2],"float64"), axis=2, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.579639 GPU 1 69611 test begin: paddle.logsumexp(x=Tensor([0, 3, 2],"float64"), axis=list[0,1,], )
[paddle error] paddle.logsumexp(x=Tensor([0, 3, 2],"float64"), axis=list[0,1,], ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.588533 GPU 1 69605 test begin: paddle.logsumexp(x=Tensor([0, 3, 2],"float64"), axis=list[0,1,], keepdim=True, )
[paddle error] paddle.logsumexp(x=Tensor([0, 3, 2],"float64"), axis=list[0,1,], keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.589301 GPU 1 69617 test begin: paddle.logsumexp(x=Tensor([2, 0, 2],"float32"), axis=2, )
[paddle error] paddle.logsumexp(x=Tensor([2, 0, 2],"float32"), axis=2, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.589875 GPU 1 69600 test begin: paddle.logsumexp(x=Tensor([2, 0, 2],"float64"), axis=0, keepdim=True, )
[paddle error] paddle.logsumexp(x=Tensor([2, 0, 2],"float64"), axis=0, keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.599647 GPU 1 69615 test begin: paddle.logsumexp(x=Tensor([2, 0, 2],"float64"), axis=2, )
[paddle error] paddle.logsumexp(x=Tensor([2, 0, 2],"float64"), axis=2, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.612014 GPU 1 69604 test begin: paddle.logsumexp(x=Tensor([2, 0, 2],"float64"), axis=list[0,1,], )
[paddle error] paddle.logsumexp(x=Tensor([2, 0, 2],"float64"), axis=list[0,1,], ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.612322 GPU 1 69603 test begin: paddle.logsumexp(x=Tensor([2, 0, 2],"float64"), axis=list[0,1,], keepdim=True, )
[paddle error] paddle.logsumexp(x=Tensor([2, 0, 2],"float64"), axis=list[0,1,], keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.636195 GPU 1 69602 test begin: paddle.logsumexp(x=Tensor([2, 3, 0],"float32"), axis=2, )
[paddle error] paddle.logsumexp(x=Tensor([2, 3, 0],"float32"), axis=2, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.647675 GPU 1 69606 test begin: paddle.logsumexp(x=Tensor([2, 3, 0],"float64"), axis=0, keepdim=True, )
[paddle error] paddle.logsumexp(x=Tensor([2, 3, 0],"float64"), axis=0, keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.654219 GPU 1 69596 test begin: paddle.logsumexp(x=Tensor([2, 3, 0],"float64"), axis=2, )
[paddle error] paddle.logsumexp(x=Tensor([2, 3, 0],"float64"), axis=2, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.655416 GPU 1 69621 test begin: paddle.logsumexp(x=Tensor([2, 3, 0],"float64"), axis=list[0,1,], )
[paddle error] paddle.logsumexp(x=Tensor([2, 3, 0],"float64"), axis=list[0,1,], ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.692821 GPU 1 69607 test begin: paddle.logsumexp(x=Tensor([2, 3, 0],"float64"), axis=list[0,1,], keepdim=True, )
[paddle error] paddle.logsumexp(x=Tensor([2, 3, 0],"float64"), axis=list[0,1,], keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < xdim[i], but received 0:0 >= xdim[i]:0.] (at ../paddle/phi/kernels/gpu/logsumexp_kernel.cu:99)


2025-05-21 22:07:56.698459 GPU 1 69610 test begin: paddle.mm(Tensor([1, 10],"float32"), Tensor([10, 0],"float32"), )
W0521 22:07:56.819344 69610 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.mm(Tensor([1, 10],"float32"), Tensor([10, 0],"float32"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:40)


2025-05-21 22:07:56.701448 GPU 1 69613 test begin: paddle.mm(Tensor([1, 10],"float64"), Tensor([10, 0],"float64"), )
W0521 22:07:56.891036 69613 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.mm(Tensor([1, 10],"float64"), Tensor([10, 0],"float64"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:07:56.701418 GPU 1 69611 test begin: paddle.mm(input=Tensor([2, 3],"float32"), mat2=Tensor([3, 0],"float32"), )
W0521 22:07:56.819089 69611 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.mm(input=Tensor([2, 3],"float32"), mat2=Tensor([3, 0],"float32"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:40)

 ** On entry to SGEMM  parameter number 8 had an illegal value

2025-05-21 22:07:56.712042 GPU 1 69605 test begin: paddle.mm(input=Tensor([2, 3],"float64"), mat2=Tensor([3, 0],"float64"), )
W0521 22:07:56.824327 69605 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.mm(input=Tensor([2, 3],"float64"), mat2=Tensor([3, 0],"float64"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:07:56.719225 GPU 1 69615 test begin: paddle.multigammaln(Tensor([0, 20],"float32"), 2, )
[cuda error] paddle.multigammaln(Tensor([0, 20],"float32"), 2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:56.724517 GPU 1 69617 test begin: paddle.multigammaln(Tensor([0, 20],"float64"), 2, )
[cuda error] paddle.multigammaln(Tensor([0, 20],"float64"), 2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:56.729896 GPU 1 69600 test begin: paddle.multigammaln(Tensor([10, 0],"float32"), 2, )
[cuda error] paddle.multigammaln(Tensor([10, 0],"float32"), 2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:56.762057 GPU 1 69606 test begin: paddle.multigammaln(Tensor([10, 0],"float64"), 2, )
[cuda error] paddle.multigammaln(Tensor([10, 0],"float64"), 2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:56.797026 GPU 1 69621 test begin: paddle.mv(Tensor([0, 12],"float32"), Tensor([12],"float32"), )
[cuda error] paddle.mv(Tensor([0, 12],"float32"), Tensor([12],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:56.802631 GPU 1 69607 test begin: paddle.mv(Tensor([0, 18],"float32"), Tensor([18],"float32"), )
[cuda error] paddle.mv(Tensor([0, 18],"float32"), Tensor([18],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:56.819272 GPU 1 69603 test begin: paddle.mv(x=Tensor([0, 1],"float64"), vec=Tensor([1],"float64"), )
[cuda error] paddle.mv(x=Tensor([0, 1],"float64"), vec=Tensor([1],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:56.819767 GPU 1 69611 test begin: paddle.mv(x=Tensor([0, 2],"float64"), vec=Tensor([2],"float64"), )
[cuda error] paddle.mv(x=Tensor([0, 2],"float64"), vec=Tensor([2],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:56.820093 GPU 1 69610 test begin: paddle.nan_to_num(Tensor([0, 1],"float64"), neginf=-2.220446049250313e-16, )
[cuda error] paddle.nan_to_num(Tensor([0, 1],"float64"), neginf=-2.220446049250313e-16, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:56.825483 GPU 1 69605 test begin: paddle.nan_to_num(Tensor([0, 2],"float32"), neginf=-1.1920928955078125e-07, )
[cuda error] paddle.nan_to_num(Tensor([0, 2],"float32"), neginf=-1.1920928955078125e-07, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:56.850455 GPU 1 69604 test begin: paddle.nan_to_num(Tensor([0, 3],"float32"), )
[cuda error] paddle.nan_to_num(Tensor([0, 3],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:56.851065 GPU 1 69602 test begin: paddle.nan_to_num(Tensor([0, 3],"float32"), 1.0, 100.0, -10.0, )
[cuda error] paddle.nan_to_num(Tensor([0, 3],"float32"), 1.0, 100.0, -10.0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:56.857848 GPU 1 69629 test begin: paddle.nan_to_num(Tensor([0, 3],"float32"), 1.0, 2.0, None, )
[cuda error] paddle.nan_to_num(Tensor([0, 3],"float32"), 1.0, 2.0, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:56.867727 GPU 1 69596 test begin: paddle.nan_to_num(Tensor([0, 3],"float32"), 1.0, None, -10.0, )
[cuda error] paddle.nan_to_num(Tensor([0, 3],"float32"), 1.0, None, -10.0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:56.879973 GPU 1 69612 test begin: paddle.nan_to_num(Tensor([0, 3],"float32"), 1.0, None, None, )
[cuda error] paddle.nan_to_num(Tensor([0, 3],"float32"), 1.0, None, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:56.891901 GPU 1 69613 test begin: paddle.nan_to_num(Tensor([0, 4],"float32"), )
[cuda error] paddle.nan_to_num(Tensor([0, 4],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:56.937147 GPU 1 69610 test begin: paddle.nan_to_num(Tensor([0, 5, 3],"float32"), neginf=-1.1920928955078125e-07, )
[cuda error] paddle.nan_to_num(Tensor([0, 5, 3],"float32"), neginf=-1.1920928955078125e-07, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:56.938343 GPU 1 69605 test begin: paddle.nan_to_num(Tensor([0],"float64"), neginf=-2.220446049250313e-16, )
[cuda error] paddle.nan_to_num(Tensor([0],"float64"), neginf=-2.220446049250313e-16, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:56.941682 GPU 1 69611 test begin: paddle.nan_to_num(Tensor([114, 0],"float64"), neginf=-2.220446049250313e-16, )
[cuda error] paddle.nan_to_num(Tensor([114, 0],"float64"), neginf=-2.220446049250313e-16, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:56.957227 GPU 1 69607 test begin: paddle.nan_to_num(Tensor([148, 0, 3],"float32"), neginf=-1.1920928955078125e-07, )
[cuda error] paddle.nan_to_num(Tensor([148, 0, 3],"float32"), neginf=-1.1920928955078125e-07, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:56.969438 GPU 1 69604 test begin: paddle.nan_to_num(Tensor([148, 5, 0],"float32"), neginf=-1.1920928955078125e-07, )
[cuda error] paddle.nan_to_num(Tensor([148, 5, 0],"float32"), neginf=-1.1920928955078125e-07, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:56.981992 GPU 1 69600 test begin: paddle.nan_to_num(Tensor([1948, 0],"float32"), neginf=-1.1920928955078125e-07, )
[cuda error] paddle.nan_to_num(Tensor([1948, 0],"float32"), neginf=-1.1920928955078125e-07, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.022204 GPU 1 69602 test begin: paddle.nan_to_num(Tensor([2, 0],"float32"), )
[cuda error] paddle.nan_to_num(Tensor([2, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.055377 GPU 1 69605 test begin: paddle.nan_to_num(Tensor([2, 0],"float32"), 1.0, 100.0, -10.0, )
[cuda error] paddle.nan_to_num(Tensor([2, 0],"float32"), 1.0, 100.0, -10.0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.055814 GPU 1 69610 test begin: paddle.nan_to_num(Tensor([2, 0],"float32"), 1.0, 2.0, None, )
[cuda error] paddle.nan_to_num(Tensor([2, 0],"float32"), 1.0, 2.0, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.073696 GPU 1 69612 test begin: paddle.nan_to_num(Tensor([2, 0],"float32"), 1.0, None, -10.0, )
[cuda error] paddle.nan_to_num(Tensor([2, 0],"float32"), 1.0, None, -10.0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.076688 GPU 1 69596 test begin: paddle.nan_to_num(Tensor([2, 0],"float32"), 1.0, None, None, )
[cuda error] paddle.nan_to_num(Tensor([2, 0],"float32"), 1.0, None, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.077138 GPU 1 69611 test begin: paddle.nan_to_num(Tensor([400, 0],"float64"), neginf=-2.220446049250313e-16, )
[cuda error] paddle.nan_to_num(Tensor([400, 0],"float64"), neginf=-2.220446049250313e-16, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.086430 GPU 1 69615 test begin: paddle.nanmean(Tensor([0, 3, 4, 5],"float32"), -1, False, )
[cuda error] paddle.nanmean(Tensor([0, 3, 4, 5],"float32"), -1, False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.087448 GPU 1 69606 test begin: paddle.nanmean(Tensor([0, 3, 4, 5],"float32"), 2, True, )
[cuda error] paddle.nanmean(Tensor([0, 3, 4, 5],"float32"), 2, True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.099105 GPU 1 69613 test begin: paddle.nanmean(Tensor([0, 3, 4, 5],"float32"), None, False, )
[cuda error] paddle.nanmean(Tensor([0, 3, 4, 5],"float32"), None, False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.105350 GPU 1 69604 test begin: paddle.nanmean(Tensor([0, 3, 4, 5],"float32"), None, True, )
[cuda error] paddle.nanmean(Tensor([0, 3, 4, 5],"float32"), None, True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.124058 GPU 1 69600 test begin: paddle.nanmean(Tensor([0, 3, 4, 5],"float32"), list[0,1,2,3,], False, )
[cuda error] paddle.nanmean(Tensor([0, 3, 4, 5],"float32"), list[0,1,2,3,], False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.174423 GPU 1 69610 test begin: paddle.nanmean(Tensor([0, 3, 4, 5],"float32"), list[0,2,], False, )
 ** On entry to DGEMM  parameter number 8 had an illegal value
 ** On entry to DGEMM  parameter number 8 had an illegal value
 ** On entry to DGEMM  parameter number 8 had an illegal value
 ** On entry to SGEMM  parameter number 8 had an illegal value
[cuda error] paddle.nanmean(Tensor([0, 3, 4, 5],"float32"), list[0,2,], False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.175090 GPU 1 69605 test begin: paddle.nanmean(Tensor([0, 3, 4, 5],"float32"), list[], False, )
[cuda error] paddle.nanmean(Tensor([0, 3, 4, 5],"float32"), list[], False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.190078 GPU 1 69611 test begin: paddle.nanmean(Tensor([0, 3, 4, 5],"float32"), tuple(0,2,), False, )
[cuda error] paddle.nanmean(Tensor([0, 3, 4, 5],"float32"), tuple(0,2,), False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.197549 GPU 1 69603 test begin: paddle.nanmean(Tensor([0, 3],"float32"), -1, False, )
[cuda error] paddle.nanmean(Tensor([0, 3],"float32"), -1, False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.197839 GPU 1 69612 test begin: paddle.nanmean(Tensor([0, 3],"float32"), 0, True, )
[cuda error] paddle.nanmean(Tensor([0, 3],"float32"), 0, True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.199175 GPU 1 69617 test begin: paddle.nanmean(Tensor([0, 3],"float32"), 1, False, )
[cuda error] paddle.nanmean(Tensor([0, 3],"float32"), 1, False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.201857 GPU 1 69596 test begin: paddle.nanmean(Tensor([0, 3],"float32"), None, False, )
 ** On entry to SgemmStridedBatched parameter number 8 had an illegal value
 ** On entry to SGEMM  parameter number 8 had an illegal value
 ** On entry to DGEMM  parameter number 10 had an illegal value
[cuda error] paddle.nanmean(Tensor([0, 3],"float32"), None, False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.207511 GPU 1 69602 test begin: paddle.nanmean(Tensor([0, 3],"float32"), None, True, )
[cuda error] paddle.nanmean(Tensor([0, 3],"float32"), None, True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.256762 GPU 1 69629 test begin: paddle.nanmean(Tensor([0, 3],"float32"), tuple(0,1,), False, )
[cuda error] paddle.nanmean(Tensor([0, 3],"float32"), tuple(0,1,), False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.266416 GPU 1 69607 test begin: paddle.nanmean(Tensor([0, 5],"float32"), axis=None, )
 ** On entry to SGEMM  parameter number 8 had an illegal value
[cuda error] paddle.nanmean(Tensor([0, 5],"float32"), axis=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.318862 GPU 1 69617 test begin: paddle.nanmean(Tensor([0, 5],"float32"), keepdim=True, )
[cuda error] paddle.nanmean(Tensor([0, 5],"float32"), keepdim=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.397905 GPU 1 69603 test begin: paddle.nanmean(Tensor([0],"float32"), axis=0, )
[cuda error] paddle.nanmean(Tensor([0],"float32"), axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.402757 GPU 1 69610 test begin: paddle.nanmean(Tensor([2, 0, 4, 5],"float32"), -1, False, )
[cuda error] paddle.nanmean(Tensor([2, 0, 4, 5],"float32"), -1, False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.421776 GPU 1 69600 test begin: paddle.nanmean(Tensor([2, 0, 4, 5],"float32"), 2, True, )
[cuda error] paddle.nanmean(Tensor([2, 0, 4, 5],"float32"), 2, True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.489726 GPU 1 69612 test begin: paddle.nanmean(Tensor([2, 0, 4, 5],"float32"), None, False, )
[cuda error] paddle.nanmean(Tensor([2, 0, 4, 5],"float32"), None, False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.491161 GPU 1 69615 test begin: paddle.nanmean(Tensor([2, 0, 4, 5],"float32"), None, True, )
[cuda error] paddle.nanmean(Tensor([2, 0, 4, 5],"float32"), None, True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.493595 GPU 1 69602 test begin: paddle.nanmean(Tensor([2, 0, 4, 5],"float32"), list[0,1,2,3,], False, )
[cuda error] paddle.nanmean(Tensor([2, 0, 4, 5],"float32"), list[0,1,2,3,], False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.499668 GPU 1 69596 test begin: paddle.nanmean(Tensor([2, 0, 4, 5],"float32"), list[0,2,], False, )
[cuda error] paddle.nanmean(Tensor([2, 0, 4, 5],"float32"), list[0,2,], False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.509477 GPU 1 69606 test begin: paddle.nanmean(Tensor([2, 0, 4, 5],"float32"), list[], False, )
[cuda error] paddle.nanmean(Tensor([2, 0, 4, 5],"float32"), list[], False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.525768 GPU 1 69610 test begin: paddle.nanmean(Tensor([2, 0, 4, 5],"float32"), tuple(0,2,), False, )
[cuda error] paddle.nanmean(Tensor([2, 0, 4, 5],"float32"), tuple(0,2,), False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.547761 GPU 1 69604 test begin: paddle.nanmean(Tensor([2, 0],"float32"), -1, False, )
[cuda error] paddle.nanmean(Tensor([2, 0],"float32"), -1, False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.565084 GPU 1 69600 test begin: paddle.nanmean(Tensor([2, 0],"float32"), 0, True, )
[cuda error] paddle.nanmean(Tensor([2, 0],"float32"), 0, True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.658016 GPU 1 69615 test begin: paddle.nanmean(Tensor([2, 0],"float32"), 1, False, )
[cuda error] paddle.nanmean(Tensor([2, 0],"float32"), 1, False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.682238 GPU 1 69605 test begin: paddle.nanmean(Tensor([2, 0],"float32"), None, False, )
[cuda error] paddle.nanmean(Tensor([2, 0],"float32"), None, False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.684179 GPU 1 69603 test begin: paddle.nanmean(Tensor([2, 0],"float32"), None, True, )
[cuda error] paddle.nanmean(Tensor([2, 0],"float32"), None, True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.684473 GPU 1 69611 test begin: paddle.nanmean(Tensor([2, 0],"float32"), tuple(0,1,), False, )
[cuda error] paddle.nanmean(Tensor([2, 0],"float32"), tuple(0,1,), False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.684893 GPU 1 69612 test begin: paddle.nanmean(Tensor([2, 3, 0, 5],"float32"), -1, False, )
[cuda error] paddle.nanmean(Tensor([2, 3, 0, 5],"float32"), -1, False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.685020 GPU 1 69607 test begin: paddle.nanmean(Tensor([2, 3, 0, 5],"float32"), 2, True, )
[cuda error] paddle.nanmean(Tensor([2, 3, 0, 5],"float32"), 2, True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.685099 GPU 1 69606 test begin: paddle.nanmean(Tensor([2, 3, 0, 5],"float32"), None, False, )
[cuda error] paddle.nanmean(Tensor([2, 3, 0, 5],"float32"), None, False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.685249 GPU 1 69602 test begin: paddle.nanmean(Tensor([2, 3, 0, 5],"float32"), None, True, )
[cuda error] paddle.nanmean(Tensor([2, 3, 0, 5],"float32"), None, True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.685864 GPU 1 69629 test begin: paddle.nanmean(Tensor([2, 3, 0, 5],"float32"), list[0,1,2,3,], False, )
[cuda error] paddle.nanmean(Tensor([2, 3, 0, 5],"float32"), list[0,1,2,3,], False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.685986 GPU 1 69613 test begin: paddle.nanmean(Tensor([2, 3, 0, 5],"float32"), list[0,2,], False, )
[cuda error] paddle.nanmean(Tensor([2, 3, 0, 5],"float32"), list[0,2,], False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.686029 GPU 1 69617 test begin: paddle.nanmean(Tensor([2, 3, 0, 5],"float32"), list[], False, )
[cuda error] paddle.nanmean(Tensor([2, 3, 0, 5],"float32"), list[], False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.797501 GPU 1 69596 test begin: paddle.nanmean(Tensor([2, 3, 0, 5],"float32"), tuple(0,2,), False, )
[cuda error] paddle.nanmean(Tensor([2, 3, 0, 5],"float32"), tuple(0,2,), False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.799821 GPU 1 69612 test begin: paddle.nanmean(Tensor([2, 3, 4, 0],"float32"), -1, False, )
[cuda error] paddle.nanmean(Tensor([2, 3, 4, 0],"float32"), -1, False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.803861 GPU 1 69600 test begin: paddle.nanmean(Tensor([2, 3, 4, 0],"float32"), 2, True, )
[cuda error] paddle.nanmean(Tensor([2, 3, 4, 0],"float32"), 2, True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.832562 GPU 1 69610 test begin: paddle.nanmean(Tensor([2, 3, 4, 0],"float32"), None, False, )
[cuda error] paddle.nanmean(Tensor([2, 3, 4, 0],"float32"), None, False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.908230 GPU 1 69613 test begin: paddle.nanmean(Tensor([2, 3, 4, 0],"float32"), None, True, )
[cuda error] paddle.nanmean(Tensor([2, 3, 4, 0],"float32"), None, True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.927543 GPU 1 69615 test begin: paddle.nanmean(Tensor([2, 3, 4, 0],"float32"), list[0,1,2,3,], False, )
[cuda error] paddle.nanmean(Tensor([2, 3, 4, 0],"float32"), list[0,1,2,3,], False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.927920 GPU 1 69617 test begin: paddle.nanmean(Tensor([2, 3, 4, 0],"float32"), list[0,2,], False, )
[cuda error] paddle.nanmean(Tensor([2, 3, 4, 0],"float32"), list[0,2,], False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.929445 GPU 1 69604 test begin: paddle.nanmean(Tensor([2, 3, 4, 0],"float32"), list[], False, )
[cuda error] paddle.nanmean(Tensor([2, 3, 4, 0],"float32"), list[], False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.930091 GPU 1 69606 test begin: paddle.nanmean(Tensor([2, 3, 4, 0],"float32"), tuple(0,2,), False, )
[cuda error] paddle.nanmean(Tensor([2, 3, 4, 0],"float32"), tuple(0,2,), False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.931652 GPU 1 69607 test begin: paddle.nanmean(Tensor([3, 0],"float32"), axis=None, )
[cuda error] paddle.nanmean(Tensor([3, 0],"float32"), axis=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.933038 GPU 1 69603 test begin: paddle.nanmean(Tensor([3, 0],"float32"), keepdim=True, )
[cuda error] paddle.nanmean(Tensor([3, 0],"float32"), keepdim=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:57.933925 GPU 1 69611 test begin: paddle.nansum(Tensor([0, 3, 4, 5],"float32"), axis=None, keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([0, 3, 4, 5],"float32"), axis=None, keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.036492 GPU 1 69600 test begin: paddle.nansum(Tensor([0, 3, 4, 5],"float32"), axis=None, keepdim=True, name=None, )
[cuda error] paddle.nansum(Tensor([0, 3, 4, 5],"float32"), axis=None, keepdim=True, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.046683 GPU 1 69606 test begin: paddle.nansum(Tensor([0, 3, 4, 5],"float32"), axis=list[-1,], keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([0, 3, 4, 5],"float32"), axis=list[-1,], keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.047768 GPU 1 69605 test begin: paddle.nansum(Tensor([0, 3, 4, 5],"float32"), axis=list[0,1,2,3,], keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([0, 3, 4, 5],"float32"), axis=list[0,1,2,3,], keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.049069 GPU 1 69602 test begin: paddle.nansum(Tensor([0, 3, 4, 5],"float32"), axis=list[0,2,], keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([0, 3, 4, 5],"float32"), axis=list[0,2,], keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.049261 GPU 1 69615 test begin: paddle.nansum(Tensor([0, 3, 4, 5],"float32"), axis=list[2,], keepdim=True, name=None, )
[cuda error] paddle.nansum(Tensor([0, 3, 4, 5],"float32"), axis=list[2,], keepdim=True, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.049630 GPU 1 69629 test begin: paddle.nansum(Tensor([0, 3, 4, 5],"float32"), axis=list[], keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([0, 3, 4, 5],"float32"), axis=list[], keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.074805 GPU 1 69617 test begin: paddle.nansum(Tensor([0, 3, 4, 5],"float32"), axis=tuple(0,2,), keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([0, 3, 4, 5],"float32"), axis=tuple(0,2,), keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.076232 GPU 1 69610 test begin: paddle.nansum(Tensor([0, 3],"float32"), axis=None, keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([0, 3],"float32"), axis=None, keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.077175 GPU 1 69612 test begin: paddle.nansum(Tensor([0, 3],"float32"), axis=None, keepdim=True, name=None, )
[cuda error] paddle.nansum(Tensor([0, 3],"float32"), axis=None, keepdim=True, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.081422 GPU 1 69607 test begin: paddle.nansum(Tensor([0, 3],"float32"), axis=list[-1,], keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([0, 3],"float32"), axis=list[-1,], keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.102146 GPU 1 69603 test begin: paddle.nansum(Tensor([0, 3],"float32"), axis=list[0,], keepdim=True, name=None, )
[cuda error] paddle.nansum(Tensor([0, 3],"float32"), axis=list[0,], keepdim=True, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.103441 GPU 1 69611 test begin: paddle.nansum(Tensor([0, 3],"float32"), axis=list[1,], keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([0, 3],"float32"), axis=list[1,], keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.108165 GPU 1 69596 test begin: paddle.nansum(Tensor([0, 3],"float32"), axis=tuple(0,1,), keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([0, 3],"float32"), axis=tuple(0,1,), keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.167505 GPU 1 69606 test begin: paddle.nansum(Tensor([0, 4],"float32"), )
[cuda error] paddle.nansum(Tensor([0, 4],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.189891 GPU 1 69615 test begin: paddle.nansum(Tensor([0, 5],"float32"), axis=None, )
[cuda error] paddle.nansum(Tensor([0, 5],"float32"), axis=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.305117 GPU 1 69607 test begin: paddle.nansum(Tensor([0, 5],"float32"), axis=None, keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([0, 5],"float32"), axis=None, keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.309920 GPU 1 69610 test begin: paddle.nansum(Tensor([0, 5],"float32"), axis=None, keepdim=True, name=None, )
[cuda error] paddle.nansum(Tensor([0, 5],"float32"), axis=None, keepdim=True, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.311360 GPU 1 69600 test begin: paddle.nansum(Tensor([0, 5],"float32"), keepdim=True, )
[cuda error] paddle.nansum(Tensor([0, 5],"float32"), keepdim=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.311756 GPU 1 70805 test begin: paddle.nansum(Tensor([0],"float32"), axis=0, )
[cuda error] paddle.nansum(Tensor([0],"float32"), axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.311729 GPU 1 69605 test begin: paddle.nansum(Tensor([0],"float32"), axis=list[0,], keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([0],"float32"), axis=list[0,], keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.312110 GPU 1 69602 test begin: paddle.nansum(Tensor([2, 0, 4, 5],"float32"), axis=None, keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([2, 0, 4, 5],"float32"), axis=None, keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.312256 GPU 1 69604 test begin: paddle.nansum(Tensor([2, 0, 4, 5],"float32"), axis=None, keepdim=True, name=None, )
[cuda error] paddle.nansum(Tensor([2, 0, 4, 5],"float32"), axis=None, keepdim=True, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.313463 GPU 1 69611 test begin: paddle.nansum(Tensor([2, 0, 4, 5],"float32"), axis=list[-1,], keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([2, 0, 4, 5],"float32"), axis=list[-1,], keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.315762 GPU 1 69617 test begin: paddle.nansum(Tensor([2, 0, 4, 5],"float32"), axis=list[0,1,2,3,], keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([2, 0, 4, 5],"float32"), axis=list[0,1,2,3,], keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.316363 GPU 1 69613 test begin: paddle.nansum(Tensor([2, 0, 4, 5],"float32"), axis=list[0,2,], keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([2, 0, 4, 5],"float32"), axis=list[0,2,], keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.317007 GPU 1 69603 test begin: paddle.nansum(Tensor([2, 0, 4, 5],"float32"), axis=list[2,], keepdim=True, name=None, )
[cuda error] paddle.nansum(Tensor([2, 0, 4, 5],"float32"), axis=list[2,], keepdim=True, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.317150 GPU 1 69612 test begin: paddle.nansum(Tensor([2, 0, 4, 5],"float32"), axis=list[], keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([2, 0, 4, 5],"float32"), axis=list[], keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.317420 GPU 1 69621 test begin: paddle.nansum(Tensor([2, 0, 4, 5],"float32"), axis=tuple(0,2,), keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([2, 0, 4, 5],"float32"), axis=tuple(0,2,), keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.351813 GPU 1 69629 test begin: paddle.nansum(Tensor([2, 0],"float32"), )
[cuda error] paddle.nansum(Tensor([2, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.433014 GPU 1 69606 test begin: paddle.nansum(Tensor([2, 0],"float32"), axis=None, keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([2, 0],"float32"), axis=None, keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.442183 GPU 1 69596 test begin: paddle.nansum(Tensor([2, 0],"float32"), axis=None, keepdim=True, name=None, )
[cuda error] paddle.nansum(Tensor([2, 0],"float32"), axis=None, keepdim=True, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.443153 GPU 1 69612 test begin: paddle.nansum(Tensor([2, 0],"float32"), axis=list[-1,], keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([2, 0],"float32"), axis=list[-1,], keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.446020 GPU 1 69607 test begin: paddle.nansum(Tensor([2, 0],"float32"), axis=list[0,], keepdim=True, name=None, )
[cuda error] paddle.nansum(Tensor([2, 0],"float32"), axis=list[0,], keepdim=True, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.449664 GPU 1 69605 test begin: paddle.nansum(Tensor([2, 0],"float32"), axis=list[1,], keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([2, 0],"float32"), axis=list[1,], keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.473133 GPU 1 69610 test begin: paddle.nansum(Tensor([2, 0],"float32"), axis=tuple(0,1,), keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([2, 0],"float32"), axis=tuple(0,1,), keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.473396 GPU 1 69615 test begin: paddle.nansum(Tensor([2, 3, 0, 5],"float32"), axis=None, keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([2, 3, 0, 5],"float32"), axis=None, keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.473757 GPU 1 69604 test begin: paddle.nansum(Tensor([2, 3, 0, 5],"float32"), axis=None, keepdim=True, name=None, )
[cuda error] paddle.nansum(Tensor([2, 3, 0, 5],"float32"), axis=None, keepdim=True, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.474510 GPU 1 69603 test begin: paddle.nansum(Tensor([2, 3, 0, 5],"float32"), axis=list[-1,], keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([2, 3, 0, 5],"float32"), axis=list[-1,], keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.477928 GPU 1 69611 test begin: paddle.nansum(Tensor([2, 3, 0, 5],"float32"), axis=list[0,1,2,3,], keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([2, 3, 0, 5],"float32"), axis=list[0,1,2,3,], keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.487174 GPU 1 69617 test begin: paddle.nansum(Tensor([2, 3, 0, 5],"float32"), axis=list[0,2,], keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([2, 3, 0, 5],"float32"), axis=list[0,2,], keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.549049 GPU 1 69613 test begin: paddle.nansum(Tensor([2, 3, 0, 5],"float32"), axis=list[2,], keepdim=True, name=None, )
[cuda error] paddle.nansum(Tensor([2, 3, 0, 5],"float32"), axis=list[2,], keepdim=True, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.560881 GPU 1 69607 test begin: paddle.nansum(Tensor([2, 3, 0, 5],"float32"), axis=list[], keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([2, 3, 0, 5],"float32"), axis=list[], keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.583345 GPU 1 69621 test begin: paddle.nansum(Tensor([2, 3, 0, 5],"float32"), axis=tuple(0,2,), keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([2, 3, 0, 5],"float32"), axis=tuple(0,2,), keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.626941 GPU 1 69603 test begin: paddle.nansum(Tensor([2, 3, 4, 0],"float32"), axis=None, keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([2, 3, 4, 0],"float32"), axis=None, keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.657007 GPU 1 69606 test begin: paddle.nansum(Tensor([2, 3, 4, 0],"float32"), axis=None, keepdim=True, name=None, )
[cuda error] paddle.nansum(Tensor([2, 3, 4, 0],"float32"), axis=None, keepdim=True, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.657214 GPU 1 69596 test begin: paddle.nansum(Tensor([2, 3, 4, 0],"float32"), axis=list[-1,], keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([2, 3, 4, 0],"float32"), axis=list[-1,], keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.657771 GPU 1 69612 test begin: paddle.nansum(Tensor([2, 3, 4, 0],"float32"), axis=list[0,1,2,3,], keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([2, 3, 4, 0],"float32"), axis=list[0,1,2,3,], keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.658617 GPU 1 69610 test begin: paddle.nansum(Tensor([2, 3, 4, 0],"float32"), axis=list[0,2,], keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([2, 3, 4, 0],"float32"), axis=list[0,2,], keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.659042 GPU 1 69605 test begin: paddle.nansum(Tensor([2, 3, 4, 0],"float32"), axis=list[2,], keepdim=True, name=None, )
[cuda error] paddle.nansum(Tensor([2, 3, 4, 0],"float32"), axis=list[2,], keepdim=True, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.659334 GPU 1 69602 test begin: paddle.nansum(Tensor([2, 3, 4, 0],"float32"), axis=list[], keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([2, 3, 4, 0],"float32"), axis=list[], keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.659885 GPU 1 69604 test begin: paddle.nansum(Tensor([2, 3, 4, 0],"float32"), axis=tuple(0,2,), keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([2, 3, 4, 0],"float32"), axis=tuple(0,2,), keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.660347 GPU 1 69629 test begin: paddle.nansum(Tensor([3, 0],"float32"), axis=None, )
[cuda error] paddle.nansum(Tensor([3, 0],"float32"), axis=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.660415 GPU 1 69600 test begin: paddle.nansum(Tensor([3, 0],"float32"), axis=None, keepdim=False, name=None, )
[cuda error] paddle.nansum(Tensor([3, 0],"float32"), axis=None, keepdim=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.660644 GPU 1 69611 test begin: paddle.nansum(Tensor([3, 0],"float32"), axis=None, keepdim=True, name=None, )
[cuda error] paddle.nansum(Tensor([3, 0],"float32"), axis=None, keepdim=True, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.661103 GPU 1 69615 test begin: paddle.nansum(Tensor([3, 0],"float32"), keepdim=True, )
[cuda error] paddle.nansum(Tensor([3, 0],"float32"), keepdim=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.661364 GPU 1 69617 test begin: paddle.nansum(x=Tensor([0, 2, 3, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, )
[cuda error] paddle.nansum(x=Tensor([0, 2, 3, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.768934 GPU 1 69610 test begin: paddle.nansum(x=Tensor([0, 3, 3],"float64"), )
[cuda error] paddle.nansum(x=Tensor([0, 3, 3],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.810782 GPU 1 69596 test begin: paddle.nansum(x=Tensor([0, 3, 3],"float64"), axis=-1, )
[cuda error] paddle.nansum(x=Tensor([0, 3, 3],"float64"), axis=-1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.810996 GPU 1 69606 test begin: paddle.nansum(x=Tensor([0, 3, 3],"float64"), axis=0, )
[cuda error] paddle.nansum(x=Tensor([0, 3, 3],"float64"), axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.811856 GPU 1 69621 test begin: paddle.nansum(x=Tensor([0, 3, 3],"float64"), axis=0, keepdim=True, )
[cuda error] paddle.nansum(x=Tensor([0, 3, 3],"float64"), axis=0, keepdim=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.813095 GPU 1 69607 test begin: paddle.nansum(x=Tensor([3, 0, 3, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, )
[cuda error] paddle.nansum(x=Tensor([3, 0, 3, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.920493 GPU 1 69617 test begin: paddle.nansum(x=Tensor([3, 0, 3],"float64"), )
[cuda error] paddle.nansum(x=Tensor([3, 0, 3],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.924249 GPU 1 69604 test begin: paddle.nansum(x=Tensor([3, 0, 3],"float64"), axis=-1, )
[cuda error] paddle.nansum(x=Tensor([3, 0, 3],"float64"), axis=-1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.928702 GPU 1 69605 test begin: paddle.nansum(x=Tensor([3, 0, 3],"float64"), axis=0, )
[cuda error] paddle.nansum(x=Tensor([3, 0, 3],"float64"), axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.955990 GPU 1 69596 test begin: paddle.nansum(x=Tensor([3, 0, 3],"float64"), axis=0, keepdim=True, )
[cuda error] paddle.nansum(x=Tensor([3, 0, 3],"float64"), axis=0, keepdim=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.973380 GPU 1 69612 test begin: paddle.nansum(x=Tensor([3, 2, 0, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, )
[cuda error] paddle.nansum(x=Tensor([3, 2, 0, 4, 5, 1, 2],"float64"), axis=3, keepdim=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.973942 GPU 1 69610 test begin: paddle.nansum(x=Tensor([3, 2, 3, 0, 5, 1, 2],"float64"), axis=3, keepdim=True, )
[cuda error] paddle.nansum(x=Tensor([3, 2, 3, 0, 5, 1, 2],"float64"), axis=3, keepdim=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.974104 GPU 1 69613 test begin: paddle.nansum(x=Tensor([3, 2, 3, 4, 0, 1, 2],"float64"), axis=3, keepdim=True, )
[cuda error] paddle.nansum(x=Tensor([3, 2, 3, 4, 0, 1, 2],"float64"), axis=3, keepdim=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.974593 GPU 1 69629 test begin: paddle.nansum(x=Tensor([3, 2, 3, 4, 5, 0, 2],"float64"), axis=3, keepdim=True, )
[cuda error] paddle.nansum(x=Tensor([3, 2, 3, 4, 5, 0, 2],"float64"), axis=3, keepdim=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.975046 GPU 1 69603 test begin: paddle.nansum(x=Tensor([3, 2, 3, 4, 5, 1, 0],"float64"), axis=3, keepdim=True, )
[cuda error] paddle.nansum(x=Tensor([3, 2, 3, 4, 5, 1, 0],"float64"), axis=3, keepdim=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.975483 GPU 1 69611 test begin: paddle.nansum(x=Tensor([3, 3, 0],"float64"), )
[cuda error] paddle.nansum(x=Tensor([3, 3, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:58.975706 GPU 1 69615 test begin: paddle.nansum(x=Tensor([3, 3, 0],"float64"), axis=-1, )
[cuda error] paddle.nansum(x=Tensor([3, 3, 0],"float64"), axis=-1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:59.084062 GPU 1 69596 test begin: paddle.nansum(x=Tensor([3, 3, 0],"float64"), axis=0, )
[cuda error] paddle.nansum(x=Tensor([3, 3, 0],"float64"), axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:59.087421 GPU 1 69604 test begin: paddle.nansum(x=Tensor([3, 3, 0],"float64"), axis=0, keepdim=True, )
[cuda error] paddle.nansum(x=Tensor([3, 3, 0],"float64"), axis=0, keepdim=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:59.088056 GPU 1 69605 test begin: paddle.nextafter(Tensor([0, 3, 2],"float32"), Tensor([0, 3, 2],"float64"), )
W0521 22:07:59.250415 69605 dygraph_functions.cc:55133] got different data type, run type promotion automatically, this may cause data type been changed.
[cuda error] paddle.nextafter(Tensor([0, 3, 2],"float32"), Tensor([0, 3, 2],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:59.091433 GPU 1 69607 test begin: paddle.nextafter(Tensor([0, 3, 2],"float64"), Tensor([0, 3, 2],"float32"), )
W0521 22:07:59.248265 69607 dygraph_functions.cc:55133] got different data type, run type promotion automatically, this may cause data type been changed.
[cuda error] paddle.nextafter(Tensor([0, 3, 2],"float64"), Tensor([0, 3, 2],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:59.137527 GPU 1 69600 test begin: paddle.nextafter(Tensor([0, 3, 4, 5],"float32"), Tensor([0, 3, 4, 5],"float32"), )
[cuda error] paddle.nextafter(Tensor([0, 3, 4, 5],"float32"), Tensor([0, 3, 4, 5],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:59.137839 GPU 1 69602 test begin: paddle.nextafter(Tensor([2, 0, 4, 5],"float32"), Tensor([2, 0, 4, 5],"float32"), )
[cuda error] paddle.nextafter(Tensor([2, 0, 4, 5],"float32"), Tensor([2, 0, 4, 5],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:59.138746 GPU 1 69617 test begin: paddle.nextafter(Tensor([2, 3, 0, 5],"float32"), Tensor([2, 3, 0, 5],"float32"), )
[cuda error] paddle.nextafter(Tensor([2, 3, 0, 5],"float32"), Tensor([2, 3, 0, 5],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:59.249411 GPU 1 69607 test begin: paddle.nextafter(Tensor([2, 3, 4, 0],"float32"), Tensor([2, 3, 4, 0],"float32"), )
[cuda error] paddle.nextafter(Tensor([2, 3, 4, 0],"float32"), Tensor([2, 3, 4, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:59.249501 GPU 1 69612 test begin: paddle.nextafter(Tensor([4, 0, 2],"float32"), Tensor([4, 0, 2],"float64"), )
W0521 22:07:59.408288 69612 dygraph_functions.cc:55133] got different data type, run type promotion automatically, this may cause data type been changed.
[cuda error] paddle.nextafter(Tensor([4, 0, 2],"float32"), Tensor([4, 0, 2],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:59.251364 GPU 1 69605 test begin: paddle.nextafter(Tensor([4, 0, 2],"float64"), Tensor([4, 0, 2],"float32"), )
[cuda error] paddle.nextafter(Tensor([4, 0, 2],"float64"), Tensor([4, 0, 2],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:59.252451 GPU 1 69596 test begin: paddle.nextafter(Tensor([4, 3, 0],"float32"), Tensor([4, 3, 0],"float64"), )
W0521 22:07:59.407799 69596 dygraph_functions.cc:55133] got different data type, run type promotion automatically, this may cause data type been changed.
[cuda error] paddle.nextafter(Tensor([4, 3, 0],"float32"), Tensor([4, 3, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:59.255089 GPU 1 69604 test begin: paddle.nextafter(Tensor([4, 3, 0],"float64"), Tensor([4, 3, 0],"float32"), )
W0521 22:07:59.582816 69604 dygraph_functions.cc:55133] got different data type, run type promotion automatically, this may cause data type been changed.
[cuda error] paddle.nextafter(Tensor([4, 3, 0],"float64"), Tensor([4, 3, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:59.280611 GPU 1 69629 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([0, 1024, 49],"float32"), 1, None, )
[paddle error] paddle.nn.functional.adaptive_avg_pool1d(Tensor([0, 1024, 49],"float32"), 1, None, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:59.291291 GPU 1 69606 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([0, 256, 16],"float32"), 1, None, )
[paddle error] paddle.nn.functional.adaptive_avg_pool1d(Tensor([0, 256, 16],"float32"), 1, None, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:59.297267 GPU 1 69615 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([0, 3, 32],"float32"), 16, )
[cuda error] paddle.nn.functional.adaptive_avg_pool1d(Tensor([0, 3, 32],"float32"), 16, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:59.297338 GPU 1 69610 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([0, 3, 32],"float32"), 16, None, )
[cuda error] paddle.nn.functional.adaptive_avg_pool1d(Tensor([0, 3, 32],"float32"), 16, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:59.298677 GPU 1 69621 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([0, 3, 32],"float32"), output_size=16, )
[cuda error] paddle.nn.functional.adaptive_avg_pool1d(Tensor([0, 3, 32],"float32"), output_size=16, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:59.332136 GPU 1 69603 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([0, 3, 8],"float32"), 2, None, )
[cuda error] paddle.nn.functional.adaptive_avg_pool1d(Tensor([0, 3, 8],"float32"), 2, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:59.344313 GPU 1 69613 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([0, 3, 8],"float64"), 2, None, )
[cuda error] paddle.nn.functional.adaptive_avg_pool1d(Tensor([0, 3, 8],"float64"), 2, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:59.408276 GPU 1 69605 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([0, 3, 8],"float64"), 4, None, )
[cuda error] paddle.nn.functional.adaptive_avg_pool1d(Tensor([0, 3, 8],"float64"), 4, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:59.408352 GPU 1 69606 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([0, 3, 8],"float64"), 8, None, )
[cuda error] paddle.nn.functional.adaptive_avg_pool1d(Tensor([0, 3, 8],"float64"), 8, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:59.409590 GPU 1 69612 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([12, 0, 16],"float32"), 1, None, )
[paddle error] paddle.nn.functional.adaptive_avg_pool1d(Tensor([12, 0, 16],"float32"), 1, None, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:59.409818 GPU 1 69596 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([12, 0, 49],"float32"), 1, None, )
[paddle error] paddle.nn.functional.adaptive_avg_pool1d(Tensor([12, 0, 49],"float32"), 1, None, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:07:59.411786 GPU 1 69617 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([12, 1024, 0],"float32"), 1, None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   Pool2dGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::pool2d_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, bool, bool, std::string const&, std::string const&, bool, bool, std::string const&, paddle::Tensor*)
4   void phi::Pool2dGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, bool, bool, std::string const&, std::string const&, bool, bool, std::string const&, phi::DenseTensor*)
5   void phi::PoolGradRawKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, bool, std::string const&, std::string const&, bool, bool, std::string const&, float, phi::DenseTensor*)
6   phi::funcs::Pool2dGradFunctor<phi::GPUContext, phi::funcs::AvgPoolGrad<float>, float>::operator()(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string, bool, bool, phi::DenseTensor*, phi::funcs::AvgPoolGrad<float>)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836479 (unix time) try "date -d @1747836479" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fbf1d5fec0c) received by PID 69617 (TID 0x7fc026c82740) from PID 492825612 ***]


2025-05-21 22:07:59.413021 GPU 1 69607 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([12, 256, 0],"float32"), 1, None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   Pool2dGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::pool2d_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, bool, bool, std::string const&, std::string const&, bool, bool, std::string const&, paddle::Tensor*)
4   void phi::Pool2dGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, bool, bool, std::string const&, std::string const&, bool, bool, std::string const&, phi::DenseTensor*)
5   void phi::PoolGradRawKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, bool, std::string const&, std::string const&, bool, bool, std::string const&, float, phi::DenseTensor*)
6   phi::funcs::Pool2dGradFunctor<phi::GPUContext, phi::funcs::AvgPoolGrad<float>, float>::operator()(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string, bool, bool, phi::DenseTensor*, phi::funcs::AvgPoolGrad<float>)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836479 (unix time) try "date -d @1747836479" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fd2bcae8c0c) received by PID 69607 (TID 0x7fd3c616e740) from PID 18446744072580140044 ***]


2025-05-21 22:07:59.499905 GPU 1 69602 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([2, 0, 32],"float32"), 16, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_pool2d(_object*, _object*, _object*)
1   pool2d_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, std::vector<long, std::allocator<long> >, std::vector<long, std::allocator<long> >, bool, bool, std::string, std::string, bool, bool, std::string)
2   paddle::experimental::pool2d(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, bool, bool, std::string const&, std::string const&, bool, bool, std::string const&)
3   void phi::Pool2dKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, bool, bool, std::string const&, std::string const&, bool, bool, std::string const&, phi::DenseTensor*)
4   void phi::PoolRawKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, bool, std::string const&, std::string const&, bool, bool, std::string const&, float, phi::DenseTensor*)
5   phi::funcs::Pool2dFunctor<phi::GPUContext, phi::funcs::AvgPool<float>, float>::operator()(phi::GPUContext const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string, bool, bool, phi::DenseTensor*, phi::funcs::AvgPool<float>)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836480 (unix time) try "date -d @1747836480" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f32637c30fb) received by PID 69602 (TID 0x7f336ce6d740) from PID 1669083387 ***]


2025-05-21 22:07:59.504168 GPU 1 69600 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([2, 0, 32],"float32"), 16, None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_pool2d(_object*, _object*, _object*)
1   pool2d_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, std::vector<long, std::allocator<long> >, std::vector<long, std::allocator<long> >, bool, bool, std::string, std::string, bool, bool, std::string)
2   paddle::experimental::pool2d(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, bool, bool, std::string const&, std::string const&, bool, bool, std::string const&)
3   void phi::Pool2dKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, bool, bool, std::string const&, std::string const&, bool, bool, std::string const&, phi::DenseTensor*)
4   void phi::PoolRawKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, bool, std::string const&, std::string const&, bool, bool, std::string const&, float, phi::DenseTensor*)
5   phi::funcs::Pool2dFunctor<phi::GPUContext, phi::funcs::AvgPool<float>, float>::operator()(phi::GPUContext const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string, bool, bool, phi::DenseTensor*, phi::funcs::AvgPool<float>)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836479 (unix time) try "date -d @1747836479" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f2a324800fb) received by PID 69600 (TID 0x7f2b3bb2a740) from PID 843579643 ***]


2025-05-21 22:07:59.573338 GPU 1 69606 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([2, 0, 32],"float32"), output_size=16, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_pool2d(_object*, _object*, _object*)
1   pool2d_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, std::vector<long, std::allocator<long> >, std::vector<long, std::allocator<long> >, bool, bool, std::string, std::string, bool, bool, std::string)
2   paddle::experimental::pool2d(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, bool, bool, std::string const&, std::string const&, bool, bool, std::string const&)
3   void phi::Pool2dKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, bool, bool, std::string const&, std::string const&, bool, bool, std::string const&, phi::DenseTensor*)
4   void phi::PoolRawKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, bool, std::string const&, std::string const&, bool, bool, std::string const&, float, phi::DenseTensor*)
5   phi::funcs::Pool2dFunctor<phi::GPUContext, phi::funcs::AvgPool<float>, float>::operator()(phi::GPUContext const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string, bool, bool, phi::DenseTensor*, phi::funcs::AvgPool<float>)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836479 (unix time) try "date -d @1747836479" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f25694300fb) received by PID 69606 (TID 0x7f2672ada740) from PID 1765998843 ***]


2025-05-21 22:07:59.573780 GPU 1 69615 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([2, 0, 8],"float32"), 2, None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_pool2d(_object*, _object*, _object*)
1   pool2d_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, std::vector<long, std::allocator<long> >, std::vector<long, std::allocator<long> >, bool, bool, std::string, std::string, bool, bool, std::string)
2   paddle::experimental::pool2d(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, bool, bool, std::string const&, std::string const&, bool, bool, std::string const&)
3   void phi::Pool2dKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, bool, bool, std::string const&, std::string const&, bool, bool, std::string const&, phi::DenseTensor*)
4   void phi::PoolRawKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, bool, std::string const&, std::string const&, bool, bool, std::string const&, float, phi::DenseTensor*)
5   phi::funcs::Pool2dFunctor<phi::GPUContext, phi::funcs::AvgPool<float>, float>::operator()(phi::GPUContext const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string, bool, bool, phi::DenseTensor*, phi::funcs::AvgPool<float>)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836479 (unix time) try "date -d @1747836479" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f7110b980fb) received by PID 69615 (TID 0x7f721a242740) from PID 280592635 ***]


2025-05-21 22:07:59.574027 GPU 1 69612 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([2, 0, 8],"float64"), 2, None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_pool2d(_object*, _object*, _object*)
1   pool2d_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, std::vector<long, std::allocator<long> >, std::vector<long, std::allocator<long> >, bool, bool, std::string, std::string, bool, bool, std::string)
2   paddle::experimental::pool2d(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, bool, bool, std::string const&, std::string const&, bool, bool, std::string const&)
3   void phi::Pool2dKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, bool, bool, std::string const&, std::string const&, bool, bool, std::string const&, phi::DenseTensor*)
4   void phi::PoolRawKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, bool, std::string const&, std::string const&, bool, bool, std::string const&, float, phi::DenseTensor*)
5   phi::funcs::Pool2dFunctor<phi::GPUContext, phi::funcs::AvgPool<double>, double>::operator()(phi::GPUContext const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string, bool, bool, phi::DenseTensor*, phi::funcs::AvgPool<double>)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836479 (unix time) try "date -d @1747836479" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f12895a6c4b) received by PID 69612 (TID 0x7f1392c4e740) from PID 18446744071718988875 ***]


2025-05-21 22:07:59.574284 GPU 1 69605 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([2, 0, 8],"float64"), 4, None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_pool2d(_object*, _object*, _object*)
1   pool2d_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, std::vector<long, std::allocator<long> >, std::vector<long, std::allocator<long> >, bool, bool, std::string, std::string, bool, bool, std::string)
2   paddle::experimental::pool2d(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, bool, bool, std::string const&, std::string const&, bool, bool, std::string const&)
3   void phi::Pool2dKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, bool, bool, std::string const&, std::string const&, bool, bool, std::string const&, phi::DenseTensor*)
4   void phi::PoolRawKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, bool, std::string const&, std::string const&, bool, bool, std::string const&, float, phi::DenseTensor*)
5   phi::funcs::Pool2dFunctor<phi::GPUContext, phi::funcs::AvgPool<double>, double>::operator()(phi::GPUContext const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string, bool, bool, phi::DenseTensor*, phi::funcs::AvgPool<double>)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836479 (unix time) try "date -d @1747836479" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fd76eeb4c4b) received by PID 69605 (TID 0x7fd87855c740) from PID 1860914251 ***]


2025-05-21 22:07:59.576212 GPU 1 69610 test begin: paddle.nn.functional.adaptive_avg_pool1d(Tensor([2, 0, 8],"float64"), 8, None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_pool2d(_object*, _object*, _object*)
1   pool2d_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, std::vector<long, std::allocator<long> >, std::vector<long, std::allocator<long> >, bool, bool, std::string, std::string, bool, bool, std::string)
2   paddle::experimental::pool2d(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, bool, bool, std::string const&, std::string const&, bool, bool, std::string const&)
3   void phi::Pool2dKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, bool, bool, std::string const&, std::string const&, bool, bool, std::string const&, phi::DenseTensor*)
4   void phi::PoolRawKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, bool, std::string const&, std::string const&, bool, bool, std::string const&, float, phi::DenseTensor*)
5   phi::funcs::Pool2dFunctor<phi::GPUContext, phi::funcs::AvgPool<double>, double>::operator()(phi::GPUContext const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string, bool, bool, phi::DenseTensor*, phi::funcs::AvgPool<double>)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836479 (unix time) try "date -d @1747836479" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f5bfd98ec4b) received by PID 69610 (TID 0x7f5d07036740) from PID 18446744073669241931 ***]


2025-05-21 22:07:59.579930 GPU 1 69596 test begin: paddle.nn.functional.adaptive_avg_pool1d(x=Tensor([0, 3, 8],"float32"), output_size=2, )
[cuda error] paddle.nn.functional.adaptive_avg_pool1d(x=Tensor([0, 3, 8],"float32"), output_size=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:59.583194 GPU 1 69629 test begin: paddle.nn.functional.adaptive_avg_pool1d(x=Tensor([0, 3, 8],"float64"), output_size=2, )
[cuda error] paddle.nn.functional.adaptive_avg_pool1d(x=Tensor([0, 3, 8],"float64"), output_size=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:59.583850 GPU 1 69604 test begin: paddle.nn.functional.adaptive_avg_pool1d(x=Tensor([0, 3, 8],"float64"), output_size=4, )
[cuda error] paddle.nn.functional.adaptive_avg_pool1d(x=Tensor([0, 3, 8],"float64"), output_size=4, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:59.615422 GPU 1 69603 test begin: paddle.nn.functional.adaptive_avg_pool1d(x=Tensor([0, 3, 8],"float64"), output_size=8, )
[cuda error] paddle.nn.functional.adaptive_avg_pool1d(x=Tensor([0, 3, 8],"float64"), output_size=8, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:59.623881 GPU 1 69621 test begin: paddle.nn.functional.adaptive_avg_pool1d(x=Tensor([2, 0, 8],"float32"), output_size=2, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_pool2d(_object*, _object*, _object*)
1   pool2d_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, std::vector<long, std::allocator<long> >, std::vector<long, std::allocator<long> >, bool, bool, std::string, std::string, bool, bool, std::string)
2   paddle::experimental::pool2d(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, bool, bool, std::string const&, std::string const&, bool, bool, std::string const&)
3   void phi::Pool2dKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, bool, bool, std::string const&, std::string const&, bool, bool, std::string const&, phi::DenseTensor*)
4   void phi::PoolRawKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, bool, std::string const&, std::string const&, bool, bool, std::string const&, float, phi::DenseTensor*)
5   phi::funcs::Pool2dFunctor<phi::GPUContext, phi::funcs::AvgPool<float>, float>::operator()(phi::GPUContext const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string, bool, bool, phi::DenseTensor*, phi::funcs::AvgPool<float>)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836479 (unix time) try "date -d @1747836479" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f47128570fb) received by PID 69621 (TID 0x7f481bf01740) from PID 310735099 ***]


2025-05-21 22:07:59.678100 GPU 1 69613 test begin: paddle.nn.functional.adaptive_avg_pool1d(x=Tensor([2, 0, 8],"float64"), output_size=2, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_pool2d(_object*, _object*, _object*)
1   pool2d_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, std::vector<long, std::allocator<long> >, std::vector<long, std::allocator<long> >, bool, bool, std::string, std::string, bool, bool, std::string)
2   paddle::experimental::pool2d(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, bool, bool, std::string const&, std::string const&, bool, bool, std::string const&)
3   void phi::Pool2dKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, bool, bool, std::string const&, std::string const&, bool, bool, std::string const&, phi::DenseTensor*)
4   void phi::PoolRawKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, bool, std::string const&, std::string const&, bool, bool, std::string const&, float, phi::DenseTensor*)
5   phi::funcs::Pool2dFunctor<phi::GPUContext, phi::funcs::AvgPool<double>, double>::operator()(phi::GPUContext const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string, bool, bool, phi::DenseTensor*, phi::funcs::AvgPool<double>)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836480 (unix time) try "date -d @1747836480" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f3c0c3b5c4b) received by PID 69613 (TID 0x7f3d15a5d740) from PID 205216843 ***]


2025-05-21 22:07:59.745915 GPU 1 69596 test begin: paddle.nn.functional.adaptive_avg_pool1d(x=Tensor([2, 0, 8],"float64"), output_size=4, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_pool2d(_object*, _object*, _object*)
1   pool2d_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, std::vector<long, std::allocator<long> >, std::vector<long, std::allocator<long> >, bool, bool, std::string, std::string, bool, bool, std::string)
2   paddle::experimental::pool2d(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, bool, bool, std::string const&, std::string const&, bool, bool, std::string const&)
3   void phi::Pool2dKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, bool, bool, std::string const&, std::string const&, bool, bool, std::string const&, phi::DenseTensor*)
4   void phi::PoolRawKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, bool, std::string const&, std::string const&, bool, bool, std::string const&, float, phi::DenseTensor*)
5   phi::funcs::Pool2dFunctor<phi::GPUContext, phi::funcs::AvgPool<double>, double>::operator()(phi::GPUContext const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string, bool, bool, phi::DenseTensor*, phi::funcs::AvgPool<double>)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836479 (unix time) try "date -d @1747836479" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f1565f06c4b) received by PID 69596 (TID 0x7f166f5ae740) from PID 1710255179 ***]


2025-05-21 22:07:59.786008 GPU 1 69629 test begin: paddle.nn.functional.adaptive_avg_pool1d(x=Tensor([2, 0, 8],"float64"), output_size=8, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_pool2d(_object*, _object*, _object*)
1   pool2d_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, std::vector<long, std::allocator<long> >, std::vector<long, std::allocator<long> >, bool, bool, std::string, std::string, bool, bool, std::string)
2   paddle::experimental::pool2d(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, bool, bool, std::string const&, std::string const&, bool, bool, std::string const&)
3   void phi::Pool2dKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, bool, bool, std::string const&, std::string const&, bool, bool, std::string const&, phi::DenseTensor*)
4   void phi::PoolRawKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, bool, std::string const&, std::string const&, bool, bool, std::string const&, float, phi::DenseTensor*)
5   phi::funcs::Pool2dFunctor<phi::GPUContext, phi::funcs::AvgPool<double>, double>::operator()(phi::GPUContext const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string, bool, bool, phi::DenseTensor*, phi::funcs::AvgPool<double>)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836480 (unix time) try "date -d @1747836480" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f111c708c4b) received by PID 69629 (TID 0x7f1225db0740) from PID 477137995 ***]


2025-05-21 22:07:59.790697 GPU 1 69611 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([0, 1, 4],"float64"), 4, True, None, )
element 1 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.nn.functional.adaptive_max_pool1d(Tensor([0, 1, 4],"float64"), 4, True, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:59.949607 GPU 1 69611 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([0, 3, 32],"float32"), 16, False, None, )
[cuda error] paddle.nn.functional.adaptive_max_pool1d(Tensor([0, 3, 32],"float32"), 16, False, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:07:59.963015 GPU 1 69604 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([0, 3, 32],"float32"), output_size=16, )
[cuda error] paddle.nn.functional.adaptive_max_pool1d(Tensor([0, 3, 32],"float32"), output_size=16, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:00.015854 GPU 1 69603 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([0, 3, 32],"float64"), 8, False, None, )
[cuda error] paddle.nn.functional.adaptive_max_pool1d(Tensor([0, 3, 32],"float64"), 8, False, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:00.098783 GPU 1 69611 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([0, 3, 8],"float32"), 4, False, None, )
[cuda error] paddle.nn.functional.adaptive_max_pool1d(Tensor([0, 3, 8],"float32"), 4, False, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:00.121527 GPU 1 69604 test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([0, 3, 8],"float64"), 4, False, None, )
[cuda error] paddle.nn.functional.adaptive_max_pool1d(Tensor([0, 3, 8],"float64"), 4, False, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:00.170517 GPU 1 69603 test begin: paddle.nn.functional.adaptive_max_pool1d(x=Tensor([0, 1, 4],"float64"), output_size=4, return_mask=True, )
element 1 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.nn.functional.adaptive_max_pool1d(x=Tensor([0, 1, 4],"float64"), output_size=4, return_mask=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:00.256057 GPU 1 69611 test begin: paddle.nn.functional.adaptive_max_pool1d(x=Tensor([0, 3, 32],"float64"), output_size=8, )
[cuda error] paddle.nn.functional.adaptive_max_pool1d(x=Tensor([0, 3, 32],"float64"), output_size=8, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:00.282778 GPU 1 69604 test begin: paddle.nn.functional.adaptive_max_pool1d(x=Tensor([0, 3, 8],"float32"), output_size=4, )
[cuda error] paddle.nn.functional.adaptive_max_pool1d(x=Tensor([0, 3, 8],"float32"), output_size=4, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:00.283382 GPU 1 69603 test begin: paddle.nn.functional.adaptive_max_pool1d(x=Tensor([0, 3, 8],"float64"), output_size=4, )
[cuda error] paddle.nn.functional.adaptive_max_pool1d(x=Tensor([0, 3, 8],"float64"), output_size=4, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:00.388616 GPU 1 69603 test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([0, 1, 5, 5],"float32"), output_size=3, return_mask=True, name=None, )
element 1 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.nn.functional.adaptive_max_pool2d(Tensor([0, 1, 5, 5],"float32"), output_size=3, return_mask=True, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:00.423771 GPU 1 69611 test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([0, 1, 5, 5],"float64"), output_size=3, return_mask=True, name=None, )
element 1 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.nn.functional.adaptive_max_pool2d(Tensor([0, 1, 5, 5],"float64"), output_size=3, return_mask=True, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:00.425200 GPU 1 69604 test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([0, 1, 8, 8],"float32"), output_size=3, return_mask=False, name=None, )
[cuda error] paddle.nn.functional.adaptive_max_pool2d(Tensor([0, 1, 8, 8],"float32"), output_size=3, return_mask=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:00.506842 GPU 1 69603 test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([0, 1, 8, 8],"float64"), output_size=3, return_mask=False, name=None, )
[cuda error] paddle.nn.functional.adaptive_max_pool2d(Tensor([0, 1, 8, 8],"float64"), output_size=3, return_mask=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:00.537180 GPU 1 69611 test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([0, 2, 8, 8],"float64"), output_size=4, return_mask=False, name=None, )
[cuda error] paddle.nn.functional.adaptive_max_pool2d(Tensor([0, 2, 8, 8],"float64"), output_size=4, return_mask=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:00.583531 GPU 1 69604 test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([0, 3, 7, 7],"float32"), output_size=5, return_mask=False, name=None, )
[cuda error] paddle.nn.functional.adaptive_max_pool2d(Tensor([0, 3, 7, 7],"float32"), output_size=5, return_mask=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:00.651444 GPU 1 69603 test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([0, 3, 7, 7],"float32"), output_size=list[2,5,], return_mask=False, name=None, )
[cuda error] paddle.nn.functional.adaptive_max_pool2d(Tensor([0, 3, 7, 7],"float32"), output_size=list[2,5,], return_mask=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:00.655902 GPU 1 69611 test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([0, 3, 7, 7],"float32"), output_size=list[3,3,], return_mask=False, name=None, )
[cuda error] paddle.nn.functional.adaptive_max_pool2d(Tensor([0, 3, 7, 7],"float32"), output_size=list[3,3,], return_mask=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:00.718113 GPU 1 69604 test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([0, 3, 7, 7],"float32"), output_size=list[None,3,], return_mask=False, name=None, )
[cuda error] paddle.nn.functional.adaptive_max_pool2d(Tensor([0, 3, 7, 7],"float32"), output_size=list[None,3,], return_mask=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:00.770841 GPU 1 69611 test begin: paddle.nn.functional.adaptive_max_pool2d(x=Tensor([0, 1, 5, 5],"float32"), output_size=3, return_mask=True, )
element 1 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.nn.functional.adaptive_max_pool2d(x=Tensor([0, 1, 5, 5],"float32"), output_size=3, return_mask=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:00.784239 GPU 1 69603 test begin: paddle.nn.functional.adaptive_max_pool2d(x=Tensor([0, 1, 5, 5],"float64"), output_size=3, return_mask=True, )
element 1 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.nn.functional.adaptive_max_pool2d(x=Tensor([0, 1, 5, 5],"float64"), output_size=3, return_mask=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:00.830263 GPU 1 69604 test begin: paddle.nn.functional.adaptive_max_pool2d(x=Tensor([0, 1, 8, 8],"float32"), output_size=3, )
[cuda error] paddle.nn.functional.adaptive_max_pool2d(x=Tensor([0, 1, 8, 8],"float32"), output_size=3, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:00.879084 GPU 1 69611 test begin: paddle.nn.functional.adaptive_max_pool2d(x=Tensor([0, 1, 8, 8],"float64"), output_size=3, )
[cuda error] paddle.nn.functional.adaptive_max_pool2d(x=Tensor([0, 1, 8, 8],"float64"), output_size=3, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:00.909732 GPU 1 69603 test begin: paddle.nn.functional.adaptive_max_pool2d(x=Tensor([0, 2, 8, 8],"float64"), output_size=4, )
[cuda error] paddle.nn.functional.adaptive_max_pool2d(x=Tensor([0, 2, 8, 8],"float64"), output_size=4, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:00.957198 GPU 1 69604 test begin: paddle.nn.functional.adaptive_max_pool2d(x=Tensor([0, 3, 7, 7],"float32"), output_size=5, )
[cuda error] paddle.nn.functional.adaptive_max_pool2d(x=Tensor([0, 3, 7, 7],"float32"), output_size=5, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:00.997510 GPU 1 69611 test begin: paddle.nn.functional.adaptive_max_pool2d(x=Tensor([0, 3, 7, 7],"float32"), output_size=list[2,5,], )
[cuda error] paddle.nn.functional.adaptive_max_pool2d(x=Tensor([0, 3, 7, 7],"float32"), output_size=list[2,5,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:01.123359 GPU 1 69611 test begin: paddle.nn.functional.adaptive_max_pool2d(x=Tensor([0, 3, 7, 7],"float32"), output_size=list[None,3,], )
[cuda error] paddle.nn.functional.adaptive_max_pool2d(x=Tensor([0, 3, 7, 7],"float32"), output_size=list[None,3,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:01.191564 GPU 1 69603 test begin: paddle.nn.functional.adaptive_max_pool2d(x=Tensor([0, 3, 7, 7],"float32"), return_mask=False, output_size=list[3,3,], )
[cuda error] paddle.nn.functional.adaptive_max_pool2d(x=Tensor([0, 3, 7, 7],"float32"), return_mask=False, output_size=list[3,3,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:01.266657 GPU 1 69611 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([0, 1, 5, 5, 5],"float32"), output_size=3, return_mask=True, name=None, )
element 1 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.nn.functional.adaptive_max_pool3d(Tensor([0, 1, 5, 5, 5],"float32"), output_size=3, return_mask=True, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:01.298162 GPU 1 69604 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([0, 1, 5, 5, 5],"float64"), output_size=3, return_mask=True, name=None, )
element 1 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.nn.functional.adaptive_max_pool3d(Tensor([0, 1, 5, 5, 5],"float64"), output_size=3, return_mask=True, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:01.462246 GPU 1 69603 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([0, 2, 8, 8, 8],"float32"), output_size=4, return_mask=False, name=None, )
[cuda error] paddle.nn.functional.adaptive_max_pool3d(Tensor([0, 2, 8, 8, 8],"float32"), output_size=4, return_mask=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:01.521987 GPU 1 69604 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([0, 2, 8, 8, 8],"float64"), output_size=4, return_mask=False, name=None, )
[cuda error] paddle.nn.functional.adaptive_max_pool3d(Tensor([0, 2, 8, 8, 8],"float64"), output_size=4, return_mask=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:01.669432 GPU 1 69604 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([0, 3, 5, 7, 7],"float32"), output_size=5, return_mask=False, name=None, )
[cuda error] paddle.nn.functional.adaptive_max_pool3d(Tensor([0, 3, 5, 7, 7],"float32"), output_size=5, return_mask=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:01.701920 GPU 1 69611 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([0, 3, 5, 7, 7],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, )
[cuda error] paddle.nn.functional.adaptive_max_pool3d(Tensor([0, 3, 5, 7, 7],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:01.722279 GPU 1 69603 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([0, 3, 5, 7, 7],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, )
[cuda error] paddle.nn.functional.adaptive_max_pool3d(Tensor([0, 3, 5, 7, 7],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:01.819432 GPU 1 69604 test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([0, 3, 5, 7, 7],"float32"), output_size=list[None,3,None,], return_mask=False, name=None, )
[cuda error] paddle.nn.functional.adaptive_max_pool3d(Tensor([0, 3, 5, 7, 7],"float32"), output_size=list[None,3,None,], return_mask=False, name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:01.936308 GPU 1 69604 test begin: paddle.nn.functional.adaptive_max_pool3d(x=Tensor([0, 1, 5, 5, 5],"float32"), output_size=3, return_mask=True, )
element 1 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.nn.functional.adaptive_max_pool3d(x=Tensor([0, 1, 5, 5, 5],"float32"), output_size=3, return_mask=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:02.041194 GPU 1 69611 test begin: paddle.nn.functional.adaptive_max_pool3d(x=Tensor([0, 1, 5, 5, 5],"float64"), output_size=3, return_mask=True, )
element 1 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.nn.functional.adaptive_max_pool3d(x=Tensor([0, 1, 5, 5, 5],"float64"), output_size=3, return_mask=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:02.052914 GPU 1 69604 test begin: paddle.nn.functional.adaptive_max_pool3d(x=Tensor([0, 2, 8, 8, 8],"float32"), output_size=4, )
[cuda error] paddle.nn.functional.adaptive_max_pool3d(x=Tensor([0, 2, 8, 8, 8],"float32"), output_size=4, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:02.116906 GPU 1 69603 test begin: paddle.nn.functional.adaptive_max_pool3d(x=Tensor([0, 2, 8, 8, 8],"float64"), output_size=4, )
[cuda error] paddle.nn.functional.adaptive_max_pool3d(x=Tensor([0, 2, 8, 8, 8],"float64"), output_size=4, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:02.170142 GPU 1 69604 test begin: paddle.nn.functional.adaptive_max_pool3d(x=Tensor([0, 3, 5, 7, 7],"float32"), output_size=5, )
[cuda error] paddle.nn.functional.adaptive_max_pool3d(x=Tensor([0, 3, 5, 7, 7],"float32"), output_size=5, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:02.179653 GPU 1 69611 test begin: paddle.nn.functional.adaptive_max_pool3d(x=Tensor([0, 3, 5, 7, 7],"float32"), output_size=list[2,3,5,], )
[cuda error] paddle.nn.functional.adaptive_max_pool3d(x=Tensor([0, 3, 5, 7, 7],"float32"), output_size=list[2,3,5,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:02.291611 GPU 1 69604 test begin: paddle.nn.functional.adaptive_max_pool3d(x=Tensor([0, 3, 5, 7, 7],"float32"), output_size=list[3,3,3,], )
[cuda error] paddle.nn.functional.adaptive_max_pool3d(x=Tensor([0, 3, 5, 7, 7],"float32"), output_size=list[3,3,3,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:02.317878 GPU 1 69611 test begin: paddle.nn.functional.adaptive_max_pool3d(x=Tensor([0, 3, 5, 7, 7],"float32"), output_size=list[None,3,None,], )
[cuda error] paddle.nn.functional.adaptive_max_pool3d(x=Tensor([0, 3, 5, 7, 7],"float32"), output_size=list[None,3,None,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:02.318663 GPU 1 69603 test begin: paddle.nn.functional.cosine_similarity(Tensor([0, 12, 10],"float32"), Tensor([0, 1, 10],"float32"), axis=2, eps=1e-06, )
[accuracy error] backward  paddle.nn.functional.cosine_similarity(Tensor([0, 12, 10],"float32"), Tensor([0, 1, 10],"float32"), axis=2, eps=1e-06, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (0, 10), (0, 1, 10) mismatch)
 ACTUAL: array([], shape=(0, 10), dtype=float32)
 DESIRED: array([], shape=(0, 1, 10), dtype=float32)

2025-05-21 22:08:02.407077 GPU 1 69604 test begin: paddle.nn.functional.cosine_similarity(Tensor([0, 5, 2],"float64"), Tensor([1, 5, 2],"float64"), axis=-1, eps=1e-08, )
[accuracy error] backward  paddle.nn.functional.cosine_similarity(Tensor([0, 5, 2],"float64"), Tensor([1, 5, 2],"float64"), axis=-1, eps=1e-08, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (5, 2), (1, 5, 2) mismatch)
 ACTUAL: array([[0., 0.],
       [0., 0.],
       [0., 0.],...
 DESIRED: array([[[0., 0.],
        [0., 0.],
        [0., 0.],...

2025-05-21 22:08:02.461284 GPU 1 69611 test begin: paddle.nn.functional.cosine_similarity(Tensor([0, 5, 2],"float64"), Tensor([1, 5, 2],"float64"), axis=-2, eps=1e-08, )
[accuracy error] backward  paddle.nn.functional.cosine_similarity(Tensor([0, 5, 2],"float64"), Tensor([1, 5, 2],"float64"), axis=-2, eps=1e-08, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (5, 2), (1, 5, 2) mismatch)
 ACTUAL: array([[0., 0.],
       [0., 0.],
       [0., 0.],...
 DESIRED: array([[[0., 0.],
        [0., 0.],
        [0., 0.],...

2025-05-21 22:08:02.474007 GPU 1 69603 test begin: paddle.nn.functional.cosine_similarity(Tensor([0, 5, 2],"float64"), Tensor([1, 5, 2],"float64"), axis=0, eps=1e-08, )
[accuracy error] backward  paddle.nn.functional.cosine_similarity(Tensor([0, 5, 2],"float64"), Tensor([1, 5, 2],"float64"), axis=0, eps=1e-08, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (5, 2), (1, 5, 2) mismatch)
 ACTUAL: array([[0., 0.],
       [0., 0.],
       [0., 0.],...
 DESIRED: array([[[0., 0.],
        [0., 0.],
        [0., 0.],...

2025-05-21 22:08:02.646856 GPU 1 69604 test begin: paddle.nn.functional.cosine_similarity(Tensor([0, 5, 2],"float64"), Tensor([1, 5, 2],"float64"), axis=1, eps=1e-08, )
[accuracy error] backward  paddle.nn.functional.cosine_similarity(Tensor([0, 5, 2],"float64"), Tensor([1, 5, 2],"float64"), axis=1, eps=1e-08, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (5, 2), (1, 5, 2) mismatch)
 ACTUAL: array([[0., 0.],
       [0., 0.],
       [0., 0.],...
 DESIRED: array([[[0., 0.],
        [0., 0.],
        [0., 0.],...

2025-05-21 22:08:02.822697 GPU 1 69611 test begin: paddle.nn.functional.cosine_similarity(Tensor([0, 5, 2],"float64"), Tensor([1, 5, 2],"float64"), axis=2, eps=1e-08, )
[accuracy error] backward  paddle.nn.functional.cosine_similarity(Tensor([0, 5, 2],"float64"), Tensor([1, 5, 2],"float64"), axis=2, eps=1e-08, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (5, 2), (1, 5, 2) mismatch)
 ACTUAL: array([[0., 0.],
       [0., 0.],
       [0., 0.],...
 DESIRED: array([[[0., 0.],
        [0., 0.],
        [0., 0.],...

2025-05-21 22:08:02.834927 GPU 1 69604 test begin: paddle.nn.functional.cosine_similarity(Tensor([0, 5],"float64"), Tensor([1, 5],"float64"), axis=1, eps=1e-06, )
[accuracy error] backward  paddle.nn.functional.cosine_similarity(Tensor([0, 5],"float64"), Tensor([1, 5],"float64"), axis=1, eps=1e-06, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (5,), (1, 5) mismatch)
 ACTUAL: array([0., 0., 0., 0., 0.])
 DESIRED: array([[0., 0., 0., 0., 0.]])

2025-05-21 22:08:02.942262 GPU 1 69603 test begin: paddle.nn.functional.cosine_similarity(Tensor([0, 5],"float64"), Tensor([1, 5],"float64"), axis=1, eps=1e-07, )
[accuracy error] backward  paddle.nn.functional.cosine_similarity(Tensor([0, 5],"float64"), Tensor([1, 5],"float64"), axis=1, eps=1e-07, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (5,), (1, 5) mismatch)
 ACTUAL: array([0., 0., 0., 0., 0.])
 DESIRED: array([[0., 0., 0., 0., 0.]])

2025-05-21 22:08:03.037138 GPU 1 69604 test begin: paddle.nn.functional.cosine_similarity(Tensor([0, 5],"float64"), Tensor([1, 5],"float64"), axis=1, eps=1e-08, )
[accuracy error] backward  paddle.nn.functional.cosine_similarity(Tensor([0, 5],"float64"), Tensor([1, 5],"float64"), axis=1, eps=1e-08, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (5,), (1, 5) mismatch)
 ACTUAL: array([0., 0., 0., 0., 0.])
 DESIRED: array([[0., 0., 0., 0., 0.]])

2025-05-21 22:08:03.037250 GPU 1 69611 test begin: paddle.nn.functional.cosine_similarity(Tensor([0, 5],"float64"), Tensor([1, 5],"float64"), axis=1, eps=1e-09, )
[accuracy error] backward  paddle.nn.functional.cosine_similarity(Tensor([0, 5],"float64"), Tensor([1, 5],"float64"), axis=1, eps=1e-09, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (5,), (1, 5) mismatch)
 ACTUAL: array([0., 0., 0., 0., 0.])
 DESIRED: array([[0., 0., 0., 0., 0.]])

2025-05-21 22:08:03.143736 GPU 1 69603 test begin: paddle.nn.functional.cosine_similarity(Tensor([1, 5, 2],"float64"), Tensor([0, 5, 2],"float64"), axis=-1, eps=1e-08, )
[accuracy error] backward  paddle.nn.functional.cosine_similarity(Tensor([1, 5, 2],"float64"), Tensor([0, 5, 2],"float64"), axis=-1, eps=1e-08, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (5, 2), (1, 5, 2) mismatch)
 ACTUAL: array([[0., 0.],
       [0., 0.],
       [0., 0.],...
 DESIRED: array([[[0., 0.],
        [0., 0.],
        [0., 0.],...

2025-05-21 22:08:03.186960 GPU 1 69611 test begin: paddle.nn.functional.cosine_similarity(Tensor([1, 5, 2],"float64"), Tensor([0, 5, 2],"float64"), axis=-2, eps=1e-08, )
[accuracy error] backward  paddle.nn.functional.cosine_similarity(Tensor([1, 5, 2],"float64"), Tensor([0, 5, 2],"float64"), axis=-2, eps=1e-08, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (5, 2), (1, 5, 2) mismatch)
 ACTUAL: array([[0., 0.],
       [0., 0.],
       [0., 0.],...
 DESIRED: array([[[0., 0.],
        [0., 0.],
        [0., 0.],...

2025-05-21 22:08:03.187794 GPU 1 69604 test begin: paddle.nn.functional.cosine_similarity(Tensor([1, 5, 2],"float64"), Tensor([0, 5, 2],"float64"), axis=0, eps=1e-08, )
[accuracy error] backward  paddle.nn.functional.cosine_similarity(Tensor([1, 5, 2],"float64"), Tensor([0, 5, 2],"float64"), axis=0, eps=1e-08, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (5, 2), (1, 5, 2) mismatch)
 ACTUAL: array([[0., 0.],
       [0., 0.],
       [0., 0.],...
 DESIRED: array([[[0., 0.],
        [0., 0.],
        [0., 0.],...

2025-05-21 22:08:03.202930 GPU 1 70853 test begin: paddle.nn.functional.cosine_similarity(Tensor([1, 5, 2],"float64"), Tensor([0, 5, 2],"float64"), axis=1, eps=1e-08, )
[accuracy error] backward  paddle.nn.functional.cosine_similarity(Tensor([1, 5, 2],"float64"), Tensor([0, 5, 2],"float64"), axis=1, eps=1e-08, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (5, 2), (1, 5, 2) mismatch)
 ACTUAL: array([[0., 0.],
       [0., 0.],
       [0., 0.],...
 DESIRED: array([[[0., 0.],
        [0., 0.],
        [0., 0.],...

2025-05-21 22:08:03.335652 GPU 1 69611 test begin: paddle.nn.functional.cosine_similarity(Tensor([1, 5, 2],"float64"), Tensor([0, 5, 2],"float64"), axis=2, eps=1e-08, )
[accuracy error] backward  paddle.nn.functional.cosine_similarity(Tensor([1, 5, 2],"float64"), Tensor([0, 5, 2],"float64"), axis=2, eps=1e-08, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (5, 2), (1, 5, 2) mismatch)
 ACTUAL: array([[0., 0.],
       [0., 0.],
       [0., 0.],...
 DESIRED: array([[[0., 0.],
        [0., 0.],
        [0., 0.],...

2025-05-21 22:08:03.335929 GPU 1 69604 test begin: paddle.nn.functional.cosine_similarity(Tensor([1, 5],"float64"), Tensor([0, 5],"float64"), axis=1, eps=1e-06, )
[accuracy error] backward  paddle.nn.functional.cosine_similarity(Tensor([1, 5],"float64"), Tensor([0, 5],"float64"), axis=1, eps=1e-06, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (5,), (1, 5) mismatch)
 ACTUAL: array([0., 0., 0., 0., 0.])
 DESIRED: array([[0., 0., 0., 0., 0.]])

2025-05-21 22:08:03.350023 GPU 1 69603 test begin: paddle.nn.functional.cosine_similarity(Tensor([1, 5],"float64"), Tensor([0, 5],"float64"), axis=1, eps=1e-07, )
[accuracy error] backward  paddle.nn.functional.cosine_similarity(Tensor([1, 5],"float64"), Tensor([0, 5],"float64"), axis=1, eps=1e-07, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (5,), (1, 5) mismatch)
 ACTUAL: array([0., 0., 0., 0., 0.])
 DESIRED: array([[0., 0., 0., 0., 0.]])

2025-05-21 22:08:03.566092 GPU 1 69611 test begin: paddle.nn.functional.cosine_similarity(Tensor([1, 5],"float64"), Tensor([0, 5],"float64"), axis=1, eps=1e-08, )
[accuracy error] backward  paddle.nn.functional.cosine_similarity(Tensor([1, 5],"float64"), Tensor([0, 5],"float64"), axis=1, eps=1e-08, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (5,), (1, 5) mismatch)
 ACTUAL: array([0., 0., 0., 0., 0.])
 DESIRED: array([[0., 0., 0., 0., 0.]])

2025-05-21 22:08:03.573050 GPU 1 69604 test begin: paddle.nn.functional.cosine_similarity(Tensor([1, 5],"float64"), Tensor([0, 5],"float64"), axis=1, eps=1e-09, )
[accuracy error] backward  paddle.nn.functional.cosine_similarity(Tensor([1, 5],"float64"), Tensor([0, 5],"float64"), axis=1, eps=1e-09, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (5,), (1, 5) mismatch)
 ACTUAL: array([0., 0., 0., 0., 0.])
 DESIRED: array([[0., 0., 0., 0., 0.]])

2025-05-21 22:08:03.720180 GPU 1 69603 test begin: paddle.nn.functional.cosine_similarity(Tensor([10, 0, 10],"float32"), Tensor([10, 1, 10],"float32"), axis=2, eps=1e-06, )
[accuracy error] backward  paddle.nn.functional.cosine_similarity(Tensor([10, 0, 10],"float32"), Tensor([10, 1, 10],"float32"), axis=2, eps=1e-06, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (10, 10), (10, 1, 10) mismatch)
 ACTUAL: array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],...
 DESIRED: array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],

       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],...

2025-05-21 22:08:04.058906 GPU 1 69603 test begin: paddle.nn.functional.cosine_similarity(Tensor([10, 12, 0],"float32"), Tensor([10, 1, 0],"float32"), axis=2, eps=1e-06, )
[accuracy error] backward  paddle.nn.functional.cosine_similarity(Tensor([10, 12, 0],"float32"), Tensor([10, 1, 0],"float32"), axis=2, eps=1e-06, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (10, 0), (10, 1, 0) mismatch)
 ACTUAL: array([], shape=(10, 0), dtype=float32)
 DESIRED: array([], shape=(10, 1, 0), dtype=float32)

2025-05-21 22:08:04.082114 GPU 1 69611 test begin: paddle.nn.functional.cosine_similarity(x1=Tensor([2, 0, 4],"float64"), x2=Tensor([2, 0, 4],"float64"), axis=1, eps=0, )
[accuracy error] paddle.nn.functional.cosine_similarity(x1=Tensor([2, 0, 4],"float64"), x2=Tensor([2, 0, 4],"float64"), axis=1, eps=0, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array([[nan, nan, nan, nan],
       [nan, nan, nan, nan]])
 DESIRED: array([[0., 0., 0., 0.],
       [0., 0., 0., 0.]])

2025-05-21 22:08:04.243272 GPU 1 69604 test begin: paddle.nn.functional.grid_sample(Tensor([0, 1, 176, 176],"float32"), Tensor([0, 1, 12544, 2],"float32"), align_corners=False, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([0, 1, 176, 176],"float32"), Tensor([0, 1, 12544, 2],"float32"), align_corners=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:04.450313 GPU 1 69604 test begin: paddle.nn.functional.grid_sample(Tensor([0, 1, 176, 176],"float32"), Tensor([0, 1, 37632, 2],"float32"), align_corners=False, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([0, 1, 176, 176],"float32"), Tensor([0, 1, 37632, 2],"float32"), align_corners=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:04.596801 GPU 1 69603 test begin: paddle.nn.functional.grid_sample(Tensor([0, 2, 3, 3],"float64"), Tensor([0, 3, 3, 2],"float64"), mode="bilinear", padding_mode="reflection", align_corners=True, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([0, 2, 3, 3],"float64"), Tensor([0, 3, 3, 2],"float64"), mode="bilinear", padding_mode="reflection", align_corners=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:04.784592 GPU 1 69611 test begin: paddle.nn.functional.grid_sample(Tensor([0, 256, 64, 64],"float32"), Tensor([0, 64, 64, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=True, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([0, 256, 64, 64],"float32"), Tensor([0, 64, 64, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:04.798438 GPU 1 69604 test begin: paddle.nn.functional.grid_sample(Tensor([0, 3, 16, 16],"float32"), Tensor([0, 16, 16, 2],"float32"), mode="bilinear", padding_mode="border", align_corners=True, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([0, 3, 16, 16],"float32"), Tensor([0, 16, 16, 2],"float32"), mode="bilinear", padding_mode="border", align_corners=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:04.904354 GPU 1 69603 test begin: paddle.nn.functional.grid_sample(Tensor([0, 3, 2, 2],"float32"), Tensor([0, 2, 2, 2],"float32"), mode="bilinear", padding_mode="border", align_corners=True, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([0, 3, 2, 2],"float32"), Tensor([0, 2, 2, 2],"float32"), mode="bilinear", padding_mode="border", align_corners=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:04.931424 GPU 1 69611 test begin: paddle.nn.functional.grid_sample(Tensor([0, 3, 256, 256],"float32"), Tensor([0, 256, 256, 2],"float32"), mode="bilinear", padding_mode="reflection", align_corners=True, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([0, 3, 256, 256],"float32"), Tensor([0, 256, 256, 2],"float32"), mode="bilinear", padding_mode="reflection", align_corners=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:05.024929 GPU 1 69604 test begin: paddle.nn.functional.grid_sample(Tensor([0, 3, 256, 256],"float32"), Tensor([0, 256, 256, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=True, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([0, 3, 256, 256],"float32"), Tensor([0, 256, 256, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:05.045384 GPU 1 69603 test begin: paddle.nn.functional.grid_sample(Tensor([0, 32, 20, 20],"float32"), Tensor([0, 476, 4, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([0, 32, 20, 20],"float32"), Tensor([0, 476, 4, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:05.072272 GPU 1 69611 test begin: paddle.nn.functional.grid_sample(Tensor([0, 4, 28, 28],"float32"), Tensor([0, 28, 28, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([0, 4, 28, 28],"float32"), Tensor([0, 28, 28, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:05.145792 GPU 1 69604 test begin: paddle.nn.functional.grid_sample(Tensor([0, 4, 28, 28],"float32"), Tensor([0, 34, 34, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([0, 4, 28, 28],"float32"), Tensor([0, 34, 34, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:05.172838 GPU 1 70896 test begin: paddle.nn.functional.grid_sample(Tensor([0, 4, 280, 350],"float32"), Tensor([0, 280, 350, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([0, 4, 280, 350],"float32"), Tensor([0, 280, 350, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:05.180019 GPU 1 69603 test begin: paddle.nn.functional.grid_sample(Tensor([1, 0, 176, 176],"float32"), Tensor([1, 0, 12544, 2],"float32"), align_corners=False, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([1, 0, 176, 176],"float32"), Tensor([1, 0, 12544, 2],"float32"), align_corners=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:05.184964 GPU 1 69611 test begin: paddle.nn.functional.grid_sample(Tensor([1, 0, 176, 176],"float32"), Tensor([1, 0, 37632, 2],"float32"), align_corners=False, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([1, 0, 176, 176],"float32"), Tensor([1, 0, 37632, 2],"float32"), align_corners=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:05.198342 GPU 1 70886 test begin: paddle.nn.functional.grid_sample(Tensor([1, 0, 28, 28],"float32"), Tensor([1, 0, 28, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([1, 0, 28, 28],"float32"), Tensor([1, 0, 28, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:05.249055 GPU 1 70910 test begin: paddle.nn.functional.grid_sample(Tensor([1, 0, 28, 28],"float32"), Tensor([1, 0, 34, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([1, 0, 28, 28],"float32"), Tensor([1, 0, 34, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:05.275925 GPU 1 69604 test begin: paddle.nn.functional.grid_sample(Tensor([1, 0, 280, 350],"float32"), Tensor([1, 0, 350, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([1, 0, 280, 350],"float32"), Tensor([1, 0, 350, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:05.284874 GPU 1 69611 test begin: paddle.nn.functional.grid_sample(Tensor([1, 1, 176, 176],"float32"), Tensor([1, 0, 12544, 2],"float32"), align_corners=False, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([1, 1, 176, 176],"float32"), Tensor([1, 0, 12544, 2],"float32"), align_corners=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:05.312620 GPU 1 69603 test begin: paddle.nn.functional.grid_sample(Tensor([1, 1, 176, 176],"float32"), Tensor([1, 0, 37632, 2],"float32"), align_corners=False, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([1, 1, 176, 176],"float32"), Tensor([1, 0, 37632, 2],"float32"), align_corners=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:05.314175 GPU 1 70902 test begin: paddle.nn.functional.grid_sample(Tensor([1, 1, 176, 176],"float32"), Tensor([1, 1, 0, 2],"float32"), align_corners=False, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([1, 1, 176, 176],"float32"), Tensor([1, 1, 0, 2],"float32"), align_corners=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:05.353088 GPU 1 70872 test begin: paddle.nn.functional.grid_sample(Tensor([1, 4, 28, 28],"float32"), Tensor([1, 0, 28, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([1, 4, 28, 28],"float32"), Tensor([1, 0, 28, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:05.419339 GPU 1 69611 test begin: paddle.nn.functional.grid_sample(Tensor([1, 4, 28, 28],"float32"), Tensor([1, 0, 34, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([1, 4, 28, 28],"float32"), Tensor([1, 0, 34, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:05.434714 GPU 1 69604 test begin: paddle.nn.functional.grid_sample(Tensor([1, 4, 28, 28],"float32"), Tensor([1, 28, 0, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([1, 4, 28, 28],"float32"), Tensor([1, 28, 0, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:05.454316 GPU 1 69603 test begin: paddle.nn.functional.grid_sample(Tensor([1, 4, 28, 28],"float32"), Tensor([1, 34, 0, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([1, 4, 28, 28],"float32"), Tensor([1, 34, 0, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:05.556915 GPU 1 69604 test begin: paddle.nn.functional.grid_sample(Tensor([1, 4, 280, 350],"float32"), Tensor([1, 0, 350, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([1, 4, 280, 350],"float32"), Tensor([1, 0, 350, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:05.557175 GPU 1 69611 test begin: paddle.nn.functional.grid_sample(Tensor([1, 4, 280, 350],"float32"), Tensor([1, 280, 0, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([1, 4, 280, 350],"float32"), Tensor([1, 280, 0, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:05.591996 GPU 1 69603 test begin: paddle.nn.functional.grid_sample(Tensor([128, 0, 20, 20],"float32"), Tensor([128, 0, 4, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([128, 0, 20, 20],"float32"), Tensor([128, 0, 4, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:05.594247 GPU 1 70936 test begin: paddle.nn.functional.grid_sample(Tensor([128, 32, 20, 20],"float32"), Tensor([128, 0, 4, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([128, 32, 20, 20],"float32"), Tensor([128, 0, 4, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:05.681793 GPU 1 69611 test begin: paddle.nn.functional.grid_sample(Tensor([128, 32, 20, 20],"float32"), Tensor([128, 476, 0, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([128, 32, 20, 20],"float32"), Tensor([128, 476, 0, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:05.684447 GPU 1 69604 test begin: paddle.nn.functional.grid_sample(Tensor([16, 0, 256, 256],"float32"), Tensor([16, 0, 256, 2],"float32"), mode="bilinear", padding_mode="reflection", align_corners=True, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([16, 0, 256, 256],"float32"), Tensor([16, 0, 256, 2],"float32"), mode="bilinear", padding_mode="reflection", align_corners=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:05.798861 GPU 1 69603 test begin: paddle.nn.functional.grid_sample(Tensor([16, 0, 256, 256],"float32"), Tensor([16, 0, 256, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=True, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([16, 0, 256, 256],"float32"), Tensor([16, 0, 256, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:05.814106 GPU 1 69604 test begin: paddle.nn.functional.grid_sample(Tensor([16, 0, 64, 64],"float32"), Tensor([16, 0, 64, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=True, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([16, 0, 64, 64],"float32"), Tensor([16, 0, 64, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:05.939832 GPU 1 70929 test begin: paddle.nn.functional.grid_sample(Tensor([16, 256, 64, 64],"float32"), Tensor([16, 0, 64, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=True, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([16, 256, 64, 64],"float32"), Tensor([16, 0, 64, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:05.946647 GPU 1 69604 test begin: paddle.nn.functional.grid_sample(Tensor([16, 256, 64, 64],"float32"), Tensor([16, 64, 0, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=True, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([16, 256, 64, 64],"float32"), Tensor([16, 64, 0, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:05.953493 GPU 1 69603 test begin: paddle.nn.functional.grid_sample(Tensor([16, 3, 256, 256],"float32"), Tensor([16, 0, 256, 2],"float32"), mode="bilinear", padding_mode="reflection", align_corners=True, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([16, 3, 256, 256],"float32"), Tensor([16, 0, 256, 2],"float32"), mode="bilinear", padding_mode="reflection", align_corners=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:05.994733 GPU 1 69611 test begin: paddle.nn.functional.grid_sample(Tensor([16, 3, 256, 256],"float32"), Tensor([16, 0, 256, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=True, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([16, 3, 256, 256],"float32"), Tensor([16, 0, 256, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:06.173007 GPU 1 70947 test begin: paddle.nn.functional.grid_sample(Tensor([16, 3, 256, 256],"float32"), Tensor([16, 256, 0, 2],"float32"), mode="bilinear", padding_mode="reflection", align_corners=True, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([16, 3, 256, 256],"float32"), Tensor([16, 256, 0, 2],"float32"), mode="bilinear", padding_mode="reflection", align_corners=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:06.309262 GPU 1 69603 test begin: paddle.nn.functional.grid_sample(Tensor([16, 3, 256, 256],"float32"), Tensor([16, 256, 0, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=True, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([16, 3, 256, 256],"float32"), Tensor([16, 256, 0, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:06.327651 GPU 1 69611 test begin: paddle.nn.functional.grid_sample(Tensor([2, 0, 3, 3],"float64"), Tensor([2, 0, 3, 2],"float64"), mode="bilinear", padding_mode="reflection", align_corners=True, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([2, 0, 3, 3],"float64"), Tensor([2, 0, 3, 2],"float64"), mode="bilinear", padding_mode="reflection", align_corners=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:06.549797 GPU 1 69611 test begin: paddle.nn.functional.grid_sample(Tensor([2, 2, 3, 3],"float64"), Tensor([2, 0, 3, 2],"float64"), mode="bilinear", padding_mode="reflection", align_corners=True, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([2, 2, 3, 3],"float64"), Tensor([2, 0, 3, 2],"float64"), mode="bilinear", padding_mode="reflection", align_corners=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:06.565994 GPU 1 69603 test begin: paddle.nn.functional.grid_sample(Tensor([2, 2, 3, 3],"float64"), Tensor([2, 3, 0, 2],"float64"), mode="bilinear", padding_mode="reflection", align_corners=True, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([2, 2, 3, 3],"float64"), Tensor([2, 3, 0, 2],"float64"), mode="bilinear", padding_mode="reflection", align_corners=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:06.635816 GPU 1 69604 test begin: paddle.nn.functional.grid_sample(Tensor([56, 0, 16, 16],"float32"), Tensor([56, 0, 16, 2],"float32"), mode="bilinear", padding_mode="border", align_corners=True, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([56, 0, 16, 16],"float32"), Tensor([56, 0, 16, 2],"float32"), mode="bilinear", padding_mode="border", align_corners=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:06.745285 GPU 1 69603 test begin: paddle.nn.functional.grid_sample(Tensor([56, 0, 2, 2],"float32"), Tensor([56, 0, 2, 2],"float32"), mode="bilinear", padding_mode="border", align_corners=True, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([56, 0, 2, 2],"float32"), Tensor([56, 0, 2, 2],"float32"), mode="bilinear", padding_mode="border", align_corners=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:06.770593 GPU 1 69611 test begin: paddle.nn.functional.grid_sample(Tensor([56, 3, 16, 16],"float32"), Tensor([56, 0, 16, 2],"float32"), mode="bilinear", padding_mode="border", align_corners=True, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([56, 3, 16, 16],"float32"), Tensor([56, 0, 16, 2],"float32"), mode="bilinear", padding_mode="border", align_corners=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:06.792823 GPU 1 71028 test begin: paddle.nn.functional.grid_sample(Tensor([56, 3, 16, 16],"float32"), Tensor([56, 16, 0, 2],"float32"), mode="bilinear", padding_mode="border", align_corners=True, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([56, 3, 16, 16],"float32"), Tensor([56, 16, 0, 2],"float32"), mode="bilinear", padding_mode="border", align_corners=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:06.859586 GPU 1 69603 test begin: paddle.nn.functional.grid_sample(Tensor([56, 3, 2, 2],"float32"), Tensor([56, 0, 2, 2],"float32"), mode="bilinear", padding_mode="border", align_corners=True, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([56, 3, 2, 2],"float32"), Tensor([56, 0, 2, 2],"float32"), mode="bilinear", padding_mode="border", align_corners=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:06.893713 GPU 1 69604 test begin: paddle.nn.functional.grid_sample(Tensor([56, 3, 2, 2],"float32"), Tensor([56, 2, 0, 2],"float32"), mode="bilinear", padding_mode="border", align_corners=True, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([56, 3, 2, 2],"float32"), Tensor([56, 2, 0, 2],"float32"), mode="bilinear", padding_mode="border", align_corners=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:06.934350 GPU 1 69611 test begin: paddle.nn.functional.grid_sample(x=Tensor([0, 64, 80, 94, 311],"float32"), grid=Tensor([0, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[cuda error] paddle.nn.functional.grid_sample(x=Tensor([0, 64, 80, 94, 311],"float32"), grid=Tensor([0, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:07.069732 GPU 1 69603 test begin: paddle.nn.functional.grid_sample(x=Tensor([4, 0, 80, 94, 311],"float32"), grid=Tensor([4, 0, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[cuda error] paddle.nn.functional.grid_sample(x=Tensor([4, 0, 80, 94, 311],"float32"), grid=Tensor([4, 0, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:07.069861 GPU 1 69611 test begin: paddle.nn.functional.grid_sample(x=Tensor([4, 64, 80, 94, 311],"float32"), grid=Tensor([4, 0, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[cuda error] paddle.nn.functional.grid_sample(x=Tensor([4, 64, 80, 94, 311],"float32"), grid=Tensor([4, 0, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:07.078094 GPU 1 71041 test begin: paddle.nn.functional.grid_sample(x=Tensor([4, 64, 80, 94, 311],"float32"), grid=Tensor([4, 280, 0, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[cuda error] paddle.nn.functional.grid_sample(x=Tensor([4, 64, 80, 94, 311],"float32"), grid=Tensor([4, 280, 0, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:07.099247 GPU 1 71051 test begin: paddle.nn.functional.grid_sample(x=Tensor([4, 64, 80, 94, 311],"float32"), grid=Tensor([4, 280, 376, 0, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
[cuda error] paddle.nn.functional.grid_sample(x=Tensor([4, 64, 80, 94, 311],"float32"), grid=Tensor([4, 280, 376, 0, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:07.186104 GPU 1 69603 test begin: paddle.nn.functional.layer_norm(Tensor([0, 10, 4, 4],"float32"), list[10,4,4,], )
[cuda error] paddle.nn.functional.layer_norm(Tensor([0, 10, 4, 4],"float32"), list[10,4,4,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:07.193625 GPU 1 69604 test begin: paddle.nn.functional.layer_norm(Tensor([0, 10, 4, 4],"float32"), tuple(10,4,4,), )
[cuda error] paddle.nn.functional.layer_norm(Tensor([0, 10, 4, 4],"float32"), tuple(10,4,4,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:07.293329 GPU 1 69603 test begin: paddle.nn.functional.layer_norm(Tensor([0, 10, 60, 30],"float32"), list[10,60,30,], weight=None, bias=None, epsilon=1e-05, )
[cuda error] paddle.nn.functional.layer_norm(Tensor([0, 10, 60, 30],"float32"), list[10,60,30,], weight=None, bias=None, epsilon=1e-05, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:07.328964 GPU 1 69604 test begin: paddle.nn.functional.layer_norm(Tensor([0, 10, 60, 70],"float32"), list[10,60,70,], weight=None, bias=None, epsilon=1e-05, )
[cuda error] paddle.nn.functional.layer_norm(Tensor([0, 10, 60, 70],"float32"), list[10,60,70,], weight=None, bias=None, epsilon=1e-05, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:07.393949 GPU 1 69603 test begin: paddle.nn.functional.layer_norm(Tensor([0, 100],"float32"), list[100,], weight=Tensor([100],"float32"), bias=Tensor([100],"float32"), epsilon=1e-05, )
[cuda error] paddle.nn.functional.layer_norm(Tensor([0, 100],"float32"), list[100,], weight=Tensor([100],"float32"), bias=Tensor([100],"float32"), epsilon=1e-05, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:07.494083 GPU 1 69604 test begin: paddle.nn.functional.layer_norm(Tensor([0, 128, 256],"float32"), list[256,], weight=Tensor([256],"float32"), bias=Tensor([256],"float32"), epsilon=1e-05, )
[cuda error] paddle.nn.functional.layer_norm(Tensor([0, 128, 256],"float32"), list[256,], weight=Tensor([256],"float32"), bias=Tensor([256],"float32"), epsilon=1e-05, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:07.509244 GPU 1 69603 test begin: paddle.nn.functional.layer_norm(Tensor([0, 129],"float32"), list[129,], Tensor([129],"float32"), None, )
[cuda error] paddle.nn.functional.layer_norm(Tensor([0, 129],"float32"), list[129,], Tensor([129],"float32"), None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:07.604001 GPU 1 71061 test begin: paddle.nn.functional.layer_norm(Tensor([0, 20],"float16"), list[20,], Tensor([20],"float16"), Tensor([20],"float16"), )
[cuda error] paddle.nn.functional.layer_norm(Tensor([0, 20],"float16"), list[20,], Tensor([20],"float16"), Tensor([20],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:07.685618 GPU 1 69604 test begin: paddle.nn.functional.layer_norm(Tensor([0, 32, 128],"float32"), list[32,128,], )
[cuda error] paddle.nn.functional.layer_norm(Tensor([0, 32, 128],"float32"), list[32,128,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:07.723339 GPU 1 69603 test begin: paddle.nn.functional.layer_norm(Tensor([0, 4],"float32"), list[4,], None, None, )
[cuda error] paddle.nn.functional.layer_norm(Tensor([0, 4],"float32"), list[4,], None, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:07.837906 GPU 1 69603 test begin: paddle.nn.functional.layer_norm(Tensor([0, 4],"float32"), list[4,], Tensor([4],"float32"), Tensor([4],"float32"), )
[cuda error] paddle.nn.functional.layer_norm(Tensor([0, 4],"float32"), list[4,], Tensor([4],"float32"), Tensor([4],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:07.856055 GPU 1 71062 test begin: paddle.nn.functional.layer_norm(Tensor([0, 512],"float32"), list[512,], None, None, )
[cuda error] paddle.nn.functional.layer_norm(Tensor([0, 512],"float32"), list[512,], None, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:07.968151 GPU 1 69604 test begin: paddle.nn.functional.layer_norm(Tensor([0, 6, 6, 3],"float32"), list[6,6,3,], weight=None, bias=None, epsilon=1e-05, )
[cuda error] paddle.nn.functional.layer_norm(Tensor([0, 6, 6, 3],"float32"), list[6,6,3,], weight=None, bias=None, epsilon=1e-05, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:08.149690 GPU 1 69604 test begin: paddle.nn.functional.layer_norm(Tensor([0, 6, 6, 3],"float64"), list[6,6,3,], weight=None, bias=None, epsilon=1e-05, )
[cuda error] paddle.nn.functional.layer_norm(Tensor([0, 6, 6, 3],"float64"), list[6,6,3,], weight=None, bias=None, epsilon=1e-05, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:08.250570 GPU 1 69603 test begin: paddle.nn.functional.layer_norm(Tensor([0, 64, 128],"float32"), list[64,128,], None, None, )
[cuda error] paddle.nn.functional.layer_norm(Tensor([0, 64, 128],"float32"), list[64,128,], None, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:08.297837 GPU 1 69604 test begin: paddle.nn.functional.layer_norm(Tensor([0, 64, 64],"float32"), list[64,], None, None, )
[cuda error] paddle.nn.functional.layer_norm(Tensor([0, 64, 64],"float32"), list[64,], None, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:08.450135 GPU 1 69604 test begin: paddle.nn.functional.layer_norm(Tensor([0, 64, 64],"float32"), list[64,], Tensor([64],"float32"), Tensor([64],"float32"), )
[cuda error] paddle.nn.functional.layer_norm(Tensor([0, 64, 64],"float32"), list[64,], Tensor([64],"float32"), Tensor([64],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:08.526917 GPU 1 69603 test begin: paddle.nn.functional.layer_norm(Tensor([0, 768],"float32"), list[768,], None, None, )
[cuda error] paddle.nn.functional.layer_norm(Tensor([0, 768],"float32"), list[768,], None, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:08.702367 GPU 1 69604 test begin: paddle.nn.functional.layer_norm(Tensor([128, 0, 64],"float32"), list[64,], None, None, )
[cuda error] paddle.nn.functional.layer_norm(Tensor([128, 0, 64],"float32"), list[64,], None, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:08.790278 GPU 1 69603 test begin: paddle.nn.functional.layer_norm(Tensor([128, 0, 64],"float32"), list[64,], Tensor([64],"float32"), Tensor([64],"float32"), )
[cuda error] paddle.nn.functional.layer_norm(Tensor([128, 0, 64],"float32"), list[64,], Tensor([64],"float32"), Tensor([64],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:08.835096 GPU 1 69604 test begin: paddle.nn.functional.layer_norm(Tensor([8, 0, 256],"float32"), list[256,], weight=Tensor([256],"float32"), bias=Tensor([256],"float32"), epsilon=1e-05, )
[cuda error] paddle.nn.functional.layer_norm(Tensor([8, 0, 256],"float32"), list[256,], weight=Tensor([256],"float32"), bias=Tensor([256],"float32"), epsilon=1e-05, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:08.979621 GPU 1 69604 test begin: paddle.nn.functional.layer_norm(normalized_shape=tuple(2,2,3,), x=Tensor([0, 2, 2, 3],"float32"), )
[cuda error] paddle.nn.functional.layer_norm(normalized_shape=tuple(2,2,3,), x=Tensor([0, 2, 2, 3],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:09.000158 GPU 1 71096 test begin: paddle.nn.functional.layer_norm(normalized_shape=tuple(2,2,3,), x=Tensor([0, 2, 2, 3],"float32"), epsilon=1e-05, )
[cuda error] paddle.nn.functional.layer_norm(normalized_shape=tuple(2,2,3,), x=Tensor([0, 2, 2, 3],"float32"), epsilon=1e-05, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:09.027240 GPU 1 71070 test begin: paddle.nn.functional.layer_norm(normalized_shape=tuple(2,2,3,), x=Tensor([0, 2, 2, 3],"float32"), epsilon=1e-05, weight=None, bias=None, )
[cuda error] paddle.nn.functional.layer_norm(normalized_shape=tuple(2,2,3,), x=Tensor([0, 2, 2, 3],"float32"), epsilon=1e-05, weight=None, bias=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:09.118796 GPU 1 69604 test begin: paddle.nn.functional.layer_norm(normalized_shape=tuple(2,2,3,), x=Tensor([0, 2, 2, 3],"float64"), )
[cuda error] paddle.nn.functional.layer_norm(normalized_shape=tuple(2,2,3,), x=Tensor([0, 2, 2, 3],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:09.200539 GPU 1 69603 test begin: paddle.nn.functional.layer_norm(normalized_shape=tuple(2,2,3,), x=Tensor([0, 2, 2, 3],"float64"), epsilon=1e-05, )
[cuda error] paddle.nn.functional.layer_norm(normalized_shape=tuple(2,2,3,), x=Tensor([0, 2, 2, 3],"float64"), epsilon=1e-05, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:09.268206 GPU 1 69604 test begin: paddle.nn.functional.layer_norm(normalized_shape=tuple(2,2,3,), x=Tensor([0, 2, 2, 3],"float64"), epsilon=1e-05, weight=None, bias=None, )
[cuda error] paddle.nn.functional.layer_norm(normalized_shape=tuple(2,2,3,), x=Tensor([0, 2, 2, 3],"float64"), epsilon=1e-05, weight=None, bias=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:09.415515 GPU 1 69604 test begin: paddle.nn.functional.layer_norm(normalized_shape=tuple(2,3,), x=Tensor([0, 2, 3],"float32"), )
[cuda error] paddle.nn.functional.layer_norm(normalized_shape=tuple(2,3,), x=Tensor([0, 2, 3],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:09.452019 GPU 1 71121 test begin: paddle.nn.functional.layer_norm(normalized_shape=tuple(2,3,), x=Tensor([0, 2, 3],"float32"), epsilon=1e-05, )
[cuda error] paddle.nn.functional.layer_norm(normalized_shape=tuple(2,3,), x=Tensor([0, 2, 3],"float32"), epsilon=1e-05, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:09.483139 GPU 1 69603 test begin: paddle.nn.functional.layer_norm(normalized_shape=tuple(2,3,), x=Tensor([0, 2, 3],"float64"), )
[cuda error] paddle.nn.functional.layer_norm(normalized_shape=tuple(2,3,), x=Tensor([0, 2, 3],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:09.559016 GPU 1 69604 test begin: paddle.nn.functional.layer_norm(normalized_shape=tuple(2,3,), x=Tensor([0, 2, 3],"float64"), epsilon=1e-05, )
[cuda error] paddle.nn.functional.layer_norm(normalized_shape=tuple(2,3,), x=Tensor([0, 2, 3],"float64"), epsilon=1e-05, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:09.651428 GPU 1 71152 test begin: paddle.nn.functional.layer_norm(normalized_shape=tuple(3,), x=Tensor([0, 3],"float32"), )
[cuda error] paddle.nn.functional.layer_norm(normalized_shape=tuple(3,), x=Tensor([0, 3],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:09.700038 GPU 1 69604 test begin: paddle.nn.functional.layer_norm(normalized_shape=tuple(3,), x=Tensor([0, 3],"float32"), epsilon=1e-05, )
[cuda error] paddle.nn.functional.layer_norm(normalized_shape=tuple(3,), x=Tensor([0, 3],"float32"), epsilon=1e-05, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:09.705075 GPU 1 71093 test begin: paddle.nn.functional.layer_norm(normalized_shape=tuple(3,), x=Tensor([0, 3],"float64"), )
[cuda error] paddle.nn.functional.layer_norm(normalized_shape=tuple(3,), x=Tensor([0, 3],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:09.799621 GPU 1 69603 test begin: paddle.nn.functional.layer_norm(normalized_shape=tuple(3,), x=Tensor([0, 3],"float64"), epsilon=1e-05, )
[cuda error] paddle.nn.functional.layer_norm(normalized_shape=tuple(3,), x=Tensor([0, 3],"float64"), epsilon=1e-05, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:09.832355 GPU 1 69604 test begin: paddle.nn.functional.normalize(Tensor([0, 10],"float32"), axis=0, )
W0521 22:08:09.958452 69604 backward.cc:437] While running Node (MaximumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.nn.functional.normalize(Tensor([0, 10],"float32"), axis=0, ) 
 (InvalidArgument) ReduceOp: invalid axis, when x_dims is 1, axis[i] should less than x_dims, but got 1.
  [Hint: Expected e < dim_size, but received e:1 >= dim_size:1.] (at ../paddle/phi/kernels/funcs/reduce_function.h:112)


2025-05-21 22:08:09.959294 GPU 1 69604 test begin: paddle.nn.functional.normalize(Tensor([0, 5],"float32"), axis=0, )
W0521 22:08:10.110687 69604 backward.cc:437] While running Node (MaximumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.nn.functional.normalize(Tensor([0, 5],"float32"), axis=0, ) 
 (InvalidArgument) ReduceOp: invalid axis, when x_dims is 1, axis[i] should less than x_dims, but got 1.
  [Hint: Expected e < dim_size, but received e:1 >= dim_size:1.] (at ../paddle/phi/kernels/funcs/reduce_function.h:112)


2025-05-21 22:08:10.000074 GPU 1 71129 test begin: paddle.nn.functional.normalize(Tensor([1, 0, 16, 16],"float32"), axis=1, )
W0521 22:08:33.336434 71129 backward.cc:437] While running Node (MaximumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.nn.functional.normalize(Tensor([1, 0, 16, 16],"float32"), axis=1, ) 
 (InvalidArgument) ReduceOp: invalid axis, when x_dims is 3, axis[i] should less than x_dims, but got 3.
  [Hint: Expected e < dim_size, but received e:3 >= dim_size:3.] (at ../paddle/phi/kernels/funcs/reduce_function.h:112)


2025-05-21 22:08:10.052479 GPU 1 69603 test begin: paddle.nn.functional.normalize(Tensor([1, 0, 32, 32],"float32"), axis=1, )
W0521 22:08:10.534752 69603 backward.cc:437] While running Node (MaximumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.nn.functional.normalize(Tensor([1, 0, 32, 32],"float32"), axis=1, ) 
 (InvalidArgument) ReduceOp: invalid axis, when x_dims is 3, axis[i] should less than x_dims, but got 3.
  [Hint: Expected e < dim_size, but received e:3 >= dim_size:3.] (at ../paddle/phi/kernels/funcs/reduce_function.h:112)


2025-05-21 22:08:10.112030 GPU 1 69604 test begin: paddle.nn.functional.normalize(Tensor([1, 0],"float32"), axis=1, )
W0521 22:08:10.308658 69604 backward.cc:437] While running Node (MaximumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.nn.functional.normalize(Tensor([1, 0],"float32"), axis=1, ) 
 (InvalidArgument) ReduceOp: invalid axis, when x_dims is 1, axis[i] should less than x_dims, but got 1.
  [Hint: Expected e < dim_size, but received e:1 >= dim_size:1.] (at ../paddle/phi/kernels/funcs/reduce_function.h:112)


2025-05-21 22:08:10.168991 GPU 1 71112 test begin: paddle.nn.functional.normalize(Tensor([10, 0],"float16"), )
W0521 22:08:34.220561 71112 backward.cc:437] While running Node (MaximumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.nn.functional.normalize(Tensor([10, 0],"float16"), ) 
 (InvalidArgument) ReduceOp: invalid axis, when x_dims is 1, axis[i] should less than x_dims, but got 1.
  [Hint: Expected e < dim_size, but received e:1 >= dim_size:1.] (at ../paddle/phi/kernels/funcs/reduce_function.h:112)


2025-05-21 22:08:10.309430 GPU 1 69604 test begin: paddle.nn.functional.normalize(Tensor([10, 0],"float32"), )
W0521 22:08:10.682083 69604 backward.cc:437] While running Node (MaximumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.nn.functional.normalize(Tensor([10, 0],"float32"), ) 
 (InvalidArgument) ReduceOp: invalid axis, when x_dims is 1, axis[i] should less than x_dims, but got 1.
  [Hint: Expected e < dim_size, but received e:1 >= dim_size:1.] (at ../paddle/phi/kernels/funcs/reduce_function.h:112)


2025-05-21 22:08:10.535781 GPU 1 69603 test begin: paddle.nn.functional.normalize(Tensor([10, 0],"float32"), p=1.5, )
free(): invalid pointer

2025-05-21 22:08:10.682932 GPU 1 69604 test begin: paddle.nn.functional.normalize(Tensor([12, 0],"float32"), axis=-1, )
W0521 22:08:11.007665 69604 backward.cc:437] While running Node (MaximumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.nn.functional.normalize(Tensor([12, 0],"float32"), axis=-1, ) 
 (InvalidArgument) ReduceOp: invalid axis, when x_dims is 1, axis[i] should less than x_dims, but got 1.
  [Hint: Expected e < dim_size, but received e:1 >= dim_size:1.] (at ../paddle/phi/kernels/funcs/reduce_function.h:112)


2025-05-21 22:08:11.008475 GPU 1 69604 test begin: paddle.nn.functional.normalize(Tensor([2, 0],"float16"), p=2, axis=-1, )
W0521 22:08:11.349898 69604 backward.cc:437] While running Node (MaximumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.nn.functional.normalize(Tensor([2, 0],"float16"), p=2, axis=-1, ) 
 (InvalidArgument) ReduceOp: invalid axis, when x_dims is 1, axis[i] should less than x_dims, but got 1.
  [Hint: Expected e < dim_size, but received e:1 >= dim_size:1.] (at ../paddle/phi/kernels/funcs/reduce_function.h:112)


2025-05-21 22:08:11.351006 GPU 1 69604 test begin: paddle.nn.functional.normalize(Tensor([80, 0],"float32"), axis=-1, )
W0521 22:08:11.798035 69604 backward.cc:437] While running Node (MaximumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.nn.functional.normalize(Tensor([80, 0],"float32"), axis=-1, ) 
 (InvalidArgument) ReduceOp: invalid axis, when x_dims is 1, axis[i] should less than x_dims, but got 1.
  [Hint: Expected e < dim_size, but received e:1 >= dim_size:1.] (at ../paddle/phi/kernels/funcs/reduce_function.h:112)


2025-05-21 22:08:11.799045 GPU 1 69604 test begin: paddle.nn.functional.normalize(x=Tensor([1, 0],"float32"), axis=-1, )
W0521 22:08:12.056981 69604 backward.cc:437] While running Node (MaximumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.nn.functional.normalize(x=Tensor([1, 0],"float32"), axis=-1, ) 
 (InvalidArgument) ReduceOp: invalid axis, when x_dims is 1, axis[i] should less than x_dims, but got 1.
  [Hint: Expected e < dim_size, but received e:1 >= dim_size:1.] (at ../paddle/phi/kernels/funcs/reduce_function.h:112)


2025-05-21 22:08:12.057935 GPU 1 69604 test begin: paddle.nn.functional.normalize(x=Tensor([2, 0],"float32"), )
W0521 22:08:12.354941 69604 backward.cc:437] While running Node (MaximumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.nn.functional.normalize(x=Tensor([2, 0],"float32"), ) 
 (InvalidArgument) ReduceOp: invalid axis, when x_dims is 1, axis[i] should less than x_dims, but got 1.
  [Hint: Expected e < dim_size, but received e:1 >= dim_size:1.] (at ../paddle/phi/kernels/funcs/reduce_function.h:112)


2025-05-21 22:08:12.355987 GPU 1 69604 test begin: paddle.nn.functional.normalize(x=Tensor([2, 0],"float64"), )
W0521 22:08:12.646379 69604 backward.cc:437] While running Node (MaximumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.nn.functional.normalize(x=Tensor([2, 0],"float64"), ) 
 (InvalidArgument) ReduceOp: invalid axis, when x_dims is 1, axis[i] should less than x_dims, but got 1.
  [Hint: Expected e < dim_size, but received e:1 >= dim_size:1.] (at ../paddle/phi/kernels/funcs/reduce_function.h:112)


2025-05-21 22:08:12.647365 GPU 1 69604 test begin: paddle.nn.functional.normalize(x=Tensor([4, 0, 6, 7],"float64"), )
W0521 22:08:12.799947 69604 backward.cc:437] While running Node (MaximumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.nn.functional.normalize(x=Tensor([4, 0, 6, 7],"float64"), ) 
 (InvalidArgument) The 2-th dimension of input tensor is expected to be equal with the 2-th dimension of output tensor 7 or 1, but received 6.
  [Hint: Expected in_dim[in_idx] == out_dims[in_idx] || in_dim[in_idx] == 1 == true, but received in_dim[in_idx] == out_dims[in_idx] || in_dim[in_idx] == 1:0 != true:1.] (at ../paddle/phi/kernels/funcs/dims_simplifier.h:134)


2025-05-21 22:08:12.802085 GPU 1 69604 test begin: paddle.nn.functional.normalize(x=Tensor([4, 0, 6, 7],"float64"), p=1, )
W0521 22:08:13.034695 69604 backward.cc:437] While running Node (MaximumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.nn.functional.normalize(x=Tensor([4, 0, 6, 7],"float64"), p=1, ) 
 (InvalidArgument) The 2-th dimension of input tensor is expected to be equal with the 2-th dimension of output tensor 7 or 1, but received 6.
  [Hint: Expected in_dim[in_idx] == out_dims[in_idx] || in_dim[in_idx] == 1 == true, but received in_dim[in_idx] == out_dims[in_idx] || in_dim[in_idx] == 1:0 != true:1.] (at ../paddle/phi/kernels/funcs/dims_simplifier.h:134)


2025-05-21 22:08:13.035564 GPU 1 69604 test begin: paddle.nn.functional.normalize(x=Tensor([4, 0, 6, 7],"float64"), p=4, )
W0521 22:08:13.222365 69604 backward.cc:437] While running Node (MaximumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.nn.functional.normalize(x=Tensor([4, 0, 6, 7],"float64"), p=4, ) 
 (InvalidArgument) The 2-th dimension of input tensor is expected to be equal with the 2-th dimension of output tensor 7 or 1, but received 6.
  [Hint: Expected in_dim[in_idx] == out_dims[in_idx] || in_dim[in_idx] == 1 == true, but received in_dim[in_idx] == out_dims[in_idx] || in_dim[in_idx] == 1:0 != true:1.] (at ../paddle/phi/kernels/funcs/dims_simplifier.h:134)


2025-05-21 22:08:13.223307 GPU 1 69604 test begin: paddle.nn.functional.normalize(x=Tensor([4, 0, 6],"float64"), )
W0521 22:08:13.378748 69604 backward.cc:437] While running Node (MaximumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.nn.functional.normalize(x=Tensor([4, 0, 6],"float64"), ) 
 (InvalidArgument) ReduceOp: invalid axis, when x_dims is 2, axis[i] should less than x_dims, but got 2.
  [Hint: Expected e < dim_size, but received e:2 >= dim_size:2.] (at ../paddle/phi/kernels/funcs/reduce_function.h:112)


2025-05-21 22:08:13.379887 GPU 1 69604 test begin: paddle.nn.functional.normalize(x=Tensor([4, 0],"float64"), p=1.2, )
W0521 22:08:13.537581 69604 backward.cc:437] While running Node (MaximumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.nn.functional.normalize(x=Tensor([4, 0],"float64"), p=1.2, ) 
 (InvalidArgument) ReduceOp: invalid axis, when x_dims is 1, axis[i] should less than x_dims, but got 1.
  [Hint: Expected e < dim_size, but received e:1 >= dim_size:1.] (at ../paddle/phi/kernels/funcs/reduce_function.h:112)


2025-05-21 22:08:13.538510 GPU 1 69604 test begin: paddle.nn.functional.normalize(x=Tensor([4, 5, 6, 0],"float64"), p=4, axis=3, )
W0521 22:08:13.691479 69604 backward.cc:437] While running Node (MaximumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.nn.functional.normalize(x=Tensor([4, 5, 6, 0],"float64"), p=4, axis=3, ) 
 (InvalidArgument) ReduceOp: invalid axis, when x_dims is 3, axis[i] should less than x_dims, but got 3.
  [Hint: Expected e < dim_size, but received e:3 >= dim_size:3.] (at ../paddle/phi/kernels/funcs/reduce_function.h:112)


2025-05-21 22:08:13.693694 GPU 1 69604 test begin: paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float32"), Tensor([0, 100],"float32"), -1, 1e-06, False, None, )
free(): invalid next size (fast)


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   THPVariable_subclass_dealloc(_object*)
1   c10::TensorImpl::~TensorImpl()
2   c10::TensorImpl::~TensorImpl()
3   std::_Sp_counted_deleter<torch::autograd::generated::NormBackward1*, void (*)(torch::autograd::Node*), std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
4   torch::autograd::deleteNode(torch::autograd::Node*)
5   std::_Sp_counted_deleter<torch::autograd::generated::AddBackward1*, void (*)(torch::autograd::Node*), std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
6   torch::autograd::deleteNode(torch::autograd::Node*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836493 (unix time) try "date -d @1747836493" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10fe4) received by PID 69604 (TID 0x7f3db41bd740) from PID 69604 ***]


2025-05-21 22:08:18.728509 GPU 1 72116 test begin: paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float32"), Tensor([0, 100],"float32"), -1, 1e-06, True, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float32"), Tensor([0, 100],"float32"), -1, 1e-06, True, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:18.769214 GPU 1 72103 test begin: paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float32"), Tensor([0, 100],"float32"), -math.inf, 1e-06, False, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float32"), Tensor([0, 100],"float32"), -math.inf, 1e-06, False, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:19.565731 GPU 1 70805 test begin: paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float32"), Tensor([0, 100],"float32"), -math.inf, 1e-06, True, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float32"), Tensor([0, 100],"float32"), -math.inf, 1e-06, True, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:19.990132 GPU 1 70805 test begin: paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float32"), Tensor([0, 100],"float32"), 1, 1e-06, False, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float32"), Tensor([0, 100],"float32"), 1, 1e-06, False, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:20.251231 GPU 1 70805 test begin: paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float32"), Tensor([0, 100],"float32"), 1, 1e-06, True, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float32"), Tensor([0, 100],"float32"), 1, 1e-06, True, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:20.437914 GPU 1 70805 test begin: paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float32"), Tensor([0, 100],"float32"), 2, 1e-06, False, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float32"), Tensor([0, 100],"float32"), 2, 1e-06, False, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:20.699892 GPU 1 70805 test begin: paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float32"), Tensor([0, 100],"float32"), 2, 1e-06, True, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float32"), Tensor([0, 100],"float32"), 2, 1e-06, True, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:20.874185 GPU 1 70805 test begin: paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float32"), Tensor([0, 100],"float32"), math.inf, 1e-06, False, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float32"), Tensor([0, 100],"float32"), math.inf, 1e-06, False, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:21.253568 GPU 1 70805 test begin: paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float32"), Tensor([0, 100],"float32"), math.inf, 1e-06, True, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float32"), Tensor([0, 100],"float32"), math.inf, 1e-06, True, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:21.594694 GPU 1 69611 test begin: paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float32"), Tensor([0, 1],"float32"), 2.0, 1e-06, False, None, )
W0521 22:08:22.148301 69611 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float32"), Tensor([0, 1],"float32"), 2.0, 1e-06, False, None, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:08:21.599666 GPU 1 70805 test begin: paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float32"), Tensor([100],"float32"), 2.0, 1e-06, False, None, )
W0521 22:08:21.802526 70805 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float32"), Tensor([100],"float32"), 2.0, 1e-06, False, None, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:08:21.972436 GPU 1 70805 test begin: paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float64"), Tensor([0, 100],"float64"), -1, 1e-06, False, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float64"), Tensor([0, 100],"float64"), -1, 1e-06, False, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:22.148986 GPU 1 69611 test begin: paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float64"), Tensor([0, 100],"float64"), -1, 1e-06, True, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float64"), Tensor([0, 100],"float64"), -1, 1e-06, True, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:22.251530 GPU 1 69611 test begin: paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float64"), Tensor([0, 100],"float64"), -math.inf, 1e-06, False, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float64"), Tensor([0, 100],"float64"), -math.inf, 1e-06, False, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:22.353379 GPU 1 70805 test begin: paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float64"), Tensor([0, 100],"float64"), -math.inf, 1e-06, True, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float64"), Tensor([0, 100],"float64"), -math.inf, 1e-06, True, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:22.462697 GPU 1 69611 test begin: paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float64"), Tensor([0, 100],"float64"), 1, 1e-06, False, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float64"), Tensor([0, 100],"float64"), 1, 1e-06, False, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:22.520453 GPU 1 70805 test begin: paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float64"), Tensor([0, 100],"float64"), 1, 1e-06, True, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float64"), Tensor([0, 100],"float64"), 1, 1e-06, True, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:22.599675 GPU 1 69611 test begin: paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float64"), Tensor([0, 100],"float64"), 2, 1e-06, False, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float64"), Tensor([0, 100],"float64"), 2, 1e-06, False, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:22.750068 GPU 1 69611 test begin: paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float64"), Tensor([0, 100],"float64"), 2, 1e-06, True, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float64"), Tensor([0, 100],"float64"), 2, 1e-06, True, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:22.787248 GPU 1 70805 test begin: paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float64"), Tensor([0, 100],"float64"), math.inf, 1e-06, False, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float64"), Tensor([0, 100],"float64"), math.inf, 1e-06, False, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:22.866619 GPU 1 69611 test begin: paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float64"), Tensor([0, 100],"float64"), math.inf, 1e-06, True, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([0, 100],"float64"), Tensor([0, 100],"float64"), math.inf, 1e-06, True, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:22.960347 GPU 1 70805 test begin: paddle.nn.functional.pairwise_distance(Tensor([0],"float32"), Tensor([0],"float32"), )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([0],"float32"), Tensor([0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:22.982694 GPU 1 69611 test begin: paddle.nn.functional.pairwise_distance(Tensor([0],"float32"), Tensor([0],"float32"), 1, 1e-06, False, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([0],"float32"), Tensor([0],"float32"), 1, 1e-06, False, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:23.133553 GPU 1 70805 test begin: paddle.nn.functional.pairwise_distance(Tensor([0],"float32"), Tensor([0],"float32"), 1, 1e-06, True, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([0],"float32"), Tensor([0],"float32"), 1, 1e-06, True, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:23.159063 GPU 1 69611 test begin: paddle.nn.functional.pairwise_distance(Tensor([0],"float32"), Tensor([0],"float32"), 2, 1e-06, False, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([0],"float32"), Tensor([0],"float32"), 2, 1e-06, False, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:23.288767 GPU 1 70805 test begin: paddle.nn.functional.pairwise_distance(Tensor([0],"float32"), Tensor([0],"float32"), 2, 1e-06, True, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([0],"float32"), Tensor([0],"float32"), 2, 1e-06, True, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:23.308878 GPU 1 69611 test begin: paddle.nn.functional.pairwise_distance(Tensor([0],"float64"), Tensor([0],"float64"), 1, 1e-06, False, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([0],"float64"), Tensor([0],"float64"), 1, 1e-06, False, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:23.450479 GPU 1 70805 test begin: paddle.nn.functional.pairwise_distance(Tensor([0],"float64"), Tensor([0],"float64"), 1, 1e-06, True, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([0],"float64"), Tensor([0],"float64"), 1, 1e-06, True, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:23.451313 GPU 1 69611 test begin: paddle.nn.functional.pairwise_distance(Tensor([0],"float64"), Tensor([0],"float64"), 2, 1e-06, False, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([0],"float64"), Tensor([0],"float64"), 2, 1e-06, False, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:23.611996 GPU 1 69611 test begin: paddle.nn.functional.pairwise_distance(Tensor([0],"float64"), Tensor([0],"float64"), 2, 1e-06, True, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([0],"float64"), Tensor([0],"float64"), 2, 1e-06, True, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:23.834336 GPU 1 70805 test begin: paddle.nn.functional.pairwise_distance(Tensor([100, 0],"float32"), Tensor([100, 0],"float32"), 1, 1e-06, False, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([100, 0],"float32"), Tensor([100, 0],"float32"), 1, 1e-06, False, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:23.995484 GPU 1 69611 test begin: paddle.nn.functional.pairwise_distance(Tensor([100, 0],"float32"), Tensor([100, 0],"float32"), 1, 1e-06, True, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([100, 0],"float32"), Tensor([100, 0],"float32"), 1, 1e-06, True, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:24.194685 GPU 1 69611 test begin: paddle.nn.functional.pairwise_distance(Tensor([100, 0],"float32"), Tensor([100, 0],"float32"), 2, 1e-06, False, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([100, 0],"float32"), Tensor([100, 0],"float32"), 2, 1e-06, False, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:24.338356 GPU 1 70805 test begin: paddle.nn.functional.pairwise_distance(Tensor([100, 0],"float32"), Tensor([100, 0],"float32"), 2, 1e-06, True, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([100, 0],"float32"), Tensor([100, 0],"float32"), 2, 1e-06, True, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:24.563464 GPU 1 69611 test begin: paddle.nn.functional.pairwise_distance(Tensor([100, 0],"float32"), Tensor([100, 0],"float32"), 2.0, 1e-06, False, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([100, 0],"float32"), Tensor([100, 0],"float32"), 2.0, 1e-06, False, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:24.694952 GPU 1 72196 test begin: paddle.nn.functional.pairwise_distance(Tensor([100, 0],"float32"), Tensor([100, 1],"float32"), 2.0, 1e-06, False, None, )
W0521 22:08:49.234863 72196 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.nn.functional.pairwise_distance(Tensor([100, 0],"float32"), Tensor([100, 1],"float32"), 2.0, 1e-06, False, None, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:08:24.718740 GPU 1 70805 test begin: paddle.nn.functional.pairwise_distance(Tensor([100, 0],"float64"), Tensor([100, 0],"float64"), 1, 1e-06, False, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([100, 0],"float64"), Tensor([100, 0],"float64"), 1, 1e-06, False, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:25.090909 GPU 1 69611 test begin: paddle.nn.functional.pairwise_distance(Tensor([100, 0],"float64"), Tensor([100, 0],"float64"), 1, 1e-06, True, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([100, 0],"float64"), Tensor([100, 0],"float64"), 1, 1e-06, True, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:25.092284 GPU 1 70805 test begin: paddle.nn.functional.pairwise_distance(Tensor([100, 0],"float64"), Tensor([100, 0],"float64"), 2, 1e-06, False, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([100, 0],"float64"), Tensor([100, 0],"float64"), 2, 1e-06, False, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:25.230221 GPU 1 69611 test begin: paddle.nn.functional.pairwise_distance(Tensor([100, 0],"float64"), Tensor([100, 0],"float64"), 2, 1e-06, True, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([100, 0],"float64"), Tensor([100, 0],"float64"), 2, 1e-06, True, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:25.274995 GPU 1 70805 test begin: paddle.nn.functional.pairwise_distance(x=Tensor([0, 100],"float32"), y=Tensor([0, 1],"float32"), p=2.0, epsilon=1e-06, keepdim=False, )
W0521 22:08:25.492708 70805 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.nn.functional.pairwise_distance(x=Tensor([0, 100],"float32"), y=Tensor([0, 1],"float32"), p=2.0, epsilon=1e-06, keepdim=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:08:25.373287 GPU 1 69611 test begin: paddle.nn.functional.pairwise_distance(x=Tensor([0, 100],"float32"), y=Tensor([100],"float32"), p=2.0, epsilon=1e-06, keepdim=False, )
W0521 22:08:25.510864 69611 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.nn.functional.pairwise_distance(x=Tensor([0, 100],"float32"), y=Tensor([100],"float32"), p=2.0, epsilon=1e-06, keepdim=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:08:25.496492 GPU 1 70805 test begin: paddle.nn.functional.pairwise_distance(x=Tensor([100, 0],"float32"), y=Tensor([100, 0],"float32"), p=2.0, epsilon=1e-06, keepdim=False, )
[cuda error] paddle.nn.functional.pairwise_distance(x=Tensor([100, 0],"float32"), y=Tensor([100, 0],"float32"), p=2.0, epsilon=1e-06, keepdim=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:25.512311 GPU 1 69611 test begin: paddle.nn.functional.pairwise_distance(x=Tensor([100, 0],"float32"), y=Tensor([100, 1],"float32"), p=2.0, epsilon=1e-06, keepdim=False, )
W0521 22:08:25.673734 69611 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.nn.functional.pairwise_distance(x=Tensor([100, 0],"float32"), y=Tensor([100, 1],"float32"), p=2.0, epsilon=1e-06, keepdim=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:08:25.674788 GPU 1 69611 test begin: paddle.nn.functional.rrelu(Tensor([0, 2, 3, 4],"float64"), 0.05, 0.25, training=False, )
[cuda error] paddle.nn.functional.rrelu(Tensor([0, 2, 3, 4],"float64"), 0.05, 0.25, training=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:25.710083 GPU 1 70805 test begin: paddle.nn.functional.rrelu(Tensor([0, 2, 3, 4],"float64"), 0.1, 0.33, training=False, )
[cuda error] paddle.nn.functional.rrelu(Tensor([0, 2, 3, 4],"float64"), 0.1, 0.33, training=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:25.808349 GPU 1 69611 test begin: paddle.nn.functional.rrelu(Tensor([0, 3, 4, 5],"float16"), 0.1, 0.3, training=False, )
[cuda error] paddle.nn.functional.rrelu(Tensor([0, 3, 4, 5],"float16"), 0.1, 0.3, training=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:25.930405 GPU 1 70805 test begin: paddle.nn.functional.rrelu(Tensor([0, 3, 4, 5],"float16"), 0.3, 0.300000009, training=True, )
[cuda error] paddle.nn.functional.rrelu(Tensor([0, 3, 4, 5],"float16"), 0.3, 0.300000009, training=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:25.949636 GPU 1 70853 test begin: paddle.nn.functional.rrelu(Tensor([0, 3, 4, 5],"float32"), 0.1, 0.3, training=False, )
[cuda error] paddle.nn.functional.rrelu(Tensor([0, 3, 4, 5],"float32"), 0.1, 0.3, training=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:26.034687 GPU 1 69611 test begin: paddle.nn.functional.rrelu(Tensor([0, 3, 4, 5],"float32"), 0.3, 0.300000009, training=True, )
[cuda error] paddle.nn.functional.rrelu(Tensor([0, 3, 4, 5],"float32"), 0.3, 0.300000009, training=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:26.176048 GPU 1 70853 test begin: paddle.nn.functional.rrelu(Tensor([1, 0, 3, 4],"float64"), 0.05, 0.25, training=False, )
[cuda error] paddle.nn.functional.rrelu(Tensor([1, 0, 3, 4],"float64"), 0.05, 0.25, training=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:26.177707 GPU 1 69611 test begin: paddle.nn.functional.rrelu(Tensor([1, 0, 3, 4],"float64"), 0.1, 0.33, training=False, )
[cuda error] paddle.nn.functional.rrelu(Tensor([1, 0, 3, 4],"float64"), 0.1, 0.33, training=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:26.191442 GPU 1 70805 test begin: paddle.nn.functional.rrelu(Tensor([1, 2, 0, 4],"float64"), 0.05, 0.25, training=False, )
[cuda error] paddle.nn.functional.rrelu(Tensor([1, 2, 0, 4],"float64"), 0.05, 0.25, training=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:26.309671 GPU 1 69611 test begin: paddle.nn.functional.rrelu(Tensor([1, 2, 0, 4],"float64"), 0.1, 0.33, training=False, )
[cuda error] paddle.nn.functional.rrelu(Tensor([1, 2, 0, 4],"float64"), 0.1, 0.33, training=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:26.344899 GPU 1 70853 test begin: paddle.nn.functional.rrelu(Tensor([1, 2, 3, 0],"float64"), 0.05, 0.25, training=False, )
[cuda error] paddle.nn.functional.rrelu(Tensor([1, 2, 3, 0],"float64"), 0.05, 0.25, training=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:26.430056 GPU 1 70805 test begin: paddle.nn.functional.rrelu(Tensor([1, 2, 3, 0],"float64"), 0.1, 0.33, training=False, )
[cuda error] paddle.nn.functional.rrelu(Tensor([1, 2, 3, 0],"float64"), 0.1, 0.33, training=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:26.465472 GPU 1 69611 test begin: paddle.nn.functional.rrelu(Tensor([2, 0, 4, 5],"float16"), 0.1, 0.3, training=False, )
[cuda error] paddle.nn.functional.rrelu(Tensor([2, 0, 4, 5],"float16"), 0.1, 0.3, training=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:26.487159 GPU 1 70853 test begin: paddle.nn.functional.rrelu(Tensor([2, 0, 4, 5],"float16"), 0.3, 0.300000009, training=True, )
[cuda error] paddle.nn.functional.rrelu(Tensor([2, 0, 4, 5],"float16"), 0.3, 0.300000009, training=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:26.623246 GPU 1 69611 test begin: paddle.nn.functional.rrelu(Tensor([2, 0, 4, 5],"float32"), 0.1, 0.3, training=False, )
[cuda error] paddle.nn.functional.rrelu(Tensor([2, 0, 4, 5],"float32"), 0.1, 0.3, training=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:26.626042 GPU 1 70805 test begin: paddle.nn.functional.rrelu(Tensor([2, 0, 4, 5],"float32"), 0.3, 0.300000009, training=True, )
[cuda error] paddle.nn.functional.rrelu(Tensor([2, 0, 4, 5],"float32"), 0.3, 0.300000009, training=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:26.630640 GPU 1 70853 test begin: paddle.nn.functional.rrelu(Tensor([2, 3, 0, 5],"float16"), 0.1, 0.3, training=False, )
[cuda error] paddle.nn.functional.rrelu(Tensor([2, 3, 0, 5],"float16"), 0.1, 0.3, training=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:26.775969 GPU 1 69611 test begin: paddle.nn.functional.rrelu(Tensor([2, 3, 0, 5],"float16"), 0.3, 0.300000009, training=True, )
[cuda error] paddle.nn.functional.rrelu(Tensor([2, 3, 0, 5],"float16"), 0.3, 0.300000009, training=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:26.806048 GPU 1 70853 test begin: paddle.nn.functional.rrelu(Tensor([2, 3, 0, 5],"float32"), 0.1, 0.3, training=False, )
[cuda error] paddle.nn.functional.rrelu(Tensor([2, 3, 0, 5],"float32"), 0.1, 0.3, training=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:26.819883 GPU 1 70805 test begin: paddle.nn.functional.rrelu(Tensor([2, 3, 0, 5],"float32"), 0.3, 0.300000009, training=True, )
[cuda error] paddle.nn.functional.rrelu(Tensor([2, 3, 0, 5],"float32"), 0.3, 0.300000009, training=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:26.906514 GPU 1 69611 test begin: paddle.nn.functional.rrelu(Tensor([2, 3, 4, 0],"float16"), 0.1, 0.3, training=False, )
[cuda error] paddle.nn.functional.rrelu(Tensor([2, 3, 4, 0],"float16"), 0.1, 0.3, training=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:26.991368 GPU 1 70853 test begin: paddle.nn.functional.rrelu(Tensor([2, 3, 4, 0],"float16"), 0.3, 0.300000009, training=True, )
[cuda error] paddle.nn.functional.rrelu(Tensor([2, 3, 4, 0],"float16"), 0.3, 0.300000009, training=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:27.015954 GPU 1 70805 test begin: paddle.nn.functional.rrelu(Tensor([2, 3, 4, 0],"float32"), 0.1, 0.3, training=False, )
[cuda error] paddle.nn.functional.rrelu(Tensor([2, 3, 4, 0],"float32"), 0.1, 0.3, training=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:27.026883 GPU 1 69611 test begin: paddle.nn.functional.rrelu(Tensor([2, 3, 4, 0],"float32"), 0.3, 0.300000009, training=True, )
[cuda error] paddle.nn.functional.rrelu(Tensor([2, 3, 4, 0],"float32"), 0.3, 0.300000009, training=True, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:27.149364 GPU 1 69611 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([0, 5],"float64"), Tensor([0, 5],"float64"), Tensor([0, 5],"float64"), margin=0.3, swap=False, reduction="mean", name=None, )
[cuda error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([0, 5],"float64"), Tensor([0, 5],"float64"), Tensor([0, 5],"float64"), margin=0.3, swap=False, reduction="mean", name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:27.181002 GPU 1 70853 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([0, 5],"float64"), Tensor([0, 5],"float64"), Tensor([0, 5],"float64"), margin=0.3, swap=False, reduction="none", name=None, )
[cuda error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([0, 5],"float64"), Tensor([0, 5],"float64"), Tensor([0, 5],"float64"), margin=0.3, swap=False, reduction="none", name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:27.192229 GPU 1 70805 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([0, 5],"float64"), Tensor([0, 5],"float64"), Tensor([0, 5],"float64"), margin=0.3, swap=False, reduction="sum", name=None, )
[cuda error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([0, 5],"float64"), Tensor([0, 5],"float64"), Tensor([0, 5],"float64"), margin=0.3, swap=False, reduction="sum", name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:27.314618 GPU 1 69611 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([0, 5],"float64"), Tensor([0, 5],"float64"), Tensor([0, 5],"float64"), margin=0.3, swap=True, reduction="mean", name=None, )
[cuda error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([0, 5],"float64"), Tensor([0, 5],"float64"), Tensor([0, 5],"float64"), margin=0.3, swap=True, reduction="mean", name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:27.361229 GPU 1 70896 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), margin=0.3, swap=False, reduction="mean", name=None, )
[paddle error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), margin=0.3, swap=False, reduction="mean", name=None, ) 
 The positive distance or negative distance should be greater than 0, The distance functions should be checked.

2025-05-21 22:08:27.377448 GPU 1 70853 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), margin=0.3, swap=False, reduction="none", name=None, )
[paddle error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), margin=0.3, swap=False, reduction="none", name=None, ) 
 The positive distance or negative distance should be greater than 0, The distance functions should be checked.

2025-05-21 22:08:27.421123 GPU 1 70805 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), margin=0.3, swap=False, reduction="sum", name=None, )
[paddle error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), margin=0.3, swap=False, reduction="sum", name=None, ) 
 The positive distance or negative distance should be greater than 0, The distance functions should be checked.

2025-05-21 22:08:27.455753 GPU 1 69611 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), margin=0.3, swap=True, reduction="mean", name=None, )
[paddle error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), margin=0.3, swap=True, reduction="mean", name=None, ) 
 The positive distance or negative distance should be greater than 0, The distance functions should be checked.

2025-05-21 22:08:27.637522 GPU 1 69611 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([0, 5],"float64"), positive=Tensor([0, 5],"float64"), negative=Tensor([0, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="mean", )
[cuda error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([0, 5],"float64"), positive=Tensor([0, 5],"float64"), negative=Tensor([0, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="mean", ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:27.643563 GPU 1 70853 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([0, 5],"float64"), positive=Tensor([0, 5],"float64"), negative=Tensor([0, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="none", )
[cuda error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([0, 5],"float64"), positive=Tensor([0, 5],"float64"), negative=Tensor([0, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="none", ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:27.660825 GPU 1 70896 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([0, 5],"float64"), positive=Tensor([0, 5],"float64"), negative=Tensor([0, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="sum", )
[cuda error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([0, 5],"float64"), positive=Tensor([0, 5],"float64"), negative=Tensor([0, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="sum", ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:27.820810 GPU 1 70805 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([0, 5],"float64"), positive=Tensor([0, 5],"float64"), negative=Tensor([0, 5],"float64"), distance_function=None, margin=0.3, swap=True, reduction="mean", )
[cuda error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([0, 5],"float64"), positive=Tensor([0, 5],"float64"), negative=Tensor([0, 5],"float64"), distance_function=None, margin=0.3, swap=True, reduction="mean", ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:28.051240 GPU 1 69611 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 0],"float64"), positive=Tensor([5, 0],"float64"), negative=Tensor([5, 0],"float64"), distance_function=None, margin=0.3, swap=False, reduction="mean", )
[paddle error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 0],"float64"), positive=Tensor([5, 0],"float64"), negative=Tensor([5, 0],"float64"), distance_function=None, margin=0.3, swap=False, reduction="mean", ) 
 The positive distance or negative distance should be greater than 0, The distance functions should be checked.

2025-05-21 22:08:28.208502 GPU 1 70853 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 0],"float64"), positive=Tensor([5, 0],"float64"), negative=Tensor([5, 0],"float64"), distance_function=None, margin=0.3, swap=False, reduction="none", )
[paddle error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 0],"float64"), positive=Tensor([5, 0],"float64"), negative=Tensor([5, 0],"float64"), distance_function=None, margin=0.3, swap=False, reduction="none", ) 
 The positive distance or negative distance should be greater than 0, The distance functions should be checked.

2025-05-21 22:08:28.219552 GPU 1 70896 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 0],"float64"), positive=Tensor([5, 0],"float64"), negative=Tensor([5, 0],"float64"), distance_function=None, margin=0.3, swap=False, reduction="sum", )
[paddle error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 0],"float64"), positive=Tensor([5, 0],"float64"), negative=Tensor([5, 0],"float64"), distance_function=None, margin=0.3, swap=False, reduction="sum", ) 
 The positive distance or negative distance should be greater than 0, The distance functions should be checked.

2025-05-21 22:08:28.241732 GPU 1 70886 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 0],"float64"), positive=Tensor([5, 0],"float64"), negative=Tensor([5, 0],"float64"), distance_function=None, margin=0.3, swap=True, reduction="mean", )
[paddle error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 0],"float64"), positive=Tensor([5, 0],"float64"), negative=Tensor([5, 0],"float64"), distance_function=None, margin=0.3, swap=True, reduction="mean", ) 
 The positive distance or negative distance should be greater than 0, The distance functions should be checked.

2025-05-21 22:08:28.394683 GPU 1 70872 test begin: paddle.nn.utils.vector_to_parameters(Tensor([165],"float32"), list[Tensor([0, 15],"float32"),Tensor([15],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([165],"float32"), list[Tensor([0, 15],"float32"),Tensor([15],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 15], input(X)'s shape = [165], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:15 != input_axis_dim:165.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:28.401853 GPU 1 70902 test begin: paddle.nn.utils.vector_to_parameters(Tensor([165],"float32"), list[Tensor([10, 0],"float32"),Tensor([15],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([165],"float32"), list[Tensor([10, 0],"float32"),Tensor([15],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 15], input(X)'s shape = [165], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:15 != input_axis_dim:165.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:28.556483 GPU 1 69611 test begin: paddle.nn.utils.vector_to_parameters(Tensor([165],"float32"), list[Tensor([10, 15],"float32"),Tensor([0],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([165],"float32"), list[Tensor([10, 15],"float32"),Tensor([0],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [150, 0], input(X)'s shape = [165], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:150 != input_axis_dim:165.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:28.563643 GPU 1 70853 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:28.584399 GPU 1 70872 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:28.596902 GPU 1 70910 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:28.610778 GPU 1 70936 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:28.759850 GPU 1 70805 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:28.783754 GPU 1 70896 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:28.814618 GPU 1 70902 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:28.816271 GPU 1 69611 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:28.976801 GPU 1 70886 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:29.639261 GPU 1 70872 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:29.887847 GPU 1 70853 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:29.946561 GPU 1 69611 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:29.951770 GPU 1 70902 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:29.962515 GPU 1 70896 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:29.964776 GPU 1 70910 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([0],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([0],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:29.977545 GPU 1 70936 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:29.985901 GPU 1 70886 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:29.992189 GPU 1 70805 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:30.039261 GPU 1 71028 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:30.410601 GPU 1 70929 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:30.756685 GPU 1 70872 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:30.757500 GPU 1 70947 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:30.765931 GPU 1 71062 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:31.148893 GPU 1 69611 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:31.476932 GPU 1 71028 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:31.504901 GPU 1 70902 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:31.534588 GPU 1 70853 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:31.536338 GPU 1 70910 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:31.882176 GPU 1 71061 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:31.884761 GPU 1 70886 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:32.018471 GPU 1 70805 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:32.338676 GPU 1 70896 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:32.374496 GPU 1 70929 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:32.404108 GPU 1 70936 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:32.508749 GPU 1 71062 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:32.513033 GPU 1 70872 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:32.632520 GPU 1 70947 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([0],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([0],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:32.674084 GPU 1 69611 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:32.835823 GPU 1 71093 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:32.860992 GPU 1 71070 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:32.905139 GPU 1 70902 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:32.911854 GPU 1 70853 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:32.947658 GPU 1 71028 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:32.995567 GPU 1 70910 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:33.002950 GPU 1 70886 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:33.006533 GPU 1 71061 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:33.066670 GPU 1 70805 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:33.225968 GPU 1 70929 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:33.337891 GPU 1 71129 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:33.370093 GPU 1 70896 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:33.709858 GPU 1 71121 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:33.728405 GPU 1 71062 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:33.886362 GPU 1 71152 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:33.945848 GPU 1 70936 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:34.033889 GPU 1 70872 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:34.048709 GPU 1 71096 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:34.067166 GPU 1 70947 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:34.088420 GPU 1 69611 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:34.221766 GPU 1 71112 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([0],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([0],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:34.270279 GPU 1 71028 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:34.270791 GPU 1 70902 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:34.466178 GPU 1 71061 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:34.466593 GPU 1 70886 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:34.470562 GPU 1 70853 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:34.475022 GPU 1 71070 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:34.475218 GPU 1 70805 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:34.638013 GPU 1 71093 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:34.659321 GPU 1 70910 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:34.923858 GPU 1 70929 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:35.111106 GPU 1 71129 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:35.115894 GPU 1 70896 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:35.304550 GPU 1 71062 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:35.353293 GPU 1 71121 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:35.405762 GPU 1 70872 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:35.603938 GPU 1 70947 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:35.642399 GPU 1 70936 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:35.656045 GPU 1 71152 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:35.717256 GPU 1 71028 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:35.738446 GPU 1 71096 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:35.779586 GPU 1 70902 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:35.802903 GPU 1 69611 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([0],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([0],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:35.808105 GPU 1 70805 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:35.816164 GPU 1 71061 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:35.825805 GPU 1 71070 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:35.861701 GPU 1 71112 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:35.876030 GPU 1 70910 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:35.898094 GPU 1 70853 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:35.898439 GPU 1 70886 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:35.913523 GPU 1 71093 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:35.922923 GPU 1 70929 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:36.499738 GPU 1 71129 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:36.591365 GPU 1 70896 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:36.866605 GPU 1 71062 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:36.872150 GPU 1 71121 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:36.872530 GPU 1 70872 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:36.991554 GPU 1 70947 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:37.426695 GPU 1 70902 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:37.454707 GPU 1 70936 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:37.573461 GPU 1 71096 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:37.574014 GPU 1 70805 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:37.709032 GPU 1 71028 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:37.710455 GPU 1 71112 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:37.713081 GPU 1 70886 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:37.760926 GPU 1 69611 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:37.770446 GPU 1 71070 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:37.771909 GPU 1 70853 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:37.777060 GPU 1 71152 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:37.783768 GPU 1 70929 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:37.890261 GPU 1 70910 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:37.897523 GPU 1 71061 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:37.948643 GPU 1 71093 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:38.357628 GPU 1 71129 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:38.501747 GPU 1 70896 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:38.503386 GPU 1 70947 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:38.550573 GPU 1 71121 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:38.581059 GPU 1 70872 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:38.976283 GPU 1 70902 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([0],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([0],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:38.977002 GPU 1 70936 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:38.979703 GPU 1 71062 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:39.410297 GPU 1 70805 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:39.430037 GPU 1 71096 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:39.522623 GPU 1 71112 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:39.525903 GPU 1 69611 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:39.548414 GPU 1 70910 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:39.565281 GPU 1 70886 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:39.608153 GPU 1 71152 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:39.615647 GPU 1 71028 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:39.623667 GPU 1 71070 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:39.630195 GPU 1 70853 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:39.711010 GPU 1 71061 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:39.781473 GPU 1 71093 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:39.904195 GPU 1 70929 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:40.190342 GPU 1 70947 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:40.219541 GPU 1 70872 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:40.230476 GPU 1 70896 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:40.399523 GPU 1 71121 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:40.406953 GPU 1 71129 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:40.771654 GPU 1 70936 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:40.788082 GPU 1 71062 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:40.806792 GPU 1 70902 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:40.987623 GPU 1 71112 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:41.013730 GPU 1 71096 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:41.132660 GPU 1 69611 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:41.241692 GPU 1 70805 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:41.342661 GPU 1 71070 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:41.361505 GPU 1 70910 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:41.429422 GPU 1 70853 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:41.430256 GPU 1 71093 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:41.445303 GPU 1 71152 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:41.466880 GPU 1 72103 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:41.481576 GPU 1 71061 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:41.487323 GPU 1 71028 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:41.544916 GPU 1 70886 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([0],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([0],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:41.796844 GPU 1 70896 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:41.902008 GPU 1 70947 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:41.941201 GPU 1 70872 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:42.043356 GPU 1 70929 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:42.171883 GPU 1 71129 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:42.209267 GPU 1 71121 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:42.209816 GPU 1 71096 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:42.213737 GPU 1 71062 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:42.222194 GPU 1 70936 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:42.349620 GPU 1 72116 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:42.412114 GPU 1 70902 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:42.791821 GPU 1 69611 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:42.813234 GPU 1 71112 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:42.963278 GPU 1 71093 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:42.965629 GPU 1 71070 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:42.965822 GPU 1 70910 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:42.966840 GPU 1 71152 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:42.974136 GPU 1 70805 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:42.974277 GPU 1 70853 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:43.069235 GPU 1 71028 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:43.128263 GPU 1 71061 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:43.130483 GPU 1 70886 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:43.135724 GPU 1 72103 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:43.219199 GPU 1 71041 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:43.325100 GPU 1 70896 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:43.636188 GPU 1 70947 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:43.705553 GPU 1 70872 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:43.749224 GPU 1 71129 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:43.796246 GPU 1 70929 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:43.976101 GPU 1 71121 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:44.076341 GPU 1 70936 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:44.115512 GPU 1 70902 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:44.117984 GPU 1 71062 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:44.293859 GPU 1 71096 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:44.476312 GPU 1 72116 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:44.597914 GPU 1 69611 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([0],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([0],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:44.904243 GPU 1 70853 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:44.913056 GPU 1 70886 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:44.955483 GPU 1 71041 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:45.096202 GPU 1 71093 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:45.097534 GPU 1 71028 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:45.109965 GPU 1 71070 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:45.112530 GPU 1 71061 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:45.194882 GPU 1 70947 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:45.244430 GPU 1 71112 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:45.266421 GPU 1 70910 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:45.270733 GPU 1 70805 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:45.275660 GPU 1 71152 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:45.282675 GPU 1 70872 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:45.362175 GPU 1 70896 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:45.510697 GPU 1 72103 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:45.597701 GPU 1 70929 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:45.734191 GPU 1 71129 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:45.738130 GPU 1 70936 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:45.747948 GPU 1 71062 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:45.811865 GPU 1 70902 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:45.858340 GPU 1 69611 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:45.880110 GPU 1 71121 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:46.012310 GPU 1 70853 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:46.061862 GPU 1 71061 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:46.108031 GPU 1 70886 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:46.114844 GPU 1 71070 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:46.129260 GPU 1 71096 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:46.228537 GPU 1 70872 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:46.302206 GPU 1 70910 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:46.312100 GPU 1 70805 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:46.393755 GPU 1 71041 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:46.416159 GPU 1 70896 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:46.516771 GPU 1 71028 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:46.544464 GPU 1 71152 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:46.607168 GPU 1 71093 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:46.677645 GPU 1 70929 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([0],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([0],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:46.718149 GPU 1 71112 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:46.859942 GPU 1 70947 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:46.876381 GPU 1 72116 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:46.897961 GPU 1 72103 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:46.905283 GPU 1 70902 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:47.496735 GPU 1 71121 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:47.496799 GPU 1 70936 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:47.521562 GPU 1 71041 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:47.620482 GPU 1 71070 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:47.779458 GPU 1 69611 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:47.793542 GPU 1 71061 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-05-21 22:08:47.800403 GPU 1 70853 test begin: paddle.nn.utils.vector_to_parameters(Tensor([27],"float32"), list[Tensor([0, 2, 4],"float32"),Tensor([3],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([27],"float32"), list[Tensor([0, 2, 4],"float32"),Tensor([3],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 3], input(X)'s shape = [27], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:3 != input_axis_dim:27.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:47.805210 GPU 1 70886 test begin: paddle.nn.utils.vector_to_parameters(Tensor([27],"float32"), list[Tensor([3, 0, 4],"float32"),Tensor([3],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([27],"float32"), list[Tensor([3, 0, 4],"float32"),Tensor([3],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 3], input(X)'s shape = [27], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:3 != input_axis_dim:27.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:47.806793 GPU 1 71129 test begin: paddle.nn.utils.vector_to_parameters(Tensor([27],"float32"), list[Tensor([3, 2, 0],"float32"),Tensor([3],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([27],"float32"), list[Tensor([3, 2, 0],"float32"),Tensor([3],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 3], input(X)'s shape = [27], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:3 != input_axis_dim:27.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:47.809106 GPU 1 70872 test begin: paddle.nn.utils.vector_to_parameters(Tensor([27],"float32"), list[Tensor([3, 2, 4],"float32"),Tensor([0],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([27],"float32"), list[Tensor([3, 2, 4],"float32"),Tensor([0],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [24, 0], input(X)'s shape = [27], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:24 != input_axis_dim:27.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:47.963563 GPU 1 70910 test begin: paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([0, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([0, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 768, 48, 48, 768, 768, 48, 48], input(X)'s shape = [2880], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2496 != input_axis_dim:2880.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.098806 GPU 1 70872 test begin: paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 0],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 0],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 768, 48, 48, 768, 768, 48, 48], input(X)'s shape = [2880], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2496 != input_axis_dim:2880.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.102735 GPU 1 70886 test begin: paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([0, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([0, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [384, 0, 48, 48, 768, 768, 48, 48], input(X)'s shape = [2880], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2112 != input_axis_dim:2880.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.108987 GPU 1 70853 test begin: paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 0],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 0],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [384, 0, 48, 48, 768, 768, 48, 48], input(X)'s shape = [2880], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2112 != input_axis_dim:2880.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.180164 GPU 1 70805 test begin: paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([0],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([0],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [384, 768, 0, 48, 768, 768, 48, 48], input(X)'s shape = [2880], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2832 != input_axis_dim:2880.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.186037 GPU 1 71096 test begin: paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([0],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([0],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [384, 768, 48, 0, 768, 768, 48, 48], input(X)'s shape = [2880], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2832 != input_axis_dim:2880.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.218646 GPU 1 71129 test begin: paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([0, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([0, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [384, 768, 48, 48, 0, 768, 48, 48], input(X)'s shape = [2880], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2112 != input_axis_dim:2880.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.268264 GPU 1 70910 test begin: paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 0],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 0],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [384, 768, 48, 48, 0, 768, 48, 48], input(X)'s shape = [2880], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2112 != input_axis_dim:2880.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.287420 GPU 1 71112 test begin: paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([0, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([0, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [384, 768, 48, 48, 768, 0, 48, 48], input(X)'s shape = [2880], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2112 != input_axis_dim:2880.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.289242 GPU 1 70896 test begin: paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 0],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 0],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [384, 768, 48, 48, 768, 0, 48, 48], input(X)'s shape = [2880], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2112 != input_axis_dim:2880.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.307021 GPU 1 70872 test begin: paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([0],"float32"),Tensor([48],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([0],"float32"),Tensor([48],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [384, 768, 48, 48, 768, 768, 0, 48], input(X)'s shape = [2880], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2832 != input_axis_dim:2880.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.312142 GPU 1 70853 test begin: paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([0],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([0],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [384, 768, 48, 48, 768, 768, 48, 0], input(X)'s shape = [2880], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2832 != input_axis_dim:2880.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.363048 GPU 1 70886 test begin: paddle.nn.utils.vector_to_parameters(Tensor([30],"float32"), list[Tensor([0, 3],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([30],"float32"), list[Tensor([0, 3],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 0], input(X)'s shape = [30], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:0 != input_axis_dim:30.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.381057 GPU 1 71152 test begin: paddle.nn.utils.vector_to_parameters(Tensor([30],"float32"), list[Tensor([10, 0],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([30],"float32"), list[Tensor([10, 0],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 0], input(X)'s shape = [30], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:0 != input_axis_dim:30.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.387644 GPU 1 71028 test begin: paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([0, 8],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([64, 16],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([0, 8],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([64, 16],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 1024, 64, 64, 1024, 1024, 64, 64], input(X)'s shape = [3840], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:3328 != input_axis_dim:3840.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.405217 GPU 1 71129 test begin: paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 0],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([64, 16],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 0],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([64, 16],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 1024, 64, 64, 1024, 1024, 64, 64], input(X)'s shape = [3840], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:3328 != input_axis_dim:3840.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.415036 GPU 1 71062 test begin: paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([0, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([64, 16],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([0, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([64, 16],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [512, 0, 64, 64, 1024, 1024, 64, 64], input(X)'s shape = [3840], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2816 != input_axis_dim:3840.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.423450 GPU 1 72103 test begin: paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([64, 0],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([64, 16],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([64, 0],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([64, 16],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [512, 0, 64, 64, 1024, 1024, 64, 64], input(X)'s shape = [3840], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2816 != input_axis_dim:3840.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.425358 GPU 1 71093 test begin: paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([64, 16],"float32"),Tensor([0],"float32"),Tensor([64],"float32"),Tensor([64, 16],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([64, 16],"float32"),Tensor([0],"float32"),Tensor([64],"float32"),Tensor([64, 16],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [512, 1024, 0, 64, 1024, 1024, 64, 64], input(X)'s shape = [3840], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:3776 != input_axis_dim:3840.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.431946 GPU 1 70947 test begin: paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([0],"float32"),Tensor([64, 16],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([0],"float32"),Tensor([64, 16],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [512, 1024, 64, 0, 1024, 1024, 64, 64], input(X)'s shape = [3840], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:3776 != input_axis_dim:3840.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.454390 GPU 1 70929 test begin: paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([0, 16],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([0, 16],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [512, 1024, 64, 64, 0, 1024, 64, 64], input(X)'s shape = [3840], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2816 != input_axis_dim:3840.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.456910 GPU 1 70805 test begin: paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([64, 0],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([64, 0],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [512, 1024, 64, 64, 0, 1024, 64, 64], input(X)'s shape = [3840], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2816 != input_axis_dim:3840.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.468321 GPU 1 70896 test begin: paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([64, 16],"float32"),Tensor([0, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([64, 16],"float32"),Tensor([0, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [512, 1024, 64, 64, 1024, 0, 64, 64], input(X)'s shape = [3840], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2816 != input_axis_dim:3840.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.472464 GPU 1 70902 test begin: paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([64, 16],"float32"),Tensor([64, 0],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([64, 16],"float32"),Tensor([64, 0],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [512, 1024, 64, 64, 1024, 0, 64, 64], input(X)'s shape = [3840], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2816 != input_axis_dim:3840.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.478514 GPU 1 70910 test begin: paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([64, 16],"float32"),Tensor([64, 16],"float32"),Tensor([0],"float32"),Tensor([64],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([64, 16],"float32"),Tensor([64, 16],"float32"),Tensor([0],"float32"),Tensor([64],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [512, 1024, 64, 64, 1024, 1024, 0, 64], input(X)'s shape = [3840], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:3776 != input_axis_dim:3840.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.510605 GPU 1 71112 test begin: paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([64, 16],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([0],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([64, 16],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([0],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [512, 1024, 64, 64, 1024, 1024, 64, 0], input(X)'s shape = [3840], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:3776 != input_axis_dim:3840.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.512118 GPU 1 71041 test begin: paddle.nn.utils.vector_to_parameters(Tensor([387],"float32"), list[Tensor([0, 2, 4, 4, 4],"float32"),Tensor([3],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([387],"float32"), list[Tensor([0, 2, 4, 4, 4],"float32"),Tensor([3],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 3], input(X)'s shape = [387], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:3 != input_axis_dim:387.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.518040 GPU 1 71096 test begin: paddle.nn.utils.vector_to_parameters(Tensor([387],"float32"), list[Tensor([3, 0, 4, 4, 4],"float32"),Tensor([3],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([387],"float32"), list[Tensor([3, 0, 4, 4, 4],"float32"),Tensor([3],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 3], input(X)'s shape = [387], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:3 != input_axis_dim:387.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.536109 GPU 1 72116 test begin: paddle.nn.utils.vector_to_parameters(Tensor([387],"float32"), list[Tensor([3, 2, 0, 4, 4],"float32"),Tensor([3],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([387],"float32"), list[Tensor([3, 2, 0, 4, 4],"float32"),Tensor([3],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 3], input(X)'s shape = [387], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:3 != input_axis_dim:387.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.566887 GPU 1 71028 test begin: paddle.nn.utils.vector_to_parameters(Tensor([387],"float32"), list[Tensor([3, 2, 4, 0, 4],"float32"),Tensor([3],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([387],"float32"), list[Tensor([3, 2, 4, 0, 4],"float32"),Tensor([3],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 3], input(X)'s shape = [387], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:3 != input_axis_dim:387.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.567875 GPU 1 71121 test begin: paddle.nn.utils.vector_to_parameters(Tensor([387],"float32"), list[Tensor([3, 2, 4, 4, 0],"float32"),Tensor([3],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([387],"float32"), list[Tensor([3, 2, 4, 4, 0],"float32"),Tensor([3],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 3], input(X)'s shape = [387], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:3 != input_axis_dim:387.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.585071 GPU 1 71129 test begin: paddle.nn.utils.vector_to_parameters(Tensor([387],"float32"), list[Tensor([3, 2, 4, 4, 4],"float32"),Tensor([0],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([387],"float32"), list[Tensor([3, 2, 4, 4, 4],"float32"),Tensor([0],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [384, 0], input(X)'s shape = [387], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:384 != input_axis_dim:387.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.594473 GPU 1 71062 test begin: paddle.nn.utils.vector_to_parameters(Tensor([6],"float32"), list[Tensor([0, 2],"float32"),Tensor([2],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([6],"float32"), list[Tensor([0, 2],"float32"),Tensor([2],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 2], input(X)'s shape = [6], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2 != input_axis_dim:6.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.600157 GPU 1 72103 test begin: paddle.nn.utils.vector_to_parameters(Tensor([6],"float32"), list[Tensor([2, 0],"float32"),Tensor([2],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([6],"float32"), list[Tensor([2, 0],"float32"),Tensor([2],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 2], input(X)'s shape = [6], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2 != input_axis_dim:6.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.606652 GPU 1 71093 test begin: paddle.nn.utils.vector_to_parameters(Tensor([6],"float32"), list[Tensor([2, 2],"float32"),Tensor([0],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([6],"float32"), list[Tensor([2, 2],"float32"),Tensor([0],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [4, 0], input(X)'s shape = [6], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:4 != input_axis_dim:6.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.624251 GPU 1 70872 test begin: paddle.nn.utils.vector_to_parameters(Tensor([99],"float32"), list[Tensor([0, 2, 4, 4],"float32"),Tensor([3],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([99],"float32"), list[Tensor([0, 2, 4, 4],"float32"),Tensor([3],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 3], input(X)'s shape = [99], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:3 != input_axis_dim:99.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.627990 GPU 1 71041 test begin: paddle.nn.utils.vector_to_parameters(Tensor([99],"float32"), list[Tensor([3, 0, 4, 4],"float32"),Tensor([3],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([99],"float32"), list[Tensor([3, 0, 4, 4],"float32"),Tensor([3],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 3], input(X)'s shape = [99], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:3 != input_axis_dim:99.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.629578 GPU 1 71070 test begin: paddle.nn.utils.vector_to_parameters(Tensor([99],"float32"), list[Tensor([3, 2, 0, 4],"float32"),Tensor([3],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([99],"float32"), list[Tensor([3, 2, 0, 4],"float32"),Tensor([3],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 3], input(X)'s shape = [99], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:3 != input_axis_dim:99.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.634842 GPU 1 70929 test begin: paddle.nn.utils.vector_to_parameters(Tensor([99],"float32"), list[Tensor([3, 2, 4, 0],"float32"),Tensor([3],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([99],"float32"), list[Tensor([3, 2, 4, 0],"float32"),Tensor([3],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 3], input(X)'s shape = [99], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:3 != input_axis_dim:99.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.637275 GPU 1 70886 test begin: paddle.nn.utils.vector_to_parameters(Tensor([99],"float32"), list[Tensor([3, 2, 4, 4],"float32"),Tensor([0],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([99],"float32"), list[Tensor([3, 2, 4, 4],"float32"),Tensor([0],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [96, 0], input(X)'s shape = [99], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:96 != input_axis_dim:99.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-05-21 22:08:48.638619 GPU 1 70896 test begin: paddle.outer(Tensor([10],"float32"), Tensor([0],"float32"), )
W0521 22:08:54.331626 70896 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.outer(Tensor([10],"float32"), Tensor([0],"float32"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:40)


2025-05-21 22:08:48.648472 GPU 1 70902 test begin: paddle.outer(x=Tensor([4],"float64"), y=Tensor([0],"float64"), )
W0521 22:08:56.007368 70902 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.outer(x=Tensor([4],"float64"), y=Tensor([0],"float64"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:08:48.662705 GPU 1 70910 test begin: paddle.pdist(Tensor([0, 20],"float32"), 0, )
[cuda error] paddle.pdist(Tensor([0, 20],"float32"), 0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:48.663767 GPU 1 69611 test begin: paddle.pdist(Tensor([0, 20],"float32"), 1.0, )
[cuda error] paddle.pdist(Tensor([0, 20],"float32"), 1.0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:48.671903 GPU 1 70853 test begin: paddle.pdist(Tensor([0, 20],"float32"), 1.5, )
[cuda error] paddle.pdist(Tensor([0, 20],"float32"), 1.5, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:48.682403 GPU 1 71152 test begin: paddle.pdist(Tensor([0, 20],"float32"), 2.0, )
[cuda error] paddle.pdist(Tensor([0, 20],"float32"), 2.0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:48.686140 GPU 1 71112 test begin: paddle.pdist(Tensor([0, 20],"float32"), 2.5, )
[cuda error] paddle.pdist(Tensor([0, 20],"float32"), 2.5, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:48.690671 GPU 1 71096 test begin: paddle.pdist(Tensor([0, 20],"float32"), 3.0, )
[cuda error] paddle.pdist(Tensor([0, 20],"float32"), 3.0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:48.708161 GPU 1 70947 test begin: paddle.pdist(Tensor([0, 20],"float32"), math.inf, )
[cuda error] paddle.pdist(Tensor([0, 20],"float32"), math.inf, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:48.731000 GPU 1 71028 test begin: paddle.pdist(Tensor([0, 20],"float64"), 2.0, )
[cuda error] paddle.pdist(Tensor([0, 20],"float64"), 2.0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:48.731509 GPU 1 71121 test begin: paddle.pdist(Tensor([10, 0],"float32"), 0, )
W0521 22:08:48.914182 71121 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.pdist(Tensor([10, 0],"float32"), 0, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:08:48.736526 GPU 1 70805 test begin: paddle.pdist(Tensor([10, 0],"float32"), 1.0, )
W0521 22:08:48.940979 70805 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.pdist(Tensor([10, 0],"float32"), 1.0, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:08:48.737588 GPU 1 71041 test begin: paddle.pdist(Tensor([10, 0],"float32"), 1.5, )
W0521 22:08:48.854543 71041 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.pdist(Tensor([10, 0],"float32"), 1.5, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:08:48.750861 GPU 1 71129 test begin: paddle.pdist(Tensor([10, 0],"float32"), 2.0, )
W0521 22:08:48.929807 71129 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.pdist(Tensor([10, 0],"float32"), 2.0, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:08:48.761931 GPU 1 71062 test begin: paddle.pdist(Tensor([10, 0],"float32"), 2.5, )
W0521 22:08:49.019001 71062 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.pdist(Tensor([10, 0],"float32"), 2.5, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:08:48.766938 GPU 1 72103 test begin: paddle.pdist(Tensor([10, 0],"float32"), 3.0, )
W0521 22:08:48.943527 72103 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.pdist(Tensor([10, 0],"float32"), 3.0, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:08:48.775826 GPU 1 71093 test begin: paddle.pdist(Tensor([10, 0],"float32"), math.inf, )
W0521 22:08:48.965708 71093 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.pdist(Tensor([10, 0],"float32"), math.inf, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:08:48.785904 GPU 1 70936 test begin: paddle.pdist(Tensor([50, 0],"float64"), 2.0, )
W0521 22:08:48.975644 70936 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.pdist(Tensor([50, 0],"float64"), 2.0, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:08:48.795648 GPU 1 72116 test begin: paddle.real(Tensor([0, 10, 10, 20],"complex64"), )
[Pass] paddle.real(Tensor([0, 10, 10, 20],"complex64"), )

2025-05-21 22:08:48.797310 GPU 1 71061 test begin: paddle.real(Tensor([0, 20, 2, 3],"complex128"), )
[Pass] paddle.real(Tensor([0, 20, 2, 3],"complex128"), )

2025-05-21 22:08:48.800269 GPU 1 70929 test begin: paddle.real(Tensor([10, 0, 10, 20],"complex64"), )
[Pass] paddle.real(Tensor([10, 0, 10, 20],"complex64"), )

2025-05-21 22:08:48.802333 GPU 1 71070 test begin: paddle.real(Tensor([10, 10, 0, 20],"complex64"), )
[Pass] paddle.real(Tensor([10, 10, 0, 20],"complex64"), )

2025-05-21 22:08:48.804946 GPU 1 70872 test begin: paddle.real(Tensor([10, 10, 10, 0],"complex64"), )
[Pass] paddle.real(Tensor([10, 10, 10, 0],"complex64"), )

2025-05-21 22:08:48.824941 GPU 1 70886 test begin: paddle.real(Tensor([2, 0, 2, 3],"complex128"), )
[Pass] paddle.real(Tensor([2, 0, 2, 3],"complex128"), )

2025-05-21 22:08:48.832432 GPU 1 69611 test begin: paddle.real(Tensor([2, 20, 0, 3],"complex128"), )
[Pass] paddle.real(Tensor([2, 20, 0, 3],"complex128"), )

2025-05-21 22:08:48.849646 GPU 1 70910 test begin: paddle.real(Tensor([2, 20, 2, 0],"complex128"), )
[Pass] paddle.real(Tensor([2, 20, 2, 0],"complex128"), )

2025-05-21 22:08:48.855529 GPU 1 71041 test begin: paddle.real(x=Tensor([0, 10],"complex128"), )
[Pass] paddle.real(x=Tensor([0, 10],"complex128"), )

2025-05-21 22:08:48.878987 GPU 1 71112 test begin: paddle.real(x=Tensor([0, 10],"complex64"), )
[Pass] paddle.real(x=Tensor([0, 10],"complex64"), )

2025-05-21 22:08:48.916017 GPU 1 71121 test begin: paddle.real(x=Tensor([1, 0],"complex64"), )
[Pass] paddle.real(x=Tensor([1, 0],"complex64"), )

2025-05-21 22:08:48.930748 GPU 1 70853 test begin: paddle.real(x=Tensor([20, 0],"complex128"), )
[Pass] paddle.real(x=Tensor([20, 0],"complex128"), )

2025-05-21 22:08:48.931877 GPU 1 71129 test begin: paddle.renorm(Tensor([0, 2, 3],"float32"), 1.0, -1, 2.05, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_renorm(_object*, _object*, _object*)
1   renorm_ad_func(paddle::Tensor const&, float, int, float)
2   paddle::experimental::renorm(paddle::Tensor const&, float, int, float)
3   void phi::RenormKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, int, float, phi::DenseTensor*)
4   void phi::funcs::RenormFunc<float>(phi::GPUContext const&, float const*, float*, float, int, float, long, common::DDim const&, long)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836529 (unix time) try "date -d @1747836529" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f73dba5abd9) received by PID 71129 (TID 0x7f74806f1740) from PID 18446744073099652057 ***]


2025-05-21 22:08:48.942544 GPU 1 71028 test begin: paddle.renorm(Tensor([0, 2, 3],"float32"), 1.0, 2, 2.05, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_renorm(_object*, _object*, _object*)
1   renorm_ad_func(paddle::Tensor const&, float, int, float)
2   paddle::experimental::renorm(paddle::Tensor const&, float, int, float)
3   void phi::RenormKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, int, float, phi::DenseTensor*)
4   void phi::funcs::RenormFunc<float>(phi::GPUContext const&, float const*, float*, float, int, float, long, common::DDim const&, long)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836529 (unix time) try "date -d @1747836529" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fb939ac1bd9) received by PID 71028 (TID 0x7fb9de758740) from PID 967580633 ***]


2025-05-21 22:08:48.943079 GPU 1 70805 test begin: paddle.renorm(Tensor([0, 20, 1],"float32"), 1.0, -1, 2.05, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_renorm(_object*, _object*, _object*)
1   renorm_ad_func(paddle::Tensor const&, float, int, float)
2   paddle::experimental::renorm(paddle::Tensor const&, float, int, float)
3   void phi::RenormKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, int, float, phi::DenseTensor*)
4   void phi::funcs::RenormFunc<float>(phi::GPUContext const&, float const*, float*, float, int, float, long, common::DDim const&, long)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836529 (unix time) try "date -d @1747836529" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fc880c74bd9) received by PID 70805 (TID 0x7fc92590b740) from PID 18446744071575129049 ***]


2025-05-21 22:08:48.946322 GPU 1 72103 test begin: paddle.renorm(Tensor([10, 0, 1],"float32"), 1.0, -1, 2.05, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_renorm(_object*, _object*, _object*)
1   renorm_ad_func(paddle::Tensor const&, float, int, float)
2   paddle::experimental::renorm(paddle::Tensor const&, float, int, float)
3   void phi::RenormKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, int, float, phi::DenseTensor*)
4   void phi::funcs::RenormFunc<float>(phi::GPUContext const&, float const*, float*, float, int, float, long, common::DDim const&, long)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836529 (unix time) try "date -d @1747836529" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fa76cc9abd9) received by PID 72103 (TID 0x7fa811931740) from PID 1825156057 ***]


2025-05-21 22:08:48.958736 GPU 1 71096 test begin: paddle.renorm(Tensor([10, 20, 0],"float32"), 1.0, -1, 2.05, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_renorm(_object*, _object*, _object*)
1   renorm_ad_func(paddle::Tensor const&, float, int, float)
2   paddle::experimental::renorm(paddle::Tensor const&, float, int, float)
3   void phi::RenormKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, int, float, phi::DenseTensor*)
4   void phi::funcs::RenormFunc<float>(phi::GPUContext const&, float const*, float*, float, int, float, long, common::DDim const&, long)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836529 (unix time) try "date -d @1747836529" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fea2d3efbd9) received by PID 71096 (TID 0x7fead2086740) from PID 759102425 ***]


2025-05-21 22:08:48.965978 GPU 1 71041 test begin: paddle.renorm(Tensor([2, 0, 3],"float32"), 1.0, -1, 2.05, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_renorm(_object*, _object*, _object*)
1   renorm_ad_func(paddle::Tensor const&, float, int, float)
2   paddle::experimental::renorm(paddle::Tensor const&, float, int, float)
3   void phi::RenormKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, int, float, phi::DenseTensor*)
4   void phi::funcs::RenormFunc<float>(phi::GPUContext const&, float const*, float*, float, int, float, long, common::DDim const&, long)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836529 (unix time) try "date -d @1747836529" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f40ef153bd9) received by PID 71041 (TID 0x7f4193de8740) from PID 18446744073425730521 ***]


2025-05-21 22:08:48.967052 GPU 1 71093 test begin: paddle.renorm(Tensor([2, 0, 3],"float32"), 1.0, 2, 2.05, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_renorm(_object*, _object*, _object*)
1   renorm_ad_func(paddle::Tensor const&, float, int, float)
2   paddle::experimental::renorm(paddle::Tensor const&, float, int, float)
3   void phi::RenormKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, int, float, phi::DenseTensor*)
4   void phi::funcs::RenormFunc<float>(phi::GPUContext const&, float const*, float*, float, int, float, long, common::DDim const&, long)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836529 (unix time) try "date -d @1747836529" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7efee1174bd9) received by PID 71093 (TID 0x7eff85e0b740) from PID 18446744073190984665 ***]


2025-05-21 22:08:48.976990 GPU 1 70936 test begin: paddle.renorm(Tensor([2, 2, 0],"float32"), 1.0, -1, 2.05, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_renorm(_object*, _object*, _object*)
1   renorm_ad_func(paddle::Tensor const&, float, int, float)
2   paddle::experimental::renorm(paddle::Tensor const&, float, int, float)
3   void phi::RenormKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, int, float, phi::DenseTensor*)
4   void phi::funcs::RenormFunc<float>(phi::GPUContext const&, float const*, float*, float, int, float, long, common::DDim const&, long)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836529 (unix time) try "date -d @1747836529" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f722c8b2bd9) received by PID 70936 (TID 0x7f72d1549740) from PID 747318233 ***]


2025-05-21 22:08:48.980608 GPU 1 70872 test begin: paddle.renorm(Tensor([2, 2, 0],"float32"), 1.0, 2, 2.05, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_renorm(_object*, _object*, _object*)
1   renorm_ad_func(paddle::Tensor const&, float, int, float)
2   paddle::experimental::renorm(paddle::Tensor const&, float, int, float)
3   void phi::RenormKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, int, float, phi::DenseTensor*)
4   void phi::funcs::RenormFunc<float>(phi::GPUContext const&, float const*, float*, float, int, float, long, common::DDim const&, long)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836529 (unix time) try "date -d @1747836529" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7ff4af235bd9) received by PID 70872 (TID 0x7ff553ecc740) from PID 18446744072352914393 ***]


2025-05-21 22:08:48.992707 GPU 1 71061 test begin: paddle.renorm(x=Tensor([0, 2, 3],"float32"), p=1, axis=0, max_norm=5, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_renorm(_object*, _object*, _object*)
1   renorm_ad_func(paddle::Tensor const&, float, int, float)
2   paddle::experimental::renorm(paddle::Tensor const&, float, int, float)
3   void phi::RenormKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, int, float, phi::DenseTensor*)
4   void phi::funcs::RenormFunc<float>(phi::GPUContext const&, float const*, float*, float, int, float, long, common::DDim const&, long)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836529 (unix time) try "date -d @1747836529" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f9b8de51bd9) received by PID 71061 (TID 0x7f9c32ae8740) from PID 18446744071795186649 ***]


2025-05-21 22:08:48.995507 GPU 1 71152 test begin: paddle.renorm(x=Tensor([0, 2, 3],"float64"), p=1, axis=0, max_norm=5, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_renorm(_object*, _object*, _object*)
1   renorm_ad_func(paddle::Tensor const&, float, int, float)
2   paddle::experimental::renorm(paddle::Tensor const&, float, int, float)
3   void phi::RenormKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, int, float, phi::DenseTensor*)
4   void phi::funcs::RenormFunc<double>(phi::GPUContext const&, double const*, double*, float, int, float, long, common::DDim const&, long)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836529 (unix time) try "date -d @1747836529" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fbac1db66e9) received by PID 71152 (TID 0x7fbb66a4c740) from PID 18446744072666965737 ***]


2025-05-21 22:08:48.998796 GPU 1 71070 test begin: paddle.renorm(x=Tensor([0, 2, 3],"float64"), p=1.2, axis=2, max_norm=6.5, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_renorm(_object*, _object*, _object*)
1   renorm_ad_func(paddle::Tensor const&, float, int, float)
2   paddle::experimental::renorm(paddle::Tensor const&, float, int, float)
3   void phi::RenormKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, int, float, phi::DenseTensor*)
4   void phi::funcs::RenormFunc<double>(phi::GPUContext const&, double const*, double*, float, int, float, long, common::DDim const&, long)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836529 (unix time) try "date -d @1747836529" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fb79eeba6e9) received by PID 71070 (TID 0x7fb843b50740) from PID 18446744072080828137 ***]


2025-05-21 22:08:48.999345 GPU 1 69611 test begin: paddle.renorm(x=Tensor([0, 2, 3],"float64"), p=1.5, axis=2, max_norm=20, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_renorm(_object*, _object*, _object*)
1   renorm_ad_func(paddle::Tensor const&, float, int, float)
2   paddle::experimental::renorm(paddle::Tensor const&, float, int, float)
3   void phi::RenormKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, int, float, phi::DenseTensor*)
4   void phi::funcs::RenormFunc<double>(phi::GPUContext const&, double const*, double*, float, int, float, long, common::DDim const&, long)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836529 (unix time) try "date -d @1747836529" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f97a01c76e9) received by PID 69611 (TID 0x7f9844e5d740) from PID 18446744072100804329 ***]


2025-05-21 22:08:49.000349 GPU 1 70929 test begin: paddle.renorm(x=Tensor([0, 2, 3],"float64"), p=2, axis=1, max_norm=20, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_renorm(_object*, _object*, _object*)
1   renorm_ad_func(paddle::Tensor const&, float, int, float)
2   paddle::experimental::renorm(paddle::Tensor const&, float, int, float)
3   void phi::RenormKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, int, float, phi::DenseTensor*)
4   void phi::funcs::RenormFunc<double>(phi::GPUContext const&, double const*, double*, float, int, float, long, common::DDim const&, long)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836529 (unix time) try "date -d @1747836529" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f87962516e9) received by PID 70929 (TID 0x7f883aee7740) from PID 18446744071933597417 ***]


2025-05-21 22:08:49.002333 GPU 1 70947 test begin: paddle.renorm(x=Tensor([0, 2, 3],"float64"), p=2, axis=1, max_norm=40, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_renorm(_object*, _object*, _object*)
1   renorm_ad_func(paddle::Tensor const&, float, int, float)
2   paddle::experimental::renorm(paddle::Tensor const&, float, int, float)
3   void phi::RenormKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, int, float, phi::DenseTensor*)
4   void phi::funcs::RenormFunc<double>(phi::GPUContext const&, double const*, double*, float, int, float, long, common::DDim const&, long)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836529 (unix time) try "date -d @1747836529" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f8d272f56e9) received by PID 70947 (TID 0x7f8dcbf8b740) from PID 657413865 ***]


2025-05-21 22:08:49.020594 GPU 1 71062 test begin: paddle.renorm(x=Tensor([0, 2, 3],"float64"), p=2, axis=1, max_norm=50, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_renorm(_object*, _object*, _object*)
1   renorm_ad_func(paddle::Tensor const&, float, int, float)
2   paddle::experimental::renorm(paddle::Tensor const&, float, int, float)
3   void phi::RenormKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, int, float, phi::DenseTensor*)
4   void phi::funcs::RenormFunc<double>(phi::GPUContext const&, double const*, double*, float, int, float, long, common::DDim const&, long)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836529 (unix time) try "date -d @1747836529" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fcbaf5516e9) received by PID 71062 (TID 0x7fcc541e7740) from PID 18446744072356173545 ***]


2025-05-21 22:08:49.030163 GPU 1 70886 test begin: paddle.renorm(x=Tensor([3, 0, 3],"float32"), p=1, axis=0, max_norm=5, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_renorm(_object*, _object*, _object*)
1   renorm_ad_func(paddle::Tensor const&, float, int, float)
2   paddle::experimental::renorm(paddle::Tensor const&, float, int, float)
3   void phi::RenormKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, int, float, phi::DenseTensor*)
4   void phi::funcs::RenormFunc<float>(phi::GPUContext const&, float const*, float*, float, int, float, long, common::DDim const&, long)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836529 (unix time) try "date -d @1747836529" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f3d8e900bd9) received by PID 70886 (TID 0x7f3e33597740) from PID 18446744071806389209 ***]


2025-05-21 22:08:49.053104 GPU 1 71112 test begin: paddle.renorm(x=Tensor([3, 0, 3],"float64"), p=1, axis=0, max_norm=5, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_renorm(_object*, _object*, _object*)
1   renorm_ad_func(paddle::Tensor const&, float, int, float)
2   paddle::experimental::renorm(paddle::Tensor const&, float, int, float)
3   void phi::RenormKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, int, float, phi::DenseTensor*)
4   void phi::funcs::RenormFunc<double>(phi::GPUContext const&, double const*, double*, float, int, float, long, common::DDim const&, long)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836529 (unix time) try "date -d @1747836529" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f1fdc8736e9) received by PID 71112 (TID 0x7f2081509740) from PID 18446744073114433257 ***]


2025-05-21 22:08:49.069751 GPU 1 70853 test begin: paddle.renorm(x=Tensor([3, 0, 3],"float64"), p=1.2, axis=2, max_norm=6.5, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_renorm(_object*, _object*, _object*)
1   renorm_ad_func(paddle::Tensor const&, float, int, float)
2   paddle::experimental::renorm(paddle::Tensor const&, float, int, float)
3   void phi::RenormKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, int, float, phi::DenseTensor*)
4   void phi::funcs::RenormFunc<double>(phi::GPUContext const&, double const*, double*, float, int, float, long, common::DDim const&, long)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836529 (unix time) try "date -d @1747836529" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f840d3246e9) received by PID 70853 (TID 0x7f84b1fba740) from PID 221398761 ***]


2025-05-21 22:08:49.076064 GPU 1 70910 test begin: paddle.renorm(x=Tensor([3, 0, 3],"float64"), p=1.5, axis=2, max_norm=20, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_renorm(_object*, _object*, _object*)
1   renorm_ad_func(paddle::Tensor const&, float, int, float)
2   paddle::experimental::renorm(paddle::Tensor const&, float, int, float)
3   void phi::RenormKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, int, float, phi::DenseTensor*)
4   void phi::funcs::RenormFunc<double>(phi::GPUContext const&, double const*, double*, float, int, float, long, common::DDim const&, long)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836529 (unix time) try "date -d @1747836529" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fc4fca956e9) received by PID 70910 (TID 0x7fc5a172b740) from PID 18446744073653540585 ***]


2025-05-21 22:08:49.087830 GPU 1 72116 test begin: paddle.renorm(x=Tensor([3, 0, 3],"float64"), p=2, axis=1, max_norm=20, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_renorm(_object*, _object*, _object*)
1   renorm_ad_func(paddle::Tensor const&, float, int, float)
2   paddle::experimental::renorm(paddle::Tensor const&, float, int, float)
3   void phi::RenormKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, int, float, phi::DenseTensor*)
4   void phi::funcs::RenormFunc<double>(phi::GPUContext const&, double const*, double*, float, int, float, long, common::DDim const&, long)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836529 (unix time) try "date -d @1747836529" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f98b1ebf6e9) received by PID 72116 (TID 0x7f9956b55740) from PID 18446744072399615721 ***]


2025-05-21 22:08:49.101906 GPU 1 71121 test begin: paddle.renorm(x=Tensor([3, 0, 3],"float64"), p=2, axis=1, max_norm=40, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_renorm(_object*, _object*, _object*)
1   renorm_ad_func(paddle::Tensor const&, float, int, float)
2   paddle::experimental::renorm(paddle::Tensor const&, float, int, float)
3   void phi::RenormKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, int, float, phi::DenseTensor*)
4   void phi::funcs::RenormFunc<double>(phi::GPUContext const&, double const*, double*, float, int, float, long, common::DDim const&, long)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836529 (unix time) try "date -d @1747836529" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f32181bd6e9) received by PID 71121 (TID 0x7f32bce53740) from PID 404477673 ***]


2025-05-21 22:08:49.237005 GPU 1 72196 test begin: paddle.renorm(x=Tensor([3, 0, 3],"float64"), p=2, axis=1, max_norm=50, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_renorm(_object*, _object*, _object*)
1   renorm_ad_func(paddle::Tensor const&, float, int, float)
2   paddle::experimental::renorm(paddle::Tensor const&, float, int, float)
3   void phi::RenormKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, int, float, phi::DenseTensor*)
4   void phi::funcs::RenormFunc<double>(phi::GPUContext const&, double const*, double*, float, int, float, long, common::DDim const&, long)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836529 (unix time) try "date -d @1747836529" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7ff2d51d16e9) received by PID 72196 (TID 0x7ff379e67740) from PID 18446744072990037737 ***]


2025-05-21 22:08:51.046367 GPU 1 71051 test begin: paddle.renorm(x=Tensor([3, 2, 0],"float32"), p=1, axis=0, max_norm=5, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_renorm(_object*, _object*, _object*)
1   renorm_ad_func(paddle::Tensor const&, float, int, float)
2   paddle::experimental::renorm(paddle::Tensor const&, float, int, float)
3   void phi::RenormKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, int, float, phi::DenseTensor*)
4   void phi::funcs::RenormFunc<float>(phi::GPUContext const&, float const*, float*, float, int, float, long, common::DDim const&, long)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836531 (unix time) try "date -d @1747836531" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fde4f2a5bd9) received by PID 71051 (TID 0x7fdef3f3c740) from PID 1328176089 ***]


2025-05-21 22:08:54.332744 GPU 1 70896 test begin: paddle.renorm(x=Tensor([3, 2, 0],"float64"), p=1, axis=0, max_norm=5, )
 ** On entry to SGEMM  parameter number 8 had an illegal value


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_renorm(_object*, _object*, _object*)
1   renorm_ad_func(paddle::Tensor const&, float, int, float)
2   paddle::experimental::renorm(paddle::Tensor const&, float, int, float)
3   void phi::RenormKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, int, float, phi::DenseTensor*)
4   void phi::funcs::RenormFunc<double>(phi::GPUContext const&, double const*, double*, float, int, float, long, common::DDim const&, long)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836534 (unix time) try "date -d @1747836534" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7ff1d0f226e9) received by PID 70896 (TID 0x7ff275bb8740) from PID 18446744072920114921 ***]


2025-05-21 22:08:56.008776 GPU 1 70902 test begin: paddle.renorm(x=Tensor([3, 2, 0],"float64"), p=1.2, axis=2, max_norm=6.5, )
 ** On entry to DGEMM  parameter number 8 had an illegal value


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_renorm(_object*, _object*, _object*)
1   renorm_ad_func(paddle::Tensor const&, float, int, float)
2   paddle::experimental::renorm(paddle::Tensor const&, float, int, float)
3   void phi::RenormKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, int, float, phi::DenseTensor*)
4   void phi::funcs::RenormFunc<double>(phi::GPUContext const&, double const*, double*, float, int, float, long, common::DDim const&, long)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836536 (unix time) try "date -d @1747836536" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f0800a486e9) received by PID 70902 (TID 0x7f08a56de740) from PID 10782441 ***]


2025-05-21 22:08:56.867498 GPU 1 72442 test begin: paddle.renorm(x=Tensor([3, 2, 0],"float64"), p=1.5, axis=2, max_norm=20, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_renorm(_object*, _object*, _object*)
1   renorm_ad_func(paddle::Tensor const&, float, int, float)
2   paddle::experimental::renorm(paddle::Tensor const&, float, int, float)
3   void phi::RenormKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, int, float, phi::DenseTensor*)
4   void phi::funcs::RenormFunc<double>(phi::GPUContext const&, double const*, double*, float, int, float, long, common::DDim const&, long)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836558 (unix time) try "date -d @1747836558" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7efe0c59b6e9) received by PID 72442 (TID 0x7efeb1231740) from PID 207206121 ***]


2025-05-21 22:08:57.551028 GPU 1 72469 test begin: paddle.renorm(x=Tensor([3, 2, 0],"float64"), p=2, axis=1, max_norm=20, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_renorm(_object*, _object*, _object*)
1   renorm_ad_func(paddle::Tensor const&, float, int, float)
2   paddle::experimental::renorm(paddle::Tensor const&, float, int, float)
3   void phi::RenormKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, int, float, phi::DenseTensor*)
4   void phi::funcs::RenormFunc<double>(phi::GPUContext const&, double const*, double*, float, int, float, long, common::DDim const&, long)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836562 (unix time) try "date -d @1747836562" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f5b7c25d6e9) received by PID 72469 (TID 0x7f5c20ef3740) from PID 2082854633 ***]


2025-05-21 22:08:57.997899 GPU 1 72488 test begin: paddle.renorm(x=Tensor([3, 2, 0],"float64"), p=2, axis=1, max_norm=40, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_renorm(_object*, _object*, _object*)
1   renorm_ad_func(paddle::Tensor const&, float, int, float)
2   paddle::experimental::renorm(paddle::Tensor const&, float, int, float)
3   void phi::RenormKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, int, float, phi::DenseTensor*)
4   void phi::funcs::RenormFunc<double>(phi::GPUContext const&, double const*, double*, float, int, float, long, common::DDim const&, long)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836561 (unix time) try "date -d @1747836561" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f392bdca6e9) received by PID 72488 (TID 0x7f39d0a60740) from PID 735880937 ***]


2025-05-21 22:08:58.303364 GPU 1 72451 test begin: paddle.renorm(x=Tensor([3, 2, 0],"float64"), p=2, axis=1, max_norm=50, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_renorm(_object*, _object*, _object*)
1   renorm_ad_func(paddle::Tensor const&, float, int, float)
2   paddle::experimental::renorm(paddle::Tensor const&, float, int, float)
3   void phi::RenormKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, int, float, phi::DenseTensor*)
4   void phi::funcs::RenormFunc<double>(phi::GPUContext const&, double const*, double*, float, int, float, long, common::DDim const&, long)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836562 (unix time) try "date -d @1747836562" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f21297286e9) received by PID 72451 (TID 0x7f21ce3bc740) from PID 695371497 ***]


2025-05-21 22:08:58.322234 GPU 1 72497 test begin: paddle.repeat_interleave(Tensor([0, 1, 384, 384],"float32"), repeats=3, axis=1, )
[cuda error] paddle.repeat_interleave(Tensor([0, 1, 384, 384],"float32"), repeats=3, axis=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:58.351160 GPU 1 72516 test begin: paddle.repeat_interleave(Tensor([0, 1, 768, 768],"float32"), repeats=3, axis=1, )
[cuda error] paddle.repeat_interleave(Tensor([0, 1, 768, 768],"float32"), repeats=3, axis=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:58.379103 GPU 1 72472 test begin: paddle.repeat_interleave(Tensor([0, 128],"float32"), 128, 0, )
[cuda error] paddle.repeat_interleave(Tensor([0, 128],"float32"), 128, 0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:58.774245 GPU 1 72487 test begin: paddle.repeat_interleave(Tensor([0, 1500, 1024],"float32"), 5, axis=0, )
[cuda error] paddle.repeat_interleave(Tensor([0, 1500, 1024],"float32"), 5, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:58.822248 GPU 1 72526 test begin: paddle.repeat_interleave(Tensor([0, 1500, 1280],"float32"), 5, axis=0, )
[cuda error] paddle.repeat_interleave(Tensor([0, 1500, 1280],"float32"), 5, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:58.981653 GPU 1 72512 test begin: paddle.repeat_interleave(Tensor([0, 2],"float32"), 2, axis=1, )
[cuda error] paddle.repeat_interleave(Tensor([0, 2],"float32"), 2, axis=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:59.323975 GPU 1 72578 test begin: paddle.repeat_interleave(Tensor([0, 2],"int64"), 1, axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.repeat_interleave(Tensor([0, 2],"int64"), 1, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:59.337743 GPU 1 72556 test begin: paddle.repeat_interleave(Tensor([0, 2],"int64"), 2, axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.repeat_interleave(Tensor([0, 2],"int64"), 2, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:59.613172 GPU 1 72568 test begin: paddle.repeat_interleave(Tensor([0, 384, 1],"float32"), 1, 2, )
[cuda error] paddle.repeat_interleave(Tensor([0, 384, 1],"float32"), 1, 2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:59.772220 GPU 1 72623 test begin: paddle.repeat_interleave(Tensor([0, 3],"bfloat16"), 2, None, )
[cuda error] paddle.repeat_interleave(Tensor([0, 3],"bfloat16"), 2, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:59.789576 GPU 1 72670 test begin: paddle.repeat_interleave(Tensor([0, 3],"int32"), 2, None, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.repeat_interleave(Tensor([0, 3],"int32"), 2, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:59.802808 GPU 1 72683 test begin: paddle.repeat_interleave(Tensor([0, 3],"int64"), 5, axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.repeat_interleave(Tensor([0, 3],"int64"), 5, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:59.831803 GPU 1 72567 test begin: paddle.repeat_interleave(Tensor([0, 70],"int64"), 3, 1, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.repeat_interleave(Tensor([0, 70],"int64"), 3, 1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:59.876038 GPU 1 72649 test begin: paddle.repeat_interleave(Tensor([1, 0, 1024],"float32"), 5, axis=0, )
[cuda error] paddle.repeat_interleave(Tensor([1, 0, 1024],"float32"), 5, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:59.879562 GPU 1 72615 test begin: paddle.repeat_interleave(Tensor([1, 0, 1280],"float32"), 5, axis=0, )
[cuda error] paddle.repeat_interleave(Tensor([1, 0, 1280],"float32"), 5, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:59.895003 GPU 1 72543 test begin: paddle.repeat_interleave(Tensor([1, 0],"float32"), 128, 0, )
[cuda error] paddle.repeat_interleave(Tensor([1, 0],"float32"), 128, 0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:59.908321 GPU 1 72621 test begin: paddle.repeat_interleave(Tensor([1, 0],"float32"), 2, axis=1, )
[cuda error] paddle.repeat_interleave(Tensor([1, 0],"float32"), 2, axis=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:59.914053 GPU 1 72626 test begin: paddle.repeat_interleave(Tensor([1, 0],"int64"), 1, axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.repeat_interleave(Tensor([1, 0],"int64"), 1, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:08:59.938432 GPU 1 72614 test begin: paddle.repeat_interleave(Tensor([1, 0],"int64"), 2, axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.repeat_interleave(Tensor([1, 0],"int64"), 2, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:03.992760 GPU 1 72793 test begin: paddle.repeat_interleave(Tensor([1, 0],"int64"), 3, 1, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.repeat_interleave(Tensor([1, 0],"int64"), 3, 1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:05.125571 GPU 1 72813 test begin: paddle.repeat_interleave(Tensor([1, 0],"int64"), 5, axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.repeat_interleave(Tensor([1, 0],"int64"), 5, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:09.055945 GPU 1 72933 test begin: paddle.repeat_interleave(Tensor([1, 1500, 0],"float32"), 5, axis=0, )
[cuda error] paddle.repeat_interleave(Tensor([1, 1500, 0],"float32"), 5, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:21.944185 GPU 1 72516 test begin: paddle.repeat_interleave(Tensor([10, 0],"float32"), 2, axis=1, )
[cuda error] paddle.repeat_interleave(Tensor([10, 0],"float32"), 2, axis=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:22.313831 GPU 1 72516 test begin: paddle.repeat_interleave(Tensor([13, 0, 1],"float32"), 1, 2, )
[cuda error] paddle.repeat_interleave(Tensor([13, 0, 1],"float32"), 1, 2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:22.605322 GPU 1 72516 test begin: paddle.repeat_interleave(Tensor([13, 384, 0],"float32"), 1, 2, )
[cuda error] paddle.repeat_interleave(Tensor([13, 384, 0],"float32"), 1, 2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:22.976418 GPU 1 72516 test begin: paddle.repeat_interleave(Tensor([14, 0, 384, 384],"float32"), repeats=3, axis=1, )
[cuda error] paddle.repeat_interleave(Tensor([14, 0, 384, 384],"float32"), repeats=3, axis=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:23.020609 GPU 1 72497 test begin: paddle.repeat_interleave(Tensor([14, 1, 0, 384],"float32"), repeats=3, axis=1, )
[cuda error] paddle.repeat_interleave(Tensor([14, 1, 0, 384],"float32"), repeats=3, axis=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:23.250273 GPU 1 72497 test begin: paddle.repeat_interleave(Tensor([14, 1, 384, 0],"float32"), repeats=3, axis=1, )
[cuda error] paddle.repeat_interleave(Tensor([14, 1, 384, 0],"float32"), repeats=3, axis=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:23.284228 GPU 1 72516 test begin: paddle.repeat_interleave(Tensor([16, 0, 1],"float32"), 1, 2, )
[cuda error] paddle.repeat_interleave(Tensor([16, 0, 1],"float32"), 1, 2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:23.540491 GPU 1 72487 test begin: paddle.repeat_interleave(Tensor([16, 384, 0],"float32"), 1, 2, )
[cuda error] paddle.repeat_interleave(Tensor([16, 384, 0],"float32"), 1, 2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:23.690768 GPU 1 72516 test begin: paddle.repeat_interleave(Tensor([2, 0],"bfloat16"), 2, None, )
[cuda error] paddle.repeat_interleave(Tensor([2, 0],"bfloat16"), 2, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:23.691709 GPU 1 72497 test begin: paddle.repeat_interleave(Tensor([2, 0],"int32"), 2, None, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.repeat_interleave(Tensor([2, 0],"int32"), 2, None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:23.814686 GPU 1 72487 test begin: paddle.repeat_interleave(Tensor([5, 0, 768, 768],"float32"), repeats=3, axis=1, )
[cuda error] paddle.repeat_interleave(Tensor([5, 0, 768, 768],"float32"), repeats=3, axis=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:23.871094 GPU 1 72472 test begin: paddle.repeat_interleave(Tensor([5, 1, 0, 768],"float32"), repeats=3, axis=1, )
[cuda error] paddle.repeat_interleave(Tensor([5, 1, 0, 768],"float32"), repeats=3, axis=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:23.875661 GPU 1 72526 test begin: paddle.repeat_interleave(Tensor([5, 1, 768, 0],"float32"), repeats=3, axis=1, )
[cuda error] paddle.repeat_interleave(Tensor([5, 1, 768, 0],"float32"), repeats=3, axis=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:23.909571 GPU 1 72516 test begin: paddle.repeat_interleave(x=Tensor([0, 2, 4, 4, 5],"float64"), repeats=2, )
[cuda error] paddle.repeat_interleave(x=Tensor([0, 2, 4, 4, 5],"float64"), repeats=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:24.030827 GPU 1 72512 test begin: paddle.repeat_interleave(x=Tensor([0, 2, 4, 4, 5],"float64"), repeats=2, axis=1, )
[cuda error] paddle.repeat_interleave(x=Tensor([0, 2, 4, 4, 5],"float64"), repeats=2, axis=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:24.100582 GPU 1 72497 test begin: paddle.repeat_interleave(x=Tensor([0, 2, 4, 4, 5],"int32"), repeats=2, axis=3, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.repeat_interleave(x=Tensor([0, 2, 4, 4, 5],"int32"), repeats=2, axis=3, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:24.156646 GPU 1 72487 test begin: paddle.repeat_interleave(x=Tensor([0, 2, 4, 5],"float64"), repeats=2, )
[cuda error] paddle.repeat_interleave(x=Tensor([0, 2, 4, 5],"float64"), repeats=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:24.371005 GPU 1 72516 test begin: paddle.repeat_interleave(x=Tensor([0, 2, 4],"float64"), repeats=2, )
[cuda error] paddle.repeat_interleave(x=Tensor([0, 2, 4],"float64"), repeats=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:24.417761 GPU 1 72472 test begin: paddle.repeat_interleave(x=Tensor([0, 2],"float64"), repeats=2, )
[cuda error] paddle.repeat_interleave(x=Tensor([0, 2],"float64"), repeats=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:24.426043 GPU 1 72526 test begin: paddle.repeat_interleave(x=Tensor([0],"float32"), repeats=3, )
[cuda error] paddle.repeat_interleave(x=Tensor([0],"float32"), repeats=3, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:24.599236 GPU 1 72487 test begin: paddle.repeat_interleave(x=Tensor([0],"float64"), repeats=3, )
[cuda error] paddle.repeat_interleave(x=Tensor([0],"float64"), repeats=3, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:24.599804 GPU 1 72472 test begin: paddle.repeat_interleave(x=Tensor([4, 0, 4, 4, 5],"float64"), repeats=2, )
[cuda error] paddle.repeat_interleave(x=Tensor([4, 0, 4, 4, 5],"float64"), repeats=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:24.673221 GPU 1 72526 test begin: paddle.repeat_interleave(x=Tensor([4, 0, 4, 4, 5],"float64"), repeats=2, axis=1, )
[cuda error] paddle.repeat_interleave(x=Tensor([4, 0, 4, 4, 5],"float64"), repeats=2, axis=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:24.791999 GPU 1 72512 test begin: paddle.repeat_interleave(x=Tensor([4, 0, 4, 4, 5],"int32"), repeats=2, axis=3, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.repeat_interleave(x=Tensor([4, 0, 4, 4, 5],"int32"), repeats=2, axis=3, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:24.964393 GPU 1 72472 test begin: paddle.repeat_interleave(x=Tensor([4, 0, 4, 5],"float64"), repeats=2, )
[cuda error] paddle.repeat_interleave(x=Tensor([4, 0, 4, 5],"float64"), repeats=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:25.010310 GPU 1 72497 test begin: paddle.repeat_interleave(x=Tensor([4, 0, 4],"float64"), repeats=2, )
[cuda error] paddle.repeat_interleave(x=Tensor([4, 0, 4],"float64"), repeats=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:25.033130 GPU 1 72623 test begin: paddle.repeat_interleave(x=Tensor([4, 0],"float64"), repeats=2, )
[cuda error] paddle.repeat_interleave(x=Tensor([4, 0],"float64"), repeats=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:25.060607 GPU 1 72526 test begin: paddle.repeat_interleave(x=Tensor([4, 2, 0, 4, 5],"float64"), repeats=2, )
[cuda error] paddle.repeat_interleave(x=Tensor([4, 2, 0, 4, 5],"float64"), repeats=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:25.239931 GPU 1 72512 test begin: paddle.repeat_interleave(x=Tensor([4, 2, 0, 4, 5],"float64"), repeats=2, axis=1, )
[cuda error] paddle.repeat_interleave(x=Tensor([4, 2, 0, 4, 5],"float64"), repeats=2, axis=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:25.272273 GPU 1 72487 test begin: paddle.repeat_interleave(x=Tensor([4, 2, 0, 4, 5],"int32"), repeats=2, axis=3, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.repeat_interleave(x=Tensor([4, 2, 0, 4, 5],"int32"), repeats=2, axis=3, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:25.322751 GPU 1 72472 test begin: paddle.repeat_interleave(x=Tensor([4, 2, 0, 5],"float64"), repeats=2, )
[cuda error] paddle.repeat_interleave(x=Tensor([4, 2, 0, 5],"float64"), repeats=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:25.395687 GPU 1 72623 test begin: paddle.repeat_interleave(x=Tensor([4, 2, 0],"float64"), repeats=2, )
[cuda error] paddle.repeat_interleave(x=Tensor([4, 2, 0],"float64"), repeats=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:25.408548 GPU 1 72526 test begin: paddle.repeat_interleave(x=Tensor([4, 2, 4, 0, 5],"float64"), repeats=2, )
[cuda error] paddle.repeat_interleave(x=Tensor([4, 2, 4, 0, 5],"float64"), repeats=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:25.424989 GPU 1 72497 test begin: paddle.repeat_interleave(x=Tensor([4, 2, 4, 0, 5],"float64"), repeats=2, axis=1, )
[cuda error] paddle.repeat_interleave(x=Tensor([4, 2, 4, 0, 5],"float64"), repeats=2, axis=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:25.449621 GPU 1 72516 test begin: paddle.repeat_interleave(x=Tensor([4, 2, 4, 0, 5],"int32"), repeats=2, axis=3, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.repeat_interleave(x=Tensor([4, 2, 4, 0, 5],"int32"), repeats=2, axis=3, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:25.513634 GPU 1 72487 test begin: paddle.repeat_interleave(x=Tensor([4, 2, 4, 0],"float64"), repeats=2, )
[cuda error] paddle.repeat_interleave(x=Tensor([4, 2, 4, 0],"float64"), repeats=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:25.580255 GPU 1 72472 test begin: paddle.repeat_interleave(x=Tensor([4, 2, 4, 4, 0],"float64"), repeats=2, )
[cuda error] paddle.repeat_interleave(x=Tensor([4, 2, 4, 4, 0],"float64"), repeats=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:25.618222 GPU 1 72512 test begin: paddle.repeat_interleave(x=Tensor([4, 2, 4, 4, 0],"float64"), repeats=2, axis=1, )
[cuda error] paddle.repeat_interleave(x=Tensor([4, 2, 4, 4, 0],"float64"), repeats=2, axis=1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:25.655129 GPU 1 72526 test begin: paddle.repeat_interleave(x=Tensor([4, 2, 4, 4, 0],"int32"), repeats=2, axis=3, )
element 0 of tensors does not require grad and does not have a grad_fn
[cuda error] paddle.repeat_interleave(x=Tensor([4, 2, 4, 4, 0],"int32"), repeats=2, axis=3, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:25.730183 GPU 1 72487 test begin: paddle.roll(Tensor([0, 16, 14, 14, 384],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([0, 16, 14, 14, 384],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:25.759338 GPU 1 72472 test begin: paddle.roll(Tensor([0, 16, 14, 14, 384],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([0, 16, 14, 14, 384],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:25.789027 GPU 1 72516 test begin: paddle.roll(Tensor([0, 16, 14, 14, 384],"float32"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([0, 16, 14, 14, 384],"float32"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:25.870508 GPU 1 72623 test begin: paddle.roll(Tensor([0, 16, 14, 14, 384],"float32"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([0, 16, 14, 14, 384],"float32"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:25.944169 GPU 1 72497 test begin: paddle.roll(Tensor([0, 16, 14, 7, 768],"float16"), shifts=tuple(-4,-3,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([0, 16, 14, 7, 768],"float16"), shifts=tuple(-4,-3,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:25.953451 GPU 1 72526 test begin: paddle.roll(Tensor([0, 16, 14, 7, 768],"float16"), shifts=tuple(4,3,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([0, 16, 14, 7, 768],"float16"), shifts=tuple(4,3,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:25.955196 GPU 1 72472 test begin: paddle.roll(Tensor([0, 16, 14, 7, 768],"float32"), shifts=tuple(-4,-3,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([0, 16, 14, 7, 768],"float32"), shifts=tuple(-4,-3,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:25.963093 GPU 1 72487 test begin: paddle.roll(Tensor([0, 16, 14, 7, 768],"float32"), shifts=tuple(4,3,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([0, 16, 14, 7, 768],"float32"), shifts=tuple(4,3,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.028636 GPU 1 72567 test begin: paddle.roll(Tensor([0, 16, 16, 64],"float32"), shifts=tuple(-2,-2,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([0, 16, 16, 64],"float32"), shifts=tuple(-2,-2,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.093017 GPU 1 72472 test begin: paddle.roll(Tensor([0, 16, 16, 64],"float32"), shifts=tuple(2,2,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([0, 16, 16, 64],"float32"), shifts=tuple(2,2,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.094086 GPU 1 72487 test begin: paddle.roll(Tensor([0, 16, 7, 14, 768],"float16"), shifts=tuple(-4,0,-3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([0, 16, 7, 14, 768],"float16"), shifts=tuple(-4,0,-3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.113477 GPU 1 72568 test begin: paddle.roll(Tensor([0, 16, 7, 14, 768],"float16"), shifts=tuple(4,0,3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([0, 16, 7, 14, 768],"float16"), shifts=tuple(4,0,3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.125608 GPU 1 72526 test begin: paddle.roll(Tensor([0, 16, 7, 14, 768],"float32"), shifts=tuple(-4,0,-3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([0, 16, 7, 14, 768],"float32"), shifts=tuple(-4,0,-3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.147642 GPU 1 72512 test begin: paddle.roll(Tensor([0, 16, 7, 14, 768],"float32"), shifts=tuple(4,0,3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([0, 16, 7, 14, 768],"float32"), shifts=tuple(4,0,3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.156870 GPU 1 72516 test begin: paddle.roll(Tensor([0, 16, 7, 7, 768],"float16"), shifts=tuple(-4,0,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([0, 16, 7, 7, 768],"float16"), shifts=tuple(-4,0,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.170221 GPU 1 72497 test begin: paddle.roll(Tensor([0, 16, 7, 7, 768],"float16"), shifts=tuple(4,0,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([0, 16, 7, 7, 768],"float16"), shifts=tuple(4,0,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.204883 GPU 1 72567 test begin: paddle.roll(Tensor([0, 16, 7, 7, 768],"float32"), shifts=tuple(-4,0,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([0, 16, 7, 7, 768],"float32"), shifts=tuple(-4,0,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.207784 GPU 1 72543 test begin: paddle.roll(Tensor([0, 16, 7, 7, 768],"float32"), shifts=tuple(4,0,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([0, 16, 7, 7, 768],"float32"), shifts=tuple(4,0,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.215801 GPU 1 72472 test begin: paddle.roll(Tensor([0, 161, 126, 96],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([0, 161, 126, 96],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.221900 GPU 1 72487 test begin: paddle.roll(Tensor([0, 161, 126, 96],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([0, 161, 126, 96],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.240732 GPU 1 72623 test begin: paddle.roll(Tensor([0, 192, 144, 192],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([0, 192, 144, 192],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.256199 GPU 1 72626 test begin: paddle.roll(Tensor([0, 192, 144, 192],"float32"), shifts=tuple(6,6,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([0, 192, 144, 192],"float32"), shifts=tuple(6,6,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.291452 GPU 1 72568 test begin: paddle.roll(Tensor([0, 21, 21, 768],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([0, 21, 21, 768],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.293145 GPU 1 72621 test begin: paddle.roll(Tensor([0, 21, 21, 768],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([0, 21, 21, 768],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.293462 GPU 1 72526 test begin: paddle.roll(Tensor([0, 24, 24, 1536],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([0, 24, 24, 1536],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.353122 GPU 1 72487 test begin: paddle.roll(Tensor([0, 24, 24, 1536],"float32"), shifts=tuple(6,6,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([0, 24, 24, 1536],"float32"), shifts=tuple(6,6,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.364135 GPU 1 72512 test begin: paddle.roll(Tensor([0, 32, 32, 32],"float32"), shifts=tuple(-2,-2,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([0, 32, 32, 32],"float32"), shifts=tuple(-2,-2,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.527742 GPU 1 72543 test begin: paddle.roll(Tensor([0, 32, 32, 32],"float32"), shifts=tuple(2,2,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([0, 32, 32, 32],"float32"), shifts=tuple(2,2,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.532110 GPU 1 72578 test begin: paddle.roll(Tensor([0, 3],"float64"), shifts=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   RollGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::roll_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, std::vector<long, std::allocator<long> > const&, paddle::Tensor*)
4   void phi::RollGradKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836567 (unix time) try "date -d @1747836567" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f0377ae07d3) received by PID 72578 (TID 0x7f041c6b8740) from PID 2007893971 ***]


2025-05-21 22:09:26.534323 GPU 1 72683 test begin: paddle.roll(Tensor([0, 3],"float64"), shifts=1, axis=0, )
[cuda error] paddle.roll(Tensor([0, 3],"float64"), shifts=1, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.685667 GPU 1 72472 test begin: paddle.roll(Tensor([0],"float32"), -2, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   RollGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::roll_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, std::vector<long, std::allocator<long> > const&, paddle::Tensor*)
4   void phi::RollGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836566 (unix time) try "date -d @1747836566" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f919ffbd8c3) received by PID 72472 (TID 0x7f9244b96740) from PID 18446744072098666691 ***]


2025-05-21 22:09:26.688702 GPU 1 72567 test begin: paddle.roll(Tensor([0],"float32"), -5, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   RollGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::roll_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, std::vector<long, std::allocator<long> > const&, paddle::Tensor*)
4   void phi::RollGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836566 (unix time) try "date -d @1747836566" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f227616b8c3) received by PID 72567 (TID 0x7f231ad44740) from PID 1981200579 ***]


2025-05-21 22:09:26.704059 GPU 1 72626 test begin: paddle.roll(Tensor([1, 0, 126, 96],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([1, 0, 126, 96],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.710486 GPU 1 72516 test begin: paddle.roll(Tensor([1, 0, 126, 96],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([1, 0, 126, 96],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.712155 GPU 1 72497 test begin: paddle.roll(Tensor([1, 0, 14, 14, 384],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 0, 14, 14, 384],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.729009 GPU 1 72621 test begin: paddle.roll(Tensor([1, 0, 14, 14, 384],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 0, 14, 14, 384],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.751011 GPU 1 72526 test begin: paddle.roll(Tensor([1, 0, 14, 14, 384],"float32"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 0, 14, 14, 384],"float32"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.751292 GPU 1 72614 test begin: paddle.roll(Tensor([1, 0, 14, 14, 384],"float32"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 0, 14, 14, 384],"float32"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.751539 GPU 1 72623 test begin: paddle.roll(Tensor([1, 0, 14, 7, 768],"float16"), shifts=tuple(-4,-3,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 0, 14, 7, 768],"float16"), shifts=tuple(-4,-3,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.752282 GPU 1 72568 test begin: paddle.roll(Tensor([1, 0, 14, 7, 768],"float16"), shifts=tuple(4,3,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 0, 14, 7, 768],"float16"), shifts=tuple(4,3,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.758771 GPU 1 72487 test begin: paddle.roll(Tensor([1, 0, 14, 7, 768],"float32"), shifts=tuple(-4,-3,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 0, 14, 7, 768],"float32"), shifts=tuple(-4,-3,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.789767 GPU 1 72670 test begin: paddle.roll(Tensor([1, 0, 14, 7, 768],"float32"), shifts=tuple(4,3,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 0, 14, 7, 768],"float32"), shifts=tuple(4,3,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.933380 GPU 1 72793 test begin: paddle.roll(Tensor([1, 0, 144, 192],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([1, 0, 144, 192],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:26.938982 GPU 1 72615 test begin: paddle.roll(Tensor([1, 0, 144, 192],"float32"), shifts=tuple(6,6,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([1, 0, 144, 192],"float32"), shifts=tuple(6,6,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.097810 GPU 1 72512 test begin: paddle.roll(Tensor([1, 0, 21, 768],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([1, 0, 21, 768],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.098387 GPU 1 72543 test begin: paddle.roll(Tensor([1, 0, 21, 768],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([1, 0, 21, 768],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.099965 GPU 1 72568 test begin: paddle.roll(Tensor([1, 0, 24, 1536],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([1, 0, 24, 1536],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.100423 GPU 1 72626 test begin: paddle.roll(Tensor([1, 0, 24, 1536],"float32"), shifts=tuple(6,6,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([1, 0, 24, 1536],"float32"), shifts=tuple(6,6,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.102154 GPU 1 72649 test begin: paddle.roll(Tensor([1, 0, 7, 14, 768],"float16"), shifts=tuple(-4,0,-3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 0, 7, 14, 768],"float16"), shifts=tuple(-4,0,-3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.103013 GPU 1 72614 test begin: paddle.roll(Tensor([1, 0, 7, 14, 768],"float16"), shifts=tuple(4,0,3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 0, 7, 14, 768],"float16"), shifts=tuple(4,0,3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.112907 GPU 1 72516 test begin: paddle.roll(Tensor([1, 0, 7, 14, 768],"float32"), shifts=tuple(-4,0,-3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 0, 7, 14, 768],"float32"), shifts=tuple(-4,0,-3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.113090 GPU 1 72621 test begin: paddle.roll(Tensor([1, 0, 7, 14, 768],"float32"), shifts=tuple(4,0,3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 0, 7, 14, 768],"float32"), shifts=tuple(4,0,3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.114012 GPU 1 72497 test begin: paddle.roll(Tensor([1, 0, 7, 7, 768],"float16"), shifts=tuple(-4,0,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 0, 7, 7, 768],"float16"), shifts=tuple(-4,0,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.124442 GPU 1 72556 test begin: paddle.roll(Tensor([1, 0, 7, 7, 768],"float16"), shifts=tuple(4,0,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 0, 7, 7, 768],"float16"), shifts=tuple(4,0,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.282141 GPU 1 72649 test begin: paddle.roll(Tensor([1, 0, 7, 7, 768],"float32"), shifts=tuple(-4,0,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 0, 7, 7, 768],"float32"), shifts=tuple(-4,0,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.294799 GPU 1 72568 test begin: paddle.roll(Tensor([1, 0, 7, 7, 768],"float32"), shifts=tuple(4,0,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 0, 7, 7, 768],"float32"), shifts=tuple(4,0,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.294957 GPU 1 72626 test begin: paddle.roll(Tensor([1, 16, 0, 14, 384],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 0, 14, 384],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.296630 GPU 1 72526 test begin: paddle.roll(Tensor([1, 16, 0, 14, 384],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 0, 14, 384],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.297500 GPU 1 72487 test begin: paddle.roll(Tensor([1, 16, 0, 14, 384],"float32"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 0, 14, 384],"float32"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.300385 GPU 1 72614 test begin: paddle.roll(Tensor([1, 16, 0, 14, 384],"float32"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 0, 14, 384],"float32"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.300616 GPU 1 72543 test begin: paddle.roll(Tensor([1, 16, 0, 14, 768],"float16"), shifts=tuple(-4,0,-3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 0, 14, 768],"float16"), shifts=tuple(-4,0,-3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.301802 GPU 1 72793 test begin: paddle.roll(Tensor([1, 16, 0, 14, 768],"float16"), shifts=tuple(4,0,3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 0, 14, 768],"float16"), shifts=tuple(4,0,3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.302247 GPU 1 72615 test begin: paddle.roll(Tensor([1, 16, 0, 14, 768],"float32"), shifts=tuple(-4,0,-3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 0, 14, 768],"float32"), shifts=tuple(-4,0,-3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.303991 GPU 1 72670 test begin: paddle.roll(Tensor([1, 16, 0, 14, 768],"float32"), shifts=tuple(4,0,3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 0, 14, 768],"float32"), shifts=tuple(4,0,3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.304660 GPU 1 72623 test begin: paddle.roll(Tensor([1, 16, 0, 7, 768],"float16"), shifts=tuple(-4,-3,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 0, 7, 768],"float16"), shifts=tuple(-4,-3,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.308225 GPU 1 72683 test begin: paddle.roll(Tensor([1, 16, 0, 7, 768],"float16"), shifts=tuple(-4,0,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 0, 7, 768],"float16"), shifts=tuple(-4,0,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.472252 GPU 1 72512 test begin: paddle.roll(Tensor([1, 16, 0, 7, 768],"float16"), shifts=tuple(4,0,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 0, 7, 768],"float16"), shifts=tuple(4,0,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.475163 GPU 1 72568 test begin: paddle.roll(Tensor([1, 16, 0, 7, 768],"float16"), shifts=tuple(4,3,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 0, 7, 768],"float16"), shifts=tuple(4,3,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.475348 GPU 1 72649 test begin: paddle.roll(Tensor([1, 16, 0, 7, 768],"float32"), shifts=tuple(-4,-3,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 0, 7, 768],"float32"), shifts=tuple(-4,-3,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.475616 GPU 1 72626 test begin: paddle.roll(Tensor([1, 16, 0, 7, 768],"float32"), shifts=tuple(-4,0,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 0, 7, 768],"float32"), shifts=tuple(-4,0,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.476507 GPU 1 72621 test begin: paddle.roll(Tensor([1, 16, 0, 7, 768],"float32"), shifts=tuple(4,0,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 0, 7, 768],"float32"), shifts=tuple(4,0,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.479848 GPU 1 72556 test begin: paddle.roll(Tensor([1, 16, 0, 7, 768],"float32"), shifts=tuple(4,3,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 0, 7, 768],"float32"), shifts=tuple(4,3,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.633207 GPU 1 72487 test begin: paddle.roll(Tensor([1, 16, 14, 0, 384],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 14, 0, 384],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.634129 GPU 1 72543 test begin: paddle.roll(Tensor([1, 16, 14, 0, 384],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 14, 0, 384],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.643919 GPU 1 72516 test begin: paddle.roll(Tensor([1, 16, 14, 0, 384],"float32"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 14, 0, 384],"float32"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.644885 GPU 1 72683 test begin: paddle.roll(Tensor([1, 16, 14, 0, 384],"float32"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 14, 0, 384],"float32"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.645432 GPU 1 72623 test begin: paddle.roll(Tensor([1, 16, 14, 0, 768],"float16"), shifts=tuple(-4,-3,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 14, 0, 768],"float16"), shifts=tuple(-4,-3,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.646553 GPU 1 72526 test begin: paddle.roll(Tensor([1, 16, 14, 0, 768],"float16"), shifts=tuple(4,3,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 14, 0, 768],"float16"), shifts=tuple(4,3,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.646680 GPU 1 72497 test begin: paddle.roll(Tensor([1, 16, 14, 0, 768],"float32"), shifts=tuple(-4,-3,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 14, 0, 768],"float32"), shifts=tuple(-4,-3,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.839635 GPU 1 72615 test begin: paddle.roll(Tensor([1, 16, 14, 0, 768],"float32"), shifts=tuple(4,3,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 14, 0, 768],"float32"), shifts=tuple(4,3,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.840797 GPU 1 72649 test begin: paddle.roll(Tensor([1, 16, 14, 14, 0],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 14, 14, 0],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.841362 GPU 1 72626 test begin: paddle.roll(Tensor([1, 16, 14, 14, 0],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 14, 14, 0],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.842101 GPU 1 72568 test begin: paddle.roll(Tensor([1, 16, 14, 14, 0],"float32"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 14, 14, 0],"float32"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.845711 GPU 1 72512 test begin: paddle.roll(Tensor([1, 16, 14, 14, 0],"float32"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 14, 14, 0],"float32"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.847326 GPU 1 72614 test begin: paddle.roll(Tensor([1, 16, 14, 7, 0],"float16"), shifts=tuple(-4,-3,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 14, 7, 0],"float16"), shifts=tuple(-4,-3,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.868658 GPU 1 72670 test begin: paddle.roll(Tensor([1, 16, 14, 7, 0],"float16"), shifts=tuple(4,3,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 14, 7, 0],"float16"), shifts=tuple(4,3,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.892431 GPU 1 72793 test begin: paddle.roll(Tensor([1, 16, 14, 7, 0],"float32"), shifts=tuple(-4,-3,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 14, 7, 0],"float32"), shifts=tuple(-4,-3,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.937708 GPU 1 72543 test begin: paddle.roll(Tensor([1, 16, 14, 7, 0],"float32"), shifts=tuple(4,3,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 14, 7, 0],"float32"), shifts=tuple(4,3,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.937829 GPU 1 72621 test begin: paddle.roll(Tensor([1, 16, 7, 0, 768],"float16"), shifts=tuple(-4,0,-3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 7, 0, 768],"float16"), shifts=tuple(-4,0,-3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.966428 GPU 1 72683 test begin: paddle.roll(Tensor([1, 16, 7, 0, 768],"float16"), shifts=tuple(-4,0,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 7, 0, 768],"float16"), shifts=tuple(-4,0,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.973271 GPU 1 72649 test begin: paddle.roll(Tensor([1, 16, 7, 0, 768],"float16"), shifts=tuple(4,0,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 7, 0, 768],"float16"), shifts=tuple(4,0,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.974837 GPU 1 72626 test begin: paddle.roll(Tensor([1, 16, 7, 0, 768],"float16"), shifts=tuple(4,0,3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 7, 0, 768],"float16"), shifts=tuple(4,0,3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.976582 GPU 1 72614 test begin: paddle.roll(Tensor([1, 16, 7, 0, 768],"float32"), shifts=tuple(-4,0,-3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 7, 0, 768],"float32"), shifts=tuple(-4,0,-3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.980746 GPU 1 72615 test begin: paddle.roll(Tensor([1, 16, 7, 0, 768],"float32"), shifts=tuple(-4,0,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 7, 0, 768],"float32"), shifts=tuple(-4,0,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.983501 GPU 1 72487 test begin: paddle.roll(Tensor([1, 16, 7, 0, 768],"float32"), shifts=tuple(4,0,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 7, 0, 768],"float32"), shifts=tuple(4,0,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:27.984147 GPU 1 72568 test begin: paddle.roll(Tensor([1, 16, 7, 0, 768],"float32"), shifts=tuple(4,0,3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 7, 0, 768],"float32"), shifts=tuple(4,0,3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.081324 GPU 1 72543 test begin: paddle.roll(Tensor([1, 16, 7, 14, 0],"float16"), shifts=tuple(-4,0,-3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 7, 14, 0],"float16"), shifts=tuple(-4,0,-3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.091682 GPU 1 72556 test begin: paddle.roll(Tensor([1, 16, 7, 14, 0],"float16"), shifts=tuple(4,0,3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 7, 14, 0],"float16"), shifts=tuple(4,0,3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.093200 GPU 1 72670 test begin: paddle.roll(Tensor([1, 16, 7, 14, 0],"float32"), shifts=tuple(-4,0,-3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 7, 14, 0],"float32"), shifts=tuple(-4,0,-3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.093530 GPU 1 72516 test begin: paddle.roll(Tensor([1, 16, 7, 14, 0],"float32"), shifts=tuple(4,0,3,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 7, 14, 0],"float32"), shifts=tuple(4,0,3,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.094866 GPU 1 72649 test begin: paddle.roll(Tensor([1, 16, 7, 7, 0],"float16"), shifts=tuple(-4,0,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 7, 7, 0],"float16"), shifts=tuple(-4,0,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.095351 GPU 1 72497 test begin: paddle.roll(Tensor([1, 16, 7, 7, 0],"float16"), shifts=tuple(4,0,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 7, 7, 0],"float16"), shifts=tuple(4,0,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.096150 GPU 1 72512 test begin: paddle.roll(Tensor([1, 16, 7, 7, 0],"float32"), shifts=tuple(-4,0,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 7, 7, 0],"float32"), shifts=tuple(-4,0,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.098061 GPU 1 72526 test begin: paddle.roll(Tensor([1, 16, 7, 7, 0],"float32"), shifts=tuple(4,0,0,), axis=tuple(1,2,3,), )
[cuda error] paddle.roll(Tensor([1, 16, 7, 7, 0],"float32"), shifts=tuple(4,0,0,), axis=tuple(1,2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.099214 GPU 1 72614 test begin: paddle.roll(Tensor([1, 161, 0, 96],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([1, 161, 0, 96],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.121908 GPU 1 73507 test begin: paddle.roll(Tensor([1, 161, 0, 96],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([1, 161, 0, 96],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.124045 GPU 1 72683 test begin: paddle.roll(Tensor([1, 161, 126, 0],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([1, 161, 126, 0],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.127599 GPU 1 72623 test begin: paddle.roll(Tensor([1, 161, 126, 0],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([1, 161, 126, 0],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.153486 GPU 1 73519 test begin: paddle.roll(Tensor([1, 192, 0, 192],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([1, 192, 0, 192],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.207386 GPU 1 72626 test begin: paddle.roll(Tensor([1, 192, 0, 192],"float32"), shifts=tuple(6,6,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([1, 192, 0, 192],"float32"), shifts=tuple(6,6,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.209466 GPU 1 72621 test begin: paddle.roll(Tensor([1, 192, 144, 0],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([1, 192, 144, 0],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.216877 GPU 1 72793 test begin: paddle.roll(Tensor([1, 192, 144, 0],"float32"), shifts=tuple(6,6,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([1, 192, 144, 0],"float32"), shifts=tuple(6,6,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.229080 GPU 1 72568 test begin: paddle.roll(Tensor([1, 21, 0, 768],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([1, 21, 0, 768],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.241860 GPU 1 72543 test begin: paddle.roll(Tensor([1, 21, 0, 768],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([1, 21, 0, 768],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.260686 GPU 1 72615 test begin: paddle.roll(Tensor([1, 21, 21, 0],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([1, 21, 21, 0],"float32"), shifts=tuple(-3,-3,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.283713 GPU 1 72649 test begin: paddle.roll(Tensor([1, 21, 21, 0],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([1, 21, 21, 0],"float32"), shifts=tuple(3,3,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.275220 GPU 1 72487 test begin: paddle.roll(Tensor([1, 24, 0, 1536],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([1, 24, 0, 1536],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.321133 GPU 1 72670 test begin: paddle.roll(Tensor([1, 24, 0, 1536],"float32"), shifts=tuple(6,6,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([1, 24, 0, 1536],"float32"), shifts=tuple(6,6,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.330187 GPU 1 73549 test begin: paddle.roll(Tensor([1, 24, 24, 0],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([1, 24, 24, 0],"float32"), shifts=tuple(-6,-6,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.330517 GPU 1 72614 test begin: paddle.roll(Tensor([1, 24, 24, 0],"float32"), shifts=tuple(6,6,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([1, 24, 24, 0],"float32"), shifts=tuple(6,6,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.464733 GPU 1 72623 test begin: paddle.roll(Tensor([12, 0, 16, 64],"float32"), shifts=tuple(-2,-2,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([12, 0, 16, 64],"float32"), shifts=tuple(-2,-2,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.481440 GPU 1 72526 test begin: paddle.roll(Tensor([12, 0, 16, 64],"float32"), shifts=tuple(2,2,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([12, 0, 16, 64],"float32"), shifts=tuple(2,2,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.485583 GPU 1 72543 test begin: paddle.roll(Tensor([12, 0, 32, 32],"float32"), shifts=tuple(-2,-2,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([12, 0, 32, 32],"float32"), shifts=tuple(-2,-2,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.486497 GPU 1 72556 test begin: paddle.roll(Tensor([12, 0, 32, 32],"float32"), shifts=tuple(2,2,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([12, 0, 32, 32],"float32"), shifts=tuple(2,2,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.487457 GPU 1 72516 test begin: paddle.roll(Tensor([12, 16, 0, 64],"float32"), shifts=tuple(-2,-2,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([12, 16, 0, 64],"float32"), shifts=tuple(-2,-2,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.493418 GPU 1 72615 test begin: paddle.roll(Tensor([12, 16, 0, 64],"float32"), shifts=tuple(2,2,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([12, 16, 0, 64],"float32"), shifts=tuple(2,2,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.507621 GPU 1 72626 test begin: paddle.roll(Tensor([12, 16, 16, 0],"float32"), shifts=tuple(-2,-2,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([12, 16, 16, 0],"float32"), shifts=tuple(-2,-2,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.513074 GPU 1 72793 test begin: paddle.roll(Tensor([12, 16, 16, 0],"float32"), shifts=tuple(2,2,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([12, 16, 16, 0],"float32"), shifts=tuple(2,2,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.518969 GPU 1 72683 test begin: paddle.roll(Tensor([12, 32, 0, 32],"float32"), shifts=tuple(-2,-2,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([12, 32, 0, 32],"float32"), shifts=tuple(-2,-2,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.526213 GPU 1 72568 test begin: paddle.roll(Tensor([12, 32, 0, 32],"float32"), shifts=tuple(2,2,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([12, 32, 0, 32],"float32"), shifts=tuple(2,2,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.558043 GPU 1 72497 test begin: paddle.roll(Tensor([12, 32, 32, 0],"float32"), shifts=tuple(-2,-2,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([12, 32, 32, 0],"float32"), shifts=tuple(-2,-2,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.621459 GPU 1 72621 test begin: paddle.roll(Tensor([12, 32, 32, 0],"float32"), shifts=tuple(2,2,), axis=tuple(1,2,), )
[cuda error] paddle.roll(Tensor([12, 32, 32, 0],"float32"), shifts=tuple(2,2,), axis=tuple(1,2,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.627585 GPU 1 72512 test begin: paddle.roll(Tensor([3, 0],"float64"), shifts=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   RollGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::roll_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, std::vector<long, std::allocator<long> > const&, paddle::Tensor*)
4   void phi::RollGradKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836569 (unix time) try "date -d @1747836569" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fed7e2837d3) received by PID 72512 (TID 0x7fee22e5b740) from PID 2116564947 ***]


2025-05-21 22:09:28.681699 GPU 1 72543 test begin: paddle.roll(Tensor([3, 0],"float64"), shifts=1, axis=0, )
[cuda error] paddle.roll(Tensor([3, 0],"float64"), shifts=1, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.684429 GPU 1 72487 test begin: paddle.roll(x=Tensor([0, 3],"float32"), shifts=0, axis=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   RollGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::roll_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, std::vector<long, std::allocator<long> > const&, paddle::Tensor*)
4   void phi::RollGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836569 (unix time) try "date -d @1747836569" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f97fe2998c3) received by PID 72487 (TID 0x7f98a2e72740) from PID 18446744073678723267 ***]


2025-05-21 22:09:28.686081 GPU 1 72670 test begin: paddle.roll(x=Tensor([0, 3],"float64"), shifts=-1, axis=0, )
[cuda error] paddle.roll(x=Tensor([0, 3],"float64"), shifts=-1, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.691872 GPU 1 72526 test begin: paddle.roll(x=Tensor([0, 3],"float64"), shifts=0, axis=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   RollGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::roll_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, std::vector<long, std::allocator<long> > const&, paddle::Tensor*)
4   void phi::RollGradKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836569 (unix time) try "date -d @1747836569" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fe6768827d3) received by PID 72526 (TID 0x7fe71b45a740) from PID 1988634579 ***]


2025-05-21 22:09:28.717134 GPU 1 72793 test begin: paddle.roll(x=Tensor([0, 3],"float64"), shifts=1, axis=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   RollGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::roll_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, std::vector<long, std::allocator<long> > const&, paddle::Tensor*)
4   void phi::RollGradKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836569 (unix time) try "date -d @1747836569" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f8be07657d3) received by PID 72793 (TID 0x7f8c8533d740) from PID 18446744073180436435 ***]


2025-05-21 22:09:28.722040 GPU 1 72649 test begin: paddle.roll(x=Tensor([0, 3],"float64"), shifts=list[-1,1,], axis=list[0,1,], )
[cuda error] paddle.roll(x=Tensor([0, 3],"float64"), shifts=list[-1,1,], axis=list[0,1,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.735025 GPU 1 72683 test begin: paddle.roll(x=Tensor([0, 3],"float64"), shifts=tuple(-1,1,), axis=tuple(0,1,), )
[cuda error] paddle.roll(x=Tensor([0, 3],"float64"), shifts=tuple(-1,1,), axis=tuple(0,1,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.737671 GPU 1 72615 test begin: paddle.roll(x=Tensor([3, 0],"float32"), shifts=0, axis=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   RollGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::roll_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, std::vector<long, std::allocator<long> > const&, paddle::Tensor*)
4   void phi::RollGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836569 (unix time) try "date -d @1747836569" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fd07cfef8c3) received by PID 72615 (TID 0x7fd121bc8740) from PID 2097084611 ***]


2025-05-21 22:09:28.774796 GPU 1 72568 test begin: paddle.roll(x=Tensor([3, 0],"float64"), shifts=-1, axis=0, )
[cuda error] paddle.roll(x=Tensor([3, 0],"float64"), shifts=-1, axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.795475 GPU 1 72623 test begin: paddle.roll(x=Tensor([3, 0],"float64"), shifts=0, axis=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   RollGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::roll_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, std::vector<long, std::allocator<long> > const&, paddle::Tensor*)
4   void phi::RollGradKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836569 (unix time) try "date -d @1747836569" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fce3fd2f7d3) received by PID 72623 (TID 0x7fcee4907740) from PID 1070790611 ***]


2025-05-21 22:09:28.802484 GPU 1 72614 test begin: paddle.roll(x=Tensor([3, 0],"float64"), shifts=1, axis=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   RollGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::roll_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, std::vector<long, std::allocator<long> > const&, paddle::Tensor*)
4   void phi::RollGradKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836569 (unix time) try "date -d @1747836569" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fe614c567d3) received by PID 72614 (TID 0x7fe6b982e740) from PID 348481491 ***]


2025-05-21 22:09:28.807901 GPU 1 72621 test begin: paddle.roll(x=Tensor([3, 0],"float64"), shifts=list[-1,1,], axis=list[0,1,], )
[cuda error] paddle.roll(x=Tensor([3, 0],"float64"), shifts=list[-1,1,], axis=list[0,1,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.825022 GPU 1 72516 test begin: paddle.roll(x=Tensor([3, 0],"float64"), shifts=tuple(-1,1,), axis=tuple(0,1,), )
[cuda error] paddle.roll(x=Tensor([3, 0],"float64"), shifts=tuple(-1,1,), axis=tuple(0,1,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.825348 GPU 1 72626 test begin: paddle.rot90(Tensor([0, 3],"float32"), k=1, axes=list[0,1,], )
[cuda error] paddle.rot90(Tensor([0, 3],"float32"), k=1, axes=list[0,1,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.846768 GPU 1 72556 test begin: paddle.rot90(Tensor([2, 0],"float32"), k=1, axes=list[0,1,], )
[cuda error] paddle.rot90(Tensor([2, 0],"float32"), k=1, axes=list[0,1,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:28.913121 GPU 1 72670 test begin: paddle.rot90(x=Tensor([0, 4, 4, 4],"float64"), )
[cuda error] paddle.rot90(x=Tensor([0, 4, 4, 4],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:29.073334 GPU 1 72543 test begin: paddle.rot90(x=Tensor([0, 4, 4, 4],"float64"), k=-1, axes=list[1,2,], )
[cuda error] paddle.rot90(x=Tensor([0, 4, 4, 4],"float64"), k=-1, axes=list[1,2,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:29.157955 GPU 1 72568 test begin: paddle.rot90(x=Tensor([0, 4, 4, 4],"float64"), k=-1, axes=tuple(2,3,), )
[cuda error] paddle.rot90(x=Tensor([0, 4, 4, 4],"float64"), k=-1, axes=tuple(2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:29.179865 GPU 1 72683 test begin: paddle.rot90(x=Tensor([0, 4, 4],"float64"), )
[cuda error] paddle.rot90(x=Tensor([0, 4, 4],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:29.292775 GPU 1 72649 test begin: paddle.rot90(x=Tensor([0, 4],"float32"), )
[cuda error] paddle.rot90(x=Tensor([0, 4],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:29.317823 GPU 1 72497 test begin: paddle.rot90(x=Tensor([0, 4],"float64"), )
[cuda error] paddle.rot90(x=Tensor([0, 4],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:29.342009 GPU 1 72516 test begin: paddle.rot90(x=Tensor([0, 4],"float64"), k=-1, )
[cuda error] paddle.rot90(x=Tensor([0, 4],"float64"), k=-1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:29.352867 GPU 1 72670 test begin: paddle.rot90(x=Tensor([3, 0],"float64"), )
[cuda error] paddle.rot90(x=Tensor([3, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:29.362448 GPU 1 72568 test begin: paddle.rot90(x=Tensor([4, 0, 4, 4],"float64"), )
[cuda error] paddle.rot90(x=Tensor([4, 0, 4, 4],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:29.453725 GPU 1 72626 test begin: paddle.rot90(x=Tensor([4, 0, 4, 4],"float64"), k=-1, axes=list[1,2,], )
[cuda error] paddle.rot90(x=Tensor([4, 0, 4, 4],"float64"), k=-1, axes=list[1,2,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:29.460426 GPU 1 72683 test begin: paddle.rot90(x=Tensor([4, 0, 4, 4],"float64"), k=-1, axes=tuple(2,3,), )
[cuda error] paddle.rot90(x=Tensor([4, 0, 4, 4],"float64"), k=-1, axes=tuple(2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:29.461099 GPU 1 72543 test begin: paddle.rot90(x=Tensor([4, 0, 4],"float64"), )
[cuda error] paddle.rot90(x=Tensor([4, 0, 4],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:29.509463 GPU 1 72556 test begin: paddle.rot90(x=Tensor([4, 0],"float32"), )
[cuda error] paddle.rot90(x=Tensor([4, 0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:29.518489 GPU 1 72649 test begin: paddle.rot90(x=Tensor([4, 0],"float64"), k=-1, )
[cuda error] paddle.rot90(x=Tensor([4, 0],"float64"), k=-1, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:29.570817 GPU 1 72568 test begin: paddle.rot90(x=Tensor([4, 4, 0, 4],"float64"), )
[cuda error] paddle.rot90(x=Tensor([4, 4, 0, 4],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:29.586714 GPU 1 72516 test begin: paddle.rot90(x=Tensor([4, 4, 0, 4],"float64"), k=-1, axes=list[1,2,], )
[cuda error] paddle.rot90(x=Tensor([4, 4, 0, 4],"float64"), k=-1, axes=list[1,2,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:29.591328 GPU 1 72670 test begin: paddle.rot90(x=Tensor([4, 4, 0, 4],"float64"), k=-1, axes=tuple(2,3,), )
[cuda error] paddle.rot90(x=Tensor([4, 4, 0, 4],"float64"), k=-1, axes=tuple(2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:29.696189 GPU 1 72621 test begin: paddle.rot90(x=Tensor([4, 4, 0],"float64"), )
[cuda error] paddle.rot90(x=Tensor([4, 4, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:29.988785 GPU 1 72649 test begin: paddle.rot90(x=Tensor([4, 4, 4, 0],"float64"), )
[cuda error] paddle.rot90(x=Tensor([4, 4, 4, 0],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:29.992024 GPU 1 72626 test begin: paddle.rot90(x=Tensor([4, 4, 4, 0],"float64"), k=-1, axes=list[1,2,], )
[cuda error] paddle.rot90(x=Tensor([4, 4, 4, 0],"float64"), k=-1, axes=list[1,2,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:30.006413 GPU 1 72543 test begin: paddle.rot90(x=Tensor([4, 4, 4, 0],"float64"), k=-1, axes=tuple(2,3,), )
[cuda error] paddle.rot90(x=Tensor([4, 4, 4, 0],"float64"), k=-1, axes=tuple(2,3,), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:30.036458 GPU 1 72516 test begin: paddle.row_stack(list[Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),], )

2025-05-21 22:09:30.044275 GPU 1 72621 test begin: paddle.row_stack(list[Tensor([0],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([0],"float64"),], )

2025-05-21 22:09:30.100429 GPU 1 72670 test begin: paddle.sgn(Tensor([0, 4],"complex128"), )
[paddle error] paddle.sgn(Tensor([0, 4],"complex128"), ) 
 (InvalidArgument) Expected the stride of last dimension of input(X) to be 1.But received 2. This means that the last dimension of theTensor(x) is not continuous and cannot be as_complex directly.You can call x.contiguous() to make the Tensor(x) contiguous first.
  [Hint: Expected x.strides()[x.strides().size() - 1] == 1, but received x.strides()[x.strides().size() - 1]:2 != 1:1.] (at ../paddle/phi/kernels/stride/as_complex_kernel.cc:35)


2025-05-21 22:09:30.117639 GPU 1 72497 test begin: paddle.sgn(Tensor([0, 4],"complex64"), )
[paddle error] paddle.sgn(Tensor([0, 4],"complex64"), ) 
 (InvalidArgument) Expected the stride of last dimension of input(X) to be 1.But received 2. This means that the last dimension of theTensor(x) is not continuous and cannot be as_complex directly.You can call x.contiguous() to make the Tensor(x) contiguous first.
  [Hint: Expected x.strides()[x.strides().size() - 1] == 1, but received x.strides()[x.strides().size() - 1]:2 != 1:1.] (at ../paddle/phi/kernels/stride/as_complex_kernel.cc:35)


2025-05-21 22:09:30.151662 GPU 1 72556 test begin: paddle.sgn(Tensor([2, 0],"complex128"), )
[paddle error] paddle.sgn(Tensor([2, 0],"complex128"), ) 
 (InvalidArgument) Expected the stride of last dimension of input(X) to be 1.But received 2. This means that the last dimension of theTensor(x) is not continuous and cannot be as_complex directly.You can call x.contiguous() to make the Tensor(x) contiguous first.
  [Hint: Expected x.strides()[x.strides().size() - 1] == 1, but received x.strides()[x.strides().size() - 1]:2 != 1:1.] (at ../paddle/phi/kernels/stride/as_complex_kernel.cc:35)


2025-05-21 22:09:30.188924 GPU 1 72683 test begin: paddle.sgn(Tensor([2, 0],"complex64"), )
[paddle error] paddle.sgn(Tensor([2, 0],"complex64"), ) 
 (InvalidArgument) Expected the stride of last dimension of input(X) to be 1.But received 2. This means that the last dimension of theTensor(x) is not continuous and cannot be as_complex directly.You can call x.contiguous() to make the Tensor(x) contiguous first.
  [Hint: Expected x.strides()[x.strides().size() - 1] == 1, but received x.strides()[x.strides().size() - 1]:2 != 1:1.] (at ../paddle/phi/kernels/stride/as_complex_kernel.cc:35)


2025-05-21 22:09:30.236434 GPU 1 72568 test begin: paddle.sinc(Tensor([0, 64],"float32"), )
[cuda error] paddle.sinc(Tensor([0, 64],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:30.317587 GPU 1 72626 test begin: paddle.sinc(Tensor([0, 64],"float64"), )
[cuda error] paddle.sinc(Tensor([0, 64],"float64"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:30.381837 GPU 1 72543 test begin: paddle.sinc(Tensor([0],"float32"), )
[cuda error] paddle.sinc(Tensor([0],"float32"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:30.394244 GPU 1 72670 test begin: paddle.sinc(Tensor([0],"float64"), )
[torch error] paddle.sinc(Tensor([0],"float64"), )
Traceback (most recent call last):
  File "/root/paddlejob/PaddleAPITest-dev/tester/accuracy.py", line 113, in test
    paddle.base.core.eager._for_test_check_cuda_error()
OSError: (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:30.401698 GPU 1 72683 test begin: paddle.sinc(Tensor([16, 0],"float32"), )
[torch error] paddle.sinc(Tensor([16, 0],"float32"), )
Traceback (most recent call last):
  File "/root/paddlejob/PaddleAPITest-dev/tester/accuracy.py", line 113, in test
    paddle.base.core.eager._for_test_check_cuda_error()
OSError: (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:30.415742 GPU 1 72497 test begin: paddle.sinc(Tensor([16, 0],"float64"), )
[torch error] paddle.sinc(Tensor([16, 0],"float64"), )
Traceback (most recent call last):
  File "/root/paddlejob/PaddleAPITest-dev/tester/accuracy.py", line 113, in test
    paddle.base.core.eager._for_test_check_cuda_error()
OSError: (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:30.447423 GPU 1 72813 test begin: paddle.std(Tensor([0, 3, 4, 10],"float32"), list[1,3,], True, False, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0521 22:09:30.804205 72813 dygraph_functions.cc:85067] got different data type, run type promotion automatically, this may cause data type been changed.
W0521 22:09:30.813395 72813 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.std(Tensor([0, 3, 4, 10],"float32"), list[1,3,], True, False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:09:30.487937 GPU 1 72568 test begin: paddle.std(Tensor([0, 3, 4, 10],"float64"), 2, True, False, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0521 22:09:30.808195 72568 dygraph_functions.cc:85067] got different data type, run type promotion automatically, this may cause data type been changed.
W0521 22:09:30.810820 72568 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.std(Tensor([0, 3, 4, 10],"float64"), 2, True, False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:09:30.531970 GPU 1 72621 test begin: paddle.std(Tensor([0, 3, 4, 10],"float64"), list[1,2,], True, False, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0521 22:09:30.655570 72621 dygraph_functions.cc:85067] got different data type, run type promotion automatically, this may cause data type been changed.
W0521 22:09:30.657820 72621 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.std(Tensor([0, 3, 4, 10],"float64"), list[1,2,], True, False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:09:30.557146 GPU 1 72556 test begin: paddle.std(Tensor([0, 3, 4, 10],"float64"), list[1,3,], False, False, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
[torch error] paddle.std(Tensor([0, 3, 4, 10],"float64"), list[1,3,], False, False, )
Traceback (most recent call last):
  File "/root/paddlejob/PaddleAPITest-dev/tester/accuracy.py", line 113, in test
    paddle.base.core.eager._for_test_check_cuda_error()
OSError: (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1388)


2025-05-21 22:09:30.614846 GPU 1 72649 test begin: paddle.std(Tensor([0, 3, 4, 10],"float64"), list[1,3,], True, False, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0521 22:09:30.847998 72649 dygraph_functions.cc:85067] got different data type, run type promotion automatically, this may cause data type been changed.
W0521 22:09:30.850252 72649 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.std(Tensor([0, 3, 4, 10],"float64"), list[1,3,], True, False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:09:30.659510 GPU 1 72621 test begin: paddle.std(Tensor([0, 3, 4, 10],"float64"), tuple(1,3,), True, False, )
W0521 22:09:30.881740 72621 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.std(Tensor([0, 3, 4, 10],"float64"), tuple(1,3,), True, False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:09:30.664256 GPU 1 72516 test begin: paddle.std(Tensor([0, 32],"float32"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0521 22:09:31.234140 72516 dygraph_functions.cc:85067] got different data type, run type promotion automatically, this may cause data type been changed.
[accuracy error] paddle.std(Tensor([0, 32],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array(0., dtype=float32)
 DESIRED: array(nan, dtype=float32)

2025-05-21 22:09:30.693305 GPU 1 72543 test begin: paddle.std(Tensor([0, 5],"float32"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0521 22:09:30.810199 72543 dygraph_functions.cc:85067] got different data type, run type promotion automatically, this may cause data type been changed.
[accuracy error] paddle.std(Tensor([0, 5],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array(0., dtype=float32)
 DESIRED: array(nan, dtype=float32)

2025-05-21 22:09:30.696500 GPU 1 72626 test begin: paddle.std(Tensor([0, 9],"float32"), axis=1, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0521 22:09:30.809286 72626 dygraph_functions.cc:85067] got different data type, run type promotion automatically, this may cause data type been changed.
W0521 22:09:30.811064 72626 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.std(Tensor([0, 9],"float32"), axis=1, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:09:30.812585 GPU 1 72626 test begin: paddle.std(Tensor([0],"float32"), )
[accuracy error] paddle.std(Tensor([0],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array(0., dtype=float32)
 DESIRED: array(nan, dtype=float32)

2025-05-21 22:09:30.813121 GPU 1 72568 test begin: paddle.std(Tensor([1, 0, 4, 10],"float32"), list[1,3,], True, False, )
[accuracy error] paddle.std(Tensor([1, 0, 4, 10],"float32"), list[1,3,], True, False, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array([[0., 0., 0., 0.]], dtype=float32)
 DESIRED: array([[nan, nan, nan, nan]], dtype=float32)

2025-05-21 22:09:30.813184 GPU 1 72543 test begin: paddle.std(Tensor([1, 0, 4, 10],"float64"), 2, True, False, )
W0521 22:09:31.029107 72543 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.std(Tensor([1, 0, 4, 10],"float64"), 2, True, False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:09:30.816307 GPU 1 72813 test begin: paddle.std(Tensor([1, 0, 4, 10],"float64"), list[1,2,], True, False, )
[accuracy error] paddle.std(Tensor([1, 0, 4, 10],"float64"), list[1,2,], True, False, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])
 DESIRED: array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]])

2025-05-21 22:09:30.854898 GPU 1 72649 test begin: paddle.std(Tensor([1, 0, 4, 10],"float64"), list[1,3,], False, False, )
W0521 22:09:31.061092 72649 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.std(Tensor([1, 0, 4, 10],"float64"), list[1,3,], False, False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:09:30.884001 GPU 1 72621 test begin: paddle.std(Tensor([1, 0, 4, 10],"float64"), list[1,3,], True, False, )
[accuracy error] paddle.std(Tensor([1, 0, 4, 10],"float64"), list[1,3,], True, False, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array([[0., 0., 0., 0.]])
 DESIRED: array([[nan, nan, nan, nan]])

2025-05-21 22:09:31.026220 GPU 1 72621 test begin: paddle.std(Tensor([1, 0, 4, 10],"float64"), tuple(1,3,), True, False, )
[accuracy error] paddle.std(Tensor([1, 0, 4, 10],"float64"), tuple(1,3,), True, False, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array([[0., 0., 0., 0.]])
 DESIRED: array([[nan, nan, nan, nan]])

2025-05-21 22:09:31.031126 GPU 1 72543 test begin: paddle.std(Tensor([1, 3, 0, 10],"float32"), list[1,3,], True, False, )
W0521 22:09:31.163582 72543 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.std(Tensor([1, 3, 0, 10],"float32"), list[1,3,], True, False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:09:31.034406 GPU 1 72626 test begin: paddle.std(Tensor([1, 3, 0, 10],"float64"), 2, True, False, )
[accuracy error] paddle.std(Tensor([1, 3, 0, 10],"float64"), 2, True, False, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])
 DESIRED: array([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]])

2025-05-21 22:09:31.035005 GPU 1 72568 test begin: paddle.std(Tensor([1, 3, 0, 10],"float64"), list[1,2,], True, False, )
[accuracy error] paddle.std(Tensor([1, 3, 0, 10],"float64"), list[1,2,], True, False, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])
 DESIRED: array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]])

2025-05-21 22:09:31.062274 GPU 1 72649 test begin: paddle.std(Tensor([1, 3, 0, 10],"float64"), list[1,3,], False, False, )
W0521 22:09:31.758466 72649 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.std(Tensor([1, 3, 0, 10],"float64"), list[1,3,], False, False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:09:31.127254 GPU 1 72813 test begin: paddle.std(Tensor([1, 3, 0, 10],"float64"), list[1,3,], True, False, )
W0521 22:09:31.663077 72813 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.std(Tensor([1, 3, 0, 10],"float64"), list[1,3,], True, False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:09:31.331602 GPU 1 72543 test begin: paddle.std(Tensor([1, 3, 0, 10],"float64"), tuple(1,3,), True, False, )
W0521 22:09:31.649327 72543 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.std(Tensor([1, 3, 0, 10],"float64"), tuple(1,3,), True, False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:09:31.336565 GPU 1 72621 test begin: paddle.std(Tensor([1, 3, 4, 0],"float32"), list[1,3,], True, False, )
[accuracy error] paddle.std(Tensor([1, 3, 4, 0],"float32"), list[1,3,], True, False, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array([[0., 0., 0., 0.]], dtype=float32)
 DESIRED: array([[nan, nan, nan, nan]], dtype=float32)

2025-05-21 22:09:31.337016 GPU 1 72626 test begin: paddle.std(Tensor([1, 3, 4, 0],"float64"), 2, True, False, )
W0521 22:09:31.955952 72626 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.std(Tensor([1, 3, 4, 0],"float64"), 2, True, False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:09:31.337146 GPU 1 72568 test begin: paddle.std(Tensor([1, 3, 4, 0],"float64"), list[1,2,], True, False, )
W0521 22:09:32.351625 72568 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.std(Tensor([1, 3, 4, 0],"float64"), list[1,2,], True, False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:09:31.443863 GPU 1 72516 test begin: paddle.std(Tensor([1, 3, 4, 0],"float64"), list[1,3,], False, False, )
W0521 22:09:32.307658 72516 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.std(Tensor([1, 3, 4, 0],"float64"), list[1,3,], False, False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:09:31.651544 GPU 1 72543 test begin: paddle.std(Tensor([1, 3, 4, 0],"float64"), list[1,3,], True, False, )
[accuracy error] paddle.std(Tensor([1, 3, 4, 0],"float64"), list[1,3,], True, False, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array([[0., 0., 0., 0.]])
 DESIRED: array([[nan, nan, nan, nan]])

2025-05-21 22:09:31.672131 GPU 1 72813 test begin: paddle.std(Tensor([1, 3, 4, 0],"float64"), tuple(1,3,), True, False, )
[accuracy error] paddle.std(Tensor([1, 3, 4, 0],"float64"), tuple(1,3,), True, False, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array([[0., 0., 0., 0.]])
 DESIRED: array([[nan, nan, nan, nan]])

2025-05-21 22:09:31.759864 GPU 1 72649 test begin: paddle.std(Tensor([3, 0],"float32"), )
[accuracy error] paddle.std(Tensor([3, 0],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array(0., dtype=float32)
 DESIRED: array(nan, dtype=float32)

2025-05-21 22:09:31.895552 GPU 1 72621 test begin: paddle.std(Tensor([32, 0],"float32"), )
[accuracy error] paddle.std(Tensor([32, 0],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array(0., dtype=float32)
 DESIRED: array(nan, dtype=float32)

2025-05-21 22:09:31.905434 GPU 1 72543 test begin: paddle.std(Tensor([6, 0],"float32"), axis=1, )
[accuracy error] paddle.std(Tensor([6, 0],"float32"), axis=1, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array([0., 0., 0., 0., 0., 0.], dtype=float32)
 DESIRED: array([nan, nan, nan, nan, nan, nan], dtype=float32)

2025-05-21 22:09:31.959113 GPU 1 72626 test begin: paddle.std(x=Tensor([0, 3, 3],"float64"), )
[accuracy error] paddle.std(x=Tensor([0, 3, 3],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array(0.)
 DESIRED: array(nan)

2025-05-21 22:09:32.207593 GPU 1 72649 test begin: paddle.std(x=Tensor([0, 3, 3],"float64"), axis=0, )
[accuracy error] paddle.std(x=Tensor([0, 3, 3],"float64"), axis=0, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.]])
 DESIRED: array([[nan, nan, nan],
       [nan, nan, nan],
       [nan, nan, nan]])

2025-05-21 22:09:32.312253 GPU 1 72516 test begin: paddle.std(x=Tensor([0, 3, 3],"float64"), axis=0, unbiased=False, )
W0521 22:09:32.784062 72516 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.std(x=Tensor([0, 3, 3],"float64"), axis=0, unbiased=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:09:32.343301 GPU 1 72626 test begin: paddle.std(x=Tensor([0, 3, 3],"float64"), axis=list[0,1,], )
[accuracy error] paddle.std(x=Tensor([0, 3, 3],"float64"), axis=list[0,1,], ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array([0., 0., 0.])
 DESIRED: array([nan, nan, nan])

2025-05-21 22:09:32.350447 GPU 1 72933 test begin: paddle.std(x=Tensor([0, 3, 3],"float64"), axis=tuple(0,1,), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0521 22:09:32.599761 72933 dygraph_functions.cc:85067] got different data type, run type promotion automatically, this may cause data type been changed.
[accuracy error] paddle.std(x=Tensor([0, 3, 3],"float64"), axis=tuple(0,1,), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array([0., 0., 0.])
 DESIRED: array([nan, nan, nan])

2025-05-21 22:09:32.353765 GPU 1 72568 test begin: paddle.std(x=Tensor([0, 3, 3],"float64"), axis=tuple(0,1,), keepdim=True, )
[accuracy error] paddle.std(x=Tensor([0, 3, 3],"float64"), axis=tuple(0,1,), keepdim=True, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array([[[0., 0., 0.]]])
 DESIRED: array([[[nan, nan, nan]]])

2025-05-21 22:09:32.422824 GPU 1 72621 test begin: paddle.std(x=Tensor([0, 3],"float32"), )
[accuracy error] paddle.std(x=Tensor([0, 3],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array(0., dtype=float32)
 DESIRED: array(nan, dtype=float32)

2025-05-21 22:09:32.428136 GPU 1 72813 test begin: paddle.std(x=Tensor([0, 3],"float64"), )
[accuracy error] paddle.std(x=Tensor([0, 3],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array(0.)
 DESIRED: array(nan)

2025-05-21 22:09:32.434369 GPU 1 72543 test begin: paddle.std(x=Tensor([2, 0],"float32"), )
[accuracy error] paddle.std(x=Tensor([2, 0],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array(0., dtype=float32)
 DESIRED: array(nan, dtype=float32)

2025-05-21 22:09:32.482576 GPU 1 72649 test begin: paddle.std(x=Tensor([2, 0],"float64"), )
[accuracy error] paddle.std(x=Tensor([2, 0],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array(0.)
 DESIRED: array(nan)

2025-05-21 22:09:32.482653 GPU 1 72626 test begin: paddle.std(x=Tensor([3, 0, 3],"float64"), )
[accuracy error] paddle.std(x=Tensor([3, 0, 3],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array(0.)
 DESIRED: array(nan)

2025-05-21 22:09:32.599937 GPU 1 72543 test begin: paddle.std(x=Tensor([3, 0, 3],"float64"), axis=0, )
W0521 22:09:32.797963 72543 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.std(x=Tensor([3, 0, 3],"float64"), axis=0, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:09:32.706637 GPU 1 72568 test begin: paddle.std(x=Tensor([3, 0, 3],"float64"), axis=0, unbiased=False, )
W0521 22:09:33.010993 72568 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.std(x=Tensor([3, 0, 3],"float64"), axis=0, unbiased=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:09:32.711874 GPU 1 72626 test begin: paddle.std(x=Tensor([3, 0, 3],"float64"), axis=list[0,1,], )
[accuracy error] paddle.std(x=Tensor([3, 0, 3],"float64"), axis=list[0,1,], ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array([0., 0., 0.])
 DESIRED: array([nan, nan, nan])

2025-05-21 22:09:32.715413 GPU 1 72933 test begin: paddle.std(x=Tensor([3, 0, 3],"float64"), axis=tuple(0,1,), )
[accuracy error] paddle.std(x=Tensor([3, 0, 3],"float64"), axis=tuple(0,1,), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array([0., 0., 0.])
 DESIRED: array([nan, nan, nan])

2025-05-21 22:09:32.785307 GPU 1 72516 test begin: paddle.std(x=Tensor([3, 0, 3],"float64"), axis=tuple(0,1,), keepdim=True, )
[accuracy error] paddle.std(x=Tensor([3, 0, 3],"float64"), axis=tuple(0,1,), keepdim=True, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array([[[0., 0., 0.]]])
 DESIRED: array([[[nan, nan, nan]]])

2025-05-21 22:09:32.791585 GPU 1 72813 test begin: paddle.std(x=Tensor([3, 3, 0],"float64"), )
[accuracy error] paddle.std(x=Tensor([3, 3, 0],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array(0.)
 DESIRED: array(nan)

2025-05-21 22:09:32.797893 GPU 1 72649 test begin: paddle.std(x=Tensor([3, 3, 0],"float64"), axis=0, )
W0521 22:09:33.025754 72649 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.std(x=Tensor([3, 3, 0],"float64"), axis=0, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:09:32.799337 GPU 1 72543 test begin: paddle.std(x=Tensor([3, 3, 0],"float64"), axis=0, unbiased=False, )
W0521 22:09:32.917131 72543 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.std(x=Tensor([3, 3, 0],"float64"), axis=0, unbiased=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:09:32.850053 GPU 1 72626 test begin: paddle.std(x=Tensor([3, 3, 0],"float64"), axis=list[0,1,], )
W0521 22:09:32.968222 72626 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.std(x=Tensor([3, 3, 0],"float64"), axis=list[0,1,], ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:09:32.915441 GPU 1 72621 test begin: paddle.std(x=Tensor([3, 3, 0],"float64"), axis=tuple(0,1,), )
W0521 22:09:33.090963 72621 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.std(x=Tensor([3, 3, 0],"float64"), axis=tuple(0,1,), ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:09:32.919478 GPU 1 72543 test begin: paddle.std(x=Tensor([3, 3, 0],"float64"), axis=tuple(0,1,), keepdim=True, )
W0521 22:09:33.111172 72543 backward.cc:437] While running Node (SubtractGradNode) raises an EnforceNotMet exception
[paddle error] paddle.std(x=Tensor([3, 3, 0],"float64"), axis=tuple(0,1,), keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1092)


2025-05-21 22:09:32.980015 GPU 1 72626 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[0,1,3,2,],list[0,2,1,3,],], )
W0521 22:09:33.161336 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[0,1,3,2,],list[0,2,1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 1, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 0, 5, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:33.012106 GPU 1 72568 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[0,1,3,],list[0,3,1,],], )
W0521 22:09:33.146515 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[0,1,3,],list[0,3,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 1, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 0, 5, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:33.027850 GPU 1 72649 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[0,2,3,],list[0,1,2,],], )
W0521 22:09:33.221807 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[0,2,3,],list[0,1,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:33.089732 GPU 1 72933 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[0,2,3,],list[0,2,1,],], )
W0521 22:09:33.355309 72933 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[0,2,3,],list[0,2,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 1, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 0, 5, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:33.091904 GPU 1 72516 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[0,3,1,2,],list[3,2,1,0,],], )
W0521 22:09:39.240933 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[0,3,1,2,],list[3,2,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:33.104171 GPU 1 72621 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[0,3,2,1,],list[2,1,3,0,],], )
W0521 22:09:39.052412 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[0,3,2,1,],list[2,1,3,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 1, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 0, 5, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:33.125907 GPU 1 72543 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[1,0,2,3,],list[3,0,1,2,],], )
W0521 22:09:33.288002 72543 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[1,0,2,3,],list[3,0,1,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:33.149737 GPU 1 72568 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[1,0,3,2,],list[3,0,1,2,],], )
W0521 22:09:33.301319 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[1,0,3,2,],list[3,0,1,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 1, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 0, 5, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:33.182940 GPU 1 72626 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[1,2,0,],list[1,2,3,],], )
W0521 22:09:38.524693 72626 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[1,2,0,],list[1,2,3,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:09:33.223292 GPU 1 72649 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[1,2,0,],list[1,3,2,],], )
W0521 22:09:38.873133 72649 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[1,2,0,],list[1,3,2,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:09:33.302708 GPU 1 72543 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[1,2,3,0,],list[3,2,1,0,],], )
W0521 22:09:33.755697 72543 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[1,2,3,0,],list[3,2,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 1, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 0, 5, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:33.303180 GPU 1 72568 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[1,3,2,0,],list[1,3,2,0,],], )
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[1,3,2,0,],list[1,3,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)

W0521 22:09:33.755813 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception

2025-05-21 22:09:33.308215 GPU 1 72813 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[1,3,2,0,],list[2,1,0,3,],], )
W0521 22:09:40.380096 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[1,3,2,0,],list[2,1,0,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 1, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 0, 5, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:33.356775 GPU 1 72933 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[2,1,0,3,],list[2,0,3,1,],], )
W0521 22:09:40.108721 72933 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[2,1,0,3,],list[2,0,3,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 1, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 0, 5, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:33.761974 GPU 1 72543 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[2,3,0,],list[1,2,0,],], )
W0521 22:09:34.278484 72543 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[2,3,0,],list[1,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:33.762640 GPU 1 72568 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[2,3,0,],list[3,1,0,],], )
W0521 22:09:34.809103 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[2,3,0,],list[3,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 1, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 0, 5, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:34.280135 GPU 1 72543 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[2,3,],list[1,3,],], )
W0521 22:09:34.917637 72543 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[2,3,],list[1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:34.810335 GPU 1 72568 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,1,0,2,],list[3,1,0,2,],], )
W0521 22:09:34.986049 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,1,0,2,],list[3,1,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:34.918355 GPU 1 72543 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,1,2,0,],list[1,2,3,0,],], )
W0521 22:09:35.055447 72543 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,1,2,0,],list[1,2,3,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 1, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 0, 5, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:34.987973 GPU 1 72568 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,1,2,0,],list[2,3,1,0,],], )
W0521 22:09:35.148317 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,1,2,0,],list[2,3,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:35.068511 GPU 1 72543 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,1,2,],list[1,2,3,],], )
W0521 22:09:35.361119 72543 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,1,2,],list[1,2,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 1, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 0, 5, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:35.150196 GPU 1 72568 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,1,2,],list[1,3,2,],], )
W0521 22:09:35.273196 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,1,2,],list[1,3,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 1, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 0, 5, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:35.274035 GPU 1 72568 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,1,2,],list[2,3,1,],], )
W0521 22:09:35.474344 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,1,2,],list[2,3,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:35.362046 GPU 1 72543 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,1,2,],list[3,1,0,],], )
W0521 22:09:35.549044 72543 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,1,2,],list[3,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:35.475125 GPU 1 72568 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,2,0,],list[2,1,0,],], )
W0521 22:09:35.677403 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,2,0,],list[2,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:35.499840 GPU 1 73618 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,2,0,],list[3,2,0,],], )
W0521 22:09:57.030643 73618 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,2,0,],list[3,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:35.551089 GPU 1 72543 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,2,1,],list[2,0,1,],], )
W0521 22:09:35.806236 72543 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,2,1,],list[2,0,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:35.685055 GPU 1 72568 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,2,],list[3,1,],], )
W0521 22:09:35.851079 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,2,],list[3,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:35.851888 GPU 1 72568 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[1,2,3,0,],list[1,3,0,2,],], )
W0521 22:09:43.024082 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[1,2,3,0,],list[1,3,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:35.854453 GPU 1 72543 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[1,3,0,],list[3,0,2,],], )
W0521 22:09:43.322434 72543 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[1,3,0,],list[3,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:37.566742 GPU 1 73599 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[1,3,2,0,],list[1,3,2,0,],], )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/autograd/graph.py:823: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:180.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
W0521 22:10:11.638438 73599 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[1,3,2,0,],list[1,3,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:37.569024 GPU 1 73711 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[1,3,2,0,],list[3,0,1,2,],], )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/autograd/graph.py:823: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:180.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
W0521 22:10:10.984151 73711 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[1,3,2,0,],list[3,0,1,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:37.606877 GPU 1 73601 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[1,3,],list[1,0,],], )
W0521 22:10:04.959661 73601 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[1,3,],list[1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:37.811907 GPU 1 73676 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[2,3,0,],list[1,2,0,],], )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/autograd/graph.py:823: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:180.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
W0521 22:10:12.830896 73676 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[2,3,0,],list[1,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:37.962355 GPU 1 73677 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[2,3,1,],list[1,0,2,],], )
W0521 22:10:08.121057 73677 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[2,3,1,],list[1,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:38.095289 GPU 1 73666 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[2,3,],list[1,3,],], )
W0521 22:10:06.702992 73666 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[2,3,],list[1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:38.495360 GPU 1 73727 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,1,0,2,],list[3,1,0,2,],], )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/autograd/graph.py:823: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:180.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
W0521 22:10:13.481056 73727 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,1,0,2,],list[3,1,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:38.526304 GPU 1 72626 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,1,2,0,],list[2,3,1,0,],], )
 ** On entry to DGEMM  parameter number 8 had an illegal value
W0521 22:09:39.162624 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,1,2,0,],list[2,3,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:38.699433 GPU 1 73782 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,1,2,],list[0,3,2,],], )
W0521 22:10:08.879010 73782 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,1,2,],list[0,3,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:38.811830 GPU 1 73703 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,1,2,],list[2,3,1,],], )
W0521 22:10:08.151397 73703 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,1,2,],list[2,3,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:38.868075 GPU 1 73731 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,1,2,],list[3,1,0,],], )
W0521 22:10:08.064080 73731 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,1,2,],list[3,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:38.877223 GPU 1 72649 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,2,0,],list[2,1,0,],], )
 ** On entry to DGEMM  parameter number 8 had an illegal value
W0521 22:09:39.781288 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,2,0,],list[2,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:38.964148 GPU 1 73775 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,2,0,],list[3,2,0,],], )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/autograd/graph.py:823: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:180.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
W0521 22:10:12.996618 73775 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,2,0,],list[3,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:38.995521 GPU 1 73742 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,2,1,0,],list[0,1,3,2,],], )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/autograd/graph.py:823: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:180.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
W0521 22:10:12.772277 73742 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,2,1,0,],list[0,1,3,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:39.000386 GPU 1 73762 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,2,1,],list[2,0,1,],], )
W0521 22:10:06.633844 73762 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,2,1,],list[2,0,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:39.053486 GPU 1 72621 test begin: paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,2,],list[3,1,],], )
W0521 22:09:39.179200 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,2,],list[3,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:39.163380 GPU 1 72626 test begin: paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[0,1,3,2,],list[0,2,1,3,],], )
W0521 22:09:39.320456 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[0,1,3,2,],list[0,2,1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 5, Tensor layout is NCHW, Tensor stride is 25, 5, 1. New dims is 0, 5, 1, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:39.180031 GPU 1 72621 test begin: paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[0,1,3,],list[0,3,1,],], )
W0521 22:09:39.320040 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[0,1,3,],list[0,3,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 1, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 0, 5, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:39.228943 GPU 1 73690 test begin: paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[0,2,3,],list[0,1,2,],], )
W0521 22:10:07.606957 73690 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[0,2,3,],list[0,1,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 0, 1, 5, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:39.242413 GPU 1 72516 test begin: paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[0,2,3,],list[0,2,1,],], )
W0521 22:09:39.459861 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[0,2,3,],list[0,2,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 0, 1, 1, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:39.320804 GPU 1 72621 test begin: paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[1,0,2,3,],list[3,0,1,2,],], )
W0521 22:09:39.445108 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[1,0,2,3,],list[3,0,1,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 0, 1, 5, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:39.321467 GPU 1 72626 test begin: paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[1,0,3,2,],list[3,0,1,2,],], )
W0521 22:09:39.453588 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[1,0,3,2,],list[3,0,1,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 0, 1, 1, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:39.446013 GPU 1 72621 test begin: paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[1,2,0,],list[1,3,2,],], )
W0521 22:09:39.595609 72621 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[1,2,0,],list[1,3,2,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:39.454292 GPU 1 72626 test begin: paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[1,2,3,0,],list[3,2,1,0,],], )
W0521 22:09:39.762044 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[1,2,3,0,],list[3,2,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 0, 1, 1, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:39.460886 GPU 1 72516 test begin: paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[1,3,2,0,],list[1,3,2,0,],], )
W0521 22:09:39.648787 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[1,3,2,0,],list[1,3,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 0, 1, 1, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:39.596669 GPU 1 72621 test begin: paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[2,3,0,],list[1,2,0,],], )
W0521 22:09:39.780083 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[2,3,0,],list[1,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 0, 1, 5, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:39.649784 GPU 1 72516 test begin: paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,1,0,2,],list[3,1,0,2,],], )
W0521 22:09:39.817349 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,1,0,2,],list[3,1,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 0, 1, 1, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:39.763408 GPU 1 72626 test begin: paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,1,2,0,],list[1,2,3,0,],], )
W0521 22:09:40.216332 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,1,2,0,],list[1,2,3,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 5, Tensor layout is NCHW, Tensor stride is 25, 5, 1. New dims is 0, 5, 1, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:39.781052 GPU 1 72621 test begin: paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,1,2,0,],list[2,3,1,0,],], )
W0521 22:09:40.202153 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,1,2,0,],list[2,3,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 0, 1, 5, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:39.782249 GPU 1 72649 test begin: paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,1,2,],list[1,2,3,],], )
W0521 22:09:39.900233 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,1,2,],list[1,2,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 5, Tensor layout is NCHW, Tensor stride is 25, 5, 1. New dims is 0, 5, 1, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:39.818165 GPU 1 72516 test begin: paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,1,2,],list[1,3,2,],], )
W0521 22:09:40.087599 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,1,2,],list[1,3,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 0, 1, 1, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:39.901141 GPU 1 72649 test begin: paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,1,2,],list[2,3,1,],], )
W0521 22:09:40.119577 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,1,2,],list[2,3,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 0, 1, 5, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:40.088386 GPU 1 72516 test begin: paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,2,0,],list[2,1,0,],], )
W0521 22:09:40.410586 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,2,0,],list[2,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 0, 1, 5, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:40.110512 GPU 1 72933 test begin: paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,2,0,],list[3,2,0,],], )
W0521 22:09:40.410669 72933 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,2,0,],list[3,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 0, 1, 1, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:40.120396 GPU 1 72649 test begin: paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([5, 5, 1, 5],"float64"), list[list[3,1,2,],list[0,3,2,],], )
W0521 22:09:40.376396 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([5, 5, 1, 5],"float64"), list[list[3,1,2,],list[0,3,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 0, 1, 1, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:40.203442 GPU 1 72621 test begin: paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([5, 5, 1, 5],"float64"), list[list[3,1,2,],list[1,3,2,],], )
W0521 22:09:40.486459 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([5, 5, 1, 5],"float64"), list[list[3,1,2,],list[1,3,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 0, 1, 1, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:40.217057 GPU 1 72626 test begin: paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([5, 5, 1, 5],"float64"), list[list[3,1,2,],list[2,3,1,],], )
W0521 22:09:40.385484 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([5, 5, 1, 5],"float64"), list[list[3,1,2,],list[2,3,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 0, 1, 5, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:40.377105 GPU 1 72649 test begin: paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([5, 5, 1, 5],"float64"), list[list[3,2,1,],list[2,0,1,],], )
W0521 22:09:40.628980 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([0, 1, 5, 5],"float64"), Tensor([5, 5, 1, 5],"float64"), list[list[3,2,1,],list[2,0,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 0, 1, 5, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:40.381856 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[0,1,2,],list[2,0,1,],], )
W0521 22:09:40.622805 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[0,1,2,],list[2,0,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:40.386188 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[0,1,3,2,],list[2,3,0,1,],], )
W0521 22:09:40.502492 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[0,1,3,2,],list[2,3,0,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:40.411982 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[0,2,3,],list[0,1,2,],], )
W0521 22:09:40.627230 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[0,2,3,],list[0,1,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:40.412091 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[0,3,1,2,],list[3,2,1,0,],], )
W0521 22:09:40.860226 72933 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[0,3,1,2,],list[3,2,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:40.488078 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[1,0,2,3,],list[3,0,1,2,],], )
W0521 22:09:40.901010 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[1,0,2,3,],list[3,0,1,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:40.503260 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[1,0,3,2,],list[2,3,0,1,],], )
W0521 22:09:40.738896 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[1,0,3,2,],list[2,3,0,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:40.624547 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[1,0,3,],list[2,3,0,],], )
W0521 22:09:40.898171 72813 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[1,0,3,],list[2,3,0,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:40.628209 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[1,2,0,3,],list[0,2,1,3,],], )
W0521 22:09:40.903167 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[1,2,0,3,],list[0,2,1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:40.629689 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[1,2,0,],list[1,2,3,],], )
W0521 22:09:40.739997 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[1,2,0,],list[1,2,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:40.739712 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[1,2,0,],list[1,3,2,],], )
W0521 22:09:40.903827 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[1,2,0,],list[1,3,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:40.740695 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[1,2,3,0,],list[1,3,0,2,],], )
W0521 22:09:40.907895 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[1,2,3,0,],list[1,3,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:40.861109 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[1,3,0,],list[3,0,2,],], )
W0521 22:09:41.086149 72933 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[1,3,0,],list[3,0,2,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:40.899021 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[1,3,2,0,],list[1,3,2,0,],], )
W0521 22:09:41.055569 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[1,3,2,0,],list[1,3,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:40.902879 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[1,3,],list[1,0,],], )
W0521 22:09:41.140802 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[1,3,],list[1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:40.904015 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[2,0,1,3,],list[3,1,0,2,],], )
W0521 22:09:41.086362 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[2,0,1,3,],list[3,1,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:40.904480 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[2,0,1,],list[0,1,3,],], )
W0521 22:09:41.038363 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[2,0,1,],list[0,1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:40.909703 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[2,1,0,3,],list[2,0,1,3,],], )
W0521 22:09:41.141337 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[2,1,0,3,],list[2,0,1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:41.039248 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[2,1,0,3,],list[3,1,2,0,],], )
W0521 22:09:41.267544 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[2,1,0,3,],list[3,1,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:41.056630 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[2,1,],list[0,2,],], )
W0521 22:09:41.284541 72813 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[2,1,],list[0,2,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:41.087097 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[2,3,0,],list[1,2,0,],], )
W0521 22:09:41.267630 72933 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[2,3,0,],list[1,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:41.087323 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[2,3,1,],list[1,0,2,],], )
W0521 22:09:41.247555 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[2,3,1,],list[1,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:41.141687 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[2,3,],list[1,3,],], )
W0521 22:09:41.438338 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[2,3,],list[1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:41.148795 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,0,2,1,],list[2,1,0,3,],], )
W0521 22:09:41.286403 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,0,2,1,],list[2,1,0,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:41.248447 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,0,],list[2,1,],], )
W0521 22:09:41.410319 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,0,],list[2,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:41.268315 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,1,0,2,],list[2,3,1,0,],], )
W0521 22:09:41.391499 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,1,0,2,],list[2,3,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:41.268579 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,1,0,2,],list[3,1,0,2,],], )
W0521 22:09:41.443131 72933 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,1,0,2,],list[3,1,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:41.285534 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,1,0,],list[3,2,1,],], )
W0521 22:09:41.797786 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,1,0,],list[3,2,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:41.287523 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,1,2,0,],list[2,3,1,0,],], )
W0521 22:09:41.558334 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,1,2,0,],list[2,3,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:41.392369 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,1,2,],list[0,3,2,],], )
W0521 22:09:41.512740 72626 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,1,2,],list[0,3,2,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:41.411119 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,1,2,],list[2,3,1,],], )
W0521 22:09:41.745962 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,1,2,],list[2,3,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:41.439173 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,1,2,],list[3,1,0,],], )
W0521 22:09:41.590560 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,1,2,],list[3,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:41.443978 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,2,0,],list[2,1,0,],], )
W0521 22:09:41.666896 72933 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,2,0,],list[2,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:41.513452 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,2,0,],list[3,2,0,],], )
W0521 22:09:41.676155 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,2,0,],list[3,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:41.559109 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,2,1,0,],list[0,1,3,2,],], )
W0521 22:09:41.736044 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,2,1,0,],list[0,1,3,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:41.591393 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,2,1,],list[2,0,1,],], )
W0521 22:09:41.776965 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,2,1,],list[2,0,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:41.667707 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,2,],list[3,1,],], )
W0521 22:09:41.827657 72933 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,2,],list[3,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:41.676963 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[0,2,3,],list[0,1,2,],], )
W0521 22:09:41.978396 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[0,2,3,],list[0,1,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:41.736759 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[2,3,0,],list[1,2,0,],], )
W0521 22:09:41.920181 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[2,3,0,],list[1,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:41.746931 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[2,3,1,],list[1,0,2,],], )
W0521 22:09:42.018805 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[2,3,1,],list[1,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:41.777697 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[2,3,],list[1,3,],], )
W0521 22:09:41.912340 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[2,3,],list[1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:41.798804 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,0,2,1,],list[2,1,0,3,],], )
W0521 22:09:42.118429 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,0,2,1,],list[2,1,0,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:41.828416 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,0,],list[2,1,],], )
W0521 22:09:41.994933 72933 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,0,],list[2,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:41.913096 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,1,0,2,],list[2,3,1,0,],], )
W0521 22:09:42.331570 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,1,0,2,],list[2,3,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:41.920915 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,1,0,],list[3,2,1,],], )
W0521 22:09:42.046588 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,1,0,],list[3,2,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:41.979199 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,1,2,0,],list[2,3,1,0,],], )
W0521 22:09:42.099293 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,1,2,0,],list[2,3,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:41.995714 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,1,2,],list[0,3,2,],], )
W0521 22:09:42.581640 72933 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,1,2,],list[0,3,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:42.020076 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,1,2,],list[2,3,1,],], )
W0521 22:09:42.396538 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,1,2,],list[2,3,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:42.047387 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,2,0,],list[2,1,0,],], )
W0521 22:09:42.381969 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,2,0,],list[2,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:42.100100 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,2,0,],list[3,2,0,],], )
W0521 22:09:42.237901 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,2,0,],list[3,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:42.119970 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,2,1,0,],list[0,1,3,2,],], )
W0521 22:09:42.463529 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,2,1,0,],list[0,1,3,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:42.238870 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,2,],list[3,1,],], )
W0521 22:09:42.411309 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 1, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,2,],list[3,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:42.332391 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[0,3,1,2,],list[3,2,1,0,],], )
W0521 22:09:42.784878 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[0,3,1,2,],list[3,2,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 1, 0, 5, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:42.382754 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[1,0,3,],list[2,3,0,],], )
W0521 22:09:42.521122 72649 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[1,0,3,],list[2,3,0,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:42.397505 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[1,2,0,],list[1,2,3,],], )
W0521 22:09:42.783461 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[1,2,0,],list[1,2,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 1, 0, 1, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:42.412095 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[1,2,0,],list[1,3,2,],], )
W0521 22:09:42.558459 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[1,2,0,],list[1,3,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 0, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 5, 0, 1, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:42.465378 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[1,2,3,0,],list[1,3,0,2,],], )
W0521 22:09:42.808972 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[1,2,3,0,],list[1,3,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 0, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 5, 0, 1, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:42.521844 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[1,3,2,0,],list[1,3,2,0,],], )
W0521 22:09:42.784878 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[1,3,2,0,],list[1,3,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 1, 0, 1, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:42.559302 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[2,1,0,3,],list[3,1,2,0,],], )
W0521 22:09:42.695657 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[2,1,0,3,],list[3,1,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 0, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 5, 0, 1, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:42.582612 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[2,1,],list[0,2,],], )
W0521 22:09:43.201632 72933 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[2,1,],list[0,2,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:42.696318 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[3,0,],list[2,1,],], )
W0521 22:09:42.960812 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[3,0,],list[2,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 1, 0, 5, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:42.784705 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[3,1,0,2,],list[3,1,0,2,],], )
W0521 22:09:42.961333 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[3,1,0,2,],list[3,1,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 1, 0, 1, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:42.785924 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[3,2,0,],list[3,2,0,],], )
W0521 22:09:42.993160 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[3,2,0,],list[3,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 1, 0, 1, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:42.786071 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[3,2,1,],list[2,0,1,],], )
W0521 22:09:42.960801 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[3,2,1,],list[2,0,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 1, 0, 5, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:42.810328 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 5, 1, 5],"float64"), list[list[0,2,3,],list[0,1,2,],], )
W0521 22:09:42.973255 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 5, 1, 5],"float64"), list[list[0,2,3,],list[0,1,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 1, 0, 5, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:42.961787 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 5, 1, 5],"float64"), list[list[0,2,3,],list[0,2,1,],], )
W0521 22:09:43.590090 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 5, 1, 5],"float64"), list[list[0,2,3,],list[0,2,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 1, 0, 1, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:42.961916 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 5, 1, 5],"float64"), list[list[2,3,0,],list[1,2,0,],], )
W0521 22:09:43.590090 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 5, 1, 5],"float64"), list[list[2,3,0,],list[1,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 1, 0, 5, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:42.962356 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 5, 1, 5],"float64"), list[list[3,0,],list[2,1,],], )
W0521 22:09:43.430297 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 5, 1, 5],"float64"), list[list[3,0,],list[2,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 1, 0, 5, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:42.974546 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 5, 1, 5],"float64"), list[list[3,2,0,],list[2,1,0,],], )
W0521 22:09:43.558339 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 5, 1, 5],"float64"), list[list[3,2,0,],list[2,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 1, 0, 5, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:42.994033 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 5, 1, 5],"float64"), list[list[3,2,0,],list[3,2,0,],], )
W0521 22:09:43.504488 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 0, 5, 5],"float64"), Tensor([5, 5, 1, 5],"float64"), list[list[3,2,0,],list[3,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 1, 0, 1, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:43.025545 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[0,1,3,2,],list[0,2,1,3,],], )
W0521 22:09:43.327950 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[0,1,3,2,],list[0,2,1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 5, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:43.202621 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[0,1,3,2,],list[1,3,0,2,],], )
W0521 22:09:43.519533 72933 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[0,1,3,2,],list[1,3,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:43.323991 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[0,1,3,],list[0,3,1,],], )
W0521 22:09:43.503834 72543 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[0,1,3,],list[0,3,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 5, 0, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 1, 5, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:43.329099 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[0,2,3,],list[0,2,1,],], )
W0521 22:09:43.787204 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[0,2,3,],list[0,2,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 5, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:43.431511 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,0,3,2,],list[3,0,1,2,],], )
W0521 22:09:43.603353 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,0,3,2,],list[3,0,1,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 5, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:43.505043 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,0,3,],list[2,3,0,],], )
W0521 22:09:43.851419 72543 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,0,3,],list[2,3,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:43.505755 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,2,0,3,],list[0,2,1,3,],], )
W0521 22:09:43.837174 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,2,0,3,],list[0,2,1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:43.520835 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,2,0,],list[1,2,3,],], )
W0521 22:09:43.876212 72933 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,2,0,],list[1,2,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:43.559864 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,2,0,],list[1,3,2,],], )
W0521 22:09:44.042620 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,2,0,],list[1,3,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:43.591361 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,2,3,0,],list[1,3,0,2,],], )
W0521 22:09:43.919901 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,2,3,0,],list[1,3,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:43.591487 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,2,3,0,],list[3,2,1,0,],], )
W0521 22:09:43.916713 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,2,3,0,],list[3,2,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 5, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:43.604542 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,3,0,],list[3,0,2,],], )
W0521 22:09:43.927071 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,3,0,],list[3,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:43.788338 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,3,2,0,],list[1,3,2,0,],], )
W0521 22:09:44.050576 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,3,2,0,],list[1,3,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:43.838001 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,3,],list[1,0,],], )
W0521 22:09:44.025406 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,3,],list[1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:43.852313 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[2,0,1,],list[0,1,3,],], )
W0521 22:09:44.051138 72543 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[2,0,1,],list[0,1,3,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:43.876996 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[2,1,0,3,],list[2,0,1,3,],], )
W0521 22:09:44.246518 72933 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[2,1,0,3,],list[2,0,1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:43.917426 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[2,1,0,3,],list[2,0,3,1,],], )
W0521 22:09:44.036918 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[2,1,0,3,],list[2,0,3,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 5, 0, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 1, 5, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:43.920617 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[2,1,0,3,],list[3,1,2,0,],], )
W0521 22:09:44.042326 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[2,1,0,3,],list[3,1,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:43.927845 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[2,3,0,],list[3,1,0,],], )
W0521 22:09:44.191589 72516 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[2,3,0,],list[3,1,0,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:44.026095 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[3,1,0,2,],list[3,1,0,2,],], )
W0521 22:09:44.191790 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[3,1,0,2,],list[3,1,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:44.037599 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[3,1,0,],list[3,2,1,],], )
W0521 22:09:44.344895 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[3,1,0,],list[3,2,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:44.047787 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[3,1,2,],list[0,3,2,],], )
W0521 22:09:44.443629 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[3,1,2,],list[0,3,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:44.048124 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[3,1,2,],list[1,3,2,],], )
W0521 22:09:44.424793 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[3,1,2,],list[1,3,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 5, 0, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 1, 5, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:44.051982 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[3,1,2,],list[3,1,0,],], )
W0521 22:09:44.442888 72543 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[3,1,2,],list[3,1,0,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:44.054305 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[3,2,0,],list[3,2,0,],], )
W0521 22:09:44.528545 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[3,2,0,],list[3,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:44.193129 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[0,1,3,2,],list[1,3,0,2,],], )
W0521 22:09:44.424793 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[0,1,3,2,],list[1,3,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:44.193293 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[0,3,1,2,],list[3,2,1,0,],], )
W0521 22:09:44.471709 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[0,3,1,2,],list[3,2,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:44.247430 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[1,0,3,],list[2,3,0,],], )
W0521 22:09:44.471541 72933 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[1,0,3,],list[2,3,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:44.345659 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[1,3,0,],list[3,0,2,],], )
W0521 22:09:44.469336 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[1,3,0,],list[3,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:44.425916 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[1,3,2,0,],list[1,3,2,0,],], )
W0521 22:09:44.686570 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[1,3,2,0,],list[1,3,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:44.425988 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[1,3,],list[1,0,],], )
W0521 22:09:44.709753 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[1,3,],list[1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:44.443621 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,0,2,1,],list[2,1,0,3,],], )
W0521 22:09:44.655654 72543 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,0,2,1,],list[2,1,0,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:44.444393 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,0,],list[2,1,],], )
W0521 22:09:44.678393 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,0,],list[2,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:44.470024 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,1,0,2,],list[2,3,1,0,],], )
W0521 22:09:44.699546 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,1,0,2,],list[2,3,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:44.472428 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,1,0,2,],list[3,1,0,2,],], )
W0521 22:09:44.802744 72933 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,1,0,2,],list[3,1,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:44.472501 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,1,0,],list[3,2,1,],], )
W0521 22:09:44.760226 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,1,0,],list[3,2,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:44.529253 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,1,2,],list[0,3,2,],], )
W0521 22:09:44.722198 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,1,2,],list[0,3,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:44.656441 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,1,2,],list[3,1,0,],], )
W0521 22:09:44.801930 72543 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,1,2,],list[3,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:44.679267 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,2,0,],list[3,2,0,],], )
W0521 22:09:44.856357 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,2,0,],list[3,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:44.687775 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,2,1,],list[2,0,1,],], )
W0521 22:09:44.835989 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([1, 5, 1, 1],"float64"), list[list[3,2,1,],list[2,0,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:44.700343 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[0,1,3,2,],list[1,3,0,2,],], )
W0521 22:09:44.829254 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[0,1,3,2,],list[1,3,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 5, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:44.710559 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[0,1,3,],list[0,3,1,],], )
W0521 22:09:44.836618 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[0,1,3,],list[0,3,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 5, 0, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 1, 5, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:44.724910 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[0,2,3,],list[0,2,1,],], )
W0521 22:09:44.912604 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[0,2,3,],list[0,2,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 0, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 1, 5, 0, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:44.761085 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[1,0,3,2,],list[3,0,1,2,],], )
W0521 22:09:44.928031 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[1,0,3,2,],list[3,0,1,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 5, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:44.802711 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[1,2,0,3,],list[0,2,1,3,],], )
W0521 22:09:45.141499 72543 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[1,2,0,3,],list[0,2,1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 1, 1, 0, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:44.803957 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[1,2,0,],list[1,2,3,],], )
W0521 22:09:45.141532 72933 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[1,2,0,],list[1,2,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 5, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:44.834978 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[1,2,3,0,],list[3,2,1,0,],], )
W0521 22:09:45.140611 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[1,2,3,0,],list[3,2,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 5, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:44.837326 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[1,3,0,],list[3,0,2,],], )
W0521 22:09:45.140394 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[1,3,0,],list[3,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 5, 0, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 5, 5, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:44.841127 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[1,3,2,0,],list[1,3,2,0,],], )
W0521 22:09:45.141336 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[1,3,2,0,],list[1,3,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 1, 1, 0, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:44.858611 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[1,3,],list[1,0,],], )
W0521 22:09:44.978643 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[1,3,],list[1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 0, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 5, 1, 0, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:44.913455 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[2,1,0,3,],list[2,0,1,3,],], )
W0521 22:09:45.291601 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[2,1,0,3,],list[2,0,1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 1, 1, 0, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:44.928882 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[2,1,0,3,],list[2,0,3,1,],], )
W0521 22:09:45.291095 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[2,1,0,3,],list[2,0,3,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 5, 0, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 1, 5, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:44.979358 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[3,1,0,2,],list[3,1,0,2,],], )
W0521 22:09:45.525342 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[3,1,0,2,],list[3,1,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 1, 1, 0, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:45.141060 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[3,1,2,],list[0,3,2,],], )
W0521 22:09:45.525679 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[3,1,2,],list[0,3,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 5, 0, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 5, 5, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:45.141289 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[3,1,2,],list[1,3,2,],], )
W0521 22:09:45.527037 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[3,1,2,],list[1,3,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 5, 0, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 5, 5, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:45.142215 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[3,2,0,],list[3,2,0,],], )
W0521 22:09:45.680418 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[3,2,0,],list[3,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 0, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 1, 5, 0, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:45.142300 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 1, 5],"float64"), list[list[3,0,],list[2,1,],], )
W0521 22:09:45.527837 72543 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 0, 5],"float64"), Tensor([5, 5, 1, 5],"float64"), list[list[3,0,],list[2,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:45.142618 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[0,1,2,],list[2,0,1,],], )
W0521 22:09:45.703226 72933 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[0,1,2,],list[2,0,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:45.291984 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[0,1,3,2,],list[1,3,0,2,],], )
W0521 22:09:45.528337 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[0,1,3,2,],list[1,3,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:45.292577 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[0,1,3,2,],list[2,3,0,1,],], )
W0521 22:09:45.528098 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[0,1,3,2,],list[2,3,0,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 5, 0, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 1, 5, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:45.526132 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[0,2,3,],list[0,1,2,],], )
W0521 22:09:46.156198 72649 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[0,2,3,],list[0,1,2,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:45.526943 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[1,0,3,2,],list[2,3,0,1,],], )
W0521 22:09:46.010097 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[1,0,3,2,],list[2,3,0,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 5, 0, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 1, 5, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:45.527757 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[1,0,3,],list[2,3,0,],], )
W0521 22:09:46.008663 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[1,0,3,],list[2,3,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 5, 0, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 1, 5, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:45.528560 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[1,2,0,3,],list[0,2,1,3,],], )
W0521 22:09:46.008422 72543 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[1,2,0,3,],list[0,2,1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:45.529615 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[1,2,0,],list[1,2,3,],], )
W0521 22:09:46.010255 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[1,2,0,],list[1,2,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:45.529810 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[1,2,0,],list[1,3,2,],], )
W0521 22:09:45.856109 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[1,2,0,],list[1,3,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:45.681413 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[1,2,3,0,],list[1,3,0,2,],], )
W0521 22:09:46.157737 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[1,2,3,0,],list[1,3,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:45.704149 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[1,3,2,0,],list[1,3,2,0,],], )
W0521 22:09:46.178195 72933 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[1,3,2,0,],list[1,3,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:45.856937 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[1,3,],list[1,0,],], )
W0521 22:09:46.346885 72621 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[1,3,],list[1,0,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:46.010018 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[2,0,1,],list[0,1,3,],], )
W0521 22:09:46.452261 72543 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[2,0,1,],list[0,1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:46.010923 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[2,1,0,3,],list[2,0,1,3,],], )
W0521 22:09:46.459918 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[2,1,0,3,],list[2,0,1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:46.012050 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[2,1,],list[0,2,],], )
W0521 22:09:46.469915 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[2,1,],list[0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 5, 0, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 1, 5, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:46.012700 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[2,3,0,],list[1,2,0,],], )
W0521 22:09:46.346419 72568 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[2,3,0,],list[1,2,0,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:46.156947 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[2,3,1,],list[1,0,2,],], )
W0521 22:09:46.346532 72649 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[2,3,1,],list[1,0,2,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:46.158938 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[2,3,],list[1,3,],], )
W0521 22:09:46.346016 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[2,3,],list[1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:46.179018 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,0,2,1,],list[2,1,0,3,],], )
W0521 22:09:46.558300 72933 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,0,2,1,],list[2,1,0,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:46.347116 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,0,],list[2,1,],], )
W0521 22:09:46.578822 72813 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,0,],list[2,1,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:46.347573 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,1,0,2,],list[3,1,0,2,],], )
W0521 22:09:46.489081 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,1,0,2,],list[3,1,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:46.347667 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,1,0,],list[3,2,1,],], )
W0521 22:09:46.477458 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,1,0,],list[3,2,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:46.347902 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,1,2,],list[3,1,0,],], )
W0521 22:09:46.504004 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,1,2,],list[3,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:46.453555 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,2,0,],list[2,1,0,],], )
W0521 22:09:46.618522 72543 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,2,0,],list[2,1,0,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:46.461085 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,2,0,],list[3,2,0,],], )
W0521 22:09:46.633170 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,2,0,],list[3,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 5, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:46.471112 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,2,1,0,],list[0,1,3,2,],], )
W0521 22:09:46.642814 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,2,1,0,],list[0,1,3,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:46.478461 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,2,1,],list[2,0,1,],], )
W0521 22:09:46.662901 72649 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,2,1,],list[2,0,1,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:46.490922 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,2,],list[3,1,],], )
W0521 22:09:46.620344 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 0],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,2,],list[3,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:46.505259 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[0,1,2,],list[2,0,1,],], )
W0521 22:09:46.642414 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[0,1,2,],list[2,0,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 1, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 0, 5, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:46.559626 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[0,3,1,2,],list[3,2,1,0,],], )
W0521 22:09:46.741544 72933 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[0,3,1,2,],list[3,2,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:46.579919 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[0,3,2,1,],list[2,1,3,0,],], )
W0521 22:09:46.743206 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[0,3,2,1,],list[2,1,3,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 1, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 0, 5, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:46.619533 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[1,0,2,3,],list[3,0,1,2,],], )
W0521 22:09:46.788880 72543 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[1,0,2,3,],list[3,0,1,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 1, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 0, 5, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:46.621256 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[1,0,3,2,],list[3,0,1,2,],], )
W0521 22:09:46.754145 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[1,0,3,2,],list[3,0,1,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 1, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 0, 5, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:46.634259 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[1,2,0,],list[1,2,3,],], )
W0521 22:09:46.807991 72626 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[1,2,0,],list[1,2,3,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:46.647135 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[1,2,0,],list[1,3,2,],], )
W0521 22:09:46.792263 72516 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[1,2,0,],list[1,3,2,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:46.648613 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[1,2,3,0,],list[3,2,1,0,],], )
W0521 22:09:46.823724 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[1,2,3,0,],list[3,2,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 1, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 0, 5, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:46.664035 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[1,3,2,0,],list[1,3,2,0,],], )
W0521 22:09:46.861281 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[1,3,2,0,],list[1,3,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:46.742728 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[1,3,2,0,],list[2,1,0,3,],], )
W0521 22:09:46.999326 72933 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[1,3,2,0,],list[2,1,0,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 1, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 0, 5, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:46.744465 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[2,0,1,3,],list[3,1,0,2,],], )
W0521 22:09:46.939498 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[2,0,1,3,],list[3,1,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:46.756030 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[2,1,0,3,],list[2,0,1,3,],], )
W0521 22:09:46.900228 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[2,1,0,3,],list[2,0,1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 1, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 0, 5, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:46.789998 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[2,1,0,3,],list[2,0,3,1,],], )
W0521 22:09:46.926872 72543 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[2,1,0,3,],list[2,0,3,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 1, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 0, 5, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:46.793154 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[2,3,0,],list[1,2,0,],], )
W0521 22:09:46.931975 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[2,3,0,],list[1,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:46.809130 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[2,3,0,],list[3,1,0,],], )
W0521 22:09:46.980178 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[2,3,0,],list[3,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 1, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 0, 5, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:46.824812 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[2,3,],list[1,3,],], )
W0521 22:09:46.981268 72621 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[2,3,],list[1,3,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:46.864096 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,0,2,1,],list[2,1,0,3,],], )
W0521 22:09:47.028954 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,0,2,1,],list[2,1,0,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:46.901433 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,0,],list[2,1,],], )
W0521 22:09:47.039530 72568 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,0,],list[2,1,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:46.928010 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,1,0,2,],list[2,3,1,0,],], )
W0521 22:09:47.106868 72543 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,1,0,2,],list[2,3,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:46.932999 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,1,0,2,],list[3,1,0,2,],], )
W0521 22:09:47.096706 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,1,0,2,],list[3,1,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:46.943319 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,1,0,],list[3,2,1,],], )
W0521 22:09:47.083364 72813 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,1,0,],list[3,2,1,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:46.981630 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,1,2,0,],list[1,2,3,0,],], )
W0521 22:09:47.118599 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,1,2,0,],list[1,2,3,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 1, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 0, 5, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:46.982226 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,1,2,0,],list[2,3,1,0,],], )
W0521 22:09:47.146281 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,1,2,0,],list[2,3,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:47.001932 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,1,2,],list[1,2,3,],], )
W0521 22:09:47.182109 72933 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,1,2,],list[1,2,3,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:47.030621 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,1,2,],list[1,3,2,],], )
W0521 22:09:47.208019 72649 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,1,2,],list[1,3,2,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:47.040591 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,1,2,],list[2,3,1,],], )
W0521 22:09:47.174206 72568 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,1,2,],list[2,3,1,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:47.084312 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,1,2,],list[3,1,0,],], )
W0521 22:09:47.244447 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,1,2,],list[3,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:47.097625 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,2,0,],list[2,1,0,],], )
W0521 22:09:47.232153 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,2,0,],list[2,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 0, 1, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:47.109028 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,2,0,],list[3,2,0,],], )
W0521 22:09:47.292538 72543 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,2,0,],list[3,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 1, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 0, 5, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:47.119765 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,2,],list[3,1,],], )
W0521 22:09:47.253926 72626 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([0, 5, 1, 1],"float64"), list[list[3,2,],list[3,1,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:47.148918 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[0,1,2,],list[2,0,1,],], )
W0521 22:09:47.304383 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[0,1,2,],list[2,0,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:47.175052 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[0,1,3,2,],list[2,3,0,1,],], )
W0521 22:09:47.309266 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[0,1,3,2,],list[2,3,0,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:47.183338 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[0,2,3,],list[0,1,2,],], )
W0521 22:09:47.411216 72933 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[0,2,3,],list[0,1,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:47.209280 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[0,3,1,2,],list[3,2,1,0,],], )
W0521 22:09:47.372516 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[0,3,1,2,],list[3,2,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:47.233841 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[1,0,2,3,],list[3,0,1,2,],], )
W0521 22:09:47.371706 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[1,0,2,3,],list[3,0,1,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:47.246454 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[1,0,3,2,],list[2,3,0,1,],], )
W0521 22:09:47.399262 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[1,0,3,2,],list[2,3,0,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:47.254851 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[1,0,3,],list[2,3,0,],], )
W0521 22:09:47.387137 72626 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[1,0,3,],list[2,3,0,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:47.293959 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[1,2,0,3,],list[0,2,1,3,],], )
W0521 22:09:47.445140 72543 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[1,2,0,3,],list[0,2,1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:47.306436 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[1,3,0,],list[3,0,2,],], )
W0521 22:09:47.462484 72621 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[1,3,0,],list[3,0,2,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:47.310758 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[1,3,2,0,],list[3,0,1,2,],], )
W0521 22:09:47.546361 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[1,3,2,0,],list[3,0,1,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:47.372568 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[2,0,1,3,],list[3,1,0,2,],], )
W0521 22:09:47.498798 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[2,0,1,3,],list[3,1,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:47.373463 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[2,0,1,],list[0,1,3,],], )
W0521 22:09:47.529764 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[2,0,1,],list[0,1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:47.387994 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[2,1,0,3,],list[2,0,1,3,],], )
W0521 22:09:47.526300 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[2,1,0,3,],list[2,0,1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:47.401757 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[2,1,0,3,],list[3,1,2,0,],], )
W0521 22:09:47.550345 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[2,1,0,3,],list[3,1,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:47.412999 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[2,1,],list[0,2,],], )
W0521 22:09:47.593462 72933 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[2,1,],list[0,2,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:47.446007 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,1,0,2,],list[2,3,1,0,],], )
W0521 22:09:47.602145 72543 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,1,0,2,],list[2,3,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:47.463454 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,1,0,],list[3,2,1,],], )
W0521 22:09:47.620844 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,1,0,],list[3,2,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:47.499704 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,1,2,0,],list[2,3,1,0,],], )
W0521 22:09:47.636526 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,1,2,0,],list[2,3,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:47.527311 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,1,2,],list[0,3,2,],], )
W0521 22:09:47.671737 72626 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,1,2,],list[0,3,2,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:47.530651 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,1,2,],list[2,3,1,],], )
W0521 22:09:47.691447 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,1,2,],list[2,3,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:47.547724 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,2,0,],list[3,2,0,],], )
W0521 22:09:47.913312 72568 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,2,0,],list[3,2,0,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:47.551361 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,2,1,],list[2,0,1,],], )
W0521 22:09:47.688584 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 0, 1, 1],"float64"), list[list[3,2,1,],list[2,0,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:47.594399 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[0,1,3,2,],list[0,2,1,3,],], )
W0521 22:09:47.912309 72933 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[0,1,3,2,],list[0,2,1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 5, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:47.603448 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[0,1,3,2,],list[1,3,0,2,],], )
W0521 22:09:47.732438 72543 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[0,1,3,2,],list[1,3,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:47.621809 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[0,1,3,],list[0,3,1,],], )
W0521 22:09:47.910077 72621 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[0,1,3,],list[0,3,1,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:47.638107 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[0,2,3,],list[0,2,1,],], )
W0521 22:09:48.082224 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[0,2,3,],list[0,2,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 5, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:47.673025 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,0,3,2,],list[3,0,1,2,],], )
W0521 22:09:47.914403 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,0,3,2,],list[3,0,1,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 5, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:47.689568 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,2,0,3,],list[0,2,1,3,],], )
W0521 22:09:48.082643 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,2,0,3,],list[0,2,1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 5, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:47.693100 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,2,0,],list[1,2,3,],], )
W0521 22:09:47.914513 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,2,0,],list[1,2,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:47.733515 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,2,0,],list[1,3,2,],], )
W0521 22:09:48.294603 72543 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,2,0,],list[1,3,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:47.911086 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,2,3,0,],list[1,3,0,2,],], )
W0521 22:09:48.283659 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,2,3,0,],list[1,3,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:47.913651 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,2,3,0,],list[3,2,1,0,],], )
W0521 22:09:48.316546 72933 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,2,3,0,],list[3,2,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 5, 0, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 1, 5, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:47.914530 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,3,0,],list[3,0,2,],], )
W0521 22:09:48.111244 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,3,0,],list[3,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 5, 0, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 1, 5, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:47.915127 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,3,2,0,],list[1,3,2,0,],], )
W0521 22:09:48.318977 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,3,2,0,],list[1,3,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:47.915497 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,3,2,0,],list[3,0,1,2,],], )
W0521 22:09:48.282435 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,3,2,0,],list[3,0,1,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:48.083293 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,3,],list[1,0,],], )
W0521 22:09:48.319494 72516 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[1,3,],list[1,0,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:48.083557 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[2,0,1,],list[0,1,3,],], )
W0521 22:09:48.320576 72813 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[2,0,1,],list[0,1,3,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:48.112111 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[2,1,0,3,],list[3,1,2,0,],], )
W0521 22:09:48.325531 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[2,1,0,3,],list[3,1,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:48.283153 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[2,1,],list[0,2,],], )
W0521 22:09:48.516600 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[2,1,],list[0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 5, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:48.284326 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[2,3,0,],list[3,1,0,],], )
W0521 22:09:48.516287 72621 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[2,3,0,],list[3,1,0,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:48.295348 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[2,3,1,],list[1,0,2,],], )
W0521 22:09:48.518923 72543 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[2,3,1,],list[1,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:48.318499 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[2,3,],list[1,3,],], )
W0521 22:09:48.510711 72933 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[2,3,],list[1,3,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:48.320112 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[3,1,0,2,],list[3,1,0,2,],], )
W0521 22:09:48.516948 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[3,1,0,2,],list[3,1,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:48.320518 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[3,1,2,],list[0,3,2,],], )
W0521 22:09:48.518083 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[3,1,2,],list[0,3,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 5, 0, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 1, 5, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:48.321461 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[3,1,2,],list[1,3,2,],], )
W0521 22:09:48.517163 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[3,1,2,],list[1,3,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 5, 0, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 1, 5, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:48.326585 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[3,1,2,],list[3,1,0,],], )
W0521 22:09:48.518883 72568 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[3,1,2,],list[3,1,0,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:48.511572 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[3,2,1,0,],list[0,1,3,2,],], )
W0521 22:09:49.035043 72933 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[3,2,1,0,],list[0,1,3,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:48.517224 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[3,2,],list[3,1,],], )
W0521 22:09:49.216477 72621 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 0, 1],"float64"), list[list[3,2,],list[3,1,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:48.519003 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[0,1,2,],list[2,0,1,],], )
W0521 22:09:48.870805 72649 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[0,1,2,],list[2,0,1,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:48.520004 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[0,1,3,2,],list[0,2,1,3,],], )
W0521 22:09:48.870446 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[0,1,3,2,],list[0,2,1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 5, 0, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 1, 5, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:48.520170 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[0,1,3,2,],list[1,3,0,2,],], )
W0521 22:09:49.034914 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[0,1,3,2,],list[1,3,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:48.520287 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[0,1,3,2,],list[2,3,0,1,],], )
W0521 22:09:48.871472 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[0,1,3,2,],list[2,3,0,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 5, 0, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 1, 5, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:48.520947 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[0,1,3,],list[0,3,1,],], )
W0521 22:09:48.870258 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[0,1,3,],list[0,3,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 5, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:48.521446 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[0,2,3,],list[0,1,2,],], )
W0521 22:09:48.870466 72543 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[0,2,3,],list[0,1,2,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:48.871153 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[0,2,3,],list[0,2,1,],], )
W0521 22:09:49.325891 72543 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[0,2,3,],list[0,2,1,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:48.871454 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[0,3,2,1,],list[2,1,3,0,],], )
W0521 22:09:49.255842 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[0,3,2,1,],list[2,1,3,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 5, 0, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 1, 5, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:48.871720 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[1,0,3,2,],list[2,3,0,1,],], )
W0521 22:09:49.433806 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[1,0,3,2,],list[2,3,0,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 5, 0, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 1, 5, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:48.871907 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[1,0,3,],list[2,3,0,],], )
W0521 22:09:49.421392 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[1,0,3,],list[2,3,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 5, 0, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 1, 5, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:48.872528 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[1,2,0,],list[1,2,3,],], )
W0521 22:09:49.327844 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[1,2,0,],list[1,2,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:49.035693 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[1,2,0,],list[1,3,2,],], )
W0521 22:09:49.388155 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[1,2,0,],list[1,3,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:49.035902 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[1,2,3,0,],list[1,3,0,2,],], )
W0521 22:09:49.375535 72933 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[1,2,3,0,],list[1,3,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:49.217984 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[1,3,2,0,],list[2,1,0,3,],], )
W0521 22:09:49.344646 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[1,3,2,0,],list[2,1,0,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 5, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:49.257865 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[1,3,],list[1,0,],], )
W0521 22:09:49.433300 72649 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[1,3,],list[1,0,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:49.326638 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[2,0,1,],list[0,1,3,],], )
W0521 22:09:49.488782 72543 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[2,0,1,],list[0,1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:49.329493 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[2,1,0,3,],list[2,0,3,1,],], )
W0521 22:09:49.507948 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[2,1,0,3,],list[2,0,3,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 5, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:49.345637 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[2,1,],list[0,2,],], )
W0521 22:09:49.483278 72621 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[2,1,],list[0,2,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:49.376330 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[2,3,0,],list[1,2,0,],], )
W0521 22:09:49.556595 72933 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[2,3,0,],list[1,2,0,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:49.389070 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[2,3,1,],list[1,0,2,],], )
W0521 22:09:49.583248 72813 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[2,3,1,],list[1,0,2,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:49.422412 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,0,2,1,],list[2,1,0,3,],], )
W0521 22:09:49.556911 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,0,2,1,],list[2,1,0,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:49.434117 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,0,],list[2,1,],], )
W0521 22:09:49.560168 72649 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,0,],list[2,1,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:49.434926 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,1,2,0,],list[1,2,3,0,],], )
W0521 22:09:49.571169 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,1,2,0,],list[1,2,3,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 5, 0, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 1, 5, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:49.484074 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,1,2,],list[1,2,3,],], )
W0521 22:09:49.617890 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,1,2,],list[1,2,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 5, 0, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 1, 5, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:49.491642 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,2,0,],list[2,1,0,],], )
W0521 22:09:49.622560 72543 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,2,0,],list[2,1,0,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:49.509134 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,2,1,0,],list[0,1,3,2,],], )
W0521 22:09:49.682232 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,2,1,0,],list[0,1,3,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:49.557361 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,2,1,],list[2,0,1,],], )
W0521 22:09:49.739972 72933 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 1, 5],"float64"), Tensor([1, 5, 1, 0],"float64"), list[list[3,2,1,],list[2,0,1,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:49.557700 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[0,1,2,],list[2,0,1,],], )
W0521 22:09:49.676667 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[0,1,2,],list[2,0,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 5, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:49.560879 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[0,2,3,],list[0,1,2,],], )
W0521 22:09:49.683059 72649 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[0,2,3,],list[0,1,2,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:49.572205 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[1,2,0,3,],list[0,2,1,3,],], )
W0521 22:09:49.788854 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[1,2,0,3,],list[0,2,1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:49.584067 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[1,2,0,],list[1,2,3,],], )
W0521 22:09:49.772735 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[1,2,0,],list[1,2,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:49.618610 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[1,3,2,0,],list[1,3,2,0,],], )
W0521 22:09:49.734930 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[1,3,2,0,],list[1,3,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:49.623309 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[2,0,1,],list[0,1,3,],], )
W0521 22:09:49.787704 72543 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[2,0,1,],list[0,1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 5, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:49.677468 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[2,1,0,3,],list[2,0,1,3,],], )
W0521 22:09:49.821707 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[2,1,0,3,],list[2,0,1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:49.682995 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[2,1,],list[0,2,],], )
W0521 22:09:49.797410 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[2,1,],list[0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 5, 0, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 5, 5, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:49.683799 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[2,3,0,],list[1,2,0,],], )
W0521 22:09:49.828629 72649 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[2,3,0,],list[1,2,0,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:49.735721 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[3,0,2,1,],list[2,1,0,3,],], )
W0521 22:09:49.910176 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[3,0,2,1,],list[2,1,0,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 5, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:49.740770 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[3,0,],list[2,1,],], )
W0521 22:09:50.004539 72933 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[3,0,],list[2,1,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:49.773715 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[3,1,0,2,],list[3,1,0,2,],], )
W0521 22:09:49.973032 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[3,1,0,2,],list[3,1,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:49.788566 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[3,1,0,],list[3,2,1,],], )
W0521 22:09:49.985464 72543 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[3,1,0,],list[3,2,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 5, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:49.789621 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[3,1,2,],list[3,1,0,],], )
W0521 22:09:49.971534 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[3,1,2,],list[3,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 5, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:49.798047 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[3,2,0,],list[2,1,0,],], )
W0521 22:09:49.915000 72626 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[3,2,0,],list[2,1,0,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:49.822484 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[3,2,0,],list[3,2,0,],], )
W0521 22:09:50.014257 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[3,2,0,],list[3,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:49.829333 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[3,2,1,],list[2,0,1,],], )
W0521 22:09:49.999965 72649 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[3,2,1,],list[2,0,1,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:49.910997 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 5],"float64"), list[list[1,2,0,],list[1,2,3,],], )
W0521 22:09:50.050282 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 0],"float64"), Tensor([5, 5, 1, 5],"float64"), list[list[1,2,0,],list[1,2,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 1, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:49.915703 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[0,1,2,],list[2,0,1,],], )
W0521 22:09:50.045619 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[0,1,2,],list[2,0,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 5, Tensor layout is NCHW, Tensor stride is 25, 5, 1. New dims is 0, 5, 1, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:49.973589 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[0,3,2,1,],list[2,1,3,0,],], )
W0521 22:09:50.124468 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[0,3,2,1,],list[2,1,3,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 5, Tensor layout is NCHW, Tensor stride is 25, 5, 1. New dims is 0, 5, 1, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:49.974633 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[1,0,2,3,],list[3,0,1,2,],], )
W0521 22:09:50.208161 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[1,0,2,3,],list[3,0,1,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 1, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 0, 5, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:49.986204 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[1,0,3,2,],list[3,0,1,2,],], )
W0521 22:09:50.135798 72543 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[1,0,3,2,],list[3,0,1,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 1, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 0, 5, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:50.000888 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[1,2,0,],list[1,2,3,],], )
W0521 22:09:50.139871 72649 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[1,2,0,],list[1,2,3,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:50.005310 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[1,2,0,],list[1,3,2,],], )
W0521 22:09:50.228394 72933 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[1,2,0,],list[1,3,2,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:50.016159 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[1,2,3,0,],list[3,2,1,0,],], )
W0521 22:09:50.152230 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[1,2,3,0,],list[3,2,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 1, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 0, 5, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:50.046436 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[1,3,2,0,],list[1,3,2,0,],], )
W0521 22:09:50.179363 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[1,3,2,0,],list[1,3,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 0, 1, 1, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:50.051189 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[2,0,1,3,],list[3,1,0,2,],], )
W0521 22:09:50.209914 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[2,0,1,3,],list[3,1,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 0, 1, 1, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:50.125592 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[2,3,],list[1,3,],], )
W0521 22:09:50.269133 72516 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[2,3,],list[1,3,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:50.137077 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,0,],list[2,1,],], )
W0521 22:09:50.275709 72543 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,0,],list[2,1,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:50.140633 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,1,0,2,],list[3,1,0,2,],], )
W0521 22:09:50.290777 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,1,0,2,],list[3,1,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 0, 1, 1, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:50.153064 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,1,0,],list[3,2,1,],], )
W0521 22:09:50.381740 72568 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,1,0,],list[3,2,1,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:50.180309 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,1,2,0,],list[1,2,3,0,],], )
W0521 22:09:50.333271 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,1,2,0,],list[1,2,3,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 5, Tensor layout is NCHW, Tensor stride is 25, 5, 1. New dims is 0, 5, 1, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:50.209061 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,1,2,0,],list[2,3,1,0,],], )
W0521 22:09:50.349892 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,1,2,0,],list[2,3,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 5, 1, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 0, 5, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:50.210674 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,1,2,],list[1,2,3,],], )
W0521 22:09:50.431993 72621 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,1,2,],list[1,2,3,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:50.229142 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,1,2,],list[1,3,2,],], )
W0521 22:09:50.490362 72933 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,1,2,],list[1,3,2,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:50.269899 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,1,2,],list[2,3,1,],], )
W0521 22:09:50.393441 72516 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,1,2,],list[2,3,1,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:50.276528 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,2,],list[3,1,],], )
W0521 22:09:50.402803 72543 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,2,],list[3,1,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:50.291624 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[0,3,1,2,],list[3,2,1,0,],], )
W0521 22:09:50.439066 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[0,3,1,2,],list[3,2,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 5, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:50.334088 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[1,0,3,],list[2,3,0,],], )
W0521 22:09:50.458705 72626 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[1,0,3,],list[2,3,0,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:50.351334 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[1,2,0,3,],list[0,2,1,3,],], )
W0521 22:09:50.518581 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[1,2,0,3,],list[0,2,1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 1, 0, 1, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:50.382520 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[1,3,0,],list[3,0,2,],], )
W0521 22:09:50.542905 72568 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[1,3,0,],list[3,0,2,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:50.394194 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[2,1,0,3,],list[2,0,1,3,],], )
W0521 22:09:50.519182 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[2,1,0,3,],list[2,0,1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 0, 1, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 1, 0, 1, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:50.403678 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[2,1,],list[0,2,],], )
W0521 22:09:50.550793 72543 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[2,1,],list[0,2,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:50.432804 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[3,1,0,2,],list[2,3,1,0,],], )
W0521 22:09:50.745363 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[3,1,0,2,],list[2,3,1,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 0, 1, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 5, 0, 1, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:50.440210 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[3,1,0,],list[3,2,1,],], )
W0521 22:09:50.588315 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[3,1,0,],list[3,2,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 0, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 5, 0, 1, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:50.459470 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[3,1,2,],list[0,3,2,],], )
W0521 22:09:50.614027 72626 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[3,1,2,],list[0,3,2,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:50.491175 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[3,2,0,],list[3,2,0,],], )
W0521 22:09:50.743786 72933 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 0, 1, 5],"float64"), list[list[3,2,0,],list[3,2,0,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:50.519303 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[0,1,3,2,],list[0,2,1,3,],], )
W0521 22:09:50.645653 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[0,1,3,2,],list[0,2,1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 0, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 1, 5, 0, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:50.520009 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[0,1,3,],list[0,3,1,],], )
W0521 22:09:50.646298 72516 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[0,1,3,],list[0,3,1,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:50.543724 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[1,2,0,],list[1,3,2,],], )
W0521 22:09:50.673923 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[1,2,0,],list[1,3,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 0, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 5, 1, 0, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:50.551534 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[1,2,3,0,],list[1,3,0,2,],], )
W0521 22:09:50.720168 72543 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[1,2,3,0,],list[1,3,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 0, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 5, 1, 0, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:50.589135 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[1,3,0,],list[3,0,2,],], )
W0521 22:09:50.720139 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[1,3,0,],list[3,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 5, 0, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 5, 5, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:50.614811 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[1,3,2,0,],list[3,0,1,2,],], )
W0521 22:09:50.801751 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[1,3,2,0,],list[3,0,1,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 5, 0, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 5, 5, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:50.646761 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[1,3,],list[1,0,],], )
W0521 22:09:50.773128 72813 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[1,3,],list[1,0,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:50.647219 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[2,0,1,],list[0,1,3,],], )
W0521 22:09:50.810689 72516 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[2,0,1,],list[0,1,3,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:50.674830 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[2,1,0,3,],list[3,1,2,0,],], )
W0521 22:09:50.802340 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[2,1,0,3,],list[3,1,2,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 0, 5, Tensor layout is NCHW, Tensor stride is 5, 5, 1. New dims is 5, 1, 0, 5.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:50.720951 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[2,3,0,],list[3,1,0,],], )
W0521 22:09:50.859687 72649 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[2,3,0,],list[3,1,0,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:50.721039 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[2,3,],list[1,3,],], )
W0521 22:09:50.868031 72543 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[2,3,],list[1,3,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:50.744539 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[3,1,2,],list[3,1,0,],], )
W0521 22:09:50.938585 72933 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[3,1,2,],list[3,1,0,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:50.747365 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[3,2,1,0,],list[0,1,3,2,],], )
W0521 22:09:51.022980 72621 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[3,2,1,0,],list[0,1,3,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 5, 0, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 5, 5, 0, 1.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:50.773851 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[3,2,],list[3,1,],], )
W0521 22:09:50.932274 72813 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[3,2,],list[3,1,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:50.805330 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[0,1,2,],list[2,0,1,],], )
W0521 22:09:50.969326 72626 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[0,1,2,],list[2,0,1,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:50.806294 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[0,1,3,2,],list[1,3,0,2,],], )
W0521 22:09:50.945739 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[0,1,3,2,],list[1,3,0,2,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 5, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:50.811489 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[0,1,3,2,],list[2,3,0,1,],], )
W0521 22:09:50.977916 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[0,1,3,2,],list[2,3,0,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 5, 0, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 5, 5, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:50.860438 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[0,1,3,],list[0,3,1,],], )
W0521 22:09:51.192996 72649 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[0,1,3,],list[0,3,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 5, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:50.868775 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[0,2,3,],list[0,1,2,],], )
W0521 22:09:51.047894 72543 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[0,2,3,],list[0,1,2,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:50.932985 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[0,2,3,],list[0,2,1,],], )
W0521 22:09:51.182458 72813 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[0,2,3,],list[0,2,1,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:50.939295 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[1,0,3,2,],list[2,3,0,1,],], )
W0521 22:09:51.099821 72933 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[1,0,3,2,],list[2,3,0,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 5, 0, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 5, 5, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:50.946534 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[1,0,3,],list[2,3,0,],], )
W0521 22:09:51.099697 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[1,0,3,],list[2,3,0,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 5, 0, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 5, 5, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:50.970405 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[1,2,0,],list[1,2,3,],], )
W0521 22:09:51.125093 72626 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[1,2,0,],list[1,2,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 5, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:50.979827 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[1,3,2,0,],list[2,1,0,3,],], )
W0521 22:09:51.125093 72516 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[1,3,2,0,],list[2,1,0,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 5, 0, Tensor layout is NCHW, Tensor stride is 5, 1, 1. New dims is 5, 5, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:51.024038 GPU 1 72621 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[1,3,],list[1,0,],], )
W0521 22:09:51.269310 72621 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[1,3,],list[1,0,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.048852 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[2,0,1,],list[0,1,3,],], )
W0521 22:09:51.210160 72543 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[2,0,1,],list[0,1,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 5, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:51.100429 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[2,1,0,3,],list[2,0,3,1,],], )
W0521 22:09:51.234444 72568 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[2,1,0,3,],list[2,0,3,1,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 1, 5, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:51.100678 GPU 1 72933 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[2,1,],list[0,2,],], )
W0521 22:09:51.260895 72933 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[2,1,],list[0,2,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.126059 GPU 1 72626 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[2,3,0,],list[1,2,0,],], )
W0521 22:09:51.248224 72626 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[2,3,0,],list[1,2,0,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.126906 GPU 1 72516 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[2,3,1,],list[1,0,2,],], )
W0521 22:09:51.313028 72516 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[2,3,1,],list[1,0,2,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.183234 GPU 1 72813 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[3,0,2,1,],list[2,1,0,3,],], )
W0521 22:09:51.342173 72813 backward.cc:437] While running Node (SumGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[3,0,2,1,],list[2,1,0,3,],], ) 
 (InvalidArgument) Right now Resize is only supported for contiguous Tensor. Tensor dims is 5, 1, 0, Tensor layout is NCHW, Tensor stride is 1, 1, 1. New dims is 5, 1, 1, 0.
  [Hint: Expected meta_.is_contiguous() == true, but received meta_.is_contiguous():0 != true:1.] (at ../paddle/phi/core/dense_tensor_impl.cc:283)


2025-05-21 22:09:51.193872 GPU 1 72649 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[3,0,],list[2,1,],], )
W0521 22:09:51.418218 72649 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[3,0,],list[2,1,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.211007 GPU 1 72543 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[3,2,0,],list[2,1,0,],], )
W0521 22:09:51.329461 72543 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[3,2,0,],list[2,1,0,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.235249 GPU 1 72568 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[3,2,1,],list[2,0,1,],], )
W0521 22:09:51.379012 72568 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 1, 0],"float64"), list[list[3,2,1,],list[2,0,1,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.248982 GPU 1 72626 test begin: paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([0, 4, 5],"float32"), 0, )
W0521 22:09:51.370100 72626 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([0, 4, 5],"float32"), 0, ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:40)

 ** On entry to SGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.261716 GPU 1 72933 test begin: paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 0, 5],"float32"), 0, )
W0521 22:09:51.466625 72933 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 0, 5],"float32"), 0, ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:40)

 ** On entry to SGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.270143 GPU 1 72621 test begin: paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 0, 5],"float32"), 1, )
W0521 22:09:51.449615 72621 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 0, 5],"float32"), 1, ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:40)

 ** On entry to SGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.313947 GPU 1 72516 test begin: paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 4, 0],"float32"), 0, )
W0521 22:09:51.475726 72516 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 4, 0],"float32"), 0, ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:40)

 ** On entry to SGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.330195 GPU 1 72543 test begin: paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 4, 0],"float32"), 1, )
W0521 22:09:51.453691 72543 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 4, 0],"float32"), 1, ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:40)

 ** On entry to SGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.342940 GPU 1 72813 test begin: paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 4, 0],"float32"), 2, )
W0521 22:09:51.462942 72813 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 4, 0],"float32"), 2, ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:40)

 ** On entry to SGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.370844 GPU 1 72626 test begin: paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 4, 0],"float32"), list[list[1,2,],list[0,1,],], )
W0521 22:09:51.494181 72626 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 4, 0],"float32"), list[list[1,2,],list[0,1,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:40)

 ** On entry to SGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.379852 GPU 1 72568 test begin: paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 4, 0],"float32"), tuple(list[1,2,],list[0,1,],), )
W0521 22:09:51.502740 72568 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 4, 0],"float32"), tuple(list[1,2,],list[0,1,],), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:40)

 ** On entry to SGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.419043 GPU 1 72649 test begin: paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 4, 0],"float32"), tuple(tuple(1,2,),tuple(0,1,),), )
W0521 22:09:51.589985 72649 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 4, 0],"float32"), tuple(tuple(1,2,),tuple(0,1,),), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:40)

 ** On entry to SGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.450325 GPU 1 72621 test begin: paddle.tensordot(Tensor([3, 4, 4],"float64"), Tensor([0, 4, 5],"float64"), 0, )
W0521 22:09:51.578481 72621 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([3, 4, 4],"float64"), Tensor([0, 4, 5],"float64"), 0, ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.454494 GPU 1 72543 test begin: paddle.tensordot(Tensor([3, 4, 4],"float64"), Tensor([4, 0, 5],"float64"), 0, )
W0521 22:09:51.580089 72543 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([3, 4, 4],"float64"), Tensor([4, 0, 5],"float64"), 0, ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.463721 GPU 1 72813 test begin: paddle.tensordot(Tensor([3, 4, 4],"float64"), Tensor([4, 0, 5],"float64"), 1, )
W0521 22:09:51.598048 72813 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([3, 4, 4],"float64"), Tensor([4, 0, 5],"float64"), 1, ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.467419 GPU 1 72933 test begin: paddle.tensordot(Tensor([3, 4, 4],"float64"), Tensor([4, 4, 0],"float64"), 0, )
W0521 22:09:51.643342 72933 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([3, 4, 4],"float64"), Tensor([4, 4, 0],"float64"), 0, ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.474118 GPU 1 73519 test begin: paddle.tensordot(Tensor([3, 4, 4],"float64"), Tensor([4, 4, 0],"float64"), 1, )
W0521 22:09:58.450116 73519 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([3, 4, 4],"float64"), Tensor([4, 4, 0],"float64"), 1, ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:09:51.476515 GPU 1 72516 test begin: paddle.tensordot(Tensor([3, 4, 4],"float64"), Tensor([4, 4, 0],"float64"), 2, )
W0521 22:09:51.635228 72516 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([3, 4, 4],"float64"), Tensor([4, 4, 0],"float64"), 2, ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.494910 GPU 1 72626 test begin: paddle.tensordot(Tensor([3, 4, 4],"float64"), Tensor([4, 4, 0],"float64"), list[list[1,2,],list[0,1,],], )
W0521 22:09:51.662938 72626 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([3, 4, 4],"float64"), Tensor([4, 4, 0],"float64"), list[list[1,2,],list[0,1,],], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.496451 GPU 1 73549 test begin: paddle.tensordot(Tensor([3, 4, 4],"float64"), Tensor([4, 4, 0],"float64"), tuple(list[1,2,],list[0,1,],), )
W0521 22:09:59.407295 73549 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([3, 4, 4],"float64"), Tensor([4, 4, 0],"float64"), tuple(list[1,2,],list[0,1,],), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:09:51.503494 GPU 1 72568 test begin: paddle.tensordot(Tensor([3, 4, 4],"float64"), Tensor([4, 4, 0],"float64"), tuple(tuple(1,2,),tuple(0,1,),), )
W0521 22:09:51.636518 72568 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(Tensor([3, 4, 4],"float64"), Tensor([4, 4, 0],"float64"), tuple(tuple(1,2,),tuple(0,1,),), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.579329 GPU 1 72621 test begin: paddle.tensordot(x=Tensor([2, 3, 3, 4],"float64"), y=Tensor([0, 4, 3, 4],"float64"), axes=0, )
W0521 22:09:51.702088 72621 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(x=Tensor([2, 3, 3, 4],"float64"), y=Tensor([0, 4, 3, 4],"float64"), axes=0, ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.580817 GPU 1 72543 test begin: paddle.tensordot(x=Tensor([2, 3, 3, 4],"float64"), y=Tensor([3, 0, 3, 4],"float64"), axes=0, )
W0521 22:09:51.704653 72543 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(x=Tensor([2, 3, 3, 4],"float64"), y=Tensor([3, 0, 3, 4],"float64"), axes=0, ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.590696 GPU 1 72649 test begin: paddle.tensordot(x=Tensor([2, 3, 3, 4],"float64"), y=Tensor([3, 4, 0, 4],"float64"), )
W0521 22:09:51.865468 72649 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(x=Tensor([2, 3, 3, 4],"float64"), y=Tensor([3, 4, 0, 4],"float64"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.598741 GPU 1 72813 test begin: paddle.tensordot(x=Tensor([2, 3, 3, 4],"float64"), y=Tensor([3, 4, 0, 4],"float64"), axes=0, )
W0521 22:09:51.721504 72813 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(x=Tensor([2, 3, 3, 4],"float64"), y=Tensor([3, 4, 0, 4],"float64"), axes=0, ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.636021 GPU 1 72516 test begin: paddle.tensordot(x=Tensor([2, 3, 3, 4],"float64"), y=Tensor([3, 4, 3, 0],"float64"), )
W0521 22:09:51.765681 72516 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(x=Tensor([2, 3, 3, 4],"float64"), y=Tensor([3, 4, 3, 0],"float64"), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.637243 GPU 1 72568 test begin: paddle.tensordot(x=Tensor([2, 3, 3, 4],"float64"), y=Tensor([3, 4, 3, 0],"float64"), axes=0, )
W0521 22:09:51.765326 72568 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(x=Tensor([2, 3, 3, 4],"float64"), y=Tensor([3, 4, 3, 0],"float64"), axes=0, ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.644142 GPU 1 72933 test begin: paddle.tensordot(x=Tensor([2, 3, 4, 4],"float64"), y=Tensor([0, 3, 4, 4],"float64"), axes=0, )
W0521 22:09:51.778313 72933 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(x=Tensor([2, 3, 4, 4],"float64"), y=Tensor([0, 3, 4, 4],"float64"), axes=0, ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.663779 GPU 1 72626 test begin: paddle.tensordot(x=Tensor([2, 3, 4, 4],"float64"), y=Tensor([2, 0, 4, 4],"float64"), axes=0, )
W0521 22:09:51.876554 72626 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(x=Tensor([2, 3, 4, 4],"float64"), y=Tensor([2, 0, 4, 4],"float64"), axes=0, ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.697205 GPU 1 73507 test begin: paddle.tensordot(x=Tensor([2, 3, 4, 4],"float64"), y=Tensor([2, 3, 0, 4],"float64"), axes=0, )
W0521 22:09:59.836794 73507 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(x=Tensor([2, 3, 4, 4],"float64"), y=Tensor([2, 3, 0, 4],"float64"), axes=0, ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)


2025-05-21 22:09:51.702796 GPU 1 72621 test begin: paddle.tensordot(x=Tensor([2, 3, 4, 4],"float64"), y=Tensor([2, 3, 4, 0],"float64"), axes=0, )
W0521 22:09:51.908581 72621 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(x=Tensor([2, 3, 4, 4],"float64"), y=Tensor([2, 3, 4, 0],"float64"), axes=0, ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.705345 GPU 1 72543 test begin: paddle.tensordot(x=Tensor([2, 7, 4, 2],"float64"), y=Tensor([7, 0, 4, 2],"float64"), axes=list[tuple(1,2,3,),tuple(0,2,3,),], )
W0521 22:09:51.828920 72543 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(x=Tensor([2, 7, 4, 2],"float64"), y=Tensor([7, 0, 4, 2],"float64"), axes=list[tuple(1,2,3,),tuple(0,2,3,),], ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.722219 GPU 1 72813 test begin: paddle.tensordot(x=Tensor([2, 7, 4, 2],"float64"), y=Tensor([7, 0, 4, 2],"float64"), axes=tuple(list[1,2,3,],list[0,2,3,],), )
W0521 22:09:51.844152 72813 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(x=Tensor([2, 7, 4, 2],"float64"), y=Tensor([7, 0, 4, 2],"float64"), axes=tuple(list[1,2,3,],list[0,2,3,],), ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.766140 GPU 1 72568 test begin: paddle.tensordot(x=Tensor([3, 4, 3, 4],"float64"), y=Tensor([4, 0, 3, 4],"float64"), axes=1, )
W0521 22:09:51.899574 72568 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(x=Tensor([3, 4, 3, 4],"float64"), y=Tensor([4, 0, 3, 4],"float64"), axes=1, ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.766399 GPU 1 72516 test begin: paddle.tensordot(x=Tensor([3, 4, 3, 4],"float64"), y=Tensor([4, 4, 0, 4],"float64"), axes=1, )
W0521 22:09:51.892216 72516 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(x=Tensor([3, 4, 3, 4],"float64"), y=Tensor([4, 4, 0, 4],"float64"), axes=1, ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.779090 GPU 1 72933 test begin: paddle.tensordot(x=Tensor([3, 4, 3, 4],"float64"), y=Tensor([4, 4, 3, 0],"float64"), axes=1, )
W0521 22:09:51.895773 72933 backward.cc:437] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.tensordot(x=Tensor([3, 4, 3, 4],"float64"), y=Tensor([4, 4, 3, 0],"float64"), axes=1, ) 
 (External) CUBLAS error(7). 
  [Hint: 'CUBLAS_STATUS_INVALID_VALUE'.  An unsupported value or parameter was passed to the function (a negative vector size, for example). To correct: ensure that all the parameters being passed have valid values. ] (at ../paddle/phi/kernels/funcs/blas/blas_impl.cu.h:170)

 ** On entry to DGEMM  parameter number 8 had an illegal value

2025-05-21 22:09:51.829770 GPU 1 72543 test begin: paddle.tile(Tensor([0, 1],"float32"), list[1,1,49,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 3>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 3> const&, Eigen::DSizes<long, 6> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836591 (unix time) try "date -d @1747836591" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f5674f5f0ef) received by PID 72543 (TID 0x7f5787d5c740) from PID 1962275055 ***]


2025-05-21 22:09:51.844866 GPU 1 72813 test begin: paddle.tile(Tensor([0, 7],"float32"), list[40,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 3>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 3> const&, Eigen::DSizes<long, 6> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836591 (unix time) try "date -d @1747836591" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f471c4890ef) received by PID 72813 (TID 0x7f482f286740) from PID 474517743 ***]


2025-05-21 22:09:51.866318 GPU 1 72649 test begin: paddle.tile(Tensor([0],"float32"), list[245,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 2>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 2> const&, Eigen::DSizes<long, 4> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836592 (unix time) try "date -d @1747836592" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7feb7ad610ef) received by PID 72649 (TID 0x7fec8db5e740) from PID 2060849391 ***]


2025-05-21 22:09:51.877489 GPU 1 72626 test begin: paddle.tile(Tensor([0],"float32"), list[7,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 2>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 2> const&, Eigen::DSizes<long, 4> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836592 (unix time) try "date -d @1747836592" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fd004d890ef) received by PID 72626 (TID 0x7fd117b86740) from PID 81301743 ***]


2025-05-21 22:09:51.892984 GPU 1 72516 test begin: paddle.tile(Tensor([1, 0, 1, 1, 1, 1],"float32"), list[1,3,4,4,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 6>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 12> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836592 (unix time) try "date -d @1747836592" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f242d9e00ef) received by PID 72516 (TID 0x7f25407dd740) from PID 765329647 ***]


2025-05-21 22:09:51.896484 GPU 1 72933 test begin: paddle.tile(Tensor([1, 0, 1, 1, 1, 3],"float32"), list[216,248,1,1,2,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 6>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 12> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836592 (unix time) try "date -d @1747836592" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fee176b60ef) received by PID 72933 (TID 0x7fef2a4b3740) from PID 392913135 ***]


2025-05-21 22:09:51.900515 GPU 1 72568 test begin: paddle.tile(Tensor([1, 0, 1, 1],"float32"), list[3,1,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 4>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 4> const&, Eigen::DSizes<long, 8> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836592 (unix time) try "date -d @1747836592" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f6e98c370ef) received by PID 72568 (TID 0x7f6faba34740) from PID 18446744071977529583 ***]


2025-05-21 22:09:51.909429 GPU 1 72621 test begin: paddle.tile(Tensor([1, 0, 1, 64, 16],"float32"), list[1,1,4,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 5>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836592 (unix time) try "date -d @1747836592" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fba027e90ef) received by PID 72621 (TID 0x7fbb155e6740) from PID 41849071 ***]


2025-05-21 22:09:57.032845 GPU 1 73618 test begin: paddle.tile(Tensor([1, 0, 13, 13],"float32"), list[3,1,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 4>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 4> const&, Eigen::DSizes<long, 8> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836597 (unix time) try "date -d @1747836597" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f0b389850ef) received by PID 73618 (TID 0x7f0c4b782740) from PID 949506287 ***]


2025-05-21 22:09:58.451653 GPU 1 73519 test begin: paddle.tile(Tensor([1, 0, 2, 2],"float32"), list[1,10,1,1,], )
 ** On entry to DGEMM  parameter number 8 had an illegal value


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 4>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 4> const&, Eigen::DSizes<long, 8> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836598 (unix time) try "date -d @1747836598" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fb143b020ef) received by PID 73519 (TID 0x7fb2568ff740) from PID 1135616239 ***]


2025-05-21 22:09:59.408986 GPU 1 73549 test begin: paddle.tile(Tensor([1, 0, 2],"float32"), list[1,1,2,], )
 ** On entry to DGEMM  parameter number 8 had an illegal value


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 3>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 3> const&, Eigen::DSizes<long, 6> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836599 (unix time) try "date -d @1747836599" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f58e993a0ef) received by PID 73549 (TID 0x7f59fc737740) from PID 18446744073333350639 ***]


2025-05-21 22:09:59.840383 GPU 1 73507 test begin: paddle.tile(Tensor([1, 0, 64, 64, 2],"float32"), tuple(16,1,1,1,1,), )
 ** On entry to DGEMM  parameter number 8 had an illegal value


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 5>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836600 (unix time) try "date -d @1747836600" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f37f5f070ef) received by PID 73507 (TID 0x7f3908d04740) from PID 18446744073540759791 ***]


2025-05-21 22:10:05.013056 GPU 1 73601 test begin: paddle.tile(Tensor([1, 0],"float32"), list[256,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 2>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 2> const&, Eigen::DSizes<long, 4> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836605 (unix time) try "date -d @1747836605" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fd2c471f0ef) received by PID 73601 (TID 0x7fd3d751c740) from PID 18446744072710385903 ***]


2025-05-21 22:10:06.638870 GPU 1 73762 test begin: paddle.tile(Tensor([1, 0],"float32"), list[5,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 2>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 2> const&, Eigen::DSizes<long, 4> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836607 (unix time) try "date -d @1747836607" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fd0720df0ef) received by PID 73762 (TID 0x7fd184edc740) from PID 1913516271 ***]


2025-05-21 22:10:06.710416 GPU 1 73666 test begin: paddle.tile(Tensor([1, 0],"float32"), list[58,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 2>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 2> const&, Eigen::DSizes<long, 4> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836607 (unix time) try "date -d @1747836607" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fbb202190ef) received by PID 73666 (TID 0x7fbc33016740) from PID 539070703 ***]


2025-05-21 22:10:07.609217 GPU 1 73690 test begin: paddle.tile(Tensor([1, 0],"float32"), list[64,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 2>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 2> const&, Eigen::DSizes<long, 4> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836607 (unix time) try "date -d @1747836607" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fe4359d10ef) received by PID 73690 (TID 0x7fe5487ce740) from PID 899485935 ***]


2025-05-21 22:10:08.070009 GPU 1 73731 test begin: paddle.tile(Tensor([1, 0],"float32"), repeat_times=list[2,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 2>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 2> const&, Eigen::DSizes<long, 4> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836608 (unix time) try "date -d @1747836608" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f1d519b40ef) received by PID 73731 (TID 0x7f1e647b1740) from PID 1369129199 ***]


2025-05-21 22:10:08.124715 GPU 1 73677 test begin: paddle.tile(Tensor([1, 1, 0, 1, 1, 3],"float32"), list[216,248,1,1,2,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 6>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 12> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836608 (unix time) try "date -d @1747836608" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fb4806510ef) received by PID 73677 (TID 0x7fb59344e740) from PID 18446744071568691439 ***]


2025-05-21 22:10:08.276771 GPU 1 73703 test begin: paddle.tile(Tensor([1, 1, 0, 13],"float32"), list[3,1,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 4>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 4> const&, Eigen::DSizes<long, 8> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836608 (unix time) try "date -d @1747836608" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fc5f51070ef) received by PID 73703 (TID 0x7fc707f02740) from PID 18446744073526079727 ***]


2025-05-21 22:10:08.954885 GPU 1 73782 test begin: paddle.tile(Tensor([1, 1, 0, 1],"float32"), list[3,1,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 4>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 4> const&, Eigen::DSizes<long, 8> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836609 (unix time) try "date -d @1747836609" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f2d685960ef) received by PID 73782 (TID 0x7f2e7b393740) from PID 1750687983 ***]


2025-05-21 22:10:10.985967 GPU 1 73711 test begin: paddle.tile(Tensor([1, 1, 0, 2],"float32"), list[1,10,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 4>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 4> const&, Eigen::DSizes<long, 8> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836611 (unix time) try "date -d @1747836611" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fc3eae520ef) received by PID 73711 (TID 0x7fc4fdc4f740) from PID 18446744073355469039 ***]


2025-05-21 22:10:11.640694 GPU 1 73599 test begin: paddle.tile(Tensor([1, 1, 0, 64, 2],"float32"), tuple(16,1,1,1,1,), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 5>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836612 (unix time) try "date -d @1747836612" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fb2692a10ef) received by PID 73599 (TID 0x7fb37c09e740) from PID 1764364527 ***]


2025-05-21 22:10:11.820656 GPU 1 74533 test begin: paddle.tile(Tensor([1, 1, 1, 0, 1, 3],"float32"), list[216,248,1,1,2,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 6>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 12> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836646 (unix time) try "date -d @1747836646" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f6120e530ef) received by PID 74533 (TID 0x7f6233c50740) from PID 551891183 ***]


2025-05-21 22:10:11.967126 GPU 1 74595 test begin: paddle.tile(Tensor([1, 1, 1, 0],"float32"), list[3,1,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 4>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 4> const&, Eigen::DSizes<long, 8> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836649 (unix time) try "date -d @1747836649" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fb1925700ef) received by PID 74595 (TID 0x7fb2a536d740) from PID 18446744071869759727 ***]


2025-05-21 22:10:12.040958 GPU 1 74521 test begin: paddle.tile(Tensor([1, 1, 1, 1, 0, 3],"float32"), list[216,248,1,1,2,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 6>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 12> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836651 (unix time) try "date -d @1747836651" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7efafe3c00ef) received by PID 74521 (TID 0x7efc111bd740) from PID 18446744073679929583 ***]


2025-05-21 22:10:12.061384 GPU 1 74536 test begin: paddle.tile(Tensor([1, 1, 1, 1, 1, 0],"float32"), list[216,248,1,1,2,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 6>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 12> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836650 (unix time) try "date -d @1747836650" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f93475bb0ef) received by PID 74536 (TID 0x7f945a3b8740) from PID 1197191407 ***]


2025-05-21 22:10:12.090362 GPU 1 74579 test begin: paddle.tile(Tensor([1, 1, 13, 0],"float32"), list[3,1,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 4>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 4> const&, Eigen::DSizes<long, 8> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836650 (unix time) try "date -d @1747836650" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f3d8680e0ef) received by PID 74579 (TID 0x7f3e9960b740) from PID 18446744071671177455 ***]


2025-05-21 22:10:12.137532 GPU 1 74600 test begin: paddle.tile(Tensor([1, 1, 2, 0],"float32"), list[1,10,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 4>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 4> const&, Eigen::DSizes<long, 8> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836649 (unix time) try "date -d @1747836649" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f5d1089a0ef) received by PID 74600 (TID 0x7f5e23697740) from PID 277455087 ***]


2025-05-21 22:10:12.639004 GPU 1 74555 test begin: paddle.tile(Tensor([1, 1, 64, 0, 2],"float32"), tuple(16,1,1,1,1,), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 5>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836649 (unix time) try "date -d @1747836649" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f3be667a0ef) received by PID 74555 (TID 0x7f3cf9477740) from PID 18446744073280135407 ***]


2025-05-21 22:10:12.775088 GPU 1 73742 test begin: paddle.tile(Tensor([1, 1, 64, 64, 0],"float32"), tuple(16,1,1,1,1,), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 5>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836613 (unix time) try "date -d @1747836613" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f1f91bdb0ef) received by PID 73742 (TID 0x7f20a49d8740) from PID 18446744071859712239 ***]


2025-05-21 22:10:12.832113 GPU 1 73676 test begin: paddle.tile(Tensor([1, 192, 0],"float32"), list[1,1,2,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 3>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 3> const&, Eigen::DSizes<long, 6> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836612 (unix time) try "date -d @1747836612" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f08c8abf0ef) received by PID 73676 (TID 0x7f09db8bc740) from PID 18446744072781295855 ***]


2025-05-21 22:10:12.977871 GPU 1 74739 test begin: paddle.tile(Tensor([1, 196, 0],"float32"), list[1,1,2,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 3>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 3> const&, Eigen::DSizes<long, 6> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836650 (unix time) try "date -d @1747836650" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f152efa30ef) received by PID 74739 (TID 0x7f1641da0740) from PID 788148463 ***]


2025-05-21 22:10:12.997767 GPU 1 73775 test begin: paddle.tile(Tensor([1, 2, 0, 64, 16],"float32"), list[1,1,4,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 5>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836613 (unix time) try "date -d @1747836613" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f82756260ef) received by PID 73775 (TID 0x7f8388423740) from PID 1969381615 ***]


2025-05-21 22:10:13.371755 GPU 1 74757 test begin: paddle.tile(Tensor([1, 2, 1, 0, 16],"float32"), list[1,1,4,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 5>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836650 (unix time) try "date -d @1747836650" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f8e614920ef) received by PID 74757 (TID 0x7f8f7428f740) from PID 1632182511 ***]


2025-05-21 22:10:13.459920 GPU 1 74781 test begin: paddle.tile(Tensor([1, 2, 1, 64, 0],"float32"), list[1,1,4,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 5>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836652 (unix time) try "date -d @1747836652" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f71df7f60ef) received by PID 74781 (TID 0x7f72f25f3740) from PID 18446744073164251375 ***]


2025-05-21 22:10:13.483200 GPU 1 73727 test begin: paddle.tile(Tensor([1, 3, 0, 1, 1, 1],"float32"), list[1,3,4,4,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 6>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 12> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836613 (unix time) try "date -d @1747836613" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fb05c3a70ef) received by PID 73727 (TID 0x7fb16f1a4740) from PID 1547333871 ***]


2025-05-21 22:10:14.868248 GPU 1 74777 test begin: paddle.tile(Tensor([1, 3, 1, 0, 1, 1],"float32"), list[1,3,4,4,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 6>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 12> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836652 (unix time) try "date -d @1747836652" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fa2ea1750ef) received by PID 74777 (TID 0x7fa3fcf72740) from PID 18446744073341980911 ***]


2025-05-21 22:10:15.986434 GPU 1 75278 test begin: paddle.tile(Tensor([1, 3, 1, 1, 0, 1],"float32"), list[1,3,4,4,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 6>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 12> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836656 (unix time) try "date -d @1747836656" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fba571d30ef) received by PID 75278 (TID 0x7fbb69fd0740) from PID 1461530863 ***]


2025-05-21 22:10:18.916274 GPU 1 75365 test begin: paddle.tile(Tensor([1, 3, 1, 1, 1, 0],"float32"), list[1,3,4,4,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 6>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 12> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836658 (unix time) try "date -d @1747836658" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f37f74720ef) received by PID 75365 (TID 0x7f390a26f740) from PID 18446744073563218159 ***]


2025-05-21 22:10:19.426319 GPU 1 75742 test begin: paddle.tile(Tensor([13, 0, 16, 16],"float32"), repeat_times=list[1,1,4,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 4>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 4> const&, Eigen::DSizes<long, 8> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836657 (unix time) try "date -d @1747836657" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f83804890ef) received by PID 75742 (TID 0x7f8493286740) from PID 18446744071566823663 ***]


2025-05-21 22:10:21.243117 GPU 1 75744 test begin: paddle.tile(Tensor([13, 0, 32],"float32"), list[1,1,4,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 3>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 3> const&, Eigen::DSizes<long, 6> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836659 (unix time) try "date -d @1747836659" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f79ab3250ef) received by PID 75744 (TID 0x7f7abe122740) from PID 18446744072286785775 ***]


2025-05-21 22:10:22.566937 GPU 1 75782 test begin: paddle.tile(Tensor([13, 0, 7],"float32"), repeat_times=list[4,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 3>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 3> const&, Eigen::DSizes<long, 6> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836661 (unix time) try "date -d @1747836661" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fb64603e0ef) received by PID 75782 (TID 0x7fb758e3b740) from PID 1174659311 ***]


2025-05-21 22:10:23.659949 GPU 1 75806 test begin: paddle.tile(Tensor([13, 1, 0],"float32"), list[1,1,4,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 3>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 3> const&, Eigen::DSizes<long, 6> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836660 (unix time) try "date -d @1747836660" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f33c5ff50ef) received by PID 75806 (TID 0x7f34d8df2740) from PID 18446744072736428271 ***]


2025-05-21 22:10:24.112719 GPU 1 75815 test begin: paddle.tile(Tensor([13, 1, 0],"float32"), repeat_times=list[4,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 3>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 3> const&, Eigen::DSizes<long, 6> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836661 (unix time) try "date -d @1747836661" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f18823650ef) received by PID 75815 (TID 0x7f1995162740) from PID 18446744071599182063 ***]


2025-05-21 22:10:24.562788 GPU 1 75802 test begin: paddle.tile(Tensor([13, 2, 0, 16],"float32"), repeat_times=list[1,1,4,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 4>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 4> const&, Eigen::DSizes<long, 8> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836661 (unix time) try "date -d @1747836661" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7faf3b9e20ef) received by PID 75802 (TID 0x7fb04e7df740) from PID 1000218863 ***]


2025-05-21 22:10:25.705116 GPU 1 75825 test begin: paddle.tile(Tensor([13, 2, 16, 0],"float32"), repeat_times=list[1,1,4,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 4>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 4> const&, Eigen::DSizes<long, 8> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836662 (unix time) try "date -d @1747836662" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f978a20e0ef) received by PID 75825 (TID 0x7f989d00b740) from PID 18446744071731994863 ***]


2025-05-21 22:10:26.863883 GPU 1 75915 test begin: paddle.tile(Tensor([13, 7, 0],"float32"), repeat_times=list[4,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 3>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 3> const&, Eigen::DSizes<long, 6> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836662 (unix time) try "date -d @1747836662" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7feede3e80ef) received by PID 75915 (TID 0x7feff11e5740) from PID 18446744073143222511 ***]


2025-05-21 22:10:28.751795 GPU 1 75985 test begin: paddle.tile(Tensor([16, 0, 1, 1, 4],"float32"), list[1,1,64,64,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 5>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836668 (unix time) try "date -d @1747836668" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f3ed76fc0ef) received by PID 75985 (TID 0x7f3fea4f9740) from PID 18446744073029009647 ***]


2025-05-21 22:10:30.836050 GPU 1 75956 test begin: paddle.tile(Tensor([16, 0, 1, 3, 64, 64],"float32"), list[1,11,1,1,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 6>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 12> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836668 (unix time) try "date -d @1747836668" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fd47c2e60ef) received by PID 75956 (TID 0x7fd58f0e3740) from PID 2083414255 ***]


2025-05-21 22:10:32.449430 GPU 1 75966 test begin: paddle.tile(Tensor([16, 0, 1, 58, 58],"float32"), list[1,1,4,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 5>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836668 (unix time) try "date -d @1747836668" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f2488df40ef) received by PID 75966 (TID 0x7f259bbf1740) from PID 18446744071710916847 ***]


2025-05-21 22:10:32.483178 GPU 1 75947 test begin: paddle.tile(Tensor([16, 1, 0, 3, 64, 64],"float32"), list[1,11,1,1,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 6>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 12> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836669 (unix time) try "date -d @1747836669" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f335b87a0ef) received by PID 75947 (TID 0x7f346e677740) from PID 1535615215 ***]


2025-05-21 22:10:45.421190 GPU 1 76123 test begin: paddle.tile(Tensor([16, 1, 1, 0, 64, 64],"float32"), list[1,11,1,1,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 6>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 12> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836675 (unix time) try "date -d @1747836675" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fb1d43f40ef) received by PID 76123 (TID 0x7fb2e71f1740) from PID 18446744072975499503 ***]


2025-05-21 22:10:59.577289 GPU 1 76578 test begin: paddle.tile(Tensor([16, 1, 1, 3, 0, 64],"float32"), list[1,11,1,1,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 6>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 12> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836696 (unix time) try "date -d @1747836696" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f04f45800ef) received by PID 76578 (TID 0x7f060737d740) from PID 18446744073513992431 ***]


2025-05-21 22:11:00.519438 GPU 1 76628 test begin: paddle.tile(Tensor([16, 1, 1, 3, 64, 0],"float32"), list[1,11,1,1,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 6>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 12> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836694 (unix time) try "date -d @1747836694" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f4ffada10ef) received by PID 76628 (TID 0x7f510db9e740) from PID 18446744073623179503 ***]


2025-05-21 22:11:01.492645 GPU 1 76636 test begin: paddle.tile(Tensor([16, 10, 0, 1, 4],"float32"), list[1,1,64,64,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 5>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836698 (unix time) try "date -d @1747836698" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fab9134e0ef) received by PID 76636 (TID 0x7faca414b740) from PID 18446744071850746095 ***]


2025-05-21 22:11:02.858792 GPU 1 76653 test begin: paddle.tile(Tensor([16, 10, 0, 58, 58],"float32"), list[1,1,4,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 5>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836697 (unix time) try "date -d @1747836697" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f1b1ebcc0ef) received by PID 76653 (TID 0x7f1c319c9740) from PID 515686639 ***]


2025-05-21 22:11:03.204331 GPU 1 76690 test begin: paddle.tile(Tensor([16, 10, 1, 0, 4],"float32"), list[1,1,64,64,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 5>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836698 (unix time) try "date -d @1747836698" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f9b593970ef) received by PID 76690 (TID 0x7f9c6c194740) from PID 1496936687 ***]


2025-05-21 22:11:03.259479 GPU 1 76718 test begin: paddle.tile(Tensor([16, 10, 1, 0, 58],"float32"), list[1,1,4,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 5>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836694 (unix time) try "date -d @1747836694" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fc4e9b470ef) received by PID 76718 (TID 0x7fc5fc944740) from PID 18446744073335501039 ***]


2025-05-21 22:11:03.698722 GPU 1 76679 test begin: paddle.tile(Tensor([16, 10, 1, 1, 0],"float32"), list[1,1,64,64,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 5>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836696 (unix time) try "date -d @1747836696" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f662fae30ef) received by PID 76679 (TID 0x7f67428e0740) from PID 799944943 ***]


2025-05-21 22:11:04.211005 GPU 1 76743 test begin: paddle.tile(Tensor([16, 10, 1, 58, 0],"float32"), list[1,1,4,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 5>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836696 (unix time) try "date -d @1747836696" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f1b06c240ef) received by PID 76743 (TID 0x7f1c19a21740) from PID 113393903 ***]


2025-05-21 22:11:06.030104 GPU 1 76670 test begin: paddle.tile(Tensor([18, 0],"float32"), repeat_times=list[1,18,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 2>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 2> const&, Eigen::DSizes<long, 4> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836698 (unix time) try "date -d @1747836698" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fc34259e0ef) received by PID 76670 (TID 0x7fc45539b740) from PID 1113186543 ***]


2025-05-21 22:11:07.638354 GPU 1 76707 test begin: paddle.tile(Tensor([256, 0],"float32"), list[1,256,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 2>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 2> const&, Eigen::DSizes<long, 4> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836701 (unix time) try "date -d @1747836701" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f095748c0ef) received by PID 76707 (TID 0x7f0a6a289740) from PID 1464385775 ***]


2025-05-21 22:11:10.166045 GPU 1 76783 test begin: paddle.tile(Tensor([3, 0, 1, 64, 32],"float16"), list[1,1,8,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, phi::dtype::float16, 5>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<phi::dtype::float16, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<phi::dtype::float16 const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836701 (unix time) try "date -d @1747836701" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fa448bea0ef) received by PID 76783 (TID 0x7fa55b9e7740) from PID 1220452591 ***]


2025-05-21 22:11:16.023919 GPU 1 76973 test begin: paddle.tile(Tensor([3, 2, 0, 64, 32],"float16"), list[1,1,8,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, phi::dtype::float16, 5>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<phi::dtype::float16, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<phi::dtype::float16 const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836714 (unix time) try "date -d @1747836714" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f09159060ef) received by PID 76973 (TID 0x7f0a28703740) from PID 361783535 ***]


2025-05-21 22:11:16.746752 GPU 1 76938 test begin: paddle.tile(Tensor([3, 2, 1, 0, 32],"float16"), list[1,1,8,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, phi::dtype::float16, 5>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<phi::dtype::float16, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<phi::dtype::float16 const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836707 (unix time) try "date -d @1747836707" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fd6ff14f0ef) received by PID 76938 (TID 0x7fd811f4c740) from PID 18446744073694146799 ***]


2025-05-21 22:11:18.072340 GPU 1 77036 test begin: paddle.tile(Tensor([3, 2, 1, 64, 0],"float16"), list[1,1,8,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, phi::dtype::float16, 5>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<phi::dtype::float16, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<phi::dtype::float16 const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836713 (unix time) try "date -d @1747836713" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f3675a6a0ef) received by PID 77036 (TID 0x7f3788867740) from PID 1973854447 ***]


2025-05-21 22:11:18.431124 GPU 1 77054 test begin: paddle.tile(Tensor([4, 0, 16],"float32"), list[1,4,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 3>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 3> const&, Eigen::DSizes<long, 6> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836713 (unix time) try "date -d @1747836713" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f269bb5b0ef) received by PID 77054 (TID 0x7f27ae958740) from PID 18446744072026960111 ***]


2025-05-21 22:11:18.654245 GPU 1 77082 test begin: paddle.tile(Tensor([4, 0, 1],"float32"), list[1,1,16,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 3>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 3> const&, Eigen::DSizes<long, 6> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836712 (unix time) try "date -d @1747836712" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f9c58bc90ef) received by PID 77082 (TID 0x7f9d6b9c6740) from PID 1488752879 ***]


2025-05-21 22:11:19.163022 GPU 1 77080 test begin: paddle.tile(Tensor([4, 0, 1],"float32"), list[1,1,32,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 3>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 3> const&, Eigen::DSizes<long, 6> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836714 (unix time) try "date -d @1747836714" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7faf7af4b0ef) received by PID 77080 (TID 0x7fb08dd48740) from PID 2062856431 ***]


2025-05-21 22:11:19.537667 GPU 1 77268 test begin: paddle.tile(Tensor([4, 0, 32],"float32"), list[1,4,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 3>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 3> const&, Eigen::DSizes<long, 6> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836715 (unix time) try "date -d @1747836715" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fc30233c0ef) received by PID 77268 (TID 0x7fc415139740) from PID 36946159 ***]


2025-05-21 22:11:19.547717 GPU 1 77035 test begin: paddle.tile(Tensor([4, 0, 32],"float32"), list[1,8,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 3>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 3> const&, Eigen::DSizes<long, 6> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836714 (unix time) try "date -d @1747836714" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fc413b0a0ef) received by PID 77035 (TID 0x7fc526907740) from PID 330342639 ***]


2025-05-21 22:11:19.745711 GPU 1 77051 test begin: paddle.tile(Tensor([4, 0],"float32"), repeat_times=list[1,4,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 2>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 2> const&, Eigen::DSizes<long, 4> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836717 (unix time) try "date -d @1747836717" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fc8077230ef) received by PID 77051 (TID 0x7fc91a520740) from PID 124924143 ***]


2025-05-21 22:11:20.261622 GPU 1 77629 test begin: paddle.tile(Tensor([4, 1, 0],"float32"), list[1,4,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 3>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 3> const&, Eigen::DSizes<long, 6> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836720 (unix time) try "date -d @1747836720" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f3ab59550ef) received by PID 77629 (TID 0x7f3bc8752740) from PID 18446744072461045999 ***]


2025-05-21 22:11:20.896011 GPU 1 77642 test begin: paddle.tile(Tensor([4, 1, 0],"float32"), list[1,8,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 3>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 3> const&, Eigen::DSizes<long, 6> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836721 (unix time) try "date -d @1747836721" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fc5e5bbf0ef) received by PID 77642 (TID 0x7fc6f89bc740) from PID 18446744073268883695 ***]


2025-05-21 22:11:20.982701 GPU 1 77640 test begin: paddle.tile(Tensor([4, 4, 0],"float32"), list[1,1,16,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 3>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 3> const&, Eigen::DSizes<long, 6> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836720 (unix time) try "date -d @1747836720" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fee720580ef) received by PID 77640 (TID 0x7fef84e55740) from PID 1912963311 ***]


2025-05-21 22:11:21.052242 GPU 1 77619 test begin: paddle.tile(Tensor([4, 4, 0],"float32"), list[1,1,32,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 3>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 3> const&, Eigen::DSizes<long, 6> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836718 (unix time) try "date -d @1747836718" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f694cefd0ef) received by PID 77619 (TID 0x7f6a5fcfa740) from PID 1290785007 ***]


2025-05-21 22:11:23.174602 GPU 1 77685 test begin: paddle.tile(Tensor([4, 8, 0],"float32"), list[1,1,32,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 3>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 3> const&, Eigen::DSizes<long, 6> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836719 (unix time) try "date -d @1747836719" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f1f64d6f0ef) received by PID 77685 (TID 0x7f2077b6c740) from PID 1691807983 ***]


2025-05-21 22:11:43.411544 GPU 1 77911 test begin: paddle.tile(Tensor([40, 0],"float32"), list[1,1,49,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 3>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 3> const&, Eigen::DSizes<long, 6> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836736 (unix time) try "date -d @1747836736" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f718bd8b0ef) received by PID 77911 (TID 0x7f729eb88740) from PID 18446744071760818415 ***]


2025-05-21 22:11:45.456864 GPU 1 78183 test begin: paddle.tile(Tensor([5, 0],"float32"), list[1,5,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 2>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 2> const&, Eigen::DSizes<long, 4> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836737 (unix time) try "date -d @1747836737" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f2c0849d0ef) received by PID 78183 (TID 0x7f2d1b29a740) from PID 139055343 ***]


2025-05-21 22:11:46.660704 GPU 1 78253 test begin: paddle.tile(Tensor([5, 0],"float32"), list[8,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 2>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 2> const&, Eigen::DSizes<long, 4> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836738 (unix time) try "date -d @1747836738" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f2d2e0770ef) received by PID 78253 (TID 0x7f2e40e74740) from PID 772239599 ***]


2025-05-21 22:11:46.964386 GPU 1 78190 test begin: paddle.tile(Tensor([58, 0],"float32"), list[1,58,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 2>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 2> const&, Eigen::DSizes<long, 4> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836741 (unix time) try "date -d @1747836741" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fc9036b20ef) received by PID 78190 (TID 0x7fca164af740) from PID 57352431 ***]


2025-05-21 22:11:47.363723 GPU 1 78261 test begin: paddle.tile(Tensor([64, 0],"float32"), list[1,64,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 2>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 2> const&, Eigen::DSizes<long, 4> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836739 (unix time) try "date -d @1747836739" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fbbebff00ef) received by PID 78261 (TID 0x7fbcfeded740) from PID 18446744073373941999 ***]


2025-05-21 22:11:47.418723 GPU 1 78271 test begin: paddle.tile(Tensor([7, 0],"float32"), list[40,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, float, 3>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 3> const&, Eigen::DSizes<long, 6> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836740 (unix time) try "date -d @1747836740" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f56831ba0ef) received by PID 78271 (TID 0x7f5795fb7740) from PID 18446744071614210287 ***]


2025-05-21 22:11:50.697960 GPU 1 78290 test begin: paddle.tile(Tensor([8, 0, 1],"float64"), list[1,1,100,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, double, 3>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<double, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<double const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 3> const&, Eigen::DSizes<long, 6> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836741 (unix time) try "date -d @1747836741" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f49d3ef30ef) received by PID 78290 (TID 0x7f4ae6cf0740) from PID 18446744072970252527 ***]


2025-05-21 22:11:51.276234 GPU 1 78301 test begin: paddle.tile(Tensor([8, 4, 0],"float64"), list[1,1,100,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, double, 3>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<double, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<double const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 3> const&, Eigen::DSizes<long, 6> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836741 (unix time) try "date -d @1747836741" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fd207f720ef) received by PID 78301 (TID 0x7fd31ad6f740) from PID 133636335 ***]


2025-05-21 22:11:54.392094 GPU 1 78340 test begin: paddle.tile(x=Tensor([1, 0, 2],"float64"), repeat_times=tuple(2,3,), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, double, 3>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<double, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<double const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 3> const&, Eigen::DSizes<long, 6> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836743 (unix time) try "date -d @1747836743" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f477d7350ef) received by PID 78340 (TID 0x7f4890532740) from PID 2104709359 ***]


2025-05-21 22:11:54.995255 GPU 1 78341 test begin: paddle.tile(x=Tensor([1, 0],"float64"), repeat_times=list[471,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, double, 2>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<double, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<double const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 2> const&, Eigen::DSizes<long, 4> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836742 (unix time) try "date -d @1747836742" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fdfcfaae0ef) received by PID 78341 (TID 0x7fe0e28ab740) from PID 18446744072898666735 ***]


2025-05-21 22:12:03.614718 GPU 1 78433 test begin: paddle.tile(x=Tensor([1, 3, 0],"float64"), repeat_times=tuple(2,3,), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, double, 3>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<double, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<double const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 3> const&, Eigen::DSizes<long, 6> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836748 (unix time) try "date -d @1747836748" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f7396b3c0ef) received by PID 78433 (TID 0x7f74a9939740) from PID 18446744071942947055 ***]


2025-05-21 22:12:03.827957 GPU 1 78447 test begin: paddle.tile(x=Tensor([2, 0],"float64"), repeat_times=list[3,2,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::GpuDevice, double, 2>::Eval(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<double, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<double const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 2> const&, Eigen::DSizes<long, 4> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747836746 (unix time) try "date -d @1747836746" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fee2852c0ef) received by PID 78447 (TID 0x7fef3b329740) from PID 676511983 ***]


