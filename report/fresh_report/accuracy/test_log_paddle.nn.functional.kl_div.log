paddle.nn.functional.kl_div(Tensor([40, 20, 50],"float32"), Tensor([40, 20, 50],"float32"), "batchmean", False, )
paddle.nn.functional.kl_div(Tensor([40, 20, 50],"float32"), Tensor([40, 20, 50],"float32"), "batchmean", True, )
paddle.nn.functional.kl_div(Tensor([40, 20, 50],"float32"), Tensor([40, 20, 50],"float32"), "none", False, )
paddle.nn.functional.kl_div(Tensor([5, 20],"float32"), Tensor([5, 20],"float64"), "mean", False, )
paddle.nn.functional.kl_div(Tensor([5, 20],"float64"), Tensor([5, 20],"float32"), )
paddle.nn.functional.kl_div(Tensor([5, 20],"float64"), Tensor([5, 20],"float64"), "batchmean", False, )
paddle.nn.functional.kl_div(Tensor([5, 20],"float64"), Tensor([5, 20],"float64"), "mean", False, )
paddle.nn.functional.kl_div(Tensor([5, 20],"float64"), Tensor([5, 20],"float64"), "mean", True, )
paddle.nn.functional.kl_div(Tensor([5, 20],"float64"), Tensor([5, 20],"float64"), "none", False, )
paddle.nn.functional.kl_div(Tensor([5, 20],"float64"), Tensor([5, 20],"float64"), "sum", False, )
paddle.nn.functional.kl_div(Tensor([5, 2],"float32"), label=Tensor([5, 2],"float32"), reduction="mean", name=None, )
paddle.nn.functional.kl_div(Tensor([5, 2],"float64"), Tensor([5, 2],"float64"), "mean", False, )
paddle.nn.functional.kl_div(Tensor([],"float64"), Tensor([],"float64"), "batchmean", False, )
paddle.nn.functional.kl_div(input=Tensor([32, 128, 128],"float32"), label=Tensor([32, 128, 128],"float32"), reduction="batchmean", )



grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
2025-05-14 03:31:43.990795 test begin: paddle.nn.functional.kl_div(Tensor([40, 20, 50],"float32"), Tensor([40, 20, 50],"float32"), "batchmean", False, )
W0514 03:31:50.008167 30092 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 12.0, Runtime API Version: 11.8
W0514 03:31:50.009570 30092 gpu_resources.cc:164] device: 0, cuDNN Version: 8.8.
-------
[not compare]  None tensor([[[-3.0727e-04,  2.4849e-04, -5.5325e-05,  ..., -2.5822e-04,
          -7.7030e-05, -1.8389e-04],
         [ 8.9779e-05,  3.6598e-05,  1.4800e-04,  ...,  1.3718e-04,
          -2.2318e-04,  2.5838e-04],
         [ 1.0633e-04,  1.7968e-04, -2.9578e-05,  ..., -1.3369e-04,
          -7.0533e-05, -7.4428e-05],
         ...,
         [ 2.6536e-04, -1.0455e-04,  2.3757e-05,  ...,  2.3313e-04,
          -1.7138e-04, -6.9257e-05],
         [-2.3634e-04,  1.4099e-04,  2.5390e-05,  ...,  2.8104e-04,
           3.1621e-05, -1.0305e-04],
         [ 1.3422e-06, -2.4462e-04,  9.5404e-06,  ...,  3.0396e-04,
           5.5794e-05,  1.7784e-04]],

        [[ 3.3135e-04, -1.7371e-04, -2.3997e-04,  ...,  6.3369e-05,
           6.1234e-05,  9.3777e-05],
         [ 1.2019e-04,  3.5418e-04, -1.5136e-04,  ..., -7.1994e-05,
           1.0646e-04, -2.3477e-05],
         [ 1.4405e-04, -9.2303e-05,  1.2243e-05,  ...,  1.9005e-05,
           1.1272e-04, -3.5217e-04],
         ...,
         [ 7.9407e-05,  2.2571e-04, -1.2817e-04,  ...,  1.5558e-04,
           1.9031e-05, -1.3521e-04],
         [-2.1484e-04, -2.9112e-04, -1.9229e-04,  ...,  1.5333e-05,
          -3.0768e-05, -1.1988e-04],
         [-9.0284e-05,  5.1629e-05,  6.1334e-06,  ...,  1.1800e-04,
           1.2530e-04,  2.4646e-04]],

        [[ 1.1183e-04, -9.8771e-05,  1.7633e-04,  ...,  2.2335e-04,
           7.3675e-05, -1.2707e-04],
         [-1.5059e-04,  2.3474e-05, -3.2902e-04,  ...,  8.4446e-05,
          -2.6537e-04,  3.8580e-04],
         [ 3.6947e-04,  4.7314e-04,  1.1033e-04,  ...,  1.8737e-05,
          -2.8060e-04, -6.3177e-05],
         ...,
         [-1.8192e-04, -1.3907e-04,  1.4102e-04,  ..., -1.8020e-04,
           6.0260e-05,  4.3052e-04],
         [-1.8810e-04, -2.2566e-04,  3.6715e-04,  ...,  2.9937e-04,
           3.6586e-04,  1.1564e-04],
         [-2.6372e-05,  3.3591e-05, -1.4631e-04,  ..., -1.3187e-04,
           2.0011e-05,  6.7996e-05]],

        ...,

        [[-1.8341e-04,  2.9556e-04, -8.3906e-05,  ...,  3.3360e-04,
           2.6745e-04,  7.7934e-05],
         [ 1.2764e-04, -2.6219e-05,  2.0092e-04,  ..., -2.2422e-04,
           1.6549e-04,  3.3928e-04],
         [-2.1947e-05,  1.8877e-04,  1.0160e-05,  ...,  1.6201e-04,
          -4.7165e-06, -1.6106e-04],
         ...,
         [ 6.6796e-05,  8.6389e-05,  8.0470e-05,  ..., -2.2047e-04,
          -2.3441e-04, -7.1792e-05],
         [ 2.4887e-04,  1.2519e-04,  6.3801e-05,  ..., -8.8342e-05,
           8.2660e-05, -2.2223e-04],
         [ 8.0835e-05,  3.0241e-04,  9.5427e-05,  ..., -5.3845e-05,
           2.1167e-04,  1.1203e-04]],

        [[ 1.4330e-04, -2.0876e-04, -1.9726e-05,  ..., -6.2545e-06,
           1.4917e-04, -2.0354e-04],
         [ 1.9388e-04, -2.2355e-04,  1.6401e-05,  ...,  1.9967e-04,
           1.6876e-04, -1.5211e-04],
         [ 5.0953e-05,  1.2614e-05, -9.5704e-05,  ...,  9.3829e-05,
           4.3309e-05, -4.6863e-05],
         ...,
         [ 5.6602e-05, -7.8821e-06,  2.2758e-04,  ...,  3.1643e-04,
           2.6160e-04,  7.0633e-05],
         [ 1.3375e-04,  2.0721e-04,  4.3221e-04,  ..., -2.7292e-05,
           3.4622e-04,  4.7208e-05],
         [ 2.6270e-04, -2.6640e-05,  2.4547e-04,  ..., -1.2006e-05,
          -9.2558e-05,  2.9981e-04]],

        [[-9.6226e-05,  1.6021e-04, -6.2277e-05,  ...,  3.3620e-04,
           1.1377e-04,  1.3117e-05],
         [-1.1280e-04,  1.7073e-04,  2.1375e-04,  ...,  2.0289e-04,
          -1.8187e-04, -1.9213e-04],
         [ 9.1149e-06,  2.3537e-04, -2.5101e-04,  ..., -1.8101e-04,
           2.8218e-04,  7.1444e-05],
         ...,
         [ 2.9207e-04,  2.0218e-04,  7.1060e-05,  ...,  3.9356e-05,
           1.0750e-04,  1.3642e-04],
         [-1.7866e-04,  2.4447e-04,  9.1956e-06,  ..., -1.7984e-04,
          -2.1547e-04, -1.1444e-04],
         [ 2.7012e-04, -5.3862e-05, -3.3919e-04,  ..., -6.2163e-05,
          -5.8702e-05,  2.0738e-04]]])
2025-05-14 03:32:21.801336 test begin: paddle.nn.functional.kl_div(Tensor([40, 20, 50],"float32"), Tensor([40, 20, 50],"float32"), "batchmean", True, )
-------
[not compare]  None tensor([[[-2.6018e-03, -3.2826e-03, -4.2983e-04,  ..., -9.6532e-04,
          -3.0939e-03, -1.0563e-03],
         [-1.8268e-03, -3.7506e-04, -5.3245e-04,  ..., -5.4906e-04,
          -1.9463e-03, -3.0082e-04],
         [-1.2979e-03, -1.0331e-03, -1.3707e-03,  ..., -1.4690e-03,
          -3.4544e-03, -5.0609e-04],
         ...,
         [-3.3969e-04, -3.9321e-04, -5.1167e-04,  ..., -9.4636e-04,
          -9.6211e-04, -2.8536e-03],
         [-1.4455e-03, -1.9564e-04, -7.0365e-04,  ..., -6.0784e-04,
          -1.0380e-03, -6.6967e-04],
         [-2.2501e-03, -1.3928e-03, -3.3012e-03,  ..., -8.1752e-04,
          -8.4062e-04, -1.7563e-03]],

        [[-1.9904e-03, -6.3484e-04, -1.0037e-03,  ..., -1.1845e-03,
          -7.3168e-04, -2.2000e-03],
         [-1.1597e-03, -1.0342e-03, -8.9580e-04,  ..., -4.8679e-04,
          -5.8821e-04, -8.9975e-04],
         [-2.7939e-03, -6.3983e-04, -1.2473e-04,  ..., -3.2730e-03,
          -2.5830e-03, -1.2946e-03],
         ...,
         [-2.9596e-04, -4.3926e-04, -7.4745e-04,  ..., -8.1643e-04,
          -6.3354e-04, -1.2671e-03],
         [-4.7143e-04, -1.8920e-03, -1.6939e-03,  ..., -1.4075e-03,
          -7.5842e-04, -1.1523e-03],
         [-2.5225e-03, -3.1851e-03, -9.1538e-04,  ..., -1.6535e-03,
          -2.4595e-03, -2.1908e-03]],

        [[-2.1642e-03, -1.9928e-03, -2.5976e-03,  ..., -1.3522e-03,
          -1.8721e-03, -1.0009e-03],
         [-1.9214e-03, -8.4282e-04, -4.9597e-04,  ..., -2.2743e-03,
          -1.9214e-03, -1.7960e-03],
         [-1.3491e-03, -9.6802e-04, -8.6278e-04,  ..., -2.7191e-03,
          -4.1095e-04, -2.1547e-03],
         ...,
         [-2.9337e-04, -9.7525e-04, -1.4957e-03,  ..., -6.2265e-04,
          -9.8872e-04, -1.4169e-03],
         [-3.2455e-04, -4.7393e-04, -7.0402e-04,  ..., -1.4684e-03,
          -1.6184e-03, -1.2869e-03],
         [-1.8306e-04, -3.1082e-03, -9.2867e-04,  ..., -3.4595e-04,
          -2.8140e-03, -2.1247e-04]],

        ...,

        [[-2.2276e-03, -2.5905e-03, -2.9200e-03,  ..., -9.3998e-04,
          -9.0065e-04, -3.4665e-03],
         [-1.9231e-03, -2.2650e-03, -1.3532e-03,  ..., -6.7644e-04,
          -4.4511e-04, -3.8647e-04],
         [-1.4363e-03, -1.0240e-03, -8.4062e-04,  ..., -2.2189e-03,
          -1.7982e-03, -2.9999e-03],
         ...,
         [-9.5343e-04, -7.5469e-04, -6.4511e-04,  ..., -2.2861e-03,
          -1.8224e-03, -2.3744e-03],
         [-2.0018e-03, -2.5385e-04, -1.9247e-03,  ..., -2.6132e-03,
          -1.3289e-03, -4.8241e-04],
         [-1.5058e-03, -1.0266e-03, -3.3467e-03,  ..., -1.0656e-03,
          -1.9666e-03, -1.5627e-03]],

        [[-1.9143e-03, -2.1677e-03, -1.8453e-03,  ..., -2.2276e-03,
          -2.1690e-03, -2.2765e-03],
         [-1.8364e-03, -5.8156e-04, -5.8469e-04,  ..., -1.6040e-04,
          -9.3409e-04, -6.7201e-04],
         [-6.0815e-04, -6.3701e-04, -9.8257e-04,  ..., -1.0747e-03,
          -1.6973e-03, -1.2259e-03],
         ...,
         [-1.8351e-03, -2.6001e-03, -1.6781e-04,  ..., -2.2774e-03,
          -1.4116e-03, -9.5988e-04],
         [-1.7190e-04, -6.1210e-04, -1.9924e-03,  ..., -1.2543e-03,
          -1.2916e-03, -4.4055e-04],
         [-3.1404e-03, -9.9364e-04, -7.6692e-04,  ..., -1.1081e-03,
          -1.2999e-04, -3.0982e-03]],

        [[-1.4229e-03, -1.5055e-03, -2.4219e-03,  ..., -2.5624e-03,
          -9.9404e-04, -7.3016e-04],
         [-9.1554e-04, -1.0064e-03, -3.1053e-03,  ..., -1.4588e-03,
          -1.6264e-03, -3.0868e-04],
         [-2.8162e-04, -1.1936e-03, -2.7703e-03,  ..., -1.0838e-03,
          -1.1820e-03, -1.1200e-03],
         ...,
         [-1.7327e-03, -8.2661e-04, -6.3368e-04,  ..., -4.7284e-04,
          -3.7202e-03, -8.6366e-04],
         [-1.1521e-03, -7.5553e-04, -2.1546e-03,  ..., -1.8726e-03,
          -3.8301e-04, -1.7511e-03],
         [-5.7880e-04, -2.4358e-03, -3.5037e-03,  ..., -1.5482e-03,
          -1.2287e-03, -3.9622e-05]]])
2025-05-14 03:32:22.004370 test begin: paddle.nn.functional.kl_div(Tensor([40, 20, 50],"float32"), Tensor([40, 20, 50],"float32"), "none", False, )
-------
[not compare]  None tensor([[[-1.1406e-02, -7.5395e-02, -7.1122e-02,  ..., -3.5311e-02,
           2.4495e-01, -1.3605e-02],
         [-9.6370e-03,  2.3503e-02,  4.4727e-03,  ...,  6.9719e-02,
          -2.9284e-02, -1.0777e-02],
         [ 1.0160e-03,  4.4183e-01,  1.2248e-01,  ...,  2.9046e-03,
           3.1233e-02,  6.6976e-02],
         ...,
         [ 6.1463e-02, -1.1427e-01, -2.3900e-02,  ..., -1.3078e-02,
          -3.0129e-02, -1.6339e-02],
         [ 2.4345e-02, -1.2344e-01,  5.4947e-02,  ..., -9.9966e-02,
           1.3782e-02, -2.9584e-02],
         [-6.9592e-02,  7.7091e-02,  2.4969e-02,  ...,  3.3344e-02,
           1.3493e-01,  7.4842e-03]],

        [[ 2.6267e-02, -1.0196e-02,  6.8493e-02,  ..., -1.0954e-02,
           1.4905e-01, -8.1780e-02],
         [ 3.5660e-02, -5.7844e-02, -8.8013e-03,  ...,  1.3694e-01,
          -4.8675e-02,  3.8976e-01],
         [-6.2865e-02,  2.2301e-01, -3.2999e-02,  ..., -1.4457e-02,
           4.3202e-03, -2.0834e-02],
         ...,
         [-2.1867e-02, -5.5633e-04,  6.4449e-02,  ...,  8.7387e-03,
          -3.6911e-02, -5.5895e-02],
         [-3.0432e-01, -4.9081e-03,  7.3976e-02,  ..., -9.3093e-02,
          -1.7416e-01,  8.0143e-02],
         [-5.3449e-03,  1.4649e-01, -2.1313e-01,  ...,  2.2110e-02,
           5.6887e-03,  6.4688e-03]],

        [[-4.4197e-02, -5.2269e-03, -7.3140e-03,  ..., -1.5723e-01,
           6.7895e-02,  1.1555e-02],
         [ 1.4804e-02,  1.0076e-01,  8.6521e-02,  ..., -6.8511e-02,
           4.1587e-02, -3.8247e-01],
         [-3.4229e-01,  3.5173e-02,  1.8453e-01,  ..., -2.4979e-02,
          -9.9527e-03,  1.3723e-01],
         ...,
         [ 1.2556e-02, -2.2762e-02,  7.6867e-02,  ..., -3.1230e-02,
           7.1984e-02, -3.8017e-03],
         [ 5.0159e-02, -7.1396e-02,  1.5531e-01,  ..., -2.3200e-01,
           6.0374e-02,  1.8148e-02],
         [-1.9079e-01,  1.4840e-01,  4.9168e-03,  ...,  1.9218e-01,
           7.1249e-02,  1.3644e-01]],

        ...,

        [[-2.8628e-01,  8.8457e-02, -1.0220e-01,  ..., -1.2477e-01,
           2.6636e-01, -2.9508e-03],
         [ 1.8698e-01,  1.8297e-01, -4.9149e-01,  ..., -7.5693e-02,
           5.2976e-02, -1.3967e-02],
         [-1.0865e-01, -1.3073e-01,  5.4220e-02,  ...,  1.7379e-02,
           7.9992e-02,  1.2172e-01],
         ...,
         [ 1.8124e-02, -6.4834e-02, -3.3353e-02,  ...,  1.0819e-02,
           2.1454e-01, -2.4692e-01],
         [ 5.1932e-02,  4.0433e-03, -8.3998e-02,  ...,  4.7181e-02,
           1.5548e-02,  3.4722e-01],
         [-4.2424e-01, -1.5926e-01,  2.3585e-03,  ...,  1.8746e-02,
          -1.6456e-02, -1.8829e-01]],

        [[-1.0433e-02, -2.6196e-02,  1.4410e-01,  ...,  3.3447e-01,
           9.8076e-02, -3.8215e-02],
         [ 1.5187e-02, -8.5575e-02, -2.1178e-01,  ...,  6.5018e-03,
          -2.7001e-02, -2.6481e-01],
         [-5.1696e-02, -2.6866e-02,  5.6954e-03,  ...,  2.6834e-02,
          -4.8764e-02, -3.2507e-02],
         ...,
         [-1.1982e-01, -1.0843e-01,  6.4498e-03,  ..., -2.2441e-02,
          -4.5761e-05,  3.5382e-01],
         [ 9.2102e-03, -1.5524e-02, -1.2219e-02,  ..., -5.4073e-02,
          -8.8203e-03,  1.2152e-02],
         [ 1.9268e-01, -1.5440e-01,  5.7147e-02,  ..., -2.9587e-02,
          -1.6188e-01, -3.0385e-02]],

        [[-2.2948e-02,  2.9967e-02, -6.1229e-02,  ..., -2.5350e-01,
           1.0087e-01, -4.3459e-02],
         [ 8.2915e-03,  1.1444e-01,  1.3836e-02,  ...,  1.8401e-01,
           4.1535e-02, -2.5033e-02],
         [-5.5733e-03,  3.4888e-02, -1.5908e-01,  ..., -2.7636e-02,
          -4.8109e-03, -4.3868e-02],
         ...,
         [ 9.5863e-02, -6.2700e-02, -9.7099e-02,  ..., -2.3984e-02,
           1.3035e-03, -6.5136e-03],
         [-3.8586e-02, -1.7343e-01,  1.4295e-01,  ..., -6.1960e-02,
          -3.1679e-01,  6.6212e-02],
         [ 8.5265e-02,  3.8627e-02,  2.1296e-01,  ..., -2.6893e-01,
          -2.4552e-01, -3.6782e-02]]])
2025-05-14 03:32:22.139518 test begin: paddle.nn.functional.kl_div(Tensor([5, 20],"float32"), Tensor([5, 20],"float64"), "mean", False, )
/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:3384: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
-------
[not compare]  None tensor([[ 1.9939e-03, -5.0216e-04,  7.1233e-04,  1.2327e-03, -7.8919e-04,
         -3.2328e-04,  1.3484e-04,  8.4630e-04, -1.0066e-03, -1.6563e-03,
         -9.5694e-04,  2.5851e-03,  8.3379e-04, -2.1150e-04, -1.3460e-03,
         -1.2398e-04, -1.3036e-03,  7.5046e-04,  2.0140e-03,  2.3177e-04],
        [ 2.4283e-05,  5.6835e-04, -7.9803e-04, -7.3149e-04,  1.2546e-03,
         -5.8820e-05,  2.0522e-04,  2.0520e-03, -2.9820e-05, -4.9116e-05,
         -3.3489e-04, -1.1277e-03, -7.2090e-05,  1.2769e-03,  2.4370e-03,
         -1.6171e-03,  2.4961e-05,  1.4526e-03, -1.0025e-03,  6.4139e-04],
        [ 2.8313e-04, -5.4571e-04, -1.0797e-03, -5.2882e-04, -1.6848e-04,
         -1.2366e-03,  6.5503e-04,  1.1064e-03, -7.0925e-04,  1.6954e-03,
         -1.1547e-03, -6.5454e-04,  9.0453e-04, -6.0559e-04,  1.1626e-05,
          3.8819e-04,  1.7040e-04,  2.7761e-05,  2.8458e-04,  2.2525e-03],
        [-4.6915e-04, -1.4237e-03,  7.3855e-04, -9.9739e-04,  2.0515e-03,
          1.3233e-03, -6.8069e-04, -1.2812e-03,  1.2819e-03, -1.4954e-03,
         -1.1368e-03, -2.7614e-04,  2.7230e-03,  1.0941e-03,  2.4322e-04,
         -1.2724e-03, -2.1065e-03,  9.9334e-05,  6.0891e-06, -8.0046e-04],
        [ 1.6497e-04,  4.9649e-04,  2.4885e-03,  1.1621e-03, -1.0632e-03,
         -8.0994e-04,  1.7160e-03,  2.1227e-03, -8.4553e-04,  1.2185e-03,
          2.7607e-03,  9.6517e-04,  9.8108e-04, -1.5267e-03,  7.3920e-04,
         -1.4298e-03, -2.3337e-04, -1.3596e-04,  6.7951e-04, -1.4572e-04]],
       dtype=torch.float64)
2025-05-14 03:32:22.269469 test begin: paddle.nn.functional.kl_div(Tensor([5, 20],"float64"), Tensor([5, 20],"float32"), )
-------
[not compare]  None tensor([[-5.9187e-04, -2.9263e-04, -1.2890e-03, -8.0516e-04, -2.4862e-06,
         -2.6635e-04, -1.8153e-03, -1.7700e-04, -4.3058e-04, -1.4854e-04,
         -2.9770e-05, -3.7995e-04, -1.3019e-03, -1.1981e-03,  2.1974e-05,
         -4.4087e-04, -2.2042e-04,  4.8970e-04, -1.6984e-04,  1.2206e-03],
        [-8.0652e-04, -1.4700e-03,  1.1549e-03, -1.1585e-03, -6.9919e-04,
         -2.8007e-04,  4.1550e-04,  8.2209e-04,  7.2487e-04,  4.1972e-05,
          1.4759e-04, -1.0553e-03,  9.2793e-04, -2.4003e-04,  1.1741e-04,
          1.1213e-03, -1.4108e-03,  7.5145e-04,  7.2987e-04, -1.2978e-04],
        [ 4.3374e-04,  9.1685e-04, -3.8977e-04,  1.8432e-04, -9.0832e-04,
         -1.3565e-04,  7.9228e-05,  4.4678e-04,  8.0166e-04,  4.9397e-04,
          8.3923e-04, -7.6354e-04,  1.1104e-03, -3.6892e-04, -8.9690e-05,
          2.0177e-04, -7.1274e-04, -1.2834e-03, -5.5905e-04,  7.9375e-04],
        [ 4.4748e-05, -3.3045e-04, -1.4217e-03, -5.1033e-04,  5.7100e-05,
         -8.0838e-04, -8.4393e-04,  5.4096e-04, -6.8109e-04, -9.1538e-04,
          3.6185e-04,  7.1806e-04,  9.1177e-04,  8.3613e-04, -3.5381e-04,
          1.3660e-06, -7.1640e-04, -1.0704e-03,  3.3458e-04, -1.7574e-04],
        [ 1.3400e-03,  4.2531e-04,  8.3465e-04, -9.5897e-05,  7.4827e-04,
          6.7863e-04, -5.8486e-04, -9.8967e-04,  4.4039e-04,  1.7038e-04,
          3.7707e-04, -8.1799e-04,  5.1444e-04, -4.9643e-04, -5.3415e-04,
         -6.6967e-04,  1.1149e-04, -3.5807e-04, -7.4931e-04,  2.9269e-04]])
2025-05-14 03:32:22.403431 test begin: paddle.nn.functional.kl_div(Tensor([5, 20],"float64"), Tensor([5, 20],"float64"), "batchmean", False, )
-------
[not compare]  None tensor([[ 0.0061, -0.0233,  0.0194,  0.0229, -0.0059,  0.0059, -0.0490,  0.0257,
         -0.0037, -0.0039,  0.0019, -0.0427, -0.0207, -0.0036, -0.0210, -0.0388,
         -0.0350, -0.0014,  0.0120,  0.0218],
        [ 0.0087, -0.0103,  0.0029,  0.0091, -0.0428,  0.0091,  0.0095, -0.0506,
         -0.0264, -0.0503,  0.0089, -0.0105, -0.0089,  0.0020,  0.0327, -0.0339,
         -0.0247, -0.0005,  0.0145,  0.0019],
        [-0.0270,  0.0107,  0.0271,  0.0378, -0.0045, -0.0209,  0.0065,  0.0193,
         -0.0115,  0.0392, -0.0154, -0.0077, -0.0023,  0.0076,  0.0146, -0.0096,
          0.0055,  0.0070,  0.0160,  0.0189],
        [-0.0239,  0.0032,  0.0244, -0.0099, -0.0145,  0.0260, -0.0196, -0.0079,
          0.0415, -0.0013, -0.0088,  0.0260,  0.0257, -0.0478, -0.0258,  0.0135,
         -0.0324, -0.0293,  0.0016,  0.0162],
        [ 0.0174,  0.0341, -0.0415, -0.0307, -0.0322,  0.0127,  0.0376,  0.0115,
          0.0175, -0.0002, -0.0288,  0.0167,  0.0038, -0.0112,  0.0350, -0.0024,
          0.0222, -0.0316, -0.0416, -0.0044]], dtype=torch.float64)
2025-05-14 03:32:22.536069 test begin: paddle.nn.functional.kl_div(Tensor([5, 20],"float64"), Tensor([5, 20],"float64"), "mean", False, )
-------
[not compare]  None tensor([[ 2.2178e-05,  2.1714e-05,  4.6351e-05, -3.0950e-05, -2.6201e-06,
         -5.1612e-05, -3.8512e-05,  2.5599e-05, -1.9179e-06,  1.3343e-05,
         -3.7640e-05, -1.6190e-05,  6.8811e-05,  6.8957e-05, -1.5063e-06,
          5.7848e-05, -4.0494e-05, -4.5866e-05,  4.6230e-06, -1.9939e-05],
        [ 6.7052e-05, -1.8102e-05, -4.0042e-05,  4.0250e-05,  4.8453e-05,
         -6.9454e-07, -1.2008e-05, -2.4962e-05, -3.3077e-05, -4.4536e-05,
         -5.2084e-05,  3.5472e-06, -2.5861e-06, -2.8168e-06,  1.5786e-06,
         -2.4228e-05, -4.9935e-05, -5.4486e-06, -9.8882e-06,  5.6116e-05],
        [ 7.4540e-05, -2.4721e-05,  2.9240e-06, -1.1577e-05, -2.0864e-05,
          3.9241e-05, -1.3428e-05,  6.1291e-05, -4.2756e-05, -2.6394e-05,
         -2.9866e-05, -2.6630e-05,  1.0075e-06, -2.9265e-05,  2.2197e-05,
          2.0560e-05, -2.3582e-05,  1.3536e-05, -9.4650e-06,  7.1164e-06],
        [-4.3689e-06,  3.6348e-05, -2.4584e-05, -1.6900e-05,  4.5426e-05,
          7.0217e-05, -3.6125e-05,  1.7828e-05, -3.4749e-05, -7.2495e-06,
         -2.1890e-06, -3.6814e-05,  3.3525e-05, -1.9713e-05, -7.2424e-07,
         -5.7428e-05, -3.1805e-05,  1.2339e-05, -3.5464e-06,  8.2342e-06],
        [ 5.7885e-06,  4.0908e-05,  6.3130e-05,  7.2700e-05,  6.4686e-05,
         -2.4682e-05, -1.8293e-05,  3.6319e-05,  1.2749e-05,  6.3549e-06,
         -6.5775e-06, -1.9358e-05,  5.6763e-06,  6.7021e-06, -4.1473e-06,
         -6.4905e-06,  5.4142e-05,  2.3332e-06, -3.2820e-05,  1.2192e-05]],
       dtype=torch.float64)
2025-05-14 03:32:22.664516 test begin: paddle.nn.functional.kl_div(Tensor([5, 20],"float64"), Tensor([5, 20],"float64"), "mean", True, )
-------
[not compare]  None tensor([[0.0007, 0.0057, 0.0101, 0.0053, 0.0072, 0.0077, 0.0043, 0.0058, 0.0032,
         0.0070, 0.0188, 0.0073, 0.0100, 0.0053, 0.0253, 0.0132, 0.0294, 0.0107,
         0.0221, 0.0087],
        [0.0210, 0.0079, 0.0060, 0.0062, 0.0070, 0.0065, 0.0019, 0.0134, 0.0075,
         0.0059, 0.0091, 0.0128, 0.0019, 0.0079, 0.0095, 0.0036, 0.0083, 0.0131,
         0.0110, 0.0057],
        [0.0281, 0.0293, 0.0095, 0.0181, 0.0071, 0.0055, 0.0081, 0.0027, 0.0031,
         0.0053, 0.0298, 0.0159, 0.0088, 0.0193, 0.0144, 0.0155, 0.0066, 0.0241,
         0.0028, 0.0100],
        [0.0187, 0.0065, 0.0184, 0.0071, 0.0190, 0.0060, 0.0057, 0.0137, 0.0086,
         0.0138, 0.0067, 0.0048, 0.0114, 0.0187, 0.0132, 0.0221, 0.0071, 0.0115,
         0.0180, 0.0092],
        [0.0231, 0.0109, 0.0173, 0.0057, 0.0121, 0.0074, 0.0093, 0.0091, 0.0133,
         0.0245, 0.0075, 0.0173, 0.0082, 0.0053, 0.0116, 0.0222, 0.0192, 0.0220,
         0.0075, 0.0095]], dtype=torch.float64)
2025-05-14 03:32:22.791389 test begin: paddle.nn.functional.kl_div(Tensor([5, 20],"float64"), Tensor([5, 20],"float64"), "none", False, )
-------
[not compare]  None tensor([[ 3.1805e-02,  1.1041e-01,  8.8322e-03, -8.2339e-02, -1.0343e-03,
          1.9733e-01,  2.0735e-01,  1.0979e-01,  2.4141e-02,  5.4291e-02,
          9.5700e-02,  2.5252e-01,  8.7180e-04, -3.7847e-01,  2.5737e-01,
          1.0006e-02,  2.2246e-02, -2.0712e-01,  4.2827e-02, -4.3045e-02],
        [-3.4457e-02, -5.3035e-02, -4.2234e-02,  1.0452e-01,  1.3600e-02,
          2.8015e-02,  5.7961e-02,  6.9200e-03, -6.3880e-03,  3.3941e-02,
         -5.6937e-02, -1.6534e-02,  8.0595e-03, -6.6992e-02,  5.1277e-02,
          2.3139e-01, -4.3856e-02, -1.0039e-02,  2.6401e-01, -7.7328e-02],
        [-2.0217e-01, -4.5428e-02, -9.3563e-02, -1.3255e-01, -9.6183e-02,
         -6.4364e-02, -9.1490e-02,  6.6377e-02,  1.6067e-02,  4.5669e-02,
          9.4072e-02, -3.4178e-03,  1.7313e-03, -3.1377e-01,  1.3352e-01,
         -9.6967e-02, -7.4056e-02,  9.0433e-03,  1.9467e-02,  8.7918e-02],
        [-1.5622e-02, -8.5571e-02,  5.7945e-02, -7.7645e-02, -3.2687e-01,
          1.7057e-01, -1.8025e-02, -1.1927e-03,  9.4006e-02,  3.3363e-01,
         -4.2224e-03,  1.1860e-01,  6.5057e-05, -1.5584e-01,  1.4859e-02,
         -3.7163e-02, -1.0187e-01,  4.5560e-03, -1.1180e-02, -6.2134e-02],
        [-3.2857e-02,  4.0659e-02,  7.6932e-02, -1.4685e-01, -3.7712e-02,
         -4.3453e-03, -7.5935e-02,  5.7421e-02,  3.0244e-02,  4.7270e-04,
         -9.0605e-02, -1.0527e-02,  2.3634e-02,  1.1104e-02,  2.4523e-01,
         -1.3321e-01, -3.6957e-01, -6.6372e-03, -7.3579e-02,  1.3889e-02]],
       dtype=torch.float64)
2025-05-14 03:32:22.915178 test begin: paddle.nn.functional.kl_div(Tensor([5, 20],"float64"), Tensor([5, 20],"float64"), "sum", False, )
-------
[not compare]  None tensor([[-4.0325e-02, -5.6566e-03, -1.1337e-01, -3.2838e-02,  2.8103e-04,
         -2.9962e-02, -6.9827e-02,  2.6431e-03, -5.5839e-03, -4.5157e-03,
         -5.0167e-02, -8.9359e-02, -1.1467e-02,  7.6840e-02, -7.8217e-02,
          1.8448e-02, -1.9682e-03,  1.1072e-01, -1.1041e-01, -1.0308e-01],
        [ 1.9709e-02,  1.2838e-02, -7.5168e-02,  6.1058e-02,  1.4226e-01,
         -2.1946e-02,  4.9423e-02, -2.2095e-02,  9.6715e-02,  1.3955e-01,
          7.3643e-02, -4.5471e-02,  6.4401e-02,  1.3787e-01,  3.7002e-02,
          6.1471e-02, -1.1795e-01,  1.3446e-02, -6.1156e-02,  1.5895e-03],
        [-1.3285e-01,  8.1773e-02, -1.1237e-01,  3.4167e-02, -3.9062e-02,
         -8.8762e-02, -2.4644e-03,  4.7680e-02, -3.3004e-02,  1.2451e-01,
          1.0543e-01,  4.6254e-02,  7.0992e-02, -3.4451e-02,  7.3340e-02,
         -9.7237e-02, -3.1819e-02,  5.4168e-02, -1.8283e-02,  1.2729e-02],
        [-1.2939e-02,  5.4231e-02, -2.8256e-02, -1.1236e-01, -1.4093e-01,
          3.7170e-02, -1.1476e-01, -1.6081e-02, -1.6966e-01, -5.8707e-02,
         -2.1289e-03,  4.2977e-02, -7.5261e-03,  1.9512e-03,  1.3200e-02,
         -7.1952e-03,  1.2948e-01, -8.7617e-03, -1.2700e-01,  7.7306e-02],
        [-6.7163e-03, -5.5619e-02,  2.4720e-03, -7.2564e-02,  7.3641e-02,
          1.8302e-02,  5.7739e-03, -3.8486e-02, -5.5779e-03, -1.5940e-02,
         -9.6020e-02,  4.5976e-02,  2.1687e-02, -8.4204e-03, -5.8445e-02,
         -3.6314e-02, -7.2529e-02,  1.0314e-04, -2.5850e-02, -8.3288e-02]],
       dtype=torch.float64)
2025-05-14 03:32:23.046341 test begin: paddle.nn.functional.kl_div(Tensor([5, 2],"float32"), label=Tensor([5, 2],"float32"), reduction="mean", name=None, )
-------
[not compare]  None tensor([[-0.0051, -0.0107],
        [-0.0001, -0.0065],
        [ 0.0057,  0.0044],
        [-0.0024, -0.0085],
        [-0.0013, -0.0036]])
2025-05-14 03:32:23.171952 test begin: paddle.nn.functional.kl_div(Tensor([5, 2],"float64"), Tensor([5, 2],"float64"), "mean", False, )
-------
[not compare]  None tensor([[-0.0026, -0.0228],
        [-0.0090,  0.0196],
        [ 0.0008, -0.0022],
        [ 0.0083, -0.0032],
        [ 0.0196, -0.0029]], dtype=torch.float64)
2025-05-14 03:32:23.352873 test begin: paddle.nn.functional.kl_div(Tensor([],"float64"), Tensor([],"float64"), "batchmean", False, )
-------
[not compare]  None tensor(0.0392, dtype=torch.float64)
2025-05-14 03:32:23.503463 test begin: paddle.nn.functional.kl_div(input=Tensor([32, 128, 128],"float32"), label=Tensor([32, 128, 128],"float32"), reduction="batchmean", )
-------
[not compare]  None tensor([[[ 2.8457e-03,  2.8444e-03,  3.8087e-03,  ...,  1.2426e-03,
          -2.5744e-03, -1.4082e-03],
         [-4.5493e-03,  1.3553e-03,  1.2954e-03,  ..., -5.9981e-04,
          -4.8424e-05,  6.9275e-04],
         [ 1.3693e-03,  4.6899e-04, -3.8478e-04,  ..., -2.9444e-03,
          -3.7271e-04,  3.3293e-03],
         ...,
         [-2.6440e-03, -3.0566e-03,  1.0517e-03,  ...,  2.3165e-04,
          -4.1547e-04,  2.5950e-03],
         [ 1.4290e-03, -1.2902e-03,  1.0262e-03,  ..., -4.2083e-03,
           1.7142e-03,  3.8504e-03],
         [-1.5111e-03, -4.1758e-03,  2.0016e-03,  ...,  2.0330e-03,
           1.8262e-03, -4.6773e-04]],

        [[ 3.0480e-03,  2.0447e-03, -1.5640e-03,  ...,  3.3353e-03,
           6.8576e-04, -1.0183e-03],
         [-6.7012e-04, -1.3743e-03, -1.1239e-03,  ...,  2.1093e-04,
          -4.7879e-04,  6.3171e-04],
         [ 2.3475e-03,  7.2357e-04,  2.1945e-03,  ..., -2.6199e-03,
           7.0876e-04,  1.0917e-04],
         ...,
         [-4.0595e-04,  1.4471e-04, -9.6417e-04,  ..., -8.7342e-04,
           3.4088e-04, -3.6076e-03],
         [-5.1484e-04, -1.0428e-03, -6.3360e-04,  ..., -5.1653e-04,
           1.2878e-03, -2.4746e-05],
         [-1.1771e-03,  1.6162e-03,  9.7911e-04,  ..., -3.1777e-04,
          -1.3878e-03,  1.1846e-03]],

        [[-1.9227e-03,  1.9056e-03, -9.2782e-04,  ..., -2.6576e-04,
          -2.7332e-03, -2.0880e-03],
         [ 1.4144e-03, -4.1612e-03,  1.2748e-04,  ..., -2.6415e-03,
          -4.7096e-05, -2.7462e-03],
         [-4.0979e-03, -9.1858e-04, -1.5939e-04,  ..., -4.2682e-03,
          -2.1939e-03,  1.8611e-03],
         ...,
         [ 3.0056e-03,  8.5181e-04,  2.0760e-03,  ..., -2.8588e-04,
          -3.3758e-03,  2.1148e-04],
         [ 3.9042e-05, -8.7717e-04,  4.0412e-04,  ..., -8.1848e-04,
          -3.0940e-03, -1.8533e-03],
         [ 1.4920e-04,  1.3852e-03, -2.4461e-03,  ..., -2.3941e-04,
          -3.2676e-03, -4.2608e-03]],

        ...,

        [[-3.0772e-05, -4.3902e-03,  1.5114e-03,  ...,  3.2778e-03,
           6.7978e-04, -1.2340e-03],
         [-9.0003e-04,  1.2802e-03,  2.5889e-03,  ..., -2.3611e-03,
          -6.0160e-04,  1.4530e-03],
         [ 1.2802e-04, -1.0618e-03,  3.6096e-03,  ...,  1.7469e-04,
          -9.6305e-04, -2.4736e-03],
         ...,
         [ 1.8681e-03,  3.8296e-03, -2.8056e-04,  ...,  4.7134e-04,
           4.4608e-04, -3.2446e-03],
         [-7.6408e-05,  4.9287e-04, -6.9848e-04,  ..., -3.3710e-03,
          -3.7249e-03,  1.8017e-03],
         [ 1.2097e-03, -1.1826e-03,  7.5736e-04,  ...,  2.0927e-03,
          -2.0257e-03, -1.4850e-03]],

        [[ 3.2704e-03, -2.5943e-03,  2.0294e-03,  ..., -2.2116e-03,
          -2.1453e-03, -5.8658e-04],
         [ 4.6242e-04,  4.7505e-04, -4.3499e-03,  ..., -1.3715e-03,
          -9.5827e-05,  1.0911e-03],
         [-1.2285e-03,  5.3242e-04,  2.7679e-03,  ...,  1.0870e-03,
          -7.4796e-04, -2.4608e-04],
         ...,
         [-3.1524e-03, -2.4617e-03, -2.8336e-05,  ..., -3.6843e-04,
           1.3852e-03,  1.2975e-03],
         [-1.3615e-03, -1.3724e-03, -2.3933e-03,  ..., -1.4141e-03,
           2.1391e-03,  1.2556e-03],
         [ 1.2091e-03,  4.8773e-04, -4.8638e-03,  ...,  8.0294e-04,
           1.2440e-03, -1.1670e-03]],

        [[ 9.8147e-04, -2.6563e-03, -2.3191e-03,  ...,  3.0305e-03,
           3.1406e-03,  1.8633e-03],
         [-6.1123e-04,  8.0909e-04,  4.3007e-05,  ..., -1.3852e-03,
           1.5926e-03, -4.6667e-04],
         [-3.3681e-05, -4.4499e-04, -1.2834e-03,  ..., -2.0096e-03,
          -6.6778e-04,  2.4266e-03],
         ...,
         [ 2.7148e-04,  8.8128e-04,  2.9411e-03,  ..., -1.1192e-03,
          -1.8464e-03, -4.4540e-03],
         [-9.5705e-04,  2.4151e-03,  3.2153e-04,  ..., -6.6009e-04,
          -2.5259e-03, -1.5643e-03],
         [-5.3910e-04, -1.0871e-03,  2.4296e-03,  ..., -1.3939e-03,
          -1.2242e-03,  4.1429e-04]]])