paddle.nn.functional.embedding(Tensor([1, 1],"int64"), weight=Tensor([32000, 64],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 20],"int64"), weight=Tensor([1024, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 20],"int64"), weight=Tensor([1024, 32],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 20],"int64"), weight=Tensor([128001, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 20],"int64"), weight=Tensor([30000, 128],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 300, 4096],"int64"), Tensor([10, 3],"float32"), padding_idx=1, )
paddle.nn.functional.embedding(Tensor([1, 44],"int64"), weight=Tensor([40000, 8],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 45],"int64"), weight=Tensor([40000, 8],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 46],"int64"), weight=Tensor([40000, 8],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 21],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 24],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 25],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 26],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 27],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 28],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 28],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 29],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 30],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 31],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 32],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 32],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 33],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 33],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 34],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 34],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 35],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 35],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 36],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 36],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 37],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 37],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 38],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 38],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 39],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 39],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 40],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 41],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 42],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 43],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 44],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 45],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 46],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 47],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 48],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 49],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([104, 9],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([112, 12],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([112, 17],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([112, 21],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([112, 23],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([112, 26],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([112, 27],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([112, 28],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([112, 29],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([112, 29],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([112, 30],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([112, 30],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([112, 31],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([112, 32],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([112, 33],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([112, 33],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([112, 34],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([112, 34],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([112, 35],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([112, 35],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([112, 36],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([112, 36],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([112, 37],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([112, 38],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([112, 39],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([112, 40],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([112, 41],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([112, 42],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([112, 43],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([112, 44],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([112, 45],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([12, 7],"int32"), weight=Tensor([109, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([12, 7],"int32"), weight=Tensor([84, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([12, 7],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([120, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([120, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([120, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([120, 22],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([120, 24],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([120, 25],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([120, 26],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([120, 26],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([120, 27],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([120, 27],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([120, 28],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([120, 29],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([120, 30],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([120, 31],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([120, 31],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([120, 32],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([120, 32],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([120, 33],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([120, 33],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([120, 34],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([120, 34],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([120, 35],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([120, 36],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([120, 37],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([120, 38],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([120, 39],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([120, 40],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([120, 41],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([120, 42],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([128, 11],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([128, 13],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([128, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([128, 22],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([128, 23],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([128, 23],"int64"), weight=Tensor([6629, 384],"float16"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([128, 23],"int64"), weight=Tensor([6629, 384],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([128, 24],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([128, 25],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([128, 25],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([128, 26],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([128, 27],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([128, 28],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([128, 28],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([128, 29],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([128, 29],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([128, 30],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([128, 30],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([128, 31],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([128, 31],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([128, 32],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([128, 32],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([128, 33],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([128, 34],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([128, 35],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([128, 36],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([128, 37],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([128, 38],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([128, 39],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([128, 40],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 10],"int32"), weight=Tensor([81, 24],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 10],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 2],"int64"), weight=Tensor([32, 16],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 3],"int32"), weight=Tensor([81, 24],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 3],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 4, 7],"int32"), weight=Tensor([99, 16],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 4, 7],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([100, 16],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([103, 24],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([109, 128],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([109, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([109, 32],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([109, 32],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([109, 64],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([110, 16],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([512, 64],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([81, 24],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([84, 128],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([84, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([84, 32],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([84, 32],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([84, 64],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([85, 16],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([99, 128],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([99, 16],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([99, 64],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 7],"int64"), weight=Tensor([128, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 7],"int64"), weight=Tensor([512, 64],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 8],"int32"), weight=Tensor([109, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 8],"int32"), weight=Tensor([84, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([13, 8],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([136, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([136, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([136, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([136, 21],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([136, 22],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([136, 23],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([136, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([136, 24],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([136, 25],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([136, 26],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([136, 26],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([136, 27],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([136, 27],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([136, 28],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([136, 28],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([136, 29],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([136, 29],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([136, 30],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([136, 30],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([136, 31],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([136, 32],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([136, 33],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([136, 34],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([136, 35],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([136, 36],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([136, 37],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([136, 9],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([14, 209],"int64"), weight=Tensor([50000, 384],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([144, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([144, 15],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([144, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([144, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([144, 21],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([144, 21],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([144, 22],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([144, 23],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([144, 23],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([144, 24],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([144, 25],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([144, 25],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([144, 26],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([144, 26],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([144, 27],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([144, 27],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([144, 28],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([144, 28],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([144, 29],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([144, 30],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([144, 31],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([144, 32],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([144, 33],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([144, 34],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([144, 35],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([15, 234],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([15, 244],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([152, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([152, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([152, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([152, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([152, 21],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([152, 22],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([152, 23],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([152, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([152, 24],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([152, 25],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([152, 25],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([152, 26],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([152, 26],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([152, 27],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([152, 28],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([152, 29],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([152, 30],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([152, 31],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([152, 32],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([152, 33],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([16, 100],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([16, 109],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([16, 115],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([16, 116],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([16, 122],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([16, 141],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([16, 146],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([16, 149],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([16, 156],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([16, 166],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([16, 170],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([16, 171],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([16, 173],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([16, 174],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([16, 176],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([16, 178],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([16, 182],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([16, 182],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([16, 199],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([16, 205],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([16, 210],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([16, 217],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([16, 217],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([16, 227],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([16, 227],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([16, 264],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([16, 62],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([16, 81],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([16, 88],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([16, 88],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([16, 93],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([16, 94],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([160, 11],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([160, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([160, 17],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([160, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([160, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([160, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([160, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([160, 21],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([160, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([160, 22],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([160, 23],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([160, 23],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([160, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([160, 24],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([160, 25],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([160, 25],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([160, 26],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([160, 27],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([160, 28],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([160, 29],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([160, 30],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([160, 31],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([160, 32],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([160, 7],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([168, 12],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([168, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([168, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([168, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([168, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([168, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([168, 21],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([168, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([168, 22],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([168, 23],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([168, 23],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([168, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([168, 24],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([168, 25],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([168, 26],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([168, 27],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([168, 28],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([168, 29],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([168, 30],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([176, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([176, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([176, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([176, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([176, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([176, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([176, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([176, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([176, 21],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([176, 21],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([176, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([176, 22],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([176, 23],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([176, 23],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([176, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([176, 25],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([176, 26],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([176, 27],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([176, 28],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([176, 29],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([184, 13],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([184, 14],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([184, 15],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([184, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([184, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([184, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([184, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([184, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([184, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([184, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([184, 21],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([184, 21],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([184, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([184, 22],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([184, 23],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([184, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([184, 25],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([184, 26],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([184, 27],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([184, 7],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([192, 10],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([192, 15],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([192, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([192, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([192, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([192, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([192, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([192, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([192, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([192, 21],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([192, 21],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([192, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([192, 22],"int64"), weight=Tensor([6629, 384],"float16"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([192, 23],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([192, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([192, 25],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([192, 26],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([192, 7],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1],"int64"), weight=Tensor([19529, 300],"float32"), padding_idx=19528, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([2, 10],"int32"), weight=Tensor([1801, 8],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([2, 10],"int64"), weight=Tensor([31985, 64],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([2, 10],"int64"), weight=Tensor([32000, 64],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([2, 10],"int64"), weight=Tensor([32010, 64],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([2, 1],"int64"), weight=Tensor([32000, 64],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([2, 3],"int32"), weight=Tensor([1801, 8],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([2, 3],"int64"), Tensor([10, 4],"float32"), padding_idx=-1, scale_grad_by_freq=False, )
paddle.nn.functional.embedding(Tensor([2, 3],"int64"), Tensor([10, 4],"float32"), padding_idx=-1, scale_grad_by_freq=True, )
paddle.nn.functional.embedding(Tensor([2, 4],"int64"), Tensor([10, 4],"float32"), padding_idx=2, scale_grad_by_freq=False, )
paddle.nn.functional.embedding(Tensor([2, 4],"int64"), Tensor([10, 4],"float32"), padding_idx=2, scale_grad_by_freq=True, )
paddle.nn.functional.embedding(Tensor([2, 5],"int64"), weight=Tensor([32000, 64],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([2, 64],"int64"), weight=Tensor([30522, 768],"float16"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([2, 7],"int32"), weight=Tensor([1801, 8],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([200, 14],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([200, 15],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([200, 15],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([200, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([200, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([200, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([200, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([200, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([200, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([200, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([200, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([200, 21],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([200, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([200, 23],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([200, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([200, 25],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([208, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([208, 14],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([208, 15],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([208, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([208, 17],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([208, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([208, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([208, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([208, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([208, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([208, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([208, 21],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([208, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([208, 23],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([208, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([216, 10],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([216, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([216, 17],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([216, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([216, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([216, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([216, 21],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([216, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([216, 23],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([224, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([224, 14],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([224, 15],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([224, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([224, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([224, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([232, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([232, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([232, 17],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([232, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([232, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([232, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([232, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([232, 21],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([232, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 101],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 103],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 104],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 105],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 106],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 107],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 109],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 110],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 110],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 111],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 112],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 113],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 114],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 115],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 116],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 116],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 117],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 118],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 119],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 121],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 122],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 122],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 123],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 124],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 126],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 128],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 129],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 130],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 131],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 132],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 133],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 135],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 136],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 137],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 139],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 140],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 141],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 142],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 144],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 144],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 146],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 149],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 149],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 150],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 151],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 153],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 154],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 157],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 158],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 159],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 160],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 162],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 162],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 163],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 163],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 171],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 173],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 174],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 176],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 178],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 182],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 205],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 68],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 68],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 72],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 80],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 81],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 81],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 82],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 83],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 84],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 86],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 87],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 89],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 91],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 94],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 96],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 97],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 97],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 98],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 99],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([24, 99],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([240, 12],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([240, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([240, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([240, 14],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([240, 15],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([240, 15],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([240, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([240, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([240, 17],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([240, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([240, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([240, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([240, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([240, 21],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([240, 7],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([240, 9],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([256, 11],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([256, 12],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([256, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([256, 14],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([256, 15],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([256, 15],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([256, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([256, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([256, 17],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([256, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([256, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([256, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([264, 12],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([264, 13],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([264, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([264, 15],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([264, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([264, 17],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([264, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([264, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([272, 11],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([272, 12],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([272, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([272, 14],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([272, 15],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([272, 5],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([272, 6],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([280, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([280, 15],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([280, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([280, 17],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([280, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([288, 10],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([288, 11],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([288, 12],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([288, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([288, 14],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([296, 11],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([296, 13],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([296, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([296, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([296, 15],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([296, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([296, 17],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([296, 8],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([2],"int64"), weight=Tensor([100, 300],"float32"), padding_idx=99, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([2],"int64"), weight=Tensor([39980, 8],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([3, 1],"int64"), weight=Tensor([10, 3],"float32"), padding_idx=9, max_norm=0.5, norm_type=3.0, sparse=True, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([3, 1],"int64"), weight=Tensor([10, 3],"float32"), padding_idx=9, max_norm=None, norm_type=2.0, sparse=True, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([3, 4],"int64"), Tensor([10, 4],"float64"), padding_idx=-4, )
paddle.nn.functional.embedding(Tensor([3, 4],"int64"), Tensor([10, 4],"float64"), padding_idx=9, )
paddle.nn.functional.embedding(Tensor([312, 10],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([312, 11],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([312, 12],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([312, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([312, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([312, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([312, 6],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([312, 8],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 100],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 101],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 101],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 102],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 103],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 103],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 104],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 104],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 105],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 105],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 106],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 106],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 107],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 107],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 108],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 109],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 109],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 110],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 111],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 111],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 112],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 112],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 113],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 113],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 114],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 114],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 115],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 115],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 117],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 117],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 118],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 119],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 121],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 122],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 123],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 124],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 124],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 125],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 126],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 126],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 127],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 128],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 129],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 130],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 131],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 132],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 133],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 135],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 136],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 137],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 139],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 140],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 141],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 142],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 144],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 146],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 150],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 151],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 153],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 154],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 157],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 158],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 159],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 43],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 46],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 50],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 512],"int64"), weight=Tensor([40000, 768],"float16"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 512],"int64"), weight=Tensor([40000, 768],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 53],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 54],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 60],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 61],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 62],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 63],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 64],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 65],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 66],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 67],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 68],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 69],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 70],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 71],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 72],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 73],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 74],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 75],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 76],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 77],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 78],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 79],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 80],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 80],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 81],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 82],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 83],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 83],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 84],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 85],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 86],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 87],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 87],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 88],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 89],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 89],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 90],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 91],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 91],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 92],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 92],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 93],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 93],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 94],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 95],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 95],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 96],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 96],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 97],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 97],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 98],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 98],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 99],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([32, 99],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([320, 12],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([320, 13],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([320, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([320, 15],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([320, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([336, 10],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([336, 11],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([336, 11],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([336, 12],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([336, 12],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([336, 13],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([336, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([336, 15],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([336, 5],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([336, 6],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([336, 9],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([352, 11],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([352, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([360, 10],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([360, 11],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([360, 11],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([360, 12],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([360, 13],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([360, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([360, 6],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([360, 9],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([368, 10],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([368, 11],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([368, 3],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([368, 4],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([368, 8],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([368, 9],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([39, 7],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([392, 10],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([392, 11],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([392, 12],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([392, 13],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([4, 13],"int64"), weight=Tensor([6629, 384],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([4, 1],"int64"), weight=Tensor([32000, 64],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([4, 20],"int64"), weight=Tensor([30000, 128],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([4, 5],"int64"), weight=Tensor([32000, 64],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([4, 5],"int64"), weight=Tensor([6629, 384],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 100],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 102],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 102],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 103],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 104],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 105],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 107],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 108],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 110],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 111],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 113],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 114],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 115],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 117],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 118],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 122],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 123],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 124],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 125],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 127],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 128],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 40],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 45],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 46],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 46],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 47],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 48],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 49],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 50],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 51],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 52],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 53],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 54],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 55],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 56],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 57],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 58],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 59],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 60],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 60],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 61],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 63],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 64],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 65],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 66],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 67],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 67],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 69],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 70],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 70],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 71],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 72],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 72],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 74],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 74],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 75],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 76],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 76],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 77],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 77],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 78],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 79],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 79],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 80],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 81],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 82],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 83],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 84],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 85],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 85],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 86],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 86],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 87],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 87],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 88],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 88],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 89],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 89],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 90],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 90],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 91],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 91],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 92],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 92],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 93],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 93],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 94],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 95],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 95],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 96],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 97],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 98],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([40, 99],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([408, 10],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([408, 10],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([408, 12],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([408, 7],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([408, 8],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([408, 9],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([424, 10],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([424, 11],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([424, 12],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([424, 9],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([448, 7],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([448, 8],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([448, 9],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([464, 10],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([464, 11],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([464, 3],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([464, 4],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([464, 8],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([464, 9],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 100],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 101],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 102],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 103],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 104],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 105],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 106],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 25],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 30],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 32],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 34],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 36],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 37],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 39],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 40],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 41],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 42],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 43],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 44],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 47],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 48],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 49],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 49],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 51],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 51],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 53],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 54],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 55],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 57],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 58],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 58],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 59],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 61],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 61],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 62],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 63],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 64],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 65],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 65],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 66],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 67],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 67],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 68],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 68],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 69],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 70],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 70],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 71],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 71],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 72],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 73],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 73],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 74],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 75],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 75],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 76],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 76],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 77],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 78],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 78],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 79],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 79],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 80],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 81],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 81],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 82],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 82],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 83],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 83],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 84],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 84],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 85],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 85],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 86],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 87],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 88],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 89],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 90],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 91],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 92],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 93],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 94],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 95],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 96],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 97],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 98],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([48, 99],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([480, 5],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([480, 8],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([512, 10],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([512, 7],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([512, 7],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([512, 8],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([512, 8],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([512, 9],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([52, 7],"int32"), weight=Tensor([109, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([52, 7],"int32"), weight=Tensor([109, 64],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([52, 7],"int32"), weight=Tensor([84, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([52, 7],"int32"), weight=Tensor([84, 64],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([52, 7],"int32"), weight=Tensor([99, 128],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([52, 7],"int32"), weight=Tensor([99, 16],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([52, 7],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([52, 7],"int32"), weight=Tensor([99, 64],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([52, 7],"int64"), weight=Tensor([512, 64],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([52, 8],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([528, 9],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 25],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 26],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 28],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 33],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 35],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 37],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 38],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 39],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 42],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 44],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 45],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 45],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 47],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 50],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 51],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 52],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 52],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 53],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 53],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 54],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 55],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 56],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 56],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 57],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 58],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 59],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 60],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 60],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 61],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 62],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 62],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 63],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 64],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 65],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 66],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 66],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 67],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 68],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 69],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 69],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 70],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 71],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 71],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 72],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 72],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 73],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 73],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 74],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 75],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 76],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 77],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 78],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 79],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 80],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 81],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 82],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 83],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 84],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 85],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 86],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 87],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 88],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 89],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 90],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([56, 91],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([568, 8],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([568, 9],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([584, 6],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([584, 7],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([6, 1],"int64"), weight=Tensor([32000, 64],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([6, 3],"int32"), Tensor([10, 4],"float32"), padding_idx=5, scale_grad_by_freq=False, )
paddle.nn.functional.embedding(Tensor([6, 3],"int32"), Tensor([10, 4],"float32"), padding_idx=5, scale_grad_by_freq=True, )
paddle.nn.functional.embedding(Tensor([6, 5],"int64"), weight=Tensor([32000, 64],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([624, 7],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([624, 8],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 14],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 23],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 24],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 25],"int64"), weight=Tensor([6627, 512],"float16"), padding_idx=6626, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 25],"int64"), weight=Tensor([6627, 512],"float32"), padding_idx=6626, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 27],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 29],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 30],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 31],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 32],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 33],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 34],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 34],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 35],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 35],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 36],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 37],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 38],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 38],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 40],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 41],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 41],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 42],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 43],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 44],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 44],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 45],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 46],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 47],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 47],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 48],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 49],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 50],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 51],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 51],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 52],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 53],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 54],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 54],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 55],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 55],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 56],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 57],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 57],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 58],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 59],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 59],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 60],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 60],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 61],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 61],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 62],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 62],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 63],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 63],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 64],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 64],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 65],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 66],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 67],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 68],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 69],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 70],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 71],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 72],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 73],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 74],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 75],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 76],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 77],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 78],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 79],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 80],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([64, 8],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([640, 6],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([640, 7],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([640, 8],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([680, 6],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([7, 165],"int64"), weight=Tensor([50000, 1024],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([7, 186],"int64"), weight=Tensor([50000, 1024],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([7, 206],"int64"), weight=Tensor([50000, 1024],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([7, 209],"int64"), weight=Tensor([50000, 1024],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([7, 220],"int64"), weight=Tensor([50000, 1024],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([7, 286],"int64"), weight=Tensor([50000, 1024],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([7, 435],"int64"), weight=Tensor([50000, 1024],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 10],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 15],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 26],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 26],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 28],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 33],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 36],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 37],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 39],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 40],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 41],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 42],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 43],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 43],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 44],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 45],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 46],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 46],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 47],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 48],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 48],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 49],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 49],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 50],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 50],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 51],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 51],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 52],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 52],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 53],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 53],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 54],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 54],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 55],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 55],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 56],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 56],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 57],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 58],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 59],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 60],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 61],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 62],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 63],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 64],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 65],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 66],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 67],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 68],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 69],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 70],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([72, 71],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([728, 7],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([8, 234],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([8, 244],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([8, 25],"int64"), weight=Tensor([6627, 512],"float32"), padding_idx=6626, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 21],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 22],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 23],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 25],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 27],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 28],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 29],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 30],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 31],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 31],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 32],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 33],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 34],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 35],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 36],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 37],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 38],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 39],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 40],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 41],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 42],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 42],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 43],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 44],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 45],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 45],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 46],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 46],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 47],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 47],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 48],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 48],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 49],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 49],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 50],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 50],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 51],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 51],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 52],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 53],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 54],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 55],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 56],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 57],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 58],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 59],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 60],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 61],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 62],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 63],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([80, 64],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([848, 6],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 12],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 14],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 15],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 27],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 29],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 31],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 32],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 33],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 34],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 34],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 35],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 36],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 36],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 37],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 37],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 38],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 39],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 39],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 40],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 40],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 41],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 41],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 42],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 42],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 43],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 43],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 44],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 44],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 45],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 45],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 46],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 46],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 47],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 48],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 49],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 50],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 51],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 52],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 53],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 54],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 55],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 56],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 57],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 58],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([88, 8],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 10],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 11],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 22],"int64"), weight=Tensor([6629, 384],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 27],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 28],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 29],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 30],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 31],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 31],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 32],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 33],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 34],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 35],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 35],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 36],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 37],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 37],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 38],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 38],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 39],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 39],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 40],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 40],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 41],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 41],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 42],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 42],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 43],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 44],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 45],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 46],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 46],"int64"), weight=Tensor([50006, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 47],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 48],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 49],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 50],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 51],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 52],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 53],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([96, 9],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([],"int64"), weight=Tensor([39980, 8],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )


grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
2025-05-12 08:49:00.642040 test begin: paddle.nn.functional.embedding(Tensor([1, 1],"int64"), weight=Tensor([32000, 64],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
Warning: The core code of paddle.nn.functional.embedding is too complex.
One of the differentiated Tensors does not require grad
W0512 08:49:07.142241 17710 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 12.0, Runtime API Version: 11.8
W0512 08:49:07.143599 17710 gpu_resources.cc:164] device: 0, cuDNN Version: 8.8.
[Pass] paddle.nn.functional.embedding(Tensor([1, 1],"int64"), weight=Tensor([32000, 64],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:49:40.717548 test begin: paddle.nn.functional.embedding(Tensor([1, 20],"int64"), weight=Tensor([1024, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([1, 20],"int64"), weight=Tensor([1024, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:49:40.970947 test begin: paddle.nn.functional.embedding(Tensor([1, 20],"int64"), weight=Tensor([1024, 32],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([1, 20],"int64"), weight=Tensor([1024, 32],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:49:41.134680 test begin: paddle.nn.functional.embedding(Tensor([1, 20],"int64"), weight=Tensor([128001, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([1, 20],"int64"), weight=Tensor([128001, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:49:41.406379 test begin: paddle.nn.functional.embedding(Tensor([1, 20],"int64"), weight=Tensor([30000, 128],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([1, 20],"int64"), weight=Tensor([30000, 128],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:49:41.649923 test begin: paddle.nn.functional.embedding(Tensor([1, 300, 4096],"int64"), Tensor([10, 3],"float32"), padding_idx=1, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([1, 300, 4096],"int64"), Tensor([10, 3],"float32"), padding_idx=1, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 367638 / 3686400 (9.97%)
Max absolute difference: 0.964067
Max relative difference: 1.
 x: array([[[[0.229415, 0.675576, 0.289471],
         [0.229415, 0.675576, 0.289471],
         [0.      , 0.      , 0.      ],...
 y: array([[[[0.229415, 0.675576, 0.289471],
         [0.229415, 0.675576, 0.289471],
         [0.964067, 0.070379, 0.193983],...
2025-05-12 08:49:42.117249 test begin: paddle.nn.functional.embedding(Tensor([1, 44],"int64"), weight=Tensor([40000, 8],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([1, 44],"int64"), weight=Tensor([40000, 8],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:49:42.298793 test begin: paddle.nn.functional.embedding(Tensor([1, 45],"int64"), weight=Tensor([40000, 8],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([1, 45],"int64"), weight=Tensor([40000, 8],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:49:42.473625 test begin: paddle.nn.functional.embedding(Tensor([1, 46],"int64"), weight=Tensor([40000, 8],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([1, 46],"int64"), weight=Tensor([40000, 8],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:49:42.637316 test begin: paddle.nn.functional.embedding(Tensor([104, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:49:43.207398 test begin: paddle.nn.functional.embedding(Tensor([104, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:49:44.154526 test begin: paddle.nn.functional.embedding(Tensor([104, 21],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 21],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:49:45.123030 test begin: paddle.nn.functional.embedding(Tensor([104, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:49:46.067967 test begin: paddle.nn.functional.embedding(Tensor([104, 24],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 24],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:49:46.640854 test begin: paddle.nn.functional.embedding(Tensor([104, 25],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 25],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:49:47.213962 test begin: paddle.nn.functional.embedding(Tensor([104, 26],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 26],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:49:47.784249 test begin: paddle.nn.functional.embedding(Tensor([104, 27],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 27],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:49:48.367532 test begin: paddle.nn.functional.embedding(Tensor([104, 28],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 28],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:49:49.358222 test begin: paddle.nn.functional.embedding(Tensor([104, 28],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 28],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:49:49.958512 test begin: paddle.nn.functional.embedding(Tensor([104, 29],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([104, 29],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 508 / 1544192 (0.0329%)
Max absolute difference: 0.99816597
Max relative difference: 1.
 x: array([[[0.208376, 0.45066 , 0.278731, ..., 0.895663, 0.980636,
         0.90149 ],
        [0.743131, 0.044173, 0.302932, ..., 0.023774, 0.14054 ,...
 y: array([[[0.208376, 0.45066 , 0.278731, ..., 0.895663, 0.980636,
         0.90149 ],
        [0.743131, 0.044173, 0.302932, ..., 0.023774, 0.14054 ,...
2025-05-12 08:49:50.556302 test begin: paddle.nn.functional.embedding(Tensor([104, 30],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 30],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:49:51.166792 test begin: paddle.nn.functional.embedding(Tensor([104, 31],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([104, 31],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 505 / 1650688 (0.0306%)
Max absolute difference: 0.9990477
Max relative difference: 1.
 x: array([[[0.367039, 0.610942, 0.87912 , ..., 0.007021, 0.306714,
         0.044198],
        [0.549141, 0.211624, 0.501939, ..., 0.93866 , 0.985022,...
 y: array([[[0.367039, 0.610942, 0.87912 , ..., 0.007021, 0.306714,
         0.044198],
        [0.549141, 0.211624, 0.501939, ..., 0.93866 , 0.985022,...
2025-05-12 08:49:51.791907 test begin: paddle.nn.functional.embedding(Tensor([104, 32],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 32],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:49:52.772404 test begin: paddle.nn.functional.embedding(Tensor([104, 32],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 32],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:49:53.365070 test begin: paddle.nn.functional.embedding(Tensor([104, 33],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 33],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:49:54.414236 test begin: paddle.nn.functional.embedding(Tensor([104, 33],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 33],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:49:55.000368 test begin: paddle.nn.functional.embedding(Tensor([104, 34],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 34],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:49:56.009229 test begin: paddle.nn.functional.embedding(Tensor([104, 34],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 34],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:49:56.586392 test begin: paddle.nn.functional.embedding(Tensor([104, 35],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([104, 35],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1014 / 3727360 (0.0272%)
Max absolute difference: 0.9995281
Max relative difference: 1.
 x: array([[[0.400916, 0.985888, 0.143381, ..., 0.584451, 0.52496 ,
         0.613373],
        [0.427979, 0.016456, 0.275361, ..., 0.546478, 0.956887,...
 y: array([[[0.400916, 0.985888, 0.143381, ..., 0.584451, 0.52496 ,
         0.613373],
        [0.427979, 0.016456, 0.275361, ..., 0.546478, 0.956887,...
2025-05-12 08:49:57.692510 test begin: paddle.nn.functional.embedding(Tensor([104, 35],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 35],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:49:58.350625 test begin: paddle.nn.functional.embedding(Tensor([104, 36],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 36],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:49:59.379376 test begin: paddle.nn.functional.embedding(Tensor([104, 36],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 36],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:49:59.981709 test begin: paddle.nn.functional.embedding(Tensor([104, 37],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 37],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:01.026225 test begin: paddle.nn.functional.embedding(Tensor([104, 37],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 37],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:01.679799 test begin: paddle.nn.functional.embedding(Tensor([104, 38],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([104, 38],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1012 / 4046848 (0.025%)
Max absolute difference: 0.9997459
Max relative difference: 1.
 x: array([[[0.150742, 0.832248, 0.81783 , ..., 0.629812, 0.489562,
         0.173823],
        [0.07543 , 0.658255, 0.649794, ..., 0.77545 , 0.550503,...
 y: array([[[0.150742, 0.832248, 0.81783 , ..., 0.629812, 0.489562,
         0.173823],
        [0.07543 , 0.658255, 0.649794, ..., 0.77545 , 0.550503,...
2025-05-12 08:50:02.820133 test begin: paddle.nn.functional.embedding(Tensor([104, 38],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 38],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:03.422188 test begin: paddle.nn.functional.embedding(Tensor([104, 39],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([104, 39],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2034 / 4153344 (0.049%)
Max absolute difference: 0.9984149
Max relative difference: 1.
 x: array([[[0.256889, 0.425956, 0.770205, ..., 0.858846, 0.409196,
         0.911072],
        [0.297619, 0.910699, 0.59782 , ..., 0.598268, 0.046267,...
 y: array([[[0.256889, 0.425956, 0.770205, ..., 0.858846, 0.409196,
         0.911072],
        [0.297619, 0.910699, 0.59782 , ..., 0.598268, 0.046267,...
2025-05-12 08:50:04.532882 test begin: paddle.nn.functional.embedding(Tensor([104, 39],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 39],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:05.137276 test begin: paddle.nn.functional.embedding(Tensor([104, 40],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 40],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:06.206532 test begin: paddle.nn.functional.embedding(Tensor([104, 41],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 41],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:07.285077 test begin: paddle.nn.functional.embedding(Tensor([104, 42],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 42],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:08.372068 test begin: paddle.nn.functional.embedding(Tensor([104, 43],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 43],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:09.448869 test begin: paddle.nn.functional.embedding(Tensor([104, 44],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 44],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:10.547961 test begin: paddle.nn.functional.embedding(Tensor([104, 45],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 45],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:11.677897 test begin: paddle.nn.functional.embedding(Tensor([104, 46],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 46],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:12.772306 test begin: paddle.nn.functional.embedding(Tensor([104, 47],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 47],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:13.889810 test begin: paddle.nn.functional.embedding(Tensor([104, 48],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 48],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:15.041232 test begin: paddle.nn.functional.embedding(Tensor([104, 49],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 49],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:16.167972 test begin: paddle.nn.functional.embedding(Tensor([104, 9],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([104, 9],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:16.710787 test begin: paddle.nn.functional.embedding(Tensor([112, 12],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([112, 12],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:17.631710 test begin: paddle.nn.functional.embedding(Tensor([112, 17],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([112, 17],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:18.558646 test begin: paddle.nn.functional.embedding(Tensor([112, 21],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([112, 21],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:19.128691 test begin: paddle.nn.functional.embedding(Tensor([112, 23],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([112, 23],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:19.714747 test begin: paddle.nn.functional.embedding(Tensor([112, 26],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([112, 26],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:20.292832 test begin: paddle.nn.functional.embedding(Tensor([112, 27],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([112, 27],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:20.875784 test begin: paddle.nn.functional.embedding(Tensor([112, 28],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([112, 28],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:21.466957 test begin: paddle.nn.functional.embedding(Tensor([112, 29],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([112, 29],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:22.445910 test begin: paddle.nn.functional.embedding(Tensor([112, 29],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([112, 29],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:23.029409 test begin: paddle.nn.functional.embedding(Tensor([112, 30],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([112, 30],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:24.046032 test begin: paddle.nn.functional.embedding(Tensor([112, 30],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([112, 30],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:24.654972 test begin: paddle.nn.functional.embedding(Tensor([112, 31],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([112, 31],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:25.244639 test begin: paddle.nn.functional.embedding(Tensor([112, 32],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([112, 32],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:25.842424 test begin: paddle.nn.functional.embedding(Tensor([112, 33],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([112, 33],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1014 / 3784704 (0.0268%)
Max absolute difference: 0.9994625
Max relative difference: 1.
 x: array([[[0.741816, 0.429471, 0.131735, ..., 0.707075, 0.19937 ,
         0.763285],
        [0.224792, 0.799693, 0.087043, ..., 0.293182, 0.577063,...
 y: array([[[0.741816, 0.429471, 0.131735, ..., 0.707075, 0.19937 ,
         0.763285],
        [0.224792, 0.799693, 0.087043, ..., 0.293182, 0.577063,...
2025-05-12 08:50:26.912272 test begin: paddle.nn.functional.embedding(Tensor([112, 33],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([112, 33],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:27.496618 test begin: paddle.nn.functional.embedding(Tensor([112, 34],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([112, 34],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:28.542941 test begin: paddle.nn.functional.embedding(Tensor([112, 34],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([112, 34],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:29.138327 test begin: paddle.nn.functional.embedding(Tensor([112, 35],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([112, 35],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:30.215584 test begin: paddle.nn.functional.embedding(Tensor([112, 35],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([112, 35],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:30.807930 test begin: paddle.nn.functional.embedding(Tensor([112, 36],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([112, 36],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:31.860837 test begin: paddle.nn.functional.embedding(Tensor([112, 36],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([112, 36],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:32.457772 test begin: paddle.nn.functional.embedding(Tensor([112, 37],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([112, 37],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:33.530231 test begin: paddle.nn.functional.embedding(Tensor([112, 38],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([112, 38],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:34.604849 test begin: paddle.nn.functional.embedding(Tensor([112, 39],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([112, 39],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:35.704029 test begin: paddle.nn.functional.embedding(Tensor([112, 40],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([112, 40],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:36.786290 test begin: paddle.nn.functional.embedding(Tensor([112, 41],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([112, 41],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:37.883658 test begin: paddle.nn.functional.embedding(Tensor([112, 42],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([112, 42],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:38.977524 test begin: paddle.nn.functional.embedding(Tensor([112, 43],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([112, 43],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:40.137958 test begin: paddle.nn.functional.embedding(Tensor([112, 44],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([112, 44],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:41.244574 test begin: paddle.nn.functional.embedding(Tensor([112, 45],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([112, 45],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:42.362371 test begin: paddle.nn.functional.embedding(Tensor([12, 7],"int32"), weight=Tensor([109, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([12, 7],"int32"), weight=Tensor([109, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:42.522239 test begin: paddle.nn.functional.embedding(Tensor([12, 7],"int32"), weight=Tensor([84, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([12, 7],"int32"), weight=Tensor([84, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:42.682739 test begin: paddle.nn.functional.embedding(Tensor([12, 7],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([12, 7],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 32 / 2688 (1.19%)
Max absolute difference: 0.9267531
Max relative difference: 1.
 x: array([[[0.775587, 0.077189, 0.533243, ..., 0.054211, 0.128008,
         0.481214],
        [0.179258, 0.892372, 0.476586, ..., 0.316136, 0.48338 ,...
 y: array([[[0.775587, 0.077189, 0.533243, ..., 0.054211, 0.128008,
         0.481214],
        [0.179258, 0.892372, 0.476586, ..., 0.316136, 0.48338 ,...
2025-05-12 08:50:42.847658 test begin: paddle.nn.functional.embedding(Tensor([120, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([120, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:43.797996 test begin: paddle.nn.functional.embedding(Tensor([120, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([120, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:44.743757 test begin: paddle.nn.functional.embedding(Tensor([120, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([120, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:45.698460 test begin: paddle.nn.functional.embedding(Tensor([120, 22],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([120, 22],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:46.321215 test begin: paddle.nn.functional.embedding(Tensor([120, 24],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([120, 24],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:46.941068 test begin: paddle.nn.functional.embedding(Tensor([120, 25],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([120, 25],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:47.525455 test begin: paddle.nn.functional.embedding(Tensor([120, 26],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([120, 26],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:48.523428 test begin: paddle.nn.functional.embedding(Tensor([120, 26],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([120, 26],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:49.203347 test begin: paddle.nn.functional.embedding(Tensor([120, 27],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([120, 27],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:50.255210 test begin: paddle.nn.functional.embedding(Tensor([120, 27],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([120, 27],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:50.894372 test begin: paddle.nn.functional.embedding(Tensor([120, 28],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([120, 28],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:51.528526 test begin: paddle.nn.functional.embedding(Tensor([120, 29],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([120, 29],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:52.117907 test begin: paddle.nn.functional.embedding(Tensor([120, 30],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([120, 30],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:52.715339 test begin: paddle.nn.functional.embedding(Tensor([120, 31],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([120, 31],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:53.753205 test begin: paddle.nn.functional.embedding(Tensor([120, 31],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([120, 31],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:54.350833 test begin: paddle.nn.functional.embedding(Tensor([120, 32],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([120, 32],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:55.395810 test begin: paddle.nn.functional.embedding(Tensor([120, 32],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([120, 32],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:55.988426 test begin: paddle.nn.functional.embedding(Tensor([120, 33],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([120, 33],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:57.031022 test begin: paddle.nn.functional.embedding(Tensor([120, 33],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([120, 33],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:57.641037 test begin: paddle.nn.functional.embedding(Tensor([120, 34],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([120, 34],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:58.727259 test begin: paddle.nn.functional.embedding(Tensor([120, 34],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([120, 34],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:50:59.331362 test begin: paddle.nn.functional.embedding(Tensor([120, 35],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([120, 35],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:00.409673 test begin: paddle.nn.functional.embedding(Tensor([120, 36],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([120, 36],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1006 / 4423680 (0.0227%)
Max absolute difference: 0.99999243
Max relative difference: 1.
 x: array([[[0.796916, 0.734096, 0.148903, ..., 0.500234, 0.704112,
         0.163075],
        [0.053811, 0.013487, 0.813197, ..., 0.973541, 0.160634,...
 y: array([[[0.796916, 0.734096, 0.148903, ..., 0.500234, 0.704112,
         0.163075],
        [0.053811, 0.013487, 0.813197, ..., 0.973541, 0.160634,...
2025-05-12 08:51:01.553202 test begin: paddle.nn.functional.embedding(Tensor([120, 37],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([120, 37],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:02.626395 test begin: paddle.nn.functional.embedding(Tensor([120, 38],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([120, 38],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:03.806767 test begin: paddle.nn.functional.embedding(Tensor([120, 39],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([120, 39],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:04.940823 test begin: paddle.nn.functional.embedding(Tensor([120, 40],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([120, 40],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:06.059571 test begin: paddle.nn.functional.embedding(Tensor([120, 41],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([120, 41],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:07.157170 test begin: paddle.nn.functional.embedding(Tensor([120, 42],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([120, 42],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:08.299221 test begin: paddle.nn.functional.embedding(Tensor([128, 11],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([128, 11],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:09.238416 test begin: paddle.nn.functional.embedding(Tensor([128, 13],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([128, 13],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:10.192387 test begin: paddle.nn.functional.embedding(Tensor([128, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([128, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:10.760265 test begin: paddle.nn.functional.embedding(Tensor([128, 22],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([128, 22],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:11.338824 test begin: paddle.nn.functional.embedding(Tensor([128, 23],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([128, 23],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:11.914113 test begin: paddle.nn.functional.embedding(Tensor([128, 23],"int64"), weight=Tensor([6629, 384],"float16"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([128, 23],"int64"), weight=Tensor([6629, 384],"float16"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:12.292283 test begin: paddle.nn.functional.embedding(Tensor([128, 23],"int64"), weight=Tensor([6629, 384],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([128, 23],"int64"), weight=Tensor([6629, 384],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:12.544731 test begin: paddle.nn.functional.embedding(Tensor([128, 24],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([128, 24],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:13.126479 test begin: paddle.nn.functional.embedding(Tensor([128, 25],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([128, 25],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:14.125856 test begin: paddle.nn.functional.embedding(Tensor([128, 25],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([128, 25],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:14.733473 test begin: paddle.nn.functional.embedding(Tensor([128, 26],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([128, 26],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:15.328862 test begin: paddle.nn.functional.embedding(Tensor([128, 27],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([128, 27],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:15.930189 test begin: paddle.nn.functional.embedding(Tensor([128, 28],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([128, 28],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:16.973875 test begin: paddle.nn.functional.embedding(Tensor([128, 28],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([128, 28],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:17.577009 test begin: paddle.nn.functional.embedding(Tensor([128, 29],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([128, 29],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1012 / 3801088 (0.0266%)
Max absolute difference: 0.9983461
Max relative difference: 1.
 x: array([[[0.7329  , 0.738432, 0.738296, ..., 0.056772, 0.213797,
         0.00999 ],
        [0.470372, 0.84163 , 0.860962, ..., 0.882742, 0.356571,...
 y: array([[[0.7329  , 0.738432, 0.738296, ..., 0.056772, 0.213797,
         0.00999 ],
        [0.470372, 0.84163 , 0.860962, ..., 0.882742, 0.356571,...
2025-05-12 08:51:18.669696 test begin: paddle.nn.functional.embedding(Tensor([128, 29],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([128, 29],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:19.273294 test begin: paddle.nn.functional.embedding(Tensor([128, 30],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([128, 30],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:20.326054 test begin: paddle.nn.functional.embedding(Tensor([128, 30],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([128, 30],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:20.935069 test begin: paddle.nn.functional.embedding(Tensor([128, 31],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([128, 31],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:22.059943 test begin: paddle.nn.functional.embedding(Tensor([128, 31],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([128, 31],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 509 / 2031616 (0.0251%)
Max absolute difference: 0.9917574
Max relative difference: 1.
 x: array([[[0.045662, 0.876591, 0.93969 , ..., 0.078009, 0.087128,
         0.851407],
        [0.226295, 0.99095 , 0.452208, ..., 0.003073, 0.105596,...
 y: array([[[0.045662, 0.876591, 0.93969 , ..., 0.078009, 0.087128,
         0.851407],
        [0.226295, 0.99095 , 0.452208, ..., 0.003073, 0.105596,...
2025-05-12 08:51:22.695874 test begin: paddle.nn.functional.embedding(Tensor([128, 32],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([128, 32],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:23.764902 test begin: paddle.nn.functional.embedding(Tensor([128, 32],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([128, 32],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 507 / 2097152 (0.0242%)
Max absolute difference: 0.999406
Max relative difference: 1.
 x: array([[[0.859539, 0.379235, 0.857224, ..., 0.138297, 0.378842,
         0.690344],
        [0.53212 , 0.471198, 0.019483, ..., 0.903611, 0.806883,...
 y: array([[[0.859539, 0.379235, 0.857224, ..., 0.138297, 0.378842,
         0.690344],
        [0.53212 , 0.471198, 0.019483, ..., 0.903611, 0.806883,...
2025-05-12 08:51:24.406215 test begin: paddle.nn.functional.embedding(Tensor([128, 33],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([128, 33],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1013 / 4325376 (0.0234%)
Max absolute difference: 0.9992207
Max relative difference: 1.
 x: array([[[0.888589, 0.511571, 0.018356, ..., 0.861689, 0.236098,
         0.561398],
        [0.720092, 0.745485, 0.686261, ..., 0.505154, 0.274713,...
 y: array([[[0.888589, 0.511571, 0.018356, ..., 0.861689, 0.236098,
         0.561398],
        [0.720092, 0.745485, 0.686261, ..., 0.505154, 0.274713,...
2025-05-12 08:51:25.580763 test begin: paddle.nn.functional.embedding(Tensor([128, 34],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([128, 34],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:26.682128 test begin: paddle.nn.functional.embedding(Tensor([128, 35],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([128, 35],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:27.754478 test begin: paddle.nn.functional.embedding(Tensor([128, 36],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([128, 36],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:28.879624 test begin: paddle.nn.functional.embedding(Tensor([128, 37],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([128, 37],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:30.045266 test begin: paddle.nn.functional.embedding(Tensor([128, 38],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([128, 38],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:31.153784 test begin: paddle.nn.functional.embedding(Tensor([128, 39],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([128, 39],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:32.304909 test begin: paddle.nn.functional.embedding(Tensor([128, 40],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([128, 40],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:33.453099 test begin: paddle.nn.functional.embedding(Tensor([13, 10],"int32"), weight=Tensor([81, 24],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([13, 10],"int32"), weight=Tensor([81, 24],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:33.633769 test begin: paddle.nn.functional.embedding(Tensor([13, 10],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([13, 10],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 128 / 4160 (3.08%)
Max absolute difference: 0.9865172
Max relative difference: 1.
 x: array([[[0.727254, 0.103669, 0.874404, ..., 0.556008, 0.2347  ,
         0.160341],
        [0.619135, 0.821844, 0.364041, ..., 0.72638 , 0.453822,...
 y: array([[[0.727254, 0.103669, 0.874404, ..., 0.556008, 0.2347  ,
         0.160341],
        [0.619135, 0.821844, 0.364041, ..., 0.72638 , 0.453822,...
2025-05-12 08:51:33.805874 test begin: paddle.nn.functional.embedding(Tensor([13, 2],"int64"), weight=Tensor([32, 16],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([13, 2],"int64"), weight=Tensor([32, 16],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 16 / 416 (3.85%)
Max absolute difference: 0.92506796
Max relative difference: 1.
 x: array([[[8.100866e-01, 2.072325e-01, 6.134480e-01, 5.954835e-01,
         9.957264e-02, 7.221317e-01, 3.600692e-01, 5.571716e-01,
         8.447071e-01, 4.116302e-01, 9.690650e-01, 8.022778e-01,...
 y: array([[[8.100866e-01, 2.072325e-01, 6.134480e-01, 5.954835e-01,
         9.957264e-02, 7.221317e-01, 3.600692e-01, 5.571716e-01,
         8.447071e-01, 4.116302e-01, 9.690650e-01, 8.022778e-01,...
2025-05-12 08:51:33.988048 test begin: paddle.nn.functional.embedding(Tensor([13, 3],"int32"), weight=Tensor([81, 24],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([13, 3],"int32"), weight=Tensor([81, 24],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:34.146277 test begin: paddle.nn.functional.embedding(Tensor([13, 3],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([13, 3],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:34.296760 test begin: paddle.nn.functional.embedding(Tensor([13, 4, 7],"int32"), weight=Tensor([99, 16],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([13, 4, 7],"int32"), weight=Tensor([99, 16],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 48 / 5824 (0.824%)
Max absolute difference: 0.9521488
Max relative difference: 1.
 x: array([[[[6.252196e-01, 2.285435e-01, 3.958789e-01, ..., 1.197721e-01,
          5.678771e-01, 8.513780e-01],
         [5.400255e-01, 1.036566e-02, 9.104368e-01, ..., 9.196234e-01,...
 y: array([[[[6.252196e-01, 2.285435e-01, 3.958789e-01, ..., 1.197721e-01,
          5.678771e-01, 8.513780e-01],
         [5.400255e-01, 1.036566e-02, 9.104368e-01, ..., 9.196234e-01,...
2025-05-12 08:51:34.477439 test begin: paddle.nn.functional.embedding(Tensor([13, 4, 7],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([13, 4, 7],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 96 / 11648 (0.824%)
Max absolute difference: 0.97052
Max relative difference: 1.
 x: array([[[[0.48529 , 0.507339, 0.281075, ..., 0.898265, 0.286996,
          0.147739],
         [0.963138, 0.782805, 0.125976, ..., 0.220708, 0.649312,...
 y: array([[[[0.48529 , 0.507339, 0.281075, ..., 0.898265, 0.286996,
          0.147739],
         [0.963138, 0.782805, 0.125976, ..., 0.220708, 0.649312,...
2025-05-12 08:51:34.647333 test begin: paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([100, 16],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([100, 16],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 15 / 1456 (1.03%)
Max absolute difference: 0.98214835
Max relative difference: 1.
 x: array([[[0.869986, 0.361525, 0.11633 , ..., 0.34723 , 0.072377,
         0.567441],
        [0.477743, 0.900725, 0.841933, ..., 0.649398, 0.229305,...
 y: array([[[0.869986, 0.361525, 0.11633 , ..., 0.34723 , 0.072377,
         0.567441],
        [0.477743, 0.900725, 0.841933, ..., 0.649398, 0.229305,...
2025-05-12 08:51:34.811122 test begin: paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([103, 24],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([103, 24],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 24 / 2184 (1.1%)
Max absolute difference: 0.92396414
Max relative difference: 1.
 x: array([[[3.348201e-01, 8.466888e-02, 6.458372e-01, ..., 8.058524e-01,
         5.248721e-02, 1.567586e-01],
        [5.997243e-02, 3.058361e-01, 9.766328e-01, ..., 8.367610e-03,...
 y: array([[[3.348201e-01, 8.466888e-02, 6.458372e-01, ..., 8.058524e-01,
         5.248721e-02, 1.567586e-01],
        [5.997243e-02, 3.058361e-01, 9.766328e-01, ..., 8.367610e-03,...
2025-05-12 08:51:34.966900 test begin: paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([109, 128],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([109, 128],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 127 / 11648 (1.09%)
Max absolute difference: 0.9946954
Max relative difference: 1.
 x: array([[[0.102407, 0.087249, 0.314766, ..., 0.814095, 0.965764,
         0.834342],
        [0.274848, 0.46407 , 0.778342, ..., 0.632221, 0.681001,...
 y: array([[[0.102407, 0.087249, 0.314766, ..., 0.814095, 0.965764,
         0.834342],
        [0.274848, 0.46407 , 0.778342, ..., 0.632221, 0.681001,...
2025-05-12 08:51:35.119893 test begin: paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([109, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([109, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:35.274344 test begin: paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([109, 32],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([109, 32],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 64 / 2912 (2.2%)
Max absolute difference: 0.97520846
Max relative difference: 1.
 x: array([[[0.156545, 0.433848, 0.103637, ..., 0.625105, 0.746219,
         0.020425],
        [0.372606, 0.693763, 0.483374, ..., 0.318568, 0.260715,...
 y: array([[[0.156545, 0.433848, 0.103637, ..., 0.625105, 0.746219,
         0.020425],
        [0.372606, 0.693763, 0.483374, ..., 0.318568, 0.260715,...
2025-05-12 08:51:35.443923 test begin: paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([109, 32],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([109, 32],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 32 / 2912 (1.1%)
Max absolute difference: 0.96733326
Max relative difference: 1.
 x: array([[[0.796985, 0.53476 , 0.012146, ..., 0.601684, 0.587256,
         0.9816  ],
        [0.689493, 0.987071, 0.040902, ..., 0.570373, 0.828127,...
 y: array([[[0.796985, 0.53476 , 0.012146, ..., 0.601684, 0.587256,
         0.9816  ],
        [0.689493, 0.987071, 0.040902, ..., 0.570373, 0.828127,...
2025-05-12 08:51:35.610016 test begin: paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([109, 64],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([109, 64],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 126 / 5824 (2.16%)
Max absolute difference: 0.99029404
Max relative difference: 1.
 x: array([[[0.788493, 0.620666, 0.658488, ..., 0.279293, 0.072564,
         0.875486],
        [0.931729, 0.634687, 0.90676 , ..., 0.471723, 0.092973,...
 y: array([[[0.788493, 0.620666, 0.658488, ..., 0.279293, 0.072564,
         0.875486],
        [0.931729, 0.634687, 0.90676 , ..., 0.471723, 0.092973,...
2025-05-12 08:51:35.769083 test begin: paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([110, 16],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([110, 16],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:35.926207 test begin: paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([512, 64],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([512, 64],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:36.091780 test begin: paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([81, 24],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([81, 24],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 24 / 2184 (1.1%)
Max absolute difference: 0.920756
Max relative difference: 1.
 x: array([[[0.509163, 0.542462, 0.353203, ..., 0.242908, 0.950681,
         0.571299],
        [0.419321, 0.915974, 0.298003, ..., 0.812782, 0.015148,...
 y: array([[[0.509163, 0.542462, 0.353203, ..., 0.242908, 0.950681,
         0.571299],
        [0.419321, 0.915974, 0.298003, ..., 0.812782, 0.015148,...
2025-05-12 08:51:36.250388 test begin: paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([84, 128],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([84, 128],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 375 / 11648 (3.22%)
Max absolute difference: 0.9963694
Max relative difference: 1.
 x: array([[[0.084088, 0.42932 , 0.805074, ..., 0.45459 , 0.18305 ,
         0.608896],
        [0.356223, 0.896565, 0.929349, ..., 0.782576, 0.480229,...
 y: array([[[0.084088, 0.42932 , 0.805074, ..., 0.45459 , 0.18305 ,
         0.608896],
        [0.356223, 0.896565, 0.929349, ..., 0.782576, 0.480229,...
2025-05-12 08:51:36.441038 test begin: paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([84, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([84, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:36.598351 test begin: paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([84, 32],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([84, 32],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 64 / 2912 (2.2%)
Max absolute difference: 0.94039905
Max relative difference: 1.
 x: array([[[0.338271, 0.175077, 0.037154, ..., 0.265625, 0.372134,
         0.457824],
        [0.593565, 0.174486, 0.157123, ..., 0.983317, 0.02506 ,...
 y: array([[[0.338271, 0.175077, 0.037154, ..., 0.265625, 0.372134,
         0.457824],
        [0.593565, 0.174486, 0.157123, ..., 0.983317, 0.02506 ,...
2025-05-12 08:51:36.759812 test begin: paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([84, 32],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([84, 32],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 64 / 2912 (2.2%)
Max absolute difference: 0.9903748
Max relative difference: 1.
 x: array([[[0.307174, 0.510097, 0.772083, ..., 0.664851, 0.908619,
         0.330284],
        [0.145071, 0.927494, 0.979167, ..., 0.516815, 0.680857,...
 y: array([[[0.307174, 0.510097, 0.772083, ..., 0.664851, 0.908619,
         0.330284],
        [0.145071, 0.927494, 0.979167, ..., 0.516815, 0.680857,...
2025-05-12 08:51:36.914855 test begin: paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([84, 64],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([84, 64],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 64 / 5824 (1.1%)
Max absolute difference: 0.99354595
Max relative difference: 1.
 x: array([[[0.54329 , 0.273108, 0.649785, ..., 0.039789, 0.437166,
         0.355728],
        [0.26578 , 0.095717, 0.351744, ..., 0.837522, 0.85903 ,...
 y: array([[[0.54329 , 0.273108, 0.649785, ..., 0.039789, 0.437166,
         0.355728],
        [0.26578 , 0.095717, 0.351744, ..., 0.837522, 0.85903 ,...
2025-05-12 08:51:37.071406 test begin: paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([85, 16],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([85, 16],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:37.234275 test begin: paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([99, 128],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([99, 128],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 256 / 11648 (2.2%)
Max absolute difference: 0.98934686
Max relative difference: 1.
 x: array([[[0.831565, 0.271798, 0.659959, ..., 0.181726, 0.237829,
         0.031124],
        [0.723187, 0.300505, 0.02099 , ..., 0.623669, 0.209328,...
 y: array([[[0.831565, 0.271798, 0.659959, ..., 0.181726, 0.237829,
         0.031124],
        [0.723187, 0.300505, 0.02099 , ..., 0.623669, 0.209328,...
2025-05-12 08:51:37.396633 test begin: paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([99, 16],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([99, 16],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 32 / 1456 (2.2%)
Max absolute difference: 0.9884249
Max relative difference: 1.
 x: array([[[7.285483e-01, 8.085552e-01, 6.960164e-01, ..., 7.633101e-01,
         3.153269e-01, 6.851887e-01],
        [3.246902e-01, 3.372774e-02, 4.249305e-01, ..., 7.422623e-01,...
 y: array([[[7.285483e-01, 8.085552e-01, 6.960164e-01, ..., 7.633101e-01,
         3.153269e-01, 6.851887e-01],
        [3.246902e-01, 3.372774e-02, 4.249305e-01, ..., 7.422623e-01,...
2025-05-12 08:51:37.551544 test begin: paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 32 / 2912 (1.1%)
Max absolute difference: 0.97662556
Max relative difference: 1.
 x: array([[[0.202246, 0.461035, 0.844293, ..., 0.219954, 0.702649,
         0.703993],
        [0.678039, 0.465351, 0.120927, ..., 0.946743, 0.454977,...
 y: array([[[0.202246, 0.461035, 0.844293, ..., 0.219954, 0.702649,
         0.703993],
        [0.678039, 0.465351, 0.120927, ..., 0.946743, 0.454977,...
2025-05-12 08:51:37.725313 test begin: paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 30 / 2912 (1.03%)
Max absolute difference: 0.8201301
Max relative difference: 1.
 x: array([[[0.383355, 0.961176, 0.453636, ..., 0.057745, 0.970419,
         0.962218],
        [0.547461, 0.626301, 0.158297, ..., 0.861771, 0.211913,...
 y: array([[[0.383355, 0.961176, 0.453636, ..., 0.057745, 0.970419,
         0.962218],
        [0.547461, 0.626301, 0.158297, ..., 0.861771, 0.211913,...
2025-05-12 08:51:37.889888 test begin: paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:38.041605 test begin: paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([99, 64],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([13, 7],"int32"), weight=Tensor([99, 64],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:38.206122 test begin: paddle.nn.functional.embedding(Tensor([13, 7],"int64"), weight=Tensor([128, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([13, 7],"int64"), weight=Tensor([128, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 64 / 2912 (2.2%)
Max absolute difference: 0.9594923
Max relative difference: 1.
 x: array([[[0.75741 , 0.140488, 0.236214, ..., 0.059558, 0.537296,
         0.773587],
        [0.860669, 0.327511, 0.227434, ..., 0.420253, 0.113029,...
 y: array([[[0.75741 , 0.140488, 0.236214, ..., 0.059558, 0.537296,
         0.773587],
        [0.860669, 0.327511, 0.227434, ..., 0.420253, 0.113029,...
2025-05-12 08:51:38.367192 test begin: paddle.nn.functional.embedding(Tensor([13, 7],"int64"), weight=Tensor([512, 64],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([13, 7],"int64"), weight=Tensor([512, 64],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:38.532999 test begin: paddle.nn.functional.embedding(Tensor([13, 8],"int32"), weight=Tensor([109, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([13, 8],"int32"), weight=Tensor([109, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:38.679774 test begin: paddle.nn.functional.embedding(Tensor([13, 8],"int32"), weight=Tensor([84, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([13, 8],"int32"), weight=Tensor([84, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 32 / 3328 (0.962%)
Max absolute difference: 0.9729192
Max relative difference: 1.
 x: array([[[0.897732, 0.694279, 0.807495, ..., 0.837541, 0.445864,
         0.895669],
        [0.639797, 0.096489, 0.470765, ..., 0.611077, 0.029803,...
 y: array([[[0.897732, 0.694279, 0.807495, ..., 0.837541, 0.445864,
         0.895669],
        [0.639797, 0.096489, 0.470765, ..., 0.611077, 0.029803,...
2025-05-12 08:51:38.831799 test begin: paddle.nn.functional.embedding(Tensor([13, 8],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([13, 8],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:39.001476 test begin: paddle.nn.functional.embedding(Tensor([136, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([136, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:40.016182 test begin: paddle.nn.functional.embedding(Tensor([136, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([136, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:40.596803 test begin: paddle.nn.functional.embedding(Tensor([136, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([136, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:41.193197 test begin: paddle.nn.functional.embedding(Tensor([136, 21],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([136, 21],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:41.809548 test begin: paddle.nn.functional.embedding(Tensor([136, 22],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([136, 22],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:42.409732 test begin: paddle.nn.functional.embedding(Tensor([136, 23],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([136, 23],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:43.015843 test begin: paddle.nn.functional.embedding(Tensor([136, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([136, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:44.112224 test begin: paddle.nn.functional.embedding(Tensor([136, 24],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([136, 24],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:44.706901 test begin: paddle.nn.functional.embedding(Tensor([136, 25],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([136, 25],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:45.311046 test begin: paddle.nn.functional.embedding(Tensor([136, 26],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([136, 26],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:46.377930 test begin: paddle.nn.functional.embedding(Tensor([136, 26],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([136, 26],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:46.969679 test begin: paddle.nn.functional.embedding(Tensor([136, 27],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([136, 27],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:48.014787 test begin: paddle.nn.functional.embedding(Tensor([136, 27],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([136, 27],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 509 / 1880064 (0.0271%)
Max absolute difference: 0.9980076
Max relative difference: 1.
 x: array([[[7.740932e-01, 3.453528e-01, 1.757817e-04, ..., 9.661703e-01,
         6.303012e-01, 4.969547e-01],
        [6.246840e-01, 6.811606e-01, 6.512917e-01, ..., 4.331922e-01,...
 y: array([[[7.740932e-01, 3.453528e-01, 1.757817e-04, ..., 9.661703e-01,
         6.303012e-01, 4.969547e-01],
        [6.246840e-01, 6.811606e-01, 6.512917e-01, ..., 4.331922e-01,...
2025-05-12 08:51:48.632688 test begin: paddle.nn.functional.embedding(Tensor([136, 28],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([136, 28],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:49.682998 test begin: paddle.nn.functional.embedding(Tensor([136, 28],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([136, 28],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:50.258366 test begin: paddle.nn.functional.embedding(Tensor([136, 29],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([136, 29],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1017 / 4038656 (0.0252%)
Max absolute difference: 0.99953026
Max relative difference: 1.
 x: array([[[0.370326, 0.558746, 0.098512, ..., 0.948516, 0.82224 ,
         0.681389],
        [0.529847, 0.709096, 0.932297, ..., 0.903536, 0.33647 ,...
 y: array([[[0.370326, 0.558746, 0.098512, ..., 0.948516, 0.82224 ,
         0.681389],
        [0.529847, 0.709096, 0.932297, ..., 0.903536, 0.33647 ,...
2025-05-12 08:51:51.391944 test begin: paddle.nn.functional.embedding(Tensor([136, 29],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([136, 29],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:51.959585 test begin: paddle.nn.functional.embedding(Tensor([136, 30],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([136, 30],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:53.042755 test begin: paddle.nn.functional.embedding(Tensor([136, 30],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([136, 30],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:53.648019 test begin: paddle.nn.functional.embedding(Tensor([136, 31],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([136, 31],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:54.743299 test begin: paddle.nn.functional.embedding(Tensor([136, 32],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([136, 32],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:55.838669 test begin: paddle.nn.functional.embedding(Tensor([136, 33],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([136, 33],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:56.942564 test begin: paddle.nn.functional.embedding(Tensor([136, 34],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([136, 34],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:58.075888 test begin: paddle.nn.functional.embedding(Tensor([136, 35],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([136, 35],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:51:59.152634 test begin: paddle.nn.functional.embedding(Tensor([136, 36],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([136, 36],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:00.291945 test begin: paddle.nn.functional.embedding(Tensor([136, 37],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([136, 37],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:01.427701 test begin: paddle.nn.functional.embedding(Tensor([136, 9],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([136, 9],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:02.364824 test begin: paddle.nn.functional.embedding(Tensor([14, 209],"int64"), weight=Tensor([50000, 384],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([14, 209],"int64"), weight=Tensor([50000, 384],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:02.975463 test begin: paddle.nn.functional.embedding(Tensor([144, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([144, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:03.551081 test begin: paddle.nn.functional.embedding(Tensor([144, 15],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([144, 15],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:04.125205 test begin: paddle.nn.functional.embedding(Tensor([144, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([144, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:04.737206 test begin: paddle.nn.functional.embedding(Tensor([144, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([144, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:05.319646 test begin: paddle.nn.functional.embedding(Tensor([144, 21],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([144, 21],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:06.316353 test begin: paddle.nn.functional.embedding(Tensor([144, 21],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([144, 21],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:06.910636 test begin: paddle.nn.functional.embedding(Tensor([144, 22],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([144, 22],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:07.489158 test begin: paddle.nn.functional.embedding(Tensor([144, 23],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([144, 23],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:08.540041 test begin: paddle.nn.functional.embedding(Tensor([144, 23],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([144, 23],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:09.134754 test begin: paddle.nn.functional.embedding(Tensor([144, 24],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([144, 24],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 505 / 1769472 (0.0285%)
Max absolute difference: 0.9940965
Max relative difference: 1.
 x: array([[[1.475012e-01, 7.598594e-01, 4.991572e-01, ..., 4.525315e-01,
         1.268854e-01, 1.734929e-01],
        [3.224359e-01, 3.469562e-01, 8.542487e-02, ..., 6.948971e-01,...
 y: array([[[1.475012e-01, 7.598594e-01, 4.991572e-01, ..., 4.525315e-01,
         1.268854e-01, 1.734929e-01],
        [3.224359e-01, 3.469562e-01, 8.542487e-02, ..., 6.948971e-01,...
2025-05-12 08:52:10.082232 test begin: paddle.nn.functional.embedding(Tensor([144, 25],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([144, 25],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:11.283389 test begin: paddle.nn.functional.embedding(Tensor([144, 25],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([144, 25],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:11.937437 test begin: paddle.nn.functional.embedding(Tensor([144, 26],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([144, 26],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:13.256438 test begin: paddle.nn.functional.embedding(Tensor([144, 26],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([144, 26],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:13.913497 test begin: paddle.nn.functional.embedding(Tensor([144, 27],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([144, 27],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:15.302979 test begin: paddle.nn.functional.embedding(Tensor([144, 27],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([144, 27],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:15.917750 test begin: paddle.nn.functional.embedding(Tensor([144, 28],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([144, 28],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:17.062153 test begin: paddle.nn.functional.embedding(Tensor([144, 28],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([144, 28],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:17.717938 test begin: paddle.nn.functional.embedding(Tensor([144, 29],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([144, 29],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:18.835927 test begin: paddle.nn.functional.embedding(Tensor([144, 30],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([144, 30],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:20.130964 test begin: paddle.nn.functional.embedding(Tensor([144, 31],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([144, 31],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:21.379666 test begin: paddle.nn.functional.embedding(Tensor([144, 32],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([144, 32],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:22.642145 test begin: paddle.nn.functional.embedding(Tensor([144, 33],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([144, 33],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:24.353108 test begin: paddle.nn.functional.embedding(Tensor([144, 34],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([144, 34],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1014 / 5013504 (0.0202%)
Max absolute difference: 0.9997806
Max relative difference: 1.
 x: array([[[0.415992, 0.96552 , 0.339464, ..., 0.476465, 0.869437,
         0.902016],
        [0.947727, 0.997193, 0.540883, ..., 0.829313, 0.175792,...
 y: array([[[0.415992, 0.96552 , 0.339464, ..., 0.476465, 0.869437,
         0.902016],
        [0.947727, 0.997193, 0.540883, ..., 0.829313, 0.175792,...
2025-05-12 08:52:25.853371 test begin: paddle.nn.functional.embedding(Tensor([144, 35],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([144, 35],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:27.135189 test begin: paddle.nn.functional.embedding(Tensor([15, 234],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([15, 234],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:28.003030 test begin: paddle.nn.functional.embedding(Tensor([15, 244],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([15, 244],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:28.594051 test begin: paddle.nn.functional.embedding(Tensor([152, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([152, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:29.269160 test begin: paddle.nn.functional.embedding(Tensor([152, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([152, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:30.025976 test begin: paddle.nn.functional.embedding(Tensor([152, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([152, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:30.652839 test begin: paddle.nn.functional.embedding(Tensor([152, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([152, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:31.492882 test begin: paddle.nn.functional.embedding(Tensor([152, 21],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([152, 21],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:32.133512 test begin: paddle.nn.functional.embedding(Tensor([152, 22],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([152, 22],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:32.734725 test begin: paddle.nn.functional.embedding(Tensor([152, 23],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([152, 23],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:33.370057 test begin: paddle.nn.functional.embedding(Tensor([152, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([152, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:34.482715 test begin: paddle.nn.functional.embedding(Tensor([152, 24],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([152, 24],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:35.154176 test begin: paddle.nn.functional.embedding(Tensor([152, 25],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([152, 25],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:36.319708 test begin: paddle.nn.functional.embedding(Tensor([152, 25],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([152, 25],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:36.937687 test begin: paddle.nn.functional.embedding(Tensor([152, 26],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([152, 26],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:38.023577 test begin: paddle.nn.functional.embedding(Tensor([152, 26],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([152, 26],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:38.644088 test begin: paddle.nn.functional.embedding(Tensor([152, 27],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([152, 27],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:39.749120 test begin: paddle.nn.functional.embedding(Tensor([152, 28],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([152, 28],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:40.927221 test begin: paddle.nn.functional.embedding(Tensor([152, 29],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([152, 29],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:42.138316 test begin: paddle.nn.functional.embedding(Tensor([152, 30],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([152, 30],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:43.347244 test begin: paddle.nn.functional.embedding(Tensor([152, 31],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([152, 31],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:44.605566 test begin: paddle.nn.functional.embedding(Tensor([152, 32],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([152, 32],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:45.758347 test begin: paddle.nn.functional.embedding(Tensor([152, 33],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([152, 33],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:46.927676 test begin: paddle.nn.functional.embedding(Tensor([16, 100],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([16, 100],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:47.486807 test begin: paddle.nn.functional.embedding(Tensor([16, 109],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([16, 109],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:48.080573 test begin: paddle.nn.functional.embedding(Tensor([16, 115],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([16, 115],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:48.700731 test begin: paddle.nn.functional.embedding(Tensor([16, 116],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([16, 116],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:49.311628 test begin: paddle.nn.functional.embedding(Tensor([16, 122],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([16, 122],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:49.926236 test begin: paddle.nn.functional.embedding(Tensor([16, 141],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([16, 141],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:50.525823 test begin: paddle.nn.functional.embedding(Tensor([16, 146],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([16, 146],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:51.193496 test begin: paddle.nn.functional.embedding(Tensor([16, 149],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([16, 149],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:51.841130 test begin: paddle.nn.functional.embedding(Tensor([16, 156],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([16, 156],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:52.481532 test begin: paddle.nn.functional.embedding(Tensor([16, 166],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([16, 166],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:53.139855 test begin: paddle.nn.functional.embedding(Tensor([16, 170],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([16, 170],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:54.166834 test begin: paddle.nn.functional.embedding(Tensor([16, 171],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([16, 171],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:54.769946 test begin: paddle.nn.functional.embedding(Tensor([16, 173],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([16, 173],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:55.412849 test begin: paddle.nn.functional.embedding(Tensor([16, 174],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([16, 174],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:56.016533 test begin: paddle.nn.functional.embedding(Tensor([16, 176],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([16, 176],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:56.633618 test begin: paddle.nn.functional.embedding(Tensor([16, 178],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([16, 178],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:57.225440 test begin: paddle.nn.functional.embedding(Tensor([16, 182],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([16, 182],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:58.249774 test begin: paddle.nn.functional.embedding(Tensor([16, 182],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([16, 182],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:58.884851 test begin: paddle.nn.functional.embedding(Tensor([16, 199],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([16, 199],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:52:59.495961 test begin: paddle.nn.functional.embedding(Tensor([16, 205],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([16, 205],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:00.088177 test begin: paddle.nn.functional.embedding(Tensor([16, 210],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([16, 210],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:01.121333 test begin: paddle.nn.functional.embedding(Tensor([16, 217],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([16, 217],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:02.170065 test begin: paddle.nn.functional.embedding(Tensor([16, 217],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([16, 217],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:02.798692 test begin: paddle.nn.functional.embedding(Tensor([16, 227],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([16, 227],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:03.844258 test begin: paddle.nn.functional.embedding(Tensor([16, 227],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([16, 227],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:04.469106 test begin: paddle.nn.functional.embedding(Tensor([16, 264],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([16, 264],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:05.597928 test begin: paddle.nn.functional.embedding(Tensor([16, 62],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([16, 62],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:06.546696 test begin: paddle.nn.functional.embedding(Tensor([16, 81],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([16, 81],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:07.125821 test begin: paddle.nn.functional.embedding(Tensor([16, 88],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([16, 88],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:08.104729 test begin: paddle.nn.functional.embedding(Tensor([16, 88],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([16, 88],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 510 / 720896 (0.0707%)
Max absolute difference: 0.99575025
Max relative difference: 1.
 x: array([[[0.291828, 0.664069, 0.271844, ..., 0.389978, 0.80248 ,
         0.574565],
        [0.50885 , 0.863331, 0.061563, ..., 0.697017, 0.661121,...
 y: array([[[0.291828, 0.664069, 0.271844, ..., 0.389978, 0.80248 ,
         0.574565],
        [0.50885 , 0.863331, 0.061563, ..., 0.697017, 0.661121,...
2025-05-12 08:53:08.704482 test begin: paddle.nn.functional.embedding(Tensor([16, 93],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([16, 93],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:09.277232 test begin: paddle.nn.functional.embedding(Tensor([16, 94],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([16, 94],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:09.883168 test begin: paddle.nn.functional.embedding(Tensor([160, 11],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([160, 11],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:10.471960 test begin: paddle.nn.functional.embedding(Tensor([160, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([160, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:11.067042 test begin: paddle.nn.functional.embedding(Tensor([160, 17],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([160, 17],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:12.074577 test begin: paddle.nn.functional.embedding(Tensor([160, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([160, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 508 / 1392640 (0.0365%)
Max absolute difference: 0.9997576
Max relative difference: 1.
 x: array([[[0.432279, 0.936085, 0.610719, ..., 0.545782, 0.356727,
         0.522342],
        [0.376815, 0.917663, 0.775893, ..., 0.323608, 0.189666,...
 y: array([[[0.432279, 0.936085, 0.610719, ..., 0.545782, 0.356727,
         0.522342],
        [0.376815, 0.917663, 0.775893, ..., 0.323608, 0.189666,...
2025-05-12 08:53:12.673733 test begin: paddle.nn.functional.embedding(Tensor([160, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([160, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:13.263773 test begin: paddle.nn.functional.embedding(Tensor([160, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([160, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:13.869906 test begin: paddle.nn.functional.embedding(Tensor([160, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([160, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:14.475838 test begin: paddle.nn.functional.embedding(Tensor([160, 21],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([160, 21],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:15.076251 test begin: paddle.nn.functional.embedding(Tensor([160, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([160, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:16.108351 test begin: paddle.nn.functional.embedding(Tensor([160, 22],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([160, 22],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:16.732618 test begin: paddle.nn.functional.embedding(Tensor([160, 23],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([160, 23],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:17.743983 test begin: paddle.nn.functional.embedding(Tensor([160, 23],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([160, 23],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:18.339227 test begin: paddle.nn.functional.embedding(Tensor([160, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([160, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:19.308252 test begin: paddle.nn.functional.embedding(Tensor([160, 24],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([160, 24],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:19.932986 test begin: paddle.nn.functional.embedding(Tensor([160, 25],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([160, 25],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1011 / 4096000 (0.0247%)
Max absolute difference: 0.99761105
Max relative difference: 1.
 x: array([[[7.798726e-01, 8.093683e-01, 7.978881e-02, ..., 9.481586e-01,
         3.129594e-01, 9.879020e-01],
        [7.131019e-01, 6.415411e-01, 9.876362e-02, ..., 2.809454e-01,...
 y: array([[[7.798726e-01, 8.093683e-01, 7.978881e-02, ..., 9.481586e-01,
         3.129594e-01, 9.879020e-01],
        [7.131019e-01, 6.415411e-01, 9.876362e-02, ..., 2.809454e-01,...
2025-05-12 08:53:21.039839 test begin: paddle.nn.functional.embedding(Tensor([160, 25],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([160, 25],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:21.633771 test begin: paddle.nn.functional.embedding(Tensor([160, 26],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([160, 26],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:22.717847 test begin: paddle.nn.functional.embedding(Tensor([160, 27],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([160, 27],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:23.864571 test begin: paddle.nn.functional.embedding(Tensor([160, 28],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([160, 28],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:25.033473 test begin: paddle.nn.functional.embedding(Tensor([160, 29],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([160, 29],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2028 / 4751360 (0.0427%)
Max absolute difference: 0.9999654
Max relative difference: 1.
 x: array([[[1.695537e-01, 2.281252e-01, 8.147497e-02, ..., 5.899557e-01,
         3.399224e-01, 4.799936e-01],
        [4.455313e-02, 1.874547e-01, 4.072596e-01, ..., 7.698830e-01,...
 y: array([[[1.695537e-01, 2.281252e-01, 8.147497e-02, ..., 5.899557e-01,
         3.399224e-01, 4.799936e-01],
        [4.455313e-02, 1.874547e-01, 4.072596e-01, ..., 7.698830e-01,...
2025-05-12 08:53:26.430649 test begin: paddle.nn.functional.embedding(Tensor([160, 30],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([160, 30],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:27.777150 test begin: paddle.nn.functional.embedding(Tensor([160, 31],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([160, 31],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1014 / 5079040 (0.02%)
Max absolute difference: 0.9985064
Max relative difference: 1.
 x: array([[[0.367526, 0.091252, 0.913197, ..., 0.588579, 0.991793,
         0.774525],
        [0.571022, 0.760829, 0.611285, ..., 0.369293, 0.402147,...
 y: array([[[0.367526, 0.091252, 0.913197, ..., 0.588579, 0.991793,
         0.774525],
        [0.571022, 0.760829, 0.611285, ..., 0.369293, 0.402147,...
2025-05-12 08:53:29.128931 test begin: paddle.nn.functional.embedding(Tensor([160, 32],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([160, 32],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:30.386978 test begin: paddle.nn.functional.embedding(Tensor([160, 7],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([160, 7],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:30.937868 test begin: paddle.nn.functional.embedding(Tensor([168, 12],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([168, 12],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:31.645935 test begin: paddle.nn.functional.embedding(Tensor([168, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([168, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:32.378404 test begin: paddle.nn.functional.embedding(Tensor([168, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([168, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:32.960571 test begin: paddle.nn.functional.embedding(Tensor([168, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([168, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:33.818096 test begin: paddle.nn.functional.embedding(Tensor([168, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([168, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:34.851782 test begin: paddle.nn.functional.embedding(Tensor([168, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([168, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:35.553305 test begin: paddle.nn.functional.embedding(Tensor([168, 21],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([168, 21],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:36.391874 test begin: paddle.nn.functional.embedding(Tensor([168, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([168, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:37.457209 test begin: paddle.nn.functional.embedding(Tensor([168, 22],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([168, 22],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:38.042100 test begin: paddle.nn.functional.embedding(Tensor([168, 23],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([168, 23],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:39.203308 test begin: paddle.nn.functional.embedding(Tensor([168, 23],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([168, 23],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 510 / 1978368 (0.0258%)
Max absolute difference: 0.9998485
Max relative difference: 1.
 x: array([[[0.982271, 0.133945, 0.707471, ..., 0.9275  , 0.137212,
         0.238366],
        [0.752171, 0.788   , 0.609232, ..., 0.675063, 0.707186,...
 y: array([[[0.982271, 0.133945, 0.707471, ..., 0.9275  , 0.137212,
         0.238366],
        [0.752171, 0.788   , 0.609232, ..., 0.675063, 0.707186,...
2025-05-12 08:53:40.074483 test begin: paddle.nn.functional.embedding(Tensor([168, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([168, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:41.202503 test begin: paddle.nn.functional.embedding(Tensor([168, 24],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([168, 24],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:41.800253 test begin: paddle.nn.functional.embedding(Tensor([168, 25],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([168, 25],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:42.898976 test begin: paddle.nn.functional.embedding(Tensor([168, 26],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([168, 26],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1015 / 4472832 (0.0227%)
Max absolute difference: 0.99795985
Max relative difference: 1.
 x: array([[[0.107832, 0.997675, 0.116091, ..., 0.461033, 0.966346,
         0.56785 ],
        [0.140868, 0.18522 , 0.446041, ..., 0.708234, 0.754536,...
 y: array([[[0.107832, 0.997675, 0.116091, ..., 0.461033, 0.966346,
         0.56785 ],
        [0.140868, 0.18522 , 0.446041, ..., 0.708234, 0.754536,...
2025-05-12 08:53:44.220980 test begin: paddle.nn.functional.embedding(Tensor([168, 27],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([168, 27],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:45.461902 test begin: paddle.nn.functional.embedding(Tensor([168, 28],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([168, 28],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:46.865272 test begin: paddle.nn.functional.embedding(Tensor([168, 29],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([168, 29],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:48.237949 test begin: paddle.nn.functional.embedding(Tensor([168, 30],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([168, 30],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:49.489119 test begin: paddle.nn.functional.embedding(Tensor([176, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([176, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:50.588201 test begin: paddle.nn.functional.embedding(Tensor([176, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([176, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:51.379166 test begin: paddle.nn.functional.embedding(Tensor([176, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([176, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:52.168156 test begin: paddle.nn.functional.embedding(Tensor([176, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([176, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:52.954477 test begin: paddle.nn.functional.embedding(Tensor([176, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([176, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:54.264104 test begin: paddle.nn.functional.embedding(Tensor([176, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([176, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:55.116078 test begin: paddle.nn.functional.embedding(Tensor([176, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([176, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:56.301106 test begin: paddle.nn.functional.embedding(Tensor([176, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([176, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:56.950160 test begin: paddle.nn.functional.embedding(Tensor([176, 21],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([176, 21],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:58.145575 test begin: paddle.nn.functional.embedding(Tensor([176, 21],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([176, 21],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:53:58.810109 test begin: paddle.nn.functional.embedding(Tensor([176, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([176, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1017 / 3964928 (0.0256%)
Max absolute difference: 0.99992746
Max relative difference: 1.
 x: array([[[0.540687, 0.479823, 0.70139 , ..., 0.124223, 0.330802,
         0.764599],
        [0.506708, 0.649646, 0.797766, ..., 0.707236, 0.572933,...
 y: array([[[0.540687, 0.479823, 0.70139 , ..., 0.124223, 0.330802,
         0.764599],
        [0.506708, 0.649646, 0.797766, ..., 0.707236, 0.572933,...
2025-05-12 08:54:00.375105 test begin: paddle.nn.functional.embedding(Tensor([176, 22],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([176, 22],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:01.076889 test begin: paddle.nn.functional.embedding(Tensor([176, 23],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([176, 23],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:02.403967 test begin: paddle.nn.functional.embedding(Tensor([176, 23],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([176, 23],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:03.173484 test begin: paddle.nn.functional.embedding(Tensor([176, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([176, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:04.330074 test begin: paddle.nn.functional.embedding(Tensor([176, 25],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([176, 25],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:05.569955 test begin: paddle.nn.functional.embedding(Tensor([176, 26],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([176, 26],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:07.007574 test begin: paddle.nn.functional.embedding(Tensor([176, 27],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([176, 27],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:08.236868 test begin: paddle.nn.functional.embedding(Tensor([176, 28],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([176, 28],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1016 / 5046272 (0.0201%)
Max absolute difference: 0.99967855
Max relative difference: 1.
 x: array([[[0.61676 , 0.24728 , 0.390628, ..., 0.408149, 0.642627,
         0.617151],
        [0.982579, 0.131233, 0.439191, ..., 0.330373, 0.999168,...
 y: array([[[0.61676 , 0.24728 , 0.390628, ..., 0.408149, 0.642627,
         0.617151],
        [0.982579, 0.131233, 0.439191, ..., 0.330373, 0.999168,...
2025-05-12 08:54:09.643750 test begin: paddle.nn.functional.embedding(Tensor([176, 29],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([176, 29],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:10.920207 test begin: paddle.nn.functional.embedding(Tensor([184, 13],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([184, 13],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1008 / 2449408 (0.0412%)
Max absolute difference: 0.99969894
Max relative difference: 1.
 x: array([[[0.948619, 0.141731, 0.142381, ..., 0.628901, 0.653336,
         0.763421],
        [0.84105 , 0.22925 , 0.345904, ..., 0.338656, 0.296906,...
 y: array([[[0.948619, 0.141731, 0.142381, ..., 0.628901, 0.653336,
         0.763421],
        [0.84105 , 0.22925 , 0.345904, ..., 0.338656, 0.296906,...
2025-05-12 08:54:12.022640 test begin: paddle.nn.functional.embedding(Tensor([184, 14],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([184, 14],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:12.633911 test begin: paddle.nn.functional.embedding(Tensor([184, 15],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([184, 15],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 507 / 1413120 (0.0359%)
Max absolute difference: 0.999379
Max relative difference: 1.
 x: array([[[0.76061 , 0.198866, 0.92427 , ..., 0.7489  , 0.176631,
         0.395084],
        [0.105069, 0.700693, 0.153329, ..., 0.636146, 0.662506,...
 y: array([[[0.76061 , 0.198866, 0.92427 , ..., 0.7489  , 0.176631,
         0.395084],
        [0.105069, 0.700693, 0.153329, ..., 0.636146, 0.662506,...
2025-05-12 08:54:13.290140 test begin: paddle.nn.functional.embedding(Tensor([184, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([184, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:13.892090 test begin: paddle.nn.functional.embedding(Tensor([184, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([184, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:14.535415 test begin: paddle.nn.functional.embedding(Tensor([184, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([184, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:15.660168 test begin: paddle.nn.functional.embedding(Tensor([184, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([184, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:16.353973 test begin: paddle.nn.functional.embedding(Tensor([184, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([184, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:16.943719 test begin: paddle.nn.functional.embedding(Tensor([184, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([184, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:18.078974 test begin: paddle.nn.functional.embedding(Tensor([184, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([184, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 502 / 1884160 (0.0266%)
Max absolute difference: 0.9996914
Max relative difference: 1.
 x: array([[[0.230437, 0.191929, 0.769287, ..., 0.778484, 0.154879,
         0.167517],
        [0.883043, 0.18644 , 0.309667, ..., 0.347032, 0.982238,...
 y: array([[[0.230437, 0.191929, 0.769287, ..., 0.778484, 0.154879,
         0.167517],
        [0.883043, 0.18644 , 0.309667, ..., 0.347032, 0.982238,...
2025-05-12 08:54:18.735561 test begin: paddle.nn.functional.embedding(Tensor([184, 21],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([184, 21],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:19.844776 test begin: paddle.nn.functional.embedding(Tensor([184, 21],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([184, 21],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:20.471473 test begin: paddle.nn.functional.embedding(Tensor([184, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([184, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:21.584126 test begin: paddle.nn.functional.embedding(Tensor([184, 22],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([184, 22],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:22.216904 test begin: paddle.nn.functional.embedding(Tensor([184, 23],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([184, 23],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:23.365115 test begin: paddle.nn.functional.embedding(Tensor([184, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([184, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:24.605580 test begin: paddle.nn.functional.embedding(Tensor([184, 25],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([184, 25],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:25.828192 test begin: paddle.nn.functional.embedding(Tensor([184, 26],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([184, 26],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:27.046623 test begin: paddle.nn.functional.embedding(Tensor([184, 27],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([184, 27],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:28.264088 test begin: paddle.nn.functional.embedding(Tensor([184, 7],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([184, 7],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1015 / 1318912 (0.077%)
Max absolute difference: 0.9998324
Max relative difference: 1.
 x: array([[[7.734752e-01, 3.067534e-01, 2.569661e-02, ..., 1.082264e-01,
         2.887200e-01, 7.066599e-01],
        [8.642540e-01, 8.885396e-01, 5.826311e-01, ..., 7.007251e-01,...
 y: array([[[7.734752e-01, 3.067534e-01, 2.569661e-02, ..., 1.082264e-01,
         2.887200e-01, 7.066599e-01],
        [8.642540e-01, 8.885396e-01, 5.826311e-01, ..., 7.007251e-01,...
2025-05-12 08:54:29.325822 test begin: paddle.nn.functional.embedding(Tensor([192, 10],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([192, 10],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:29.920079 test begin: paddle.nn.functional.embedding(Tensor([192, 15],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([192, 15],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:30.543194 test begin: paddle.nn.functional.embedding(Tensor([192, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([192, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:31.146155 test begin: paddle.nn.functional.embedding(Tensor([192, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([192, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:31.750824 test begin: paddle.nn.functional.embedding(Tensor([192, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([192, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:32.374789 test begin: paddle.nn.functional.embedding(Tensor([192, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([192, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:33.521026 test begin: paddle.nn.functional.embedding(Tensor([192, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([192, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:34.121716 test begin: paddle.nn.functional.embedding(Tensor([192, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([192, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:35.231542 test begin: paddle.nn.functional.embedding(Tensor([192, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([192, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:35.849390 test begin: paddle.nn.functional.embedding(Tensor([192, 21],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([192, 21],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:36.934815 test begin: paddle.nn.functional.embedding(Tensor([192, 21],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([192, 21],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:37.582029 test begin: paddle.nn.functional.embedding(Tensor([192, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([192, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:38.716765 test begin: paddle.nn.functional.embedding(Tensor([192, 22],"int64"), weight=Tensor([6629, 384],"float16"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([192, 22],"int64"), weight=Tensor([6629, 384],"float16"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 381 / 1622016 (0.0235%)
Max absolute difference: 0.9985
Max relative difference: 1.
 x: array([[[0.713   , 0.981   , 0.3262  , ..., 0.5874  , 0.4167  ,
         0.1373  ],
        [0.1183  , 0.901   , 0.415   , ..., 0.07764 , 0.1826  ,...
 y: array([[[0.713   , 0.981   , 0.3262  , ..., 0.5874  , 0.4167  ,
         0.1373  ],
        [0.1183  , 0.901   , 0.415   , ..., 0.07764 , 0.1826  ,...
2025-05-12 08:54:39.181465 test begin: paddle.nn.functional.embedding(Tensor([192, 23],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([192, 23],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:40.451222 test begin: paddle.nn.functional.embedding(Tensor([192, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([192, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:41.679297 test begin: paddle.nn.functional.embedding(Tensor([192, 25],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([192, 25],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:42.875492 test begin: paddle.nn.functional.embedding(Tensor([192, 26],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([192, 26],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:44.233404 test begin: paddle.nn.functional.embedding(Tensor([192, 7],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([192, 7],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:44.850147 test begin: paddle.nn.functional.embedding(Tensor([1],"int64"), weight=Tensor([19529, 300],"float32"), padding_idx=19528, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([1],"int64"), weight=Tensor([19529, 300],"float32"), padding_idx=19528, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:45.124630 test begin: paddle.nn.functional.embedding(Tensor([2, 10],"int32"), weight=Tensor([1801, 8],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([2, 10],"int32"), weight=Tensor([1801, 8],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:45.267325 test begin: paddle.nn.functional.embedding(Tensor([2, 10],"int64"), weight=Tensor([31985, 64],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([2, 10],"int64"), weight=Tensor([31985, 64],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:45.457338 test begin: paddle.nn.functional.embedding(Tensor([2, 10],"int64"), weight=Tensor([32000, 64],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([2, 10],"int64"), weight=Tensor([32000, 64],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:45.692362 test begin: paddle.nn.functional.embedding(Tensor([2, 10],"int64"), weight=Tensor([32010, 64],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([2, 10],"int64"), weight=Tensor([32010, 64],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:45.919890 test begin: paddle.nn.functional.embedding(Tensor([2, 1],"int64"), weight=Tensor([32000, 64],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([2, 1],"int64"), weight=Tensor([32000, 64],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:46.143542 test begin: paddle.nn.functional.embedding(Tensor([2, 3],"int32"), weight=Tensor([1801, 8],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([2, 3],"int32"), weight=Tensor([1801, 8],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:46.293919 test begin: paddle.nn.functional.embedding(Tensor([2, 3],"int64"), Tensor([10, 4],"float32"), padding_idx=-1, scale_grad_by_freq=False, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([2, 3],"int64"), Tensor([10, 4],"float32"), padding_idx=-1, scale_grad_by_freq=False, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4 / 24 (16.7%)
Max absolute difference: 0.74879396
Max relative difference: 1.
 x: array([[[0.339393, 0.8352  , 0.752787, 0.363164],
        [0.      , 0.      , 0.      , 0.      ],
        [0.720137, 0.447732, 0.840494, 0.924113]],...
 y: array([[[0.339393, 0.8352  , 0.752787, 0.363164],
        [0.748794, 0.101976, 0.735763, 0.58675 ],
        [0.720137, 0.447732, 0.840494, 0.924113]],...
2025-05-12 08:54:46.486226 test begin: paddle.nn.functional.embedding(Tensor([2, 3],"int64"), Tensor([10, 4],"float32"), padding_idx=-1, scale_grad_by_freq=True, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([2, 3],"int64"), Tensor([10, 4],"float32"), padding_idx=-1, scale_grad_by_freq=True, )
2025-05-12 08:54:46.673926 test begin: paddle.nn.functional.embedding(Tensor([2, 4],"int64"), Tensor([10, 4],"float32"), padding_idx=2, scale_grad_by_freq=False, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([2, 4],"int64"), Tensor([10, 4],"float32"), padding_idx=2, scale_grad_by_freq=False, )
2025-05-12 08:54:46.826917 test begin: paddle.nn.functional.embedding(Tensor([2, 4],"int64"), Tensor([10, 4],"float32"), padding_idx=2, scale_grad_by_freq=True, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([2, 4],"int64"), Tensor([10, 4],"float32"), padding_idx=2, scale_grad_by_freq=True, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 8 / 32 (25%)
Max absolute difference: 0.7627845
Max relative difference: 1.
 x: array([[[0.407083, 0.226062, 0.633599, 0.052844],
        [0.216581, 0.716732, 0.571368, 0.384438],
        [0.      , 0.      , 0.      , 0.      ],...
 y: array([[[0.407083, 0.226062, 0.633599, 0.052844],
        [0.216581, 0.716732, 0.571368, 0.384438],
        [0.69647 , 0.259788, 0.383742, 0.762784],...
2025-05-12 08:54:47.031299 test begin: paddle.nn.functional.embedding(Tensor([2, 5],"int64"), weight=Tensor([32000, 64],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([2, 5],"int64"), weight=Tensor([32000, 64],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:47.242807 test begin: paddle.nn.functional.embedding(Tensor([2, 64],"int64"), weight=Tensor([30522, 768],"float16"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([2, 64],"int64"), weight=Tensor([30522, 768],"float16"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:48.080707 test begin: paddle.nn.functional.embedding(Tensor([2, 7],"int32"), weight=Tensor([1801, 8],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([2, 7],"int32"), weight=Tensor([1801, 8],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:48.235126 test begin: paddle.nn.functional.embedding(Tensor([200, 14],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([200, 14],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:48.863328 test begin: paddle.nn.functional.embedding(Tensor([200, 15],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([200, 15],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:49.984673 test begin: paddle.nn.functional.embedding(Tensor([200, 15],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([200, 15],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:50.605435 test begin: paddle.nn.functional.embedding(Tensor([200, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([200, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:51.245878 test begin: paddle.nn.functional.embedding(Tensor([200, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([200, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 510 / 1740800 (0.0293%)
Max absolute difference: 0.9983815
Max relative difference: 1.
 x: array([[[2.030441e-02, 4.751561e-01, 2.268825e-01, ..., 9.384615e-01,
         3.647350e-01, 9.115048e-01],
        [4.738602e-01, 6.923695e-01, 7.500653e-01, ..., 1.666249e-02,...
 y: array([[[2.030441e-02, 4.751561e-01, 2.268825e-01, ..., 9.384615e-01,
         3.647350e-01, 9.115048e-01],
        [4.738602e-01, 6.923695e-01, 7.500653e-01, ..., 1.666249e-02,...
2025-05-12 08:54:51.843912 test begin: paddle.nn.functional.embedding(Tensor([200, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([200, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1006 / 3686400 (0.0273%)
Max absolute difference: 0.99782
Max relative difference: 1.
 x: array([[[0.455886, 0.703771, 0.170469, ..., 0.081299, 0.377229,
         0.298478],
        [0.551031, 0.150578, 0.794525, ..., 0.492473, 0.745745,...
 y: array([[[0.455886, 0.703771, 0.170469, ..., 0.081299, 0.377229,
         0.298478],
        [0.551031, 0.150578, 0.794525, ..., 0.492473, 0.745745,...
2025-05-12 08:54:52.961414 test begin: paddle.nn.functional.embedding(Tensor([200, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([200, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:53.628584 test begin: paddle.nn.functional.embedding(Tensor([200, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([200, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:54.851290 test begin: paddle.nn.functional.embedding(Tensor([200, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([200, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:55.438780 test begin: paddle.nn.functional.embedding(Tensor([200, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([200, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:56.625746 test begin: paddle.nn.functional.embedding(Tensor([200, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([200, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:57.239664 test begin: paddle.nn.functional.embedding(Tensor([200, 21],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([200, 21],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:54:58.285024 test begin: paddle.nn.functional.embedding(Tensor([200, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([200, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1015 / 4505600 (0.0225%)
Max absolute difference: 0.9965851
Max relative difference: 1.
 x: array([[[0.279764, 0.354727, 0.857846, ..., 0.162787, 0.22941 ,
         0.970742],
        [0.897103, 0.934031, 0.325137, ..., 0.547322, 0.571405,...
 y: array([[[0.279764, 0.354727, 0.857846, ..., 0.162787, 0.22941 ,
         0.970742],
        [0.897103, 0.934031, 0.325137, ..., 0.547322, 0.571405,...
2025-05-12 08:54:59.452977 test begin: paddle.nn.functional.embedding(Tensor([200, 23],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([200, 23],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:00.608005 test begin: paddle.nn.functional.embedding(Tensor([200, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([200, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:01.734025 test begin: paddle.nn.functional.embedding(Tensor([200, 25],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([200, 25],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1018 / 5120000 (0.0199%)
Max absolute difference: 0.9993128
Max relative difference: 1.
 x: array([[[0.00279 , 0.590674, 0.356219, ..., 0.027866, 0.7045  ,
         0.874246],
        [0.102998, 0.83915 , 0.116287, ..., 0.548244, 0.419746,...
 y: array([[[0.00279 , 0.590674, 0.356219, ..., 0.027866, 0.7045  ,
         0.874246],
        [0.102998, 0.83915 , 0.116287, ..., 0.548244, 0.419746,...
2025-05-12 08:55:02.923781 test begin: paddle.nn.functional.embedding(Tensor([208, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([208, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:03.539840 test begin: paddle.nn.functional.embedding(Tensor([208, 14],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([208, 14],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:04.142002 test begin: paddle.nn.functional.embedding(Tensor([208, 15],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([208, 15],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:04.746711 test begin: paddle.nn.functional.embedding(Tensor([208, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([208, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:05.407367 test begin: paddle.nn.functional.embedding(Tensor([208, 17],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([208, 17],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:06.533340 test begin: paddle.nn.functional.embedding(Tensor([208, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([208, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:07.148471 test begin: paddle.nn.functional.embedding(Tensor([208, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([208, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:08.222186 test begin: paddle.nn.functional.embedding(Tensor([208, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([208, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:08.900264 test begin: paddle.nn.functional.embedding(Tensor([208, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([208, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:09.915326 test begin: paddle.nn.functional.embedding(Tensor([208, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([208, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:10.524553 test begin: paddle.nn.functional.embedding(Tensor([208, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([208, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:11.644422 test begin: paddle.nn.functional.embedding(Tensor([208, 21],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([208, 21],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:12.756114 test begin: paddle.nn.functional.embedding(Tensor([208, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([208, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:13.877821 test begin: paddle.nn.functional.embedding(Tensor([208, 23],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([208, 23],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1013 / 4898816 (0.0207%)
Max absolute difference: 0.9998753
Max relative difference: 1.
 x: array([[[0.230233, 0.292364, 0.497864, ..., 0.012704, 0.298706,
         0.676695],
        [0.570704, 0.073548, 0.969983, ..., 0.71776 , 0.246601,...
 y: array([[[0.230233, 0.292364, 0.497864, ..., 0.012704, 0.298706,
         0.676695],
        [0.570704, 0.073548, 0.969983, ..., 0.71776 , 0.246601,...
2025-05-12 08:55:15.051680 test begin: paddle.nn.functional.embedding(Tensor([208, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([208, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:16.136357 test begin: paddle.nn.functional.embedding(Tensor([216, 10],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([216, 10],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:17.114439 test begin: paddle.nn.functional.embedding(Tensor([216, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([216, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:18.144141 test begin: paddle.nn.functional.embedding(Tensor([216, 17],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([216, 17],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:19.156044 test begin: paddle.nn.functional.embedding(Tensor([216, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([216, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1019 / 3981312 (0.0256%)
Max absolute difference: 0.99934083
Max relative difference: 1.
 x: array([[[0.85464 , 0.650243, 0.670033, ..., 0.224312, 0.63352 ,
         0.946925],
        [0.757   , 0.894158, 0.613915, ..., 0.680554, 0.921553,...
 y: array([[[0.85464 , 0.650243, 0.670033, ..., 0.224312, 0.63352 ,
         0.946925],
        [0.757   , 0.894158, 0.613915, ..., 0.680554, 0.921553,...
2025-05-12 08:55:20.277451 test begin: paddle.nn.functional.embedding(Tensor([216, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([216, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:21.367301 test begin: paddle.nn.functional.embedding(Tensor([216, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([216, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:22.507505 test begin: paddle.nn.functional.embedding(Tensor([216, 21],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([216, 21],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:23.611685 test begin: paddle.nn.functional.embedding(Tensor([216, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([216, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:24.714791 test begin: paddle.nn.functional.embedding(Tensor([216, 23],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([216, 23],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:25.900463 test begin: paddle.nn.functional.embedding(Tensor([224, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([224, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:26.467577 test begin: paddle.nn.functional.embedding(Tensor([224, 14],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([224, 14],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:27.059296 test begin: paddle.nn.functional.embedding(Tensor([224, 15],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([224, 15],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:27.678561 test begin: paddle.nn.functional.embedding(Tensor([224, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([224, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:28.286107 test begin: paddle.nn.functional.embedding(Tensor([224, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([224, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:28.884851 test begin: paddle.nn.functional.embedding(Tensor([224, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([224, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:29.484502 test begin: paddle.nn.functional.embedding(Tensor([232, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([232, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:30.099881 test begin: paddle.nn.functional.embedding(Tensor([232, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([232, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:31.137488 test begin: paddle.nn.functional.embedding(Tensor([232, 17],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([232, 17],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:32.142042 test begin: paddle.nn.functional.embedding(Tensor([232, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([232, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:32.736607 test begin: paddle.nn.functional.embedding(Tensor([232, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([232, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:33.755325 test begin: paddle.nn.functional.embedding(Tensor([232, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([232, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:34.818219 test begin: paddle.nn.functional.embedding(Tensor([232, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([232, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1014 / 4751360 (0.0213%)
Max absolute difference: 0.99932986
Max relative difference: 1.
 x: array([[[0.067314, 0.231274, 0.917614, ..., 0.769831, 0.282387,
         0.46689 ],
        [0.389055, 0.470696, 0.222992, ..., 0.368361, 0.783628,...
 y: array([[[0.067314, 0.231274, 0.917614, ..., 0.769831, 0.282387,
         0.46689 ],
        [0.389055, 0.470696, 0.222992, ..., 0.368361, 0.783628,...
2025-05-12 08:55:35.937973 test begin: paddle.nn.functional.embedding(Tensor([232, 21],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([232, 21],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:37.040559 test begin: paddle.nn.functional.embedding(Tensor([232, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([232, 22],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:38.202584 test begin: paddle.nn.functional.embedding(Tensor([24, 101],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 101],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:38.786541 test begin: paddle.nn.functional.embedding(Tensor([24, 103],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 103],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:39.378537 test begin: paddle.nn.functional.embedding(Tensor([24, 104],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([24, 104],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1018 / 1277952 (0.0797%)
Max absolute difference: 0.9995166
Max relative difference: 1.
 x: array([[[0.078316, 0.332609, 0.680821, ..., 0.826713, 0.800541,
         0.707341],
        [0.99125 , 0.906383, 0.518545, ..., 0.997223, 0.087802,...
 y: array([[[0.078316, 0.332609, 0.680821, ..., 0.826713, 0.800541,
         0.707341],
        [0.99125 , 0.906383, 0.518545, ..., 0.997223, 0.087802,...
2025-05-12 08:55:39.980834 test begin: paddle.nn.functional.embedding(Tensor([24, 105],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 105],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:40.572938 test begin: paddle.nn.functional.embedding(Tensor([24, 106],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 106],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:41.156947 test begin: paddle.nn.functional.embedding(Tensor([24, 107],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 107],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:41.741874 test begin: paddle.nn.functional.embedding(Tensor([24, 109],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 109],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:42.333726 test begin: paddle.nn.functional.embedding(Tensor([24, 110],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 110],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:43.344392 test begin: paddle.nn.functional.embedding(Tensor([24, 110],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 110],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:43.931963 test begin: paddle.nn.functional.embedding(Tensor([24, 111],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 111],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:44.523997 test begin: paddle.nn.functional.embedding(Tensor([24, 112],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([24, 112],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 507 / 1376256 (0.0368%)
Max absolute difference: 0.9998549
Max relative difference: 1.
 x: array([[[0.405776, 0.047433, 0.57531 , ..., 0.232954, 0.904711,
         0.787818],
        [0.818166, 0.104741, 0.485327, ..., 0.935897, 0.879953,...
 y: array([[[0.405776, 0.047433, 0.57531 , ..., 0.232954, 0.904711,
         0.787818],
        [0.818166, 0.104741, 0.485327, ..., 0.935897, 0.879953,...
2025-05-12 08:55:45.121111 test begin: paddle.nn.functional.embedding(Tensor([24, 113],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 113],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:45.700257 test begin: paddle.nn.functional.embedding(Tensor([24, 114],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 114],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:46.281913 test begin: paddle.nn.functional.embedding(Tensor([24, 115],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 115],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:46.871877 test begin: paddle.nn.functional.embedding(Tensor([24, 116],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 116],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:47.844697 test begin: paddle.nn.functional.embedding(Tensor([24, 116],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 116],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:48.422279 test begin: paddle.nn.functional.embedding(Tensor([24, 117],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 117],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:49.000022 test begin: paddle.nn.functional.embedding(Tensor([24, 118],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 118],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:49.588778 test begin: paddle.nn.functional.embedding(Tensor([24, 119],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 119],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:50.193505 test begin: paddle.nn.functional.embedding(Tensor([24, 121],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 121],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:50.780814 test begin: paddle.nn.functional.embedding(Tensor([24, 122],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 122],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:51.760933 test begin: paddle.nn.functional.embedding(Tensor([24, 122],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 122],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:52.342484 test begin: paddle.nn.functional.embedding(Tensor([24, 123],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 123],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:52.986031 test begin: paddle.nn.functional.embedding(Tensor([24, 124],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 124],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:53.574268 test begin: paddle.nn.functional.embedding(Tensor([24, 126],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 126],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:54.172140 test begin: paddle.nn.functional.embedding(Tensor([24, 128],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 128],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:54.766138 test begin: paddle.nn.functional.embedding(Tensor([24, 129],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 129],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:55.358019 test begin: paddle.nn.functional.embedding(Tensor([24, 130],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 130],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:55.956629 test begin: paddle.nn.functional.embedding(Tensor([24, 131],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 131],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:56.573339 test begin: paddle.nn.functional.embedding(Tensor([24, 132],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 132],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:57.163268 test begin: paddle.nn.functional.embedding(Tensor([24, 133],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 133],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:57.763868 test begin: paddle.nn.functional.embedding(Tensor([24, 135],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 135],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:58.351120 test begin: paddle.nn.functional.embedding(Tensor([24, 136],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 136],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:58.942642 test begin: paddle.nn.functional.embedding(Tensor([24, 137],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 137],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:55:59.531808 test begin: paddle.nn.functional.embedding(Tensor([24, 139],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 139],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:00.178404 test begin: paddle.nn.functional.embedding(Tensor([24, 140],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 140],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:00.781733 test begin: paddle.nn.functional.embedding(Tensor([24, 141],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 141],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:01.375252 test begin: paddle.nn.functional.embedding(Tensor([24, 142],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([24, 142],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 509 / 1744896 (0.0292%)
Max absolute difference: 0.9979
Max relative difference: 1.
 x: array([[[0.780236, 0.525429, 0.119361, ..., 0.327357, 0.196569,
         0.653603],
        [0.802886, 0.49573 , 0.248531, ..., 0.137801, 0.26239 ,...
 y: array([[[0.780236, 0.525429, 0.119361, ..., 0.327357, 0.196569,
         0.653603],
        [0.802886, 0.49573 , 0.248531, ..., 0.137801, 0.26239 ,...
2025-05-12 08:56:01.991547 test begin: paddle.nn.functional.embedding(Tensor([24, 144],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 144],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:02.989689 test begin: paddle.nn.functional.embedding(Tensor([24, 144],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([24, 144],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 507 / 1769472 (0.0287%)
Max absolute difference: 0.9980642
Max relative difference: 1.
 x: array([[[5.440813e-01, 8.197064e-01, 7.510898e-01, ..., 2.760623e-01,
         8.262594e-01, 2.194155e-01],
        [5.994274e-01, 6.113018e-01, 3.660009e-01, ..., 8.469777e-01,...
 y: array([[[5.440813e-01, 8.197064e-01, 7.510898e-01, ..., 2.760623e-01,
         8.262594e-01, 2.194155e-01],
        [5.994274e-01, 6.113018e-01, 3.660009e-01, ..., 8.469777e-01,...
2025-05-12 08:56:03.615315 test begin: paddle.nn.functional.embedding(Tensor([24, 146],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 146],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:04.213052 test begin: paddle.nn.functional.embedding(Tensor([24, 149],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 149],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:05.236228 test begin: paddle.nn.functional.embedding(Tensor([24, 149],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 149],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:05.835032 test begin: paddle.nn.functional.embedding(Tensor([24, 150],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 150],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:06.441319 test begin: paddle.nn.functional.embedding(Tensor([24, 151],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 151],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:07.036270 test begin: paddle.nn.functional.embedding(Tensor([24, 153],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 153],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:07.641630 test begin: paddle.nn.functional.embedding(Tensor([24, 154],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 154],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:08.238711 test begin: paddle.nn.functional.embedding(Tensor([24, 157],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 157],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:08.842039 test begin: paddle.nn.functional.embedding(Tensor([24, 158],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 158],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:09.439602 test begin: paddle.nn.functional.embedding(Tensor([24, 159],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 159],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:10.049719 test begin: paddle.nn.functional.embedding(Tensor([24, 160],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 160],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:11.103232 test begin: paddle.nn.functional.embedding(Tensor([24, 162],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 162],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:12.126274 test begin: paddle.nn.functional.embedding(Tensor([24, 162],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 162],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:12.733466 test begin: paddle.nn.functional.embedding(Tensor([24, 163],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 163],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:13.777204 test begin: paddle.nn.functional.embedding(Tensor([24, 163],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 163],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:14.384169 test begin: paddle.nn.functional.embedding(Tensor([24, 171],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 171],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:15.406744 test begin: paddle.nn.functional.embedding(Tensor([24, 173],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 173],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:16.496511 test begin: paddle.nn.functional.embedding(Tensor([24, 174],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 174],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:17.592264 test begin: paddle.nn.functional.embedding(Tensor([24, 176],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([24, 176],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1013 / 4325376 (0.0234%)
Max absolute difference: 0.99968636
Max relative difference: 1.
 x: array([[[0.622972, 0.104885, 0.575146, ..., 0.497692, 0.526556,
         0.41902 ],
        [0.602546, 0.111228, 0.862149, ..., 0.140769, 0.916954,...
 y: array([[[0.622972, 0.104885, 0.575146, ..., 0.497692, 0.526556,
         0.41902 ],
        [0.602546, 0.111228, 0.862149, ..., 0.140769, 0.916954,...
2025-05-12 08:56:18.732367 test begin: paddle.nn.functional.embedding(Tensor([24, 178],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 178],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:19.810265 test begin: paddle.nn.functional.embedding(Tensor([24, 182],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 182],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:20.890578 test begin: paddle.nn.functional.embedding(Tensor([24, 205],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 205],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:22.029528 test begin: paddle.nn.functional.embedding(Tensor([24, 68],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 68],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:22.981852 test begin: paddle.nn.functional.embedding(Tensor([24, 68],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 68],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:23.549081 test begin: paddle.nn.functional.embedding(Tensor([24, 72],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 72],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:24.180783 test begin: paddle.nn.functional.embedding(Tensor([24, 80],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 80],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:24.749810 test begin: paddle.nn.functional.embedding(Tensor([24, 81],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 81],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:25.717080 test begin: paddle.nn.functional.embedding(Tensor([24, 81],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 81],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:26.295468 test begin: paddle.nn.functional.embedding(Tensor([24, 82],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 82],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:26.877384 test begin: paddle.nn.functional.embedding(Tensor([24, 83],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 83],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:27.549834 test begin: paddle.nn.functional.embedding(Tensor([24, 84],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 84],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:28.154306 test begin: paddle.nn.functional.embedding(Tensor([24, 86],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 86],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:28.720634 test begin: paddle.nn.functional.embedding(Tensor([24, 87],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([24, 87],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 507 / 1069056 (0.0474%)
Max absolute difference: 0.99999833
Max relative difference: 1.
 x: array([[[0.250245, 0.52254 , 0.233647, ..., 0.267212, 0.155893,
         0.020071],
        [0.40518 , 0.907257, 0.858296, ..., 0.800775, 0.118305,...
 y: array([[[0.250245, 0.52254 , 0.233647, ..., 0.267212, 0.155893,
         0.020071],
        [0.40518 , 0.907257, 0.858296, ..., 0.800775, 0.118305,...
2025-05-12 08:56:29.315176 test begin: paddle.nn.functional.embedding(Tensor([24, 89],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 89],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:29.889552 test begin: paddle.nn.functional.embedding(Tensor([24, 91],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 91],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:30.458244 test begin: paddle.nn.functional.embedding(Tensor([24, 94],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 94],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:31.408780 test begin: paddle.nn.functional.embedding(Tensor([24, 96],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 96],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:31.984340 test begin: paddle.nn.functional.embedding(Tensor([24, 97],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 97],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:32.948173 test begin: paddle.nn.functional.embedding(Tensor([24, 97],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([24, 97],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 507 / 1191936 (0.0425%)
Max absolute difference: 0.9994891
Max relative difference: 1.
 x: array([[[0.051631, 0.10904 , 0.740398, ..., 0.017659, 0.038201,
         0.078335],
        [0.35679 , 0.27528 , 0.062685, ..., 0.185233, 0.731718,...
 y: array([[[0.051631, 0.10904 , 0.740398, ..., 0.017659, 0.038201,
         0.078335],
        [0.35679 , 0.27528 , 0.062685, ..., 0.185233, 0.731718,...
2025-05-12 08:56:33.565113 test begin: paddle.nn.functional.embedding(Tensor([24, 98],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 98],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:34.190818 test begin: paddle.nn.functional.embedding(Tensor([24, 99],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 99],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:35.165222 test begin: paddle.nn.functional.embedding(Tensor([24, 99],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([24, 99],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:35.759623 test begin: paddle.nn.functional.embedding(Tensor([240, 12],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([240, 12],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:36.356060 test begin: paddle.nn.functional.embedding(Tensor([240, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([240, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:36.964110 test begin: paddle.nn.functional.embedding(Tensor([240, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([240, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:37.990218 test begin: paddle.nn.functional.embedding(Tensor([240, 14],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([240, 14],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 508 / 1720320 (0.0295%)
Max absolute difference: 0.99864477
Max relative difference: 1.
 x: array([[[0.411644, 0.883736, 0.678058, ..., 0.439885, 0.72561 ,
         0.863748],
        [0.179597, 0.111208, 0.086057, ..., 0.95261 , 0.067267,...
 y: array([[[0.411644, 0.883736, 0.678058, ..., 0.439885, 0.72561 ,
         0.863748],
        [0.179597, 0.111208, 0.086057, ..., 0.95261 , 0.067267,...
2025-05-12 08:56:38.605966 test begin: paddle.nn.functional.embedding(Tensor([240, 15],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([240, 15],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:39.624954 test begin: paddle.nn.functional.embedding(Tensor([240, 15],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([240, 15],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:40.268753 test begin: paddle.nn.functional.embedding(Tensor([240, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([240, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:41.283882 test begin: paddle.nn.functional.embedding(Tensor([240, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([240, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:41.901305 test begin: paddle.nn.functional.embedding(Tensor([240, 17],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([240, 17],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:42.940277 test begin: paddle.nn.functional.embedding(Tensor([240, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([240, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:43.555721 test begin: paddle.nn.functional.embedding(Tensor([240, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([240, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:44.641578 test begin: paddle.nn.functional.embedding(Tensor([240, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([240, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:45.709100 test begin: paddle.nn.functional.embedding(Tensor([240, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([240, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1012 / 4915200 (0.0206%)
Max absolute difference: 0.99820954
Max relative difference: 1.
 x: array([[[7.389239e-01, 9.862353e-01, 6.052105e-01, ..., 2.206244e-01,
         9.232597e-02, 5.650130e-01],
        [8.079609e-01, 1.567980e-02, 4.377592e-01, ..., 8.748566e-01,...
 y: array([[[7.389239e-01, 9.862353e-01, 6.052105e-01, ..., 2.206244e-01,
         9.232597e-02, 5.650130e-01],
        [8.079609e-01, 1.567980e-02, 4.377592e-01, ..., 8.748566e-01,...
2025-05-12 08:56:46.878399 test begin: paddle.nn.functional.embedding(Tensor([240, 21],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([240, 21],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:47.975628 test begin: paddle.nn.functional.embedding(Tensor([240, 7],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([240, 7],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:48.946796 test begin: paddle.nn.functional.embedding(Tensor([240, 9],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([240, 9],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:49.518361 test begin: paddle.nn.functional.embedding(Tensor([256, 11],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([256, 11],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 505 / 1441792 (0.035%)
Max absolute difference: 0.9900029
Max relative difference: 1.
 x: array([[[0.631337, 0.516036, 0.65636 , ..., 0.9054  , 0.975503,
         0.690002],
        [0.616584, 0.636937, 0.445812, ..., 0.3109  , 0.773638,...
 y: array([[[0.631337, 0.516036, 0.65636 , ..., 0.9054  , 0.975503,
         0.690002],
        [0.616584, 0.636937, 0.445812, ..., 0.3109  , 0.773638,...
2025-05-12 08:56:50.129667 test begin: paddle.nn.functional.embedding(Tensor([256, 12],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([256, 12],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:50.721820 test begin: paddle.nn.functional.embedding(Tensor([256, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([256, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:51.345867 test begin: paddle.nn.functional.embedding(Tensor([256, 14],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([256, 14],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:51.923864 test begin: paddle.nn.functional.embedding(Tensor([256, 15],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([256, 15],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:52.988324 test begin: paddle.nn.functional.embedding(Tensor([256, 15],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([256, 15],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:53.594142 test begin: paddle.nn.functional.embedding(Tensor([256, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([256, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:54.629023 test begin: paddle.nn.functional.embedding(Tensor([256, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([256, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:55.281537 test begin: paddle.nn.functional.embedding(Tensor([256, 17],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([256, 17],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:56.388735 test begin: paddle.nn.functional.embedding(Tensor([256, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([256, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:57.528040 test begin: paddle.nn.functional.embedding(Tensor([256, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([256, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:58.619581 test begin: paddle.nn.functional.embedding(Tensor([256, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([256, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:56:59.728601 test begin: paddle.nn.functional.embedding(Tensor([264, 12],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([264, 12],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:00.784138 test begin: paddle.nn.functional.embedding(Tensor([264, 13],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([264, 13],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:01.782677 test begin: paddle.nn.functional.embedding(Tensor([264, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([264, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:02.790363 test begin: paddle.nn.functional.embedding(Tensor([264, 15],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([264, 15],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:03.810575 test begin: paddle.nn.functional.embedding(Tensor([264, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([264, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1016 / 4325376 (0.0235%)
Max absolute difference: 0.9986608
Max relative difference: 1.
 x: array([[[0.989329, 0.695273, 0.192136, ..., 0.235942, 0.248494,
         0.40879 ],
        [0.799299, 0.869011, 0.317897, ..., 0.821231, 0.427147,...
 y: array([[[0.989329, 0.695273, 0.192136, ..., 0.235942, 0.248494,
         0.40879 ],
        [0.799299, 0.869011, 0.317897, ..., 0.821231, 0.427147,...
2025-05-12 08:57:04.899938 test begin: paddle.nn.functional.embedding(Tensor([264, 17],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([264, 17],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:06.011660 test begin: paddle.nn.functional.embedding(Tensor([264, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([264, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:07.099152 test begin: paddle.nn.functional.embedding(Tensor([264, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([264, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:08.196269 test begin: paddle.nn.functional.embedding(Tensor([272, 11],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([272, 11],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:08.793291 test begin: paddle.nn.functional.embedding(Tensor([272, 12],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([272, 12],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:09.388780 test begin: paddle.nn.functional.embedding(Tensor([272, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([272, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:09.982074 test begin: paddle.nn.functional.embedding(Tensor([272, 14],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([272, 14],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:10.574708 test begin: paddle.nn.functional.embedding(Tensor([272, 15],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([272, 15],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:11.175543 test begin: paddle.nn.functional.embedding(Tensor([272, 5],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([272, 5],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:11.745984 test begin: paddle.nn.functional.embedding(Tensor([272, 6],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([272, 6],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:12.283642 test begin: paddle.nn.functional.embedding(Tensor([280, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([280, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:13.278108 test begin: paddle.nn.functional.embedding(Tensor([280, 15],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([280, 15],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1015 / 4300800 (0.0236%)
Max absolute difference: 0.9987433
Max relative difference: 1.
 x: array([[[0.334283, 0.859004, 0.651621, ..., 0.388587, 0.268068,
         0.072832],
        [0.588675, 0.511843, 0.295037, ..., 0.680365, 0.294289,...
 y: array([[[0.334283, 0.859004, 0.651621, ..., 0.388587, 0.268068,
         0.072832],
        [0.588675, 0.511843, 0.295037, ..., 0.680365, 0.294289,...
2025-05-12 08:57:14.322212 test begin: paddle.nn.functional.embedding(Tensor([280, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([280, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:15.388566 test begin: paddle.nn.functional.embedding(Tensor([280, 17],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([280, 17],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:16.524510 test begin: paddle.nn.functional.embedding(Tensor([280, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([280, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:17.708195 test begin: paddle.nn.functional.embedding(Tensor([288, 10],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([288, 10],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 507 / 1474560 (0.0344%)
Max absolute difference: 0.9994944
Max relative difference: 1.
 x: array([[[0.192507, 0.025215, 0.616778, ..., 0.648014, 0.842543,
         0.854272],
        [0.902941, 0.295853, 0.183832, ..., 0.254976, 0.88275 ,...
 y: array([[[0.192507, 0.025215, 0.616778, ..., 0.648014, 0.842543,
         0.854272],
        [0.902941, 0.295853, 0.183832, ..., 0.254976, 0.88275 ,...
2025-05-12 08:57:18.387750 test begin: paddle.nn.functional.embedding(Tensor([288, 11],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([288, 11],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:18.944654 test begin: paddle.nn.functional.embedding(Tensor([288, 12],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([288, 12],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:19.505091 test begin: paddle.nn.functional.embedding(Tensor([288, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([288, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:20.083631 test begin: paddle.nn.functional.embedding(Tensor([288, 14],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([288, 14],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:20.663502 test begin: paddle.nn.functional.embedding(Tensor([296, 11],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([296, 11],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:21.643657 test begin: paddle.nn.functional.embedding(Tensor([296, 13],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([296, 13],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:22.639079 test begin: paddle.nn.functional.embedding(Tensor([296, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([296, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:23.258041 test begin: paddle.nn.functional.embedding(Tensor([296, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([296, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:24.329980 test begin: paddle.nn.functional.embedding(Tensor([296, 15],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([296, 15],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1012 / 4546560 (0.0223%)
Max absolute difference: 0.9997337
Max relative difference: 1.
 x: array([[[0.983505, 0.9201  , 0.444874, ..., 0.60195 , 0.955748,
         0.258993],
        [0.284133, 0.479227, 0.279328, ..., 0.48632 , 0.059752,...
 y: array([[[0.983505, 0.9201  , 0.444874, ..., 0.60195 , 0.955748,
         0.258993],
        [0.284133, 0.479227, 0.279328, ..., 0.48632 , 0.059752,...
2025-05-12 08:57:25.528722 test begin: paddle.nn.functional.embedding(Tensor([296, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([296, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:26.624005 test begin: paddle.nn.functional.embedding(Tensor([296, 17],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([296, 17],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:27.731579 test begin: paddle.nn.functional.embedding(Tensor([296, 8],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([296, 8],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:28.310502 test begin: paddle.nn.functional.embedding(Tensor([2],"int64"), weight=Tensor([100, 300],"float32"), padding_idx=99, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([2],"int64"), weight=Tensor([100, 300],"float32"), padding_idx=99, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:28.465751 test begin: paddle.nn.functional.embedding(Tensor([2],"int64"), weight=Tensor([39980, 8],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([2],"int64"), weight=Tensor([39980, 8],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:28.638979 test begin: paddle.nn.functional.embedding(Tensor([3, 1],"int64"), weight=Tensor([10, 3],"float32"), padding_idx=9, max_norm=0.5, norm_type=3.0, sparse=True, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([3, 1],"int64"), weight=Tensor([10, 3],"float32"), padding_idx=9, max_norm=0.5, norm_type=3.0, sparse=True, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:28.803632 test begin: paddle.nn.functional.embedding(Tensor([3, 1],"int64"), weight=Tensor([10, 3],"float32"), padding_idx=9, max_norm=None, norm_type=2.0, sparse=True, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([3, 1],"int64"), weight=Tensor([10, 3],"float32"), padding_idx=9, max_norm=None, norm_type=2.0, sparse=True, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 3 / 9 (33.3%)
Max absolute difference: 0.99378926
Max relative difference: 1.
 x: array([[[0.002928, 0.598771, 0.051514]],

       [[0.      , 0.      , 0.      ]],...
 y: array([[[0.002928, 0.598771, 0.051514]],

       [[0.993789, 0.374546, 0.205056]],...
2025-05-12 08:57:28.965603 test begin: paddle.nn.functional.embedding(Tensor([3, 4],"int64"), Tensor([10, 4],"float64"), padding_idx=-4, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([3, 4],"int64"), Tensor([10, 4],"float64"), padding_idx=-4, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4 / 48 (8.33%)
Max absolute difference: 0.98300844
Max relative difference: 1.
 x: array([[[0.678383, 0.778566, 0.787949, 0.794745],
        [0.      , 0.      , 0.      , 0.      ],
        [0.613217, 0.252359, 0.430106, 0.384764],...
 y: array([[[0.678383, 0.778566, 0.787949, 0.794745],
        [0.0524  , 0.286453, 0.227994, 0.983008],
        [0.613217, 0.252359, 0.430106, 0.384764],...
2025-05-12 08:57:29.122482 test begin: paddle.nn.functional.embedding(Tensor([3, 4],"int64"), Tensor([10, 4],"float64"), padding_idx=9, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([3, 4],"int64"), Tensor([10, 4],"float64"), padding_idx=9, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 12 / 48 (25%)
Max absolute difference: 0.47267746
Max relative difference: 1.
 x: array([[[0.      , 0.      , 0.      , 0.      ],
        [0.209736, 0.80699 , 0.156618, 0.627077],
        [0.      , 0.      , 0.      , 0.      ],...
 y: array([[[0.472677, 0.111795, 0.457803, 0.122598],
        [0.209736, 0.80699 , 0.156618, 0.627077],
        [0.472677, 0.111795, 0.457803, 0.122598],...
2025-05-12 08:57:29.288443 test begin: paddle.nn.functional.embedding(Tensor([312, 10],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([312, 10],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:29.885801 test begin: paddle.nn.functional.embedding(Tensor([312, 11],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([312, 11],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:30.486577 test begin: paddle.nn.functional.embedding(Tensor([312, 12],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([312, 12],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:31.091267 test begin: paddle.nn.functional.embedding(Tensor([312, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([312, 13],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:31.702338 test begin: paddle.nn.functional.embedding(Tensor([312, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([312, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:32.757432 test begin: paddle.nn.functional.embedding(Tensor([312, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([312, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:33.886063 test begin: paddle.nn.functional.embedding(Tensor([312, 6],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([312, 6],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:34.885548 test begin: paddle.nn.functional.embedding(Tensor([312, 8],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([312, 8],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:35.872459 test begin: paddle.nn.functional.embedding(Tensor([32, 100],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 100],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:36.457862 test begin: paddle.nn.functional.embedding(Tensor([32, 101],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 101],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:37.462371 test begin: paddle.nn.functional.embedding(Tensor([32, 101],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 101],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:38.064548 test begin: paddle.nn.functional.embedding(Tensor([32, 102],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 102],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:38.651087 test begin: paddle.nn.functional.embedding(Tensor([32, 103],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 103],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:39.665805 test begin: paddle.nn.functional.embedding(Tensor([32, 103],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 103],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:40.259661 test begin: paddle.nn.functional.embedding(Tensor([32, 104],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 104],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:41.272433 test begin: paddle.nn.functional.embedding(Tensor([32, 104],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 104],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:41.882176 test begin: paddle.nn.functional.embedding(Tensor([32, 105],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([32, 105],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1015 / 3440640 (0.0295%)
Max absolute difference: 0.9989023
Max relative difference: 1.
 x: array([[[0.361243, 0.381531, 0.369866, ..., 0.13843 , 0.526583,
         0.173845],
        [0.87047 , 0.254032, 0.498909, ..., 0.714466, 0.426968,...
 y: array([[[0.361243, 0.381531, 0.369866, ..., 0.13843 , 0.526583,
         0.173845],
        [0.87047 , 0.254032, 0.498909, ..., 0.714466, 0.426968,...
2025-05-12 08:57:42.896465 test begin: paddle.nn.functional.embedding(Tensor([32, 105],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([32, 105],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 506 / 1720320 (0.0294%)
Max absolute difference: 0.9960693
Max relative difference: 1.
 x: array([[[0.399234, 0.130087, 0.783359, ..., 0.747585, 0.514309,
         0.102823],
        [0.995111, 0.483573, 0.018132, ..., 0.216641, 0.961743,...
 y: array([[[0.399234, 0.130087, 0.783359, ..., 0.747585, 0.514309,
         0.102823],
        [0.995111, 0.483573, 0.018132, ..., 0.216641, 0.961743,...
2025-05-12 08:57:43.525721 test begin: paddle.nn.functional.embedding(Tensor([32, 106],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 106],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:44.478938 test begin: paddle.nn.functional.embedding(Tensor([32, 106],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([32, 106],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1020 / 1736704 (0.0587%)
Max absolute difference: 0.9984438
Max relative difference: 1.
 x: array([[[0.635931, 0.949752, 0.373117, ..., 0.382407, 0.587822,
         0.118731],
        [0.270604, 0.556087, 0.003128, ..., 0.291361, 0.418978,...
 y: array([[[0.635931, 0.949752, 0.373117, ..., 0.382407, 0.587822,
         0.118731],
        [0.270604, 0.556087, 0.003128, ..., 0.291361, 0.418978,...
2025-05-12 08:57:45.102905 test begin: paddle.nn.functional.embedding(Tensor([32, 107],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 107],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:46.146559 test begin: paddle.nn.functional.embedding(Tensor([32, 107],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 107],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:46.803482 test begin: paddle.nn.functional.embedding(Tensor([32, 108],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 108],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:47.401868 test begin: paddle.nn.functional.embedding(Tensor([32, 109],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 109],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:48.520000 test begin: paddle.nn.functional.embedding(Tensor([32, 109],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 109],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:49.118261 test begin: paddle.nn.functional.embedding(Tensor([32, 110],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 110],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:49.793044 test begin: paddle.nn.functional.embedding(Tensor([32, 111],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 111],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:50.807752 test begin: paddle.nn.functional.embedding(Tensor([32, 111],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 111],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:51.409532 test begin: paddle.nn.functional.embedding(Tensor([32, 112],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([32, 112],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1016 / 3670016 (0.0277%)
Max absolute difference: 0.99862385
Max relative difference: 1.
 x: array([[[8.185978e-01, 4.678766e-02, 4.397556e-01, ..., 3.576290e-01,
         2.176488e-01, 7.516784e-01],
        [3.663550e-01, 9.652948e-01, 5.432816e-01, ..., 5.569073e-01,...
 y: array([[[8.185978e-01, 4.678766e-02, 4.397556e-01, ..., 3.576290e-01,
         2.176488e-01, 7.516784e-01],
        [3.663550e-01, 9.652948e-01, 5.432816e-01, ..., 5.569073e-01,...
2025-05-12 08:57:52.549992 test begin: paddle.nn.functional.embedding(Tensor([32, 112],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 112],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:53.185991 test begin: paddle.nn.functional.embedding(Tensor([32, 113],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 113],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:54.200007 test begin: paddle.nn.functional.embedding(Tensor([32, 113],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 113],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:54.803680 test begin: paddle.nn.functional.embedding(Tensor([32, 114],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 114],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:55.798673 test begin: paddle.nn.functional.embedding(Tensor([32, 114],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 114],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:56.394239 test begin: paddle.nn.functional.embedding(Tensor([32, 115],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([32, 115],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1011 / 3768320 (0.0268%)
Max absolute difference: 0.99943924
Max relative difference: 1.
 x: array([[[0.497815, 0.711311, 0.307026, ..., 0.427749, 0.805861,
         0.955694],
        [0.747282, 0.969717, 0.882365, ..., 0.650392, 0.593301,...
 y: array([[[0.497815, 0.711311, 0.307026, ..., 0.427749, 0.805861,
         0.955694],
        [0.747282, 0.969717, 0.882365, ..., 0.650392, 0.593301,...
2025-05-12 08:57:57.453055 test begin: paddle.nn.functional.embedding(Tensor([32, 115],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 115],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:58.049202 test begin: paddle.nn.functional.embedding(Tensor([32, 117],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 117],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:59.226739 test begin: paddle.nn.functional.embedding(Tensor([32, 117],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 117],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:57:59.836906 test begin: paddle.nn.functional.embedding(Tensor([32, 118],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([32, 118],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 505 / 1933312 (0.0261%)
Max absolute difference: 0.9939518
Max relative difference: 1.
 x: array([[[3.541086e-01, 8.051986e-01, 2.655786e-01, ..., 7.000442e-01,
         2.840178e-01, 3.240533e-01],
        [9.166420e-01, 7.912210e-01, 2.816603e-02, ..., 5.463567e-01,...
 y: array([[[3.541086e-01, 8.051986e-01, 2.655786e-01, ..., 7.000442e-01,
         2.840178e-01, 3.240533e-01],
        [9.166420e-01, 7.912210e-01, 2.816603e-02, ..., 5.463567e-01,...
2025-05-12 08:58:00.514256 test begin: paddle.nn.functional.embedding(Tensor([32, 119],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 119],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:01.531650 test begin: paddle.nn.functional.embedding(Tensor([32, 121],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 121],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:02.656549 test begin: paddle.nn.functional.embedding(Tensor([32, 122],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 122],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:03.266695 test begin: paddle.nn.functional.embedding(Tensor([32, 123],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 123],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:03.917778 test begin: paddle.nn.functional.embedding(Tensor([32, 124],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 124],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:04.933977 test begin: paddle.nn.functional.embedding(Tensor([32, 124],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([32, 124],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 507 / 2031616 (0.025%)
Max absolute difference: 0.99879646
Max relative difference: 1.
 x: array([[[0.853613, 0.023558, 0.17289 , ..., 0.195014, 0.447686,
         0.050865],
        [0.21344 , 0.89145 , 0.218748, ..., 0.759899, 0.050277,...
 y: array([[[0.853613, 0.023558, 0.17289 , ..., 0.195014, 0.447686,
         0.050865],
        [0.21344 , 0.89145 , 0.218748, ..., 0.759899, 0.050277,...
2025-05-12 08:58:05.597812 test begin: paddle.nn.functional.embedding(Tensor([32, 125],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 125],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:06.233348 test begin: paddle.nn.functional.embedding(Tensor([32, 126],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 126],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:07.216230 test begin: paddle.nn.functional.embedding(Tensor([32, 126],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 126],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:07.831767 test begin: paddle.nn.functional.embedding(Tensor([32, 127],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 127],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:08.489440 test begin: paddle.nn.functional.embedding(Tensor([32, 128],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 128],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:09.137065 test begin: paddle.nn.functional.embedding(Tensor([32, 129],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([32, 129],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1015 / 4227072 (0.024%)
Max absolute difference: 0.9999085
Max relative difference: 1.
 x: array([[[0.470333, 0.112039, 0.084712, ..., 0.679272, 0.874437,
         0.796266],
        [0.561874, 0.891563, 0.585469, ..., 0.789961, 0.146066,...
 y: array([[[0.470333, 0.112039, 0.084712, ..., 0.679272, 0.874437,
         0.796266],
        [0.561874, 0.891563, 0.585469, ..., 0.789961, 0.146066,...
2025-05-12 08:58:10.342947 test begin: paddle.nn.functional.embedding(Tensor([32, 130],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 130],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:11.421896 test begin: paddle.nn.functional.embedding(Tensor([32, 131],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 131],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:12.530879 test begin: paddle.nn.functional.embedding(Tensor([32, 132],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 132],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:13.757002 test begin: paddle.nn.functional.embedding(Tensor([32, 133],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 133],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:14.845486 test begin: paddle.nn.functional.embedding(Tensor([32, 135],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 135],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:16.049851 test begin: paddle.nn.functional.embedding(Tensor([32, 136],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 136],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:17.250644 test begin: paddle.nn.functional.embedding(Tensor([32, 137],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 137],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:18.348284 test begin: paddle.nn.functional.embedding(Tensor([32, 139],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 139],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:19.563670 test begin: paddle.nn.functional.embedding(Tensor([32, 140],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 140],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:20.738072 test begin: paddle.nn.functional.embedding(Tensor([32, 141],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 141],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:21.812512 test begin: paddle.nn.functional.embedding(Tensor([32, 142],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 142],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:23.044767 test begin: paddle.nn.functional.embedding(Tensor([32, 144],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 144],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:24.158197 test begin: paddle.nn.functional.embedding(Tensor([32, 146],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 146],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:25.246576 test begin: paddle.nn.functional.embedding(Tensor([32, 150],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 150],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:26.482781 test begin: paddle.nn.functional.embedding(Tensor([32, 151],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 151],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:27.675993 test begin: paddle.nn.functional.embedding(Tensor([32, 153],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 153],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:28.768467 test begin: paddle.nn.functional.embedding(Tensor([32, 154],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([32, 154],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1009 / 5046272 (0.02%)
Max absolute difference: 0.99968815
Max relative difference: 1.
 x: array([[[9.800611e-02, 7.235757e-01, 7.428423e-01, ..., 2.640005e-01,
         6.594654e-01, 8.056616e-01],
        [5.384201e-01, 7.325536e-02, 8.997278e-01, ..., 5.599500e-01,...
 y: array([[[9.800611e-02, 7.235757e-01, 7.428423e-01, ..., 2.640005e-01,
         6.594654e-01, 8.056616e-01],
        [5.384201e-01, 7.325536e-02, 8.997278e-01, ..., 5.599500e-01,...
2025-05-12 08:58:30.093528 test begin: paddle.nn.functional.embedding(Tensor([32, 157],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 157],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:31.197985 test begin: paddle.nn.functional.embedding(Tensor([32, 158],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 158],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:32.442880 test begin: paddle.nn.functional.embedding(Tensor([32, 159],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 159],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:33.558844 test begin: paddle.nn.functional.embedding(Tensor([32, 43],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 43],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:34.175611 test begin: paddle.nn.functional.embedding(Tensor([32, 46],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 46],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:34.781175 test begin: paddle.nn.functional.embedding(Tensor([32, 50],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 50],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:35.350353 test begin: paddle.nn.functional.embedding(Tensor([32, 512],"int64"), weight=Tensor([40000, 768],"float16"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 512],"int64"), weight=Tensor([40000, 768],"float16"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:37.897638 test begin: paddle.nn.functional.embedding(Tensor([32, 512],"int64"), weight=Tensor([40000, 768],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 512],"int64"), weight=Tensor([40000, 768],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:39.358190 test begin: paddle.nn.functional.embedding(Tensor([32, 53],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 53],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:39.976764 test begin: paddle.nn.functional.embedding(Tensor([32, 54],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 54],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:40.557680 test begin: paddle.nn.functional.embedding(Tensor([32, 60],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 60],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:41.182555 test begin: paddle.nn.functional.embedding(Tensor([32, 61],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 61],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:42.238423 test begin: paddle.nn.functional.embedding(Tensor([32, 62],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 62],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:42.825317 test begin: paddle.nn.functional.embedding(Tensor([32, 63],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 63],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:43.400432 test begin: paddle.nn.functional.embedding(Tensor([32, 64],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 64],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:44.025950 test begin: paddle.nn.functional.embedding(Tensor([32, 65],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 65],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:44.639377 test begin: paddle.nn.functional.embedding(Tensor([32, 66],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 66],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:45.248994 test begin: paddle.nn.functional.embedding(Tensor([32, 67],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 67],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:45.831945 test begin: paddle.nn.functional.embedding(Tensor([32, 68],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 68],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:46.367710 test begin: paddle.nn.functional.embedding(Tensor([32, 69],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 69],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:46.992873 test begin: paddle.nn.functional.embedding(Tensor([32, 70],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 70],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:47.578582 test begin: paddle.nn.functional.embedding(Tensor([32, 71],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 71],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:48.656779 test begin: paddle.nn.functional.embedding(Tensor([32, 72],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 72],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:49.626448 test begin: paddle.nn.functional.embedding(Tensor([32, 73],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 73],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:50.595381 test begin: paddle.nn.functional.embedding(Tensor([32, 74],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 74],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:51.242603 test begin: paddle.nn.functional.embedding(Tensor([32, 75],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 75],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:51.865519 test begin: paddle.nn.functional.embedding(Tensor([32, 76],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 76],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:52.449801 test begin: paddle.nn.functional.embedding(Tensor([32, 77],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 77],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:53.080005 test begin: paddle.nn.functional.embedding(Tensor([32, 78],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([32, 78],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 507 / 1277952 (0.0397%)
Max absolute difference: 0.99946564
Max relative difference: 1.
 x: array([[[0.499146, 0.678846, 0.709583, ..., 0.887706, 0.210144,
         0.937051],
        [0.034937, 0.589179, 0.512751, ..., 0.877495, 0.692891,...
 y: array([[[0.499146, 0.678846, 0.709583, ..., 0.887706, 0.210144,
         0.937051],
        [0.034937, 0.589179, 0.512751, ..., 0.877495, 0.692891,...
2025-05-12 08:58:53.683723 test begin: paddle.nn.functional.embedding(Tensor([32, 79],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 79],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:54.281573 test begin: paddle.nn.functional.embedding(Tensor([32, 80],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 80],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:55.367305 test begin: paddle.nn.functional.embedding(Tensor([32, 80],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 80],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:55.953763 test begin: paddle.nn.functional.embedding(Tensor([32, 81],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 81],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:57.041582 test begin: paddle.nn.functional.embedding(Tensor([32, 82],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 82],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:58.020708 test begin: paddle.nn.functional.embedding(Tensor([32, 83],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 83],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:58.992823 test begin: paddle.nn.functional.embedding(Tensor([32, 83],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 83],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:58:59.629545 test begin: paddle.nn.functional.embedding(Tensor([32, 84],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([32, 84],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1017 / 2752512 (0.0369%)
Max absolute difference: 0.99979764
Max relative difference: 1.
 x: array([[[0.422392, 0.086831, 0.550295, ..., 0.945395, 0.170991,
         0.802552],
        [0.808781, 0.294138, 0.989327, ..., 0.136917, 0.447946,...
 y: array([[[0.422392, 0.086831, 0.550295, ..., 0.945395, 0.170991,
         0.802552],
        [0.808781, 0.294138, 0.989327, ..., 0.136917, 0.447946,...
2025-05-12 08:59:00.637799 test begin: paddle.nn.functional.embedding(Tensor([32, 85],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 85],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:01.275435 test begin: paddle.nn.functional.embedding(Tensor([32, 86],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 86],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:02.296756 test begin: paddle.nn.functional.embedding(Tensor([32, 87],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([32, 87],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1014 / 2850816 (0.0356%)
Max absolute difference: 0.99760175
Max relative difference: 1.
 x: array([[[0.682571, 0.488531, 0.333596, ..., 0.656829, 0.369708,
         0.585993],
        [0.671195, 0.347376, 0.248213, ..., 0.825703, 0.393474,...
 y: array([[[0.682571, 0.488531, 0.333596, ..., 0.656829, 0.369708,
         0.585993],
        [0.671195, 0.347376, 0.248213, ..., 0.825703, 0.393474,...
2025-05-12 08:59:03.431027 test begin: paddle.nn.functional.embedding(Tensor([32, 87],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 87],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:04.037521 test begin: paddle.nn.functional.embedding(Tensor([32, 88],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 88],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:04.624340 test begin: paddle.nn.functional.embedding(Tensor([32, 89],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 89],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:05.718873 test begin: paddle.nn.functional.embedding(Tensor([32, 89],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 89],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:06.322510 test begin: paddle.nn.functional.embedding(Tensor([32, 90],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 90],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:06.955935 test begin: paddle.nn.functional.embedding(Tensor([32, 91],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 91],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:07.949068 test begin: paddle.nn.functional.embedding(Tensor([32, 91],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 91],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:08.599455 test begin: paddle.nn.functional.embedding(Tensor([32, 92],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 92],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:09.593898 test begin: paddle.nn.functional.embedding(Tensor([32, 92],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 92],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:10.231485 test begin: paddle.nn.functional.embedding(Tensor([32, 93],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 93],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:11.223387 test begin: paddle.nn.functional.embedding(Tensor([32, 93],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 93],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:11.818087 test begin: paddle.nn.functional.embedding(Tensor([32, 94],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 94],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:12.439186 test begin: paddle.nn.functional.embedding(Tensor([32, 95],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 95],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:13.401368 test begin: paddle.nn.functional.embedding(Tensor([32, 95],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 95],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:14.042071 test begin: paddle.nn.functional.embedding(Tensor([32, 96],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 96],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:15.045796 test begin: paddle.nn.functional.embedding(Tensor([32, 96],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 96],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:15.677919 test begin: paddle.nn.functional.embedding(Tensor([32, 97],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 97],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:16.682270 test begin: paddle.nn.functional.embedding(Tensor([32, 97],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 97],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:17.312036 test begin: paddle.nn.functional.embedding(Tensor([32, 98],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 98],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:18.316199 test begin: paddle.nn.functional.embedding(Tensor([32, 98],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 98],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:18.910488 test begin: paddle.nn.functional.embedding(Tensor([32, 99],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 99],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:19.931289 test begin: paddle.nn.functional.embedding(Tensor([32, 99],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([32, 99],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:20.527040 test begin: paddle.nn.functional.embedding(Tensor([320, 12],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([320, 12],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:21.547243 test begin: paddle.nn.functional.embedding(Tensor([320, 13],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([320, 13],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:22.611816 test begin: paddle.nn.functional.embedding(Tensor([320, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([320, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1017 / 4587520 (0.0222%)
Max absolute difference: 0.99952734
Max relative difference: 1.
 x: array([[[0.57844 , 0.229038, 0.415348, ..., 0.816734, 0.991593,
         0.766445],
        [0.89187 , 0.913736, 0.38976 , ..., 0.033698, 0.835784,...
 y: array([[[0.57844 , 0.229038, 0.415348, ..., 0.816734, 0.991593,
         0.766445],
        [0.89187 , 0.913736, 0.38976 , ..., 0.033698, 0.835784,...
2025-05-12 08:59:23.788103 test begin: paddle.nn.functional.embedding(Tensor([320, 15],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([320, 15],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:24.902790 test begin: paddle.nn.functional.embedding(Tensor([320, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([320, 16],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:26.023647 test begin: paddle.nn.functional.embedding(Tensor([336, 10],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([336, 10],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:26.619571 test begin: paddle.nn.functional.embedding(Tensor([336, 11],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([336, 11],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:27.645292 test begin: paddle.nn.functional.embedding(Tensor([336, 11],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([336, 11],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:28.258326 test begin: paddle.nn.functional.embedding(Tensor([336, 12],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([336, 12],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1010 / 4128768 (0.0245%)
Max absolute difference: 0.99775565
Max relative difference: 1.
 x: array([[[2.725177e-01, 1.089352e-01, 1.899350e-02, ..., 9.906905e-01,
         9.771384e-01, 2.737610e-01],
        [4.475150e-01, 9.395932e-01, 3.262837e-01, ..., 3.765405e-01,...
 y: array([[[2.725177e-01, 1.089352e-01, 1.899350e-02, ..., 9.906905e-01,
         9.771384e-01, 2.737610e-01],
        [4.475150e-01, 9.395932e-01, 3.262837e-01, ..., 3.765405e-01,...
2025-05-12 08:59:29.349638 test begin: paddle.nn.functional.embedding(Tensor([336, 12],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([336, 12],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:29.958137 test begin: paddle.nn.functional.embedding(Tensor([336, 13],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([336, 13],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:31.042032 test begin: paddle.nn.functional.embedding(Tensor([336, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([336, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:32.154979 test begin: paddle.nn.functional.embedding(Tensor([336, 15],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([336, 15],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:33.280796 test begin: paddle.nn.functional.embedding(Tensor([336, 5],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([336, 5],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:34.231612 test begin: paddle.nn.functional.embedding(Tensor([336, 6],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([336, 6],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:35.187111 test begin: paddle.nn.functional.embedding(Tensor([336, 9],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([336, 9],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:35.781045 test begin: paddle.nn.functional.embedding(Tensor([352, 11],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([352, 11],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:36.829086 test begin: paddle.nn.functional.embedding(Tensor([352, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([352, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:37.900256 test begin: paddle.nn.functional.embedding(Tensor([360, 10],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([360, 10],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:38.915919 test begin: paddle.nn.functional.embedding(Tensor([360, 11],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([360, 11],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:39.968470 test begin: paddle.nn.functional.embedding(Tensor([360, 11],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([360, 11],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:40.572992 test begin: paddle.nn.functional.embedding(Tensor([360, 12],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([360, 12],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1015 / 4423680 (0.0229%)
Max absolute difference: 0.99970037
Max relative difference: 1.
 x: array([[[0.269681, 0.91161 , 0.059615, ..., 0.243543, 0.260043,
         0.290543],
        [0.944662, 0.587503, 0.34079 , ..., 0.663104, 0.076552,...
 y: array([[[0.269681, 0.91161 , 0.059615, ..., 0.243543, 0.260043,
         0.290543],
        [0.944662, 0.587503, 0.34079 , ..., 0.663104, 0.076552,...
2025-05-12 08:59:41.695751 test begin: paddle.nn.functional.embedding(Tensor([360, 13],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([360, 13],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:42.786966 test begin: paddle.nn.functional.embedding(Tensor([360, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([360, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:43.942811 test begin: paddle.nn.functional.embedding(Tensor([360, 6],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([360, 6],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:44.531020 test begin: paddle.nn.functional.embedding(Tensor([360, 9],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([360, 9],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:45.551796 test begin: paddle.nn.functional.embedding(Tensor([368, 10],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([368, 10],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:46.143233 test begin: paddle.nn.functional.embedding(Tensor([368, 11],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([368, 11],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:46.744407 test begin: paddle.nn.functional.embedding(Tensor([368, 3],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([368, 3],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:47.376956 test begin: paddle.nn.functional.embedding(Tensor([368, 4],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([368, 4],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:47.945497 test begin: paddle.nn.functional.embedding(Tensor([368, 8],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([368, 8],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:48.542699 test begin: paddle.nn.functional.embedding(Tensor([368, 9],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([368, 9],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 506 / 1695744 (0.0298%)
Max absolute difference: 0.9959288
Max relative difference: 1.
 x: array([[[2.956062e-01, 2.947141e-01, 1.145680e-01, ..., 9.782258e-01,
         5.159734e-01, 4.587595e-01],
        [7.381668e-02, 8.758045e-01, 4.270767e-02, ..., 3.805256e-01,...
 y: array([[[2.956062e-01, 2.947141e-01, 1.145680e-01, ..., 9.782258e-01,
         5.159734e-01, 4.587595e-01],
        [7.381668e-02, 8.758045e-01, 4.270767e-02, ..., 3.805256e-01,...
2025-05-12 08:59:49.159943 test begin: paddle.nn.functional.embedding(Tensor([39, 7],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([39, 7],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 128 / 8736 (1.47%)
Max absolute difference: 0.9450904
Max relative difference: 1.
 x: array([[[2.484739e-01, 2.198505e-01, 1.376446e-01, ..., 7.194604e-01,
         2.621990e-01, 9.260930e-01],
        [8.351379e-01, 3.151481e-01, 7.148823e-01, ..., 2.013281e-02,...
 y: array([[[2.484739e-01, 2.198505e-01, 1.376446e-01, ..., 7.194604e-01,
         2.621990e-01, 9.260930e-01],
        [8.351379e-01, 3.151481e-01, 7.148823e-01, ..., 2.013281e-02,...
2025-05-12 08:59:49.321710 test begin: paddle.nn.functional.embedding(Tensor([392, 10],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([392, 10],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:50.381111 test begin: paddle.nn.functional.embedding(Tensor([392, 11],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([392, 11],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:51.442135 test begin: paddle.nn.functional.embedding(Tensor([392, 12],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([392, 12],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:52.524377 test begin: paddle.nn.functional.embedding(Tensor([392, 13],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([392, 13],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:53.620064 test begin: paddle.nn.functional.embedding(Tensor([4, 13],"int64"), weight=Tensor([6629, 384],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([4, 13],"int64"), weight=Tensor([6629, 384],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:53.816711 test begin: paddle.nn.functional.embedding(Tensor([4, 1],"int64"), weight=Tensor([32000, 64],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([4, 1],"int64"), weight=Tensor([32000, 64],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:54.036684 test begin: paddle.nn.functional.embedding(Tensor([4, 20],"int64"), weight=Tensor([30000, 128],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([4, 20],"int64"), weight=Tensor([30000, 128],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:54.282111 test begin: paddle.nn.functional.embedding(Tensor([4, 5],"int64"), weight=Tensor([32000, 64],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([4, 5],"int64"), weight=Tensor([32000, 64],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:54.462079 test begin: paddle.nn.functional.embedding(Tensor([4, 5],"int64"), weight=Tensor([6629, 384],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([4, 5],"int64"), weight=Tensor([6629, 384],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:54.662647 test begin: paddle.nn.functional.embedding(Tensor([40, 100],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([40, 100],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 505 / 2048000 (0.0247%)
Max absolute difference: 0.99856436
Max relative difference: 1.
 x: array([[[0.190365, 0.945322, 0.734212, ..., 0.094338, 0.980309,
         0.113776],
        [0.393967, 0.784179, 0.292291, ..., 0.191756, 0.369002,...
 y: array([[[0.190365, 0.945322, 0.734212, ..., 0.094338, 0.980309,
         0.113776],
        [0.393967, 0.784179, 0.292291, ..., 0.191756, 0.369002,...
2025-05-12 08:59:55.293924 test begin: paddle.nn.functional.embedding(Tensor([40, 102],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 102],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:56.375183 test begin: paddle.nn.functional.embedding(Tensor([40, 102],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 102],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:56.996350 test begin: paddle.nn.functional.embedding(Tensor([40, 103],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 103],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:58.063272 test begin: paddle.nn.functional.embedding(Tensor([40, 104],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 104],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 08:59:59.164209 test begin: paddle.nn.functional.embedding(Tensor([40, 105],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 105],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:00.242098 test begin: paddle.nn.functional.embedding(Tensor([40, 107],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([40, 107],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1016 / 4382720 (0.0232%)
Max absolute difference: 0.99940324
Max relative difference: 1.
 x: array([[[0.551635, 0.074863, 0.333247, ..., 0.421652, 0.780423,
         0.481535],
        [0.701563, 0.945597, 0.464738, ..., 0.759669, 0.251247,...
 y: array([[[0.551635, 0.074863, 0.333247, ..., 0.421652, 0.780423,
         0.481535],
        [0.701563, 0.945597, 0.464738, ..., 0.759669, 0.251247,...
2025-05-12 09:00:01.378318 test begin: paddle.nn.functional.embedding(Tensor([40, 108],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 108],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:02.499088 test begin: paddle.nn.functional.embedding(Tensor([40, 110],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 110],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:03.586843 test begin: paddle.nn.functional.embedding(Tensor([40, 111],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 111],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:04.659156 test begin: paddle.nn.functional.embedding(Tensor([40, 113],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 113],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:05.736982 test begin: paddle.nn.functional.embedding(Tensor([40, 114],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 114],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:06.829374 test begin: paddle.nn.functional.embedding(Tensor([40, 115],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 115],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:07.925909 test begin: paddle.nn.functional.embedding(Tensor([40, 117],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 117],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:09.037002 test begin: paddle.nn.functional.embedding(Tensor([40, 118],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 118],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:10.130086 test begin: paddle.nn.functional.embedding(Tensor([40, 122],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 122],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:11.224947 test begin: paddle.nn.functional.embedding(Tensor([40, 123],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([40, 123],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1018 / 5038080 (0.0202%)
Max absolute difference: 0.9993601
Max relative difference: 1.
 x: array([[[8.313512e-01, 5.239396e-01, 5.868189e-01, ..., 3.261596e-02,
         1.840556e-02, 2.722474e-01],
        [3.171202e-01, 3.491740e-01, 5.322279e-01, ..., 1.513056e-01,...
 y: array([[[8.313512e-01, 5.239396e-01, 5.868189e-01, ..., 3.261596e-02,
         1.840556e-02, 2.722474e-01],
        [3.171202e-01, 3.491740e-01, 5.322279e-01, ..., 1.513056e-01,...
2025-05-12 09:00:12.396134 test begin: paddle.nn.functional.embedding(Tensor([40, 124],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 124],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:13.487755 test begin: paddle.nn.functional.embedding(Tensor([40, 125],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 125],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:14.563455 test begin: paddle.nn.functional.embedding(Tensor([40, 127],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([40, 127],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1016 / 5201920 (0.0195%)
Max absolute difference: 0.99948376
Max relative difference: 1.
 x: array([[[0.559303, 0.497944, 0.207545, ..., 0.279135, 0.632495,
         0.669556],
        [0.259609, 0.110615, 0.500784, ..., 0.710084, 0.735979,...
 y: array([[[0.559303, 0.497944, 0.207545, ..., 0.279135, 0.632495,
         0.669556],
        [0.259609, 0.110615, 0.500784, ..., 0.710084, 0.735979,...
2025-05-12 09:00:15.713096 test begin: paddle.nn.functional.embedding(Tensor([40, 128],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 128],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:16.793875 test begin: paddle.nn.functional.embedding(Tensor([40, 40],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 40],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:17.346184 test begin: paddle.nn.functional.embedding(Tensor([40, 45],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 45],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:17.935578 test begin: paddle.nn.functional.embedding(Tensor([40, 46],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 46],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:18.872008 test begin: paddle.nn.functional.embedding(Tensor([40, 46],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 46],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:19.443763 test begin: paddle.nn.functional.embedding(Tensor([40, 47],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 47],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:20.012381 test begin: paddle.nn.functional.embedding(Tensor([40, 48],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 48],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:20.564662 test begin: paddle.nn.functional.embedding(Tensor([40, 49],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([40, 49],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 508 / 1003520 (0.0506%)
Max absolute difference: 0.9974327
Max relative difference: 1.
 x: array([[[0.255662, 0.413616, 0.732524, ..., 0.292809, 0.292529,
         0.329771],
        [0.061285, 0.858413, 0.847806, ..., 0.593857, 0.407996,...
 y: array([[[0.255662, 0.413616, 0.732524, ..., 0.292809, 0.292529,
         0.329771],
        [0.061285, 0.858413, 0.847806, ..., 0.593857, 0.407996,...
2025-05-12 09:00:21.173096 test begin: paddle.nn.functional.embedding(Tensor([40, 50],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([40, 50],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1013 / 2048000 (0.0495%)
Max absolute difference: 0.9983932
Max relative difference: 1.
 x: array([[[0.662152, 0.444315, 0.849659, ..., 0.383097, 0.087316,
         0.749597],
        [0.423656, 0.454747, 0.775051, ..., 0.131492, 0.243918,...
 y: array([[[0.662152, 0.444315, 0.849659, ..., 0.383097, 0.087316,
         0.749597],
        [0.423656, 0.454747, 0.775051, ..., 0.131492, 0.243918,...
2025-05-12 09:00:22.273037 test begin: paddle.nn.functional.embedding(Tensor([40, 51],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 51],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:22.885624 test begin: paddle.nn.functional.embedding(Tensor([40, 52],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 52],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:23.464545 test begin: paddle.nn.functional.embedding(Tensor([40, 53],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 53],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:24.432244 test begin: paddle.nn.functional.embedding(Tensor([40, 54],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 54],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:25.538582 test begin: paddle.nn.functional.embedding(Tensor([40, 55],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 55],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:26.117766 test begin: paddle.nn.functional.embedding(Tensor([40, 56],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 56],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:26.747976 test begin: paddle.nn.functional.embedding(Tensor([40, 57],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 57],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:27.326003 test begin: paddle.nn.functional.embedding(Tensor([40, 58],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 58],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:27.903456 test begin: paddle.nn.functional.embedding(Tensor([40, 59],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 59],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:28.475860 test begin: paddle.nn.functional.embedding(Tensor([40, 60],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 60],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:29.482597 test begin: paddle.nn.functional.embedding(Tensor([40, 60],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 60],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:30.058837 test begin: paddle.nn.functional.embedding(Tensor([40, 61],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 61],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:30.691869 test begin: paddle.nn.functional.embedding(Tensor([40, 63],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([40, 63],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1015 / 2580480 (0.0393%)
Max absolute difference: 0.9999368
Max relative difference: 1.
 x: array([[[0.071713, 0.315452, 0.33323 , ..., 0.939301, 0.727804,
         0.237029],
        [0.768958, 0.186855, 0.477212, ..., 0.889071, 0.456177,...
 y: array([[[0.071713, 0.315452, 0.33323 , ..., 0.939301, 0.727804,
         0.237029],
        [0.768958, 0.186855, 0.477212, ..., 0.889071, 0.456177,...
2025-05-12 09:00:31.794294 test begin: paddle.nn.functional.embedding(Tensor([40, 64],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 64],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:32.829987 test begin: paddle.nn.functional.embedding(Tensor([40, 65],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 65],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:33.793676 test begin: paddle.nn.functional.embedding(Tensor([40, 66],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 66],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:34.767192 test begin: paddle.nn.functional.embedding(Tensor([40, 67],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 67],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:35.742727 test begin: paddle.nn.functional.embedding(Tensor([40, 67],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([40, 67],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 505 / 1372160 (0.0368%)
Max absolute difference: 0.99856824
Max relative difference: 1.
 x: array([[[0.787745, 0.547913, 0.917242, ..., 0.97456 , 0.355608,
         0.489618],
        [0.549729, 0.388068, 0.249257, ..., 0.227549, 0.052262,...
 y: array([[[0.787745, 0.547913, 0.917242, ..., 0.97456 , 0.355608,
         0.489618],
        [0.549729, 0.388068, 0.249257, ..., 0.227549, 0.052262,...
2025-05-12 09:00:36.342982 test begin: paddle.nn.functional.embedding(Tensor([40, 69],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 69],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:37.301771 test begin: paddle.nn.functional.embedding(Tensor([40, 70],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 70],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:38.351067 test begin: paddle.nn.functional.embedding(Tensor([40, 70],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 70],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:38.934231 test begin: paddle.nn.functional.embedding(Tensor([40, 71],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 71],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:39.522514 test begin: paddle.nn.functional.embedding(Tensor([40, 72],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 72],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:40.505434 test begin: paddle.nn.functional.embedding(Tensor([40, 72],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 72],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:41.079154 test begin: paddle.nn.functional.embedding(Tensor([40, 74],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 74],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:42.061269 test begin: paddle.nn.functional.embedding(Tensor([40, 74],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 74],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:42.643024 test begin: paddle.nn.functional.embedding(Tensor([40, 75],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 75],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:43.172411 test begin: paddle.nn.functional.embedding(Tensor([40, 76],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 76],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:44.150889 test begin: paddle.nn.functional.embedding(Tensor([40, 76],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([40, 76],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1014 / 1556480 (0.0651%)
Max absolute difference: 0.99696475
Max relative difference: 1.
 x: array([[[0.458099, 0.265567, 0.755169, ..., 0.120929, 0.386129,
         0.490324],
        [0.808687, 0.399359, 0.254024, ..., 0.700215, 0.860258,...
 y: array([[[0.458099, 0.265567, 0.755169, ..., 0.120929, 0.386129,
         0.490324],
        [0.808687, 0.399359, 0.254024, ..., 0.700215, 0.860258,...
2025-05-12 09:00:44.744511 test begin: paddle.nn.functional.embedding(Tensor([40, 77],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 77],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:45.702183 test begin: paddle.nn.functional.embedding(Tensor([40, 77],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([40, 77],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 508 / 1576960 (0.0322%)
Max absolute difference: 0.99262583
Max relative difference: 1.
 x: array([[[0.267771, 0.519797, 0.54812 , ..., 0.806378, 0.591502,
         0.148767],
        [0.534105, 0.565358, 0.083437, ..., 0.453266, 0.39241 ,...
 y: array([[[0.267771, 0.519797, 0.54812 , ..., 0.806378, 0.591502,
         0.148767],
        [0.534105, 0.565358, 0.083437, ..., 0.453266, 0.39241 ,...
2025-05-12 09:00:46.316745 test begin: paddle.nn.functional.embedding(Tensor([40, 78],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 78],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:46.900458 test begin: paddle.nn.functional.embedding(Tensor([40, 79],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 79],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:47.990352 test begin: paddle.nn.functional.embedding(Tensor([40, 79],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 79],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:48.593362 test begin: paddle.nn.functional.embedding(Tensor([40, 80],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 80],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:49.180543 test begin: paddle.nn.functional.embedding(Tensor([40, 81],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([40, 81],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 504 / 1658880 (0.0304%)
Max absolute difference: 0.99791074
Max relative difference: 1.
 x: array([[[0.813375, 0.719294, 0.922218, ..., 0.185051, 0.169025,
         0.047275],
        [0.948377, 0.120217, 0.36005 , ..., 0.288997, 0.402822,...
 y: array([[[0.813375, 0.719294, 0.922218, ..., 0.185051, 0.169025,
         0.047275],
        [0.948377, 0.120217, 0.36005 , ..., 0.288997, 0.402822,...
2025-05-12 09:00:49.807553 test begin: paddle.nn.functional.embedding(Tensor([40, 82],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 82],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:50.489889 test begin: paddle.nn.functional.embedding(Tensor([40, 83],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 83],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:51.108406 test begin: paddle.nn.functional.embedding(Tensor([40, 84],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 84],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:51.748275 test begin: paddle.nn.functional.embedding(Tensor([40, 85],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 85],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:52.783488 test begin: paddle.nn.functional.embedding(Tensor([40, 85],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 85],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:53.358242 test begin: paddle.nn.functional.embedding(Tensor([40, 86],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 86],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:54.363980 test begin: paddle.nn.functional.embedding(Tensor([40, 86],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 86],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:54.957488 test begin: paddle.nn.functional.embedding(Tensor([40, 87],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 87],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:55.947237 test begin: paddle.nn.functional.embedding(Tensor([40, 87],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([40, 87],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 506 / 1781760 (0.0284%)
Max absolute difference: 0.99207515
Max relative difference: 1.
 x: array([[[0.501439, 0.52147 , 0.78423 , ..., 0.797132, 0.265771,
         0.892194],
        [0.793549, 0.033464, 0.614223, ..., 0.999497, 0.315835,...
 y: array([[[0.501439, 0.52147 , 0.78423 , ..., 0.797132, 0.265771,
         0.892194],
        [0.793549, 0.033464, 0.614223, ..., 0.999497, 0.315835,...
2025-05-12 09:00:56.567431 test begin: paddle.nn.functional.embedding(Tensor([40, 88],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 88],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:57.614695 test begin: paddle.nn.functional.embedding(Tensor([40, 88],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 88],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:58.245543 test begin: paddle.nn.functional.embedding(Tensor([40, 89],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 89],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:59.228071 test begin: paddle.nn.functional.embedding(Tensor([40, 89],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 89],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:00:59.848962 test begin: paddle.nn.functional.embedding(Tensor([40, 90],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([40, 90],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1015 / 3686400 (0.0275%)
Max absolute difference: 0.9997983
Max relative difference: 1.
 x: array([[[0.155037, 0.206837, 0.276226, ..., 0.04577 , 0.832513,
         0.428801],
        [0.447206, 0.819898, 0.099608, ..., 0.365841, 0.002747,...
 y: array([[[0.155037, 0.206837, 0.276226, ..., 0.04577 , 0.832513,
         0.428801],
        [0.447206, 0.819898, 0.099608, ..., 0.365841, 0.002747,...
2025-05-12 09:01:00.960928 test begin: paddle.nn.functional.embedding(Tensor([40, 90],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 90],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:01.598089 test begin: paddle.nn.functional.embedding(Tensor([40, 91],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 91],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:02.656618 test begin: paddle.nn.functional.embedding(Tensor([40, 91],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 91],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:03.274265 test begin: paddle.nn.functional.embedding(Tensor([40, 92],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 92],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:04.268888 test begin: paddle.nn.functional.embedding(Tensor([40, 92],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 92],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:04.875012 test begin: paddle.nn.functional.embedding(Tensor([40, 93],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 93],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:05.882334 test begin: paddle.nn.functional.embedding(Tensor([40, 93],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 93],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:06.476455 test begin: paddle.nn.functional.embedding(Tensor([40, 94],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 94],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:07.114824 test begin: paddle.nn.functional.embedding(Tensor([40, 95],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 95],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:08.158668 test begin: paddle.nn.functional.embedding(Tensor([40, 95],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 95],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:08.768798 test begin: paddle.nn.functional.embedding(Tensor([40, 96],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 96],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:09.372100 test begin: paddle.nn.functional.embedding(Tensor([40, 97],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 97],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:09.973679 test begin: paddle.nn.functional.embedding(Tensor([40, 98],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 98],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:10.584013 test begin: paddle.nn.functional.embedding(Tensor([40, 99],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([40, 99],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:11.184561 test begin: paddle.nn.functional.embedding(Tensor([408, 10],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([408, 10],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:12.209899 test begin: paddle.nn.functional.embedding(Tensor([408, 10],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([408, 10],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:12.809681 test begin: paddle.nn.functional.embedding(Tensor([408, 12],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([408, 12],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:13.910228 test begin: paddle.nn.functional.embedding(Tensor([408, 7],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([408, 7],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:14.500279 test begin: paddle.nn.functional.embedding(Tensor([408, 8],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([408, 8],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 507 / 1671168 (0.0303%)
Max absolute difference: 0.99876434
Max relative difference: 1.
 x: array([[[3.439160e-01, 6.602691e-01, 6.528618e-01, ..., 6.225517e-01,
         4.194731e-01, 6.820923e-01],
        [4.397503e-01, 5.053005e-01, 1.343131e-02, ..., 3.908607e-01,...
 y: array([[[3.439160e-01, 6.602691e-01, 6.528618e-01, ..., 6.225517e-01,
         4.194731e-01, 6.820923e-01],
        [4.397503e-01, 5.053005e-01, 1.343131e-02, ..., 3.908607e-01,...
2025-05-12 09:01:15.100062 test begin: paddle.nn.functional.embedding(Tensor([408, 9],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([408, 9],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 507 / 1880064 (0.027%)
Max absolute difference: 0.99636984
Max relative difference: 1.
 x: array([[[0.43645 , 0.615814, 0.426686, ..., 0.818788, 0.129182,
         0.950142],
        [0.608697, 0.125474, 0.056861, ..., 0.813511, 0.526996,...
 y: array([[[0.43645 , 0.615814, 0.426686, ..., 0.818788, 0.129182,
         0.950142],
        [0.608697, 0.125474, 0.056861, ..., 0.813511, 0.526996,...
2025-05-12 09:01:15.707270 test begin: paddle.nn.functional.embedding(Tensor([424, 10],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([424, 10],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:16.699676 test begin: paddle.nn.functional.embedding(Tensor([424, 11],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([424, 11],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:17.782679 test begin: paddle.nn.functional.embedding(Tensor([424, 12],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([424, 12],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:18.868150 test begin: paddle.nn.functional.embedding(Tensor([424, 9],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([424, 9],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:19.909980 test begin: paddle.nn.functional.embedding(Tensor([448, 7],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([448, 7],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:20.501068 test begin: paddle.nn.functional.embedding(Tensor([448, 8],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([448, 8],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:21.140008 test begin: paddle.nn.functional.embedding(Tensor([448, 9],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([448, 9],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:21.745111 test begin: paddle.nn.functional.embedding(Tensor([464, 10],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([464, 10],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2028 / 4751360 (0.0427%)
Max absolute difference: 0.99969006
Max relative difference: 1.
 x: array([[[7.211160e-01, 8.183540e-02, 8.146557e-02, ..., 3.537996e-01,
         5.916935e-01, 5.149822e-01],
        [5.890453e-01, 5.248252e-04, 2.952659e-02, ..., 1.819398e-01,...
 y: array([[[7.211160e-01, 8.183540e-02, 8.146557e-02, ..., 3.537996e-01,
         5.916935e-01, 5.149822e-01],
        [5.890453e-01, 5.248252e-04, 2.952659e-02, ..., 1.819398e-01,...
2025-05-12 09:01:22.871858 test begin: paddle.nn.functional.embedding(Tensor([464, 11],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([464, 11],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:23.981881 test begin: paddle.nn.functional.embedding(Tensor([464, 3],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([464, 3],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1016 / 1425408 (0.0713%)
Max absolute difference: 0.9998751
Max relative difference: 1.
 x: array([[[0.719261, 0.395495, 0.632177, ..., 0.666938, 0.33146 ,
         0.634556],
        [0.322   , 0.106352, 0.787256, ..., 0.241373, 0.81273 ,...
 y: array([[[0.719261, 0.395495, 0.632177, ..., 0.666938, 0.33146 ,
         0.634556],
        [0.322   , 0.106352, 0.787256, ..., 0.241373, 0.81273 ,...
2025-05-12 09:01:24.933012 test begin: paddle.nn.functional.embedding(Tensor([464, 4],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([464, 4],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:25.925035 test begin: paddle.nn.functional.embedding(Tensor([464, 8],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([464, 8],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:26.949262 test begin: paddle.nn.functional.embedding(Tensor([464, 9],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([464, 9],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:27.981144 test begin: paddle.nn.functional.embedding(Tensor([48, 100],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 100],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:29.131939 test begin: paddle.nn.functional.embedding(Tensor([48, 101],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 101],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:30.233961 test begin: paddle.nn.functional.embedding(Tensor([48, 102],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 102],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:31.323036 test begin: paddle.nn.functional.embedding(Tensor([48, 103],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 103],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:32.425317 test begin: paddle.nn.functional.embedding(Tensor([48, 104],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 104],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:33.511414 test begin: paddle.nn.functional.embedding(Tensor([48, 105],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([48, 105],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1011 / 5160960 (0.0196%)
Max absolute difference: 0.9993523
Max relative difference: 1.
 x: array([[[8.733871e-02, 9.951488e-01, 4.866812e-01, ..., 1.402058e-01,
         6.566972e-01, 3.526002e-01],
        [3.237329e-01, 7.194840e-01, 9.777712e-01, ..., 1.805814e-01,...
 y: array([[[8.733871e-02, 9.951488e-01, 4.866812e-01, ..., 1.402058e-01,
         6.566972e-01, 3.526002e-01],
        [3.237329e-01, 7.194840e-01, 9.777712e-01, ..., 1.805814e-01,...
2025-05-12 09:01:34.710153 test begin: paddle.nn.functional.embedding(Tensor([48, 106],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 106],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:35.797078 test begin: paddle.nn.functional.embedding(Tensor([48, 25],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 25],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:36.345689 test begin: paddle.nn.functional.embedding(Tensor([48, 30],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 30],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:36.915615 test begin: paddle.nn.functional.embedding(Tensor([48, 32],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 32],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:37.474367 test begin: paddle.nn.functional.embedding(Tensor([48, 34],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 34],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:38.028903 test begin: paddle.nn.functional.embedding(Tensor([48, 36],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 36],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:38.579791 test begin: paddle.nn.functional.embedding(Tensor([48, 37],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([48, 37],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 507 / 909312 (0.0558%)
Max absolute difference: 0.99689436
Max relative difference: 1.
 x: array([[[0.669993, 0.108797, 0.003152, ..., 0.593829, 0.987816,
         0.660492],
        [0.490542, 0.762204, 0.68895 , ..., 0.948196, 0.259508,...
 y: array([[[0.669993, 0.108797, 0.003152, ..., 0.593829, 0.987816,
         0.660492],
        [0.490542, 0.762204, 0.68895 , ..., 0.948196, 0.259508,...
2025-05-12 09:01:39.159014 test begin: paddle.nn.functional.embedding(Tensor([48, 39],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 39],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:39.763579 test begin: paddle.nn.functional.embedding(Tensor([48, 40],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 40],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:40.795345 test begin: paddle.nn.functional.embedding(Tensor([48, 41],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 41],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:41.391168 test begin: paddle.nn.functional.embedding(Tensor([48, 42],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 42],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:42.024606 test begin: paddle.nn.functional.embedding(Tensor([48, 43],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 43],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:42.986180 test begin: paddle.nn.functional.embedding(Tensor([48, 44],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 44],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:43.611558 test begin: paddle.nn.functional.embedding(Tensor([48, 47],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 47],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:44.586321 test begin: paddle.nn.functional.embedding(Tensor([48, 48],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 48],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:45.661897 test begin: paddle.nn.functional.embedding(Tensor([48, 49],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 49],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:46.635374 test begin: paddle.nn.functional.embedding(Tensor([48, 49],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 49],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:47.265487 test begin: paddle.nn.functional.embedding(Tensor([48, 51],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 51],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:48.236745 test begin: paddle.nn.functional.embedding(Tensor([48, 51],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 51],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:48.868740 test begin: paddle.nn.functional.embedding(Tensor([48, 53],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 53],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:49.486180 test begin: paddle.nn.functional.embedding(Tensor([48, 54],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 54],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:50.113457 test begin: paddle.nn.functional.embedding(Tensor([48, 55],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 55],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:51.123625 test begin: paddle.nn.functional.embedding(Tensor([48, 57],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 57],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:52.115547 test begin: paddle.nn.functional.embedding(Tensor([48, 58],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 58],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:53.092155 test begin: paddle.nn.functional.embedding(Tensor([48, 58],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 58],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:53.682786 test begin: paddle.nn.functional.embedding(Tensor([48, 59],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 59],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:54.659297 test begin: paddle.nn.functional.embedding(Tensor([48, 61],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 61],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:55.647847 test begin: paddle.nn.functional.embedding(Tensor([48, 61],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 61],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:56.283965 test begin: paddle.nn.functional.embedding(Tensor([48, 62],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 62],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:56.876825 test begin: paddle.nn.functional.embedding(Tensor([48, 63],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 63],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:57.495288 test begin: paddle.nn.functional.embedding(Tensor([48, 64],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 64],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:58.119926 test begin: paddle.nn.functional.embedding(Tensor([48, 65],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([48, 65],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1020 / 3194880 (0.0319%)
Max absolute difference: 0.9997218
Max relative difference: 1.
 x: array([[[7.949408e-01, 8.816625e-01, 6.223136e-01, ..., 4.485706e-01,
         3.928777e-01, 5.404713e-01],
        [5.197501e-01, 9.426711e-01, 6.994613e-01, ..., 2.372225e-02,...
 y: array([[[7.949408e-01, 8.816625e-01, 6.223136e-01, ..., 4.485706e-01,
         3.928777e-01, 5.404713e-01],
        [5.197501e-01, 9.426711e-01, 6.994613e-01, ..., 2.372225e-02,...
2025-05-12 09:01:59.169456 test begin: paddle.nn.functional.embedding(Tensor([48, 65],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 65],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:01:59.775231 test begin: paddle.nn.functional.embedding(Tensor([48, 66],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 66],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:00.384468 test begin: paddle.nn.functional.embedding(Tensor([48, 67],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 67],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:01.365573 test begin: paddle.nn.functional.embedding(Tensor([48, 67],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 67],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:01.987778 test begin: paddle.nn.functional.embedding(Tensor([48, 68],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 68],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:02.986375 test begin: paddle.nn.functional.embedding(Tensor([48, 68],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 68],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:03.629166 test begin: paddle.nn.functional.embedding(Tensor([48, 69],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 69],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:04.264808 test begin: paddle.nn.functional.embedding(Tensor([48, 70],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 70],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:05.318277 test begin: paddle.nn.functional.embedding(Tensor([48, 70],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 70],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:05.958485 test begin: paddle.nn.functional.embedding(Tensor([48, 71],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 71],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:06.971500 test begin: paddle.nn.functional.embedding(Tensor([48, 71],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 71],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:07.554869 test begin: paddle.nn.functional.embedding(Tensor([48, 72],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 72],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:08.125220 test begin: paddle.nn.functional.embedding(Tensor([48, 73],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 73],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:09.145028 test begin: paddle.nn.functional.embedding(Tensor([48, 73],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 73],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:09.728457 test begin: paddle.nn.functional.embedding(Tensor([48, 74],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([48, 74],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 509 / 1818624 (0.028%)
Max absolute difference: 0.99946886
Max relative difference: 1.
 x: array([[[8.513286e-01, 3.590462e-01, 4.130004e-02, ..., 6.291692e-01,
         5.025462e-01, 2.562909e-01],
        [4.441653e-01, 4.149834e-01, 5.457676e-01, ..., 7.936240e-02,...
 y: array([[[8.513286e-01, 3.590462e-01, 4.130004e-02, ..., 6.291692e-01,
         5.025462e-01, 2.562909e-01],
        [4.441653e-01, 4.149834e-01, 5.457676e-01, ..., 7.936240e-02,...
2025-05-12 09:02:10.321797 test begin: paddle.nn.functional.embedding(Tensor([48, 75],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 75],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:11.303448 test begin: paddle.nn.functional.embedding(Tensor([48, 75],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 75],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:11.913196 test begin: paddle.nn.functional.embedding(Tensor([48, 76],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 76],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:12.942821 test begin: paddle.nn.functional.embedding(Tensor([48, 76],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 76],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:13.651498 test begin: paddle.nn.functional.embedding(Tensor([48, 77],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 77],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:14.294955 test begin: paddle.nn.functional.embedding(Tensor([48, 78],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 78],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:15.328808 test begin: paddle.nn.functional.embedding(Tensor([48, 78],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 78],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:15.917805 test begin: paddle.nn.functional.embedding(Tensor([48, 79],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 79],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:16.938937 test begin: paddle.nn.functional.embedding(Tensor([48, 79],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([48, 79],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 506 / 1941504 (0.0261%)
Max absolute difference: 0.99873537
Max relative difference: 1.
 x: array([[[0.198265, 0.878183, 0.621618, ..., 0.204657, 0.937981,
         0.35896 ],
        [0.799046, 0.815774, 0.101822, ..., 0.192425, 0.668341,...
 y: array([[[0.198265, 0.878183, 0.621618, ..., 0.204657, 0.937981,
         0.35896 ],
        [0.799046, 0.815774, 0.101822, ..., 0.192425, 0.668341,...
2025-05-12 09:02:17.553638 test begin: paddle.nn.functional.embedding(Tensor([48, 80],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 80],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:18.159624 test begin: paddle.nn.functional.embedding(Tensor([48, 81],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 81],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:19.157191 test begin: paddle.nn.functional.embedding(Tensor([48, 81],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 81],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:19.731890 test begin: paddle.nn.functional.embedding(Tensor([48, 82],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 82],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:20.723812 test begin: paddle.nn.functional.embedding(Tensor([48, 82],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 82],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:21.320705 test begin: paddle.nn.functional.embedding(Tensor([48, 83],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 83],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:22.337063 test begin: paddle.nn.functional.embedding(Tensor([48, 83],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 83],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:22.930870 test begin: paddle.nn.functional.embedding(Tensor([48, 84],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 84],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:24.014450 test begin: paddle.nn.functional.embedding(Tensor([48, 84],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 84],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:24.618315 test begin: paddle.nn.functional.embedding(Tensor([48, 85],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 85],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:25.647439 test begin: paddle.nn.functional.embedding(Tensor([48, 85],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 85],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:26.261451 test begin: paddle.nn.functional.embedding(Tensor([48, 86],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 86],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:27.323353 test begin: paddle.nn.functional.embedding(Tensor([48, 87],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 87],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:28.393484 test begin: paddle.nn.functional.embedding(Tensor([48, 88],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 88],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:29.453844 test begin: paddle.nn.functional.embedding(Tensor([48, 89],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 89],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:30.534731 test begin: paddle.nn.functional.embedding(Tensor([48, 90],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 90],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:31.606744 test begin: paddle.nn.functional.embedding(Tensor([48, 91],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 91],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:32.680660 test begin: paddle.nn.functional.embedding(Tensor([48, 92],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 92],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:33.748916 test begin: paddle.nn.functional.embedding(Tensor([48, 93],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 93],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:34.825445 test begin: paddle.nn.functional.embedding(Tensor([48, 94],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 94],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:35.913013 test begin: paddle.nn.functional.embedding(Tensor([48, 95],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 95],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:37.002973 test begin: paddle.nn.functional.embedding(Tensor([48, 96],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 96],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:38.139076 test begin: paddle.nn.functional.embedding(Tensor([48, 97],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 97],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:39.240077 test begin: paddle.nn.functional.embedding(Tensor([48, 98],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 98],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:40.364318 test begin: paddle.nn.functional.embedding(Tensor([48, 99],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([48, 99],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:41.469210 test begin: paddle.nn.functional.embedding(Tensor([480, 5],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([480, 5],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:42.036801 test begin: paddle.nn.functional.embedding(Tensor([480, 8],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([480, 8],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:42.622447 test begin: paddle.nn.functional.embedding(Tensor([512, 10],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([512, 10],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:43.738814 test begin: paddle.nn.functional.embedding(Tensor([512, 7],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([512, 7],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:44.765366 test begin: paddle.nn.functional.embedding(Tensor([512, 7],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([512, 7],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:45.379893 test begin: paddle.nn.functional.embedding(Tensor([512, 8],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([512, 8],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:46.473046 test begin: paddle.nn.functional.embedding(Tensor([512, 8],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([512, 8],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:47.096234 test begin: paddle.nn.functional.embedding(Tensor([512, 9],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([512, 9],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:48.199937 test begin: paddle.nn.functional.embedding(Tensor([52, 7],"int32"), weight=Tensor([109, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([52, 7],"int32"), weight=Tensor([109, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 128 / 11648 (1.1%)
Max absolute difference: 0.98731863
Max relative difference: 1.
 x: array([[[0.984113, 0.990181, 0.235144, ..., 0.540318, 0.554952,
         0.328261],
        [0.901085, 0.184432, 0.977311, ..., 0.794247, 0.530448,...
 y: array([[[0.984113, 0.990181, 0.235144, ..., 0.540318, 0.554952,
         0.328261],
        [0.901085, 0.184432, 0.977311, ..., 0.794247, 0.530448,...
2025-05-12 09:02:48.372964 test begin: paddle.nn.functional.embedding(Tensor([52, 7],"int32"), weight=Tensor([109, 64],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([52, 7],"int32"), weight=Tensor([109, 64],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 63 / 23296 (0.27%)
Max absolute difference: 0.98743343
Max relative difference: 1.
 x: array([[[0.196945, 0.589688, 0.411361, ..., 0.603929, 0.275543,
         0.774543],
        [0.142132, 0.912602, 0.270298, ..., 0.455847, 0.180093,...
 y: array([[[0.196945, 0.589688, 0.411361, ..., 0.603929, 0.275543,
         0.774543],
        [0.142132, 0.912602, 0.270298, ..., 0.455847, 0.180093,...
2025-05-12 09:02:48.555816 test begin: paddle.nn.functional.embedding(Tensor([52, 7],"int32"), weight=Tensor([84, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([52, 7],"int32"), weight=Tensor([84, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 62 / 11648 (0.532%)
Max absolute difference: 0.9761555
Max relative difference: 1.
 x: array([[[0.342837, 0.203484, 0.656876, ..., 0.726928, 0.621302,
         0.819457],
        [0.342703, 0.67529 , 0.501639, ..., 0.025628, 0.207749,...
 y: array([[[0.342837, 0.203484, 0.656876, ..., 0.726928, 0.621302,
         0.819457],
        [0.342703, 0.67529 , 0.501639, ..., 0.025628, 0.207749,...
2025-05-12 09:02:48.724831 test begin: paddle.nn.functional.embedding(Tensor([52, 7],"int32"), weight=Tensor([84, 64],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([52, 7],"int32"), weight=Tensor([84, 64],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 378 / 23296 (1.62%)
Max absolute difference: 0.9919184
Max relative difference: 1.
 x: array([[[0.556296, 0.832133, 0.838304, ..., 0.92691 , 0.207152,
         0.280183],
        [0.808794, 0.741632, 0.350639, ..., 0.887316, 0.08583 ,...
 y: array([[[0.556296, 0.832133, 0.838304, ..., 0.92691 , 0.207152,
         0.280183],
        [0.808794, 0.741632, 0.350639, ..., 0.887316, 0.08583 ,...
2025-05-12 09:02:48.889760 test begin: paddle.nn.functional.embedding(Tensor([52, 7],"int32"), weight=Tensor([99, 128],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([52, 7],"int32"), weight=Tensor([99, 128],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 375 / 46592 (0.805%)
Max absolute difference: 0.99862236
Max relative difference: 1.
 x: array([[[0.658876, 0.65633 , 0.618212, ..., 0.274524, 0.825634,
         0.371642],
        [0.597304, 0.902884, 0.853339, ..., 0.358394, 0.376637,...
 y: array([[[0.658876, 0.65633 , 0.618212, ..., 0.274524, 0.825634,
         0.371642],
        [0.597304, 0.902884, 0.853339, ..., 0.358394, 0.376637,...
2025-05-12 09:02:49.049953 test begin: paddle.nn.functional.embedding(Tensor([52, 7],"int32"), weight=Tensor([99, 16],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([52, 7],"int32"), weight=Tensor([99, 16],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 96 / 5824 (1.65%)
Max absolute difference: 0.99068195
Max relative difference: 1.
 x: array([[[6.670085e-01, 5.856835e-01, 1.923001e-01, ..., 9.290493e-01,
         3.310643e-01, 4.602013e-01],
        [3.079613e-01, 2.744150e-01, 3.041770e-01, ..., 5.087321e-01,...
 y: array([[[6.670085e-01, 5.856835e-01, 1.923001e-01, ..., 9.290493e-01,
         3.310643e-01, 4.602013e-01],
        [3.079613e-01, 2.744150e-01, 3.041770e-01, ..., 5.087321e-01,...
2025-05-12 09:02:49.226128 test begin: paddle.nn.functional.embedding(Tensor([52, 7],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([52, 7],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 93 / 11648 (0.798%)
Max absolute difference: 0.9870053
Max relative difference: 1.
 x: array([[[0.579853, 0.587597, 0.372781, ..., 0.789462, 0.142946,
         0.049381],
        [0.783152, 0.112587, 0.934309, ..., 0.452327, 0.084104,...
 y: array([[[0.579853, 0.587597, 0.372781, ..., 0.789462, 0.142946,
         0.049381],
        [0.783152, 0.112587, 0.934309, ..., 0.452327, 0.084104,...
2025-05-12 09:02:49.393975 test begin: paddle.nn.functional.embedding(Tensor([52, 7],"int32"), weight=Tensor([99, 64],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([52, 7],"int32"), weight=Tensor([99, 64],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 192 / 23296 (0.824%)
Max absolute difference: 0.9864841
Max relative difference: 1.
 x: array([[[0.369776, 0.854375, 0.751438, ..., 0.21268 , 0.473551,
         0.388751],
        [0.570356, 0.079513, 0.175267, ..., 0.611711, 0.335661,...
 y: array([[[0.369776, 0.854375, 0.751438, ..., 0.21268 , 0.473551,
         0.388751],
        [0.570356, 0.079513, 0.175267, ..., 0.611711, 0.335661,...
2025-05-12 09:02:49.558701 test begin: paddle.nn.functional.embedding(Tensor([52, 7],"int64"), weight=Tensor([512, 64],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([52, 7],"int64"), weight=Tensor([512, 64],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 128 / 23296 (0.549%)
Max absolute difference: 0.9990373
Max relative difference: 1.
 x: array([[[0.575136, 0.565851, 0.153279, ..., 0.149505, 0.918486,
         0.748603],
        [0.091384, 0.400613, 0.254439, ..., 0.383244, 0.796106,...
 y: array([[[0.575136, 0.565851, 0.153279, ..., 0.149505, 0.918486,
         0.748603],
        [0.091384, 0.400613, 0.254439, ..., 0.383244, 0.796106,...
2025-05-12 09:02:49.719906 test begin: paddle.nn.functional.embedding(Tensor([52, 8],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([52, 8],"int32"), weight=Tensor([99, 32],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 160 / 13312 (1.2%)
Max absolute difference: 0.9845308
Max relative difference: 1.
 x: array([[[0.565237, 0.784604, 0.309848, ..., 0.849667, 0.126442,
         0.007575],
        [0.12626 , 0.371451, 0.16536 , ..., 0.845729, 0.242515,...
 y: array([[[0.565237, 0.784604, 0.309848, ..., 0.849667, 0.126442,
         0.007575],
        [0.12626 , 0.371451, 0.16536 , ..., 0.845729, 0.242515,...
2025-05-12 09:02:49.883343 test begin: paddle.nn.functional.embedding(Tensor([528, 9],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([528, 9],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:50.960467 test begin: paddle.nn.functional.embedding(Tensor([56, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:51.919826 test begin: paddle.nn.functional.embedding(Tensor([56, 25],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 25],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:52.863906 test begin: paddle.nn.functional.embedding(Tensor([56, 26],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 26],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:53.428186 test begin: paddle.nn.functional.embedding(Tensor([56, 28],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([56, 28],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 508 / 802816 (0.0633%)
Max absolute difference: 0.9952894
Max relative difference: 1.
 x: array([[[0.771032, 0.606232, 0.247414, ..., 0.789451, 0.903586,
         0.647059],
        [0.803599, 0.765265, 0.72152 , ..., 0.373954, 0.184022,...
 y: array([[[0.771032, 0.606232, 0.247414, ..., 0.789451, 0.903586,
         0.647059],
        [0.803599, 0.765265, 0.72152 , ..., 0.373954, 0.184022,...
2025-05-12 09:02:53.983317 test begin: paddle.nn.functional.embedding(Tensor([56, 33],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 33],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:54.556323 test begin: paddle.nn.functional.embedding(Tensor([56, 35],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 35],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:55.133922 test begin: paddle.nn.functional.embedding(Tensor([56, 37],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 37],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:55.701934 test begin: paddle.nn.functional.embedding(Tensor([56, 38],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 38],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:56.277719 test begin: paddle.nn.functional.embedding(Tensor([56, 39],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 39],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:57.239982 test begin: paddle.nn.functional.embedding(Tensor([56, 42],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 42],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:58.212126 test begin: paddle.nn.functional.embedding(Tensor([56, 44],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([56, 44],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 507 / 1261568 (0.0402%)
Max absolute difference: 0.9935456
Max relative difference: 1.
 x: array([[[0.804482, 0.569755, 0.877825, ..., 0.040875, 0.390863,
         0.228977],
        [0.214053, 0.659824, 0.946087, ..., 0.113569, 0.149528,...
 y: array([[[0.804482, 0.569755, 0.877825, ..., 0.040875, 0.390863,
         0.228977],
        [0.214053, 0.659824, 0.946087, ..., 0.113569, 0.149528,...
2025-05-12 09:02:58.794895 test begin: paddle.nn.functional.embedding(Tensor([56, 45],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 45],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:02:59.961478 test begin: paddle.nn.functional.embedding(Tensor([56, 45],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 45],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:00.605482 test begin: paddle.nn.functional.embedding(Tensor([56, 47],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 47],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:01.195470 test begin: paddle.nn.functional.embedding(Tensor([56, 50],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 50],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:01.837508 test begin: paddle.nn.functional.embedding(Tensor([56, 51],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 51],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:02.462936 test begin: paddle.nn.functional.embedding(Tensor([56, 52],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 52],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:03.473126 test begin: paddle.nn.functional.embedding(Tensor([56, 52],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 52],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:04.105258 test begin: paddle.nn.functional.embedding(Tensor([56, 53],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 53],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:05.097898 test begin: paddle.nn.functional.embedding(Tensor([56, 53],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 53],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:05.695753 test begin: paddle.nn.functional.embedding(Tensor([56, 54],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 54],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:06.278288 test begin: paddle.nn.functional.embedding(Tensor([56, 55],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 55],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:06.848393 test begin: paddle.nn.functional.embedding(Tensor([56, 56],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 56],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:07.824006 test begin: paddle.nn.functional.embedding(Tensor([56, 56],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 56],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:08.396830 test begin: paddle.nn.functional.embedding(Tensor([56, 57],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 57],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:08.994262 test begin: paddle.nn.functional.embedding(Tensor([56, 58],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 58],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:09.596712 test begin: paddle.nn.functional.embedding(Tensor([56, 59],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 59],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:10.178427 test begin: paddle.nn.functional.embedding(Tensor([56, 60],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 60],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:11.160759 test begin: paddle.nn.functional.embedding(Tensor([56, 60],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 60],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:11.760266 test begin: paddle.nn.functional.embedding(Tensor([56, 61],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 61],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:12.354094 test begin: paddle.nn.functional.embedding(Tensor([56, 62],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 62],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:13.341745 test begin: paddle.nn.functional.embedding(Tensor([56, 62],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 62],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:13.916269 test begin: paddle.nn.functional.embedding(Tensor([56, 63],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 63],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:14.490541 test begin: paddle.nn.functional.embedding(Tensor([56, 64],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 64],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:15.100924 test begin: paddle.nn.functional.embedding(Tensor([56, 65],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 65],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:15.693324 test begin: paddle.nn.functional.embedding(Tensor([56, 66],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([56, 66],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1016 / 3784704 (0.0268%)
Max absolute difference: 0.99851847
Max relative difference: 1.
 x: array([[[0.122197, 0.240838, 0.028193, ..., 0.218218, 0.242244,
         0.661135],
        [0.395147, 0.465018, 0.720071, ..., 0.688146, 0.524306,...
 y: array([[[0.122197, 0.240838, 0.028193, ..., 0.218218, 0.242244,
         0.661135],
        [0.395147, 0.465018, 0.720071, ..., 0.688146, 0.524306,...
2025-05-12 09:03:16.817037 test begin: paddle.nn.functional.embedding(Tensor([56, 66],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 66],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:17.410742 test begin: paddle.nn.functional.embedding(Tensor([56, 67],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 67],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:18.023167 test begin: paddle.nn.functional.embedding(Tensor([56, 68],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 68],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:18.618585 test begin: paddle.nn.functional.embedding(Tensor([56, 69],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 69],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:19.667230 test begin: paddle.nn.functional.embedding(Tensor([56, 69],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([56, 69],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 509 / 1978368 (0.0257%)
Max absolute difference: 0.99980754
Max relative difference: 1.
 x: array([[[0.98315 , 0.821769, 0.126747, ..., 0.239353, 0.725569,
         0.419364],
        [0.92081 , 0.116727, 0.01229 , ..., 0.379723, 0.029487,...
 y: array([[[0.98315 , 0.821769, 0.126747, ..., 0.239353, 0.725569,
         0.419364],
        [0.92081 , 0.116727, 0.01229 , ..., 0.379723, 0.029487,...
2025-05-12 09:03:20.341231 test begin: paddle.nn.functional.embedding(Tensor([56, 70],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 70],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:20.929429 test begin: paddle.nn.functional.embedding(Tensor([56, 71],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 71],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:21.951430 test begin: paddle.nn.functional.embedding(Tensor([56, 71],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 71],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:22.546452 test begin: paddle.nn.functional.embedding(Tensor([56, 72],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([56, 72],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1008 / 4128768 (0.0244%)
Max absolute difference: 0.9994358
Max relative difference: 1.
 x: array([[[0.983616, 0.794991, 0.939959, ..., 0.828641, 0.163387,
         0.763092],
        [0.93809 , 0.53385 , 0.075039, ..., 0.617365, 0.72261 ,...
 y: array([[[0.983616, 0.794991, 0.939959, ..., 0.828641, 0.163387,
         0.763092],
        [0.93809 , 0.53385 , 0.075039, ..., 0.617365, 0.72261 ,...
2025-05-12 09:03:23.631461 test begin: paddle.nn.functional.embedding(Tensor([56, 72],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 72],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:24.252737 test begin: paddle.nn.functional.embedding(Tensor([56, 73],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 73],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:25.459388 test begin: paddle.nn.functional.embedding(Tensor([56, 73],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 73],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:26.074533 test begin: paddle.nn.functional.embedding(Tensor([56, 74],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 74],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:27.270247 test begin: paddle.nn.functional.embedding(Tensor([56, 75],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 75],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:28.414707 test begin: paddle.nn.functional.embedding(Tensor([56, 76],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 76],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:29.470087 test begin: paddle.nn.functional.embedding(Tensor([56, 77],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 77],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:30.560058 test begin: paddle.nn.functional.embedding(Tensor([56, 78],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([56, 78],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1015 / 4472832 (0.0227%)
Max absolute difference: 0.9988737
Max relative difference: 1.
 x: array([[[0.69349 , 0.977531, 0.049616, ..., 0.478897, 0.079706,
         0.248838],
        [0.08292 , 0.541623, 0.173174, ..., 0.189844, 0.173816,...
 y: array([[[0.69349 , 0.977531, 0.049616, ..., 0.478897, 0.079706,
         0.248838],
        [0.08292 , 0.541623, 0.173174, ..., 0.189844, 0.173816,...
2025-05-12 09:03:31.679101 test begin: paddle.nn.functional.embedding(Tensor([56, 79],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([56, 79],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1015 / 4530176 (0.0224%)
Max absolute difference: 0.9996687
Max relative difference: 1.
 x: array([[[0.217669, 0.895637, 0.408294, ..., 0.844933, 0.394031,
         0.832871],
        [0.684113, 0.502975, 0.526138, ..., 0.906743, 0.861378,...
 y: array([[[0.217669, 0.895637, 0.408294, ..., 0.844933, 0.394031,
         0.832871],
        [0.684113, 0.502975, 0.526138, ..., 0.906743, 0.861378,...
2025-05-12 09:03:32.818294 test begin: paddle.nn.functional.embedding(Tensor([56, 80],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 80],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:33.903360 test begin: paddle.nn.functional.embedding(Tensor([56, 81],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 81],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:34.969288 test begin: paddle.nn.functional.embedding(Tensor([56, 82],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 82],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:36.031682 test begin: paddle.nn.functional.embedding(Tensor([56, 83],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 83],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:37.092382 test begin: paddle.nn.functional.embedding(Tensor([56, 84],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 84],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:38.206306 test begin: paddle.nn.functional.embedding(Tensor([56, 85],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([56, 85],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1019 / 4874240 (0.0209%)
Max absolute difference: 0.9989096
Max relative difference: 1.
 x: array([[[1.720549e-01, 4.755473e-01, 9.170207e-01, ..., 5.438091e-01,
         8.346306e-01, 1.199507e-02],
        [1.997256e-01, 5.222774e-01, 4.331190e-01, ..., 4.744925e-02,...
 y: array([[[1.720549e-01, 4.755473e-01, 9.170207e-01, ..., 5.438091e-01,
         8.346306e-01, 1.199507e-02],
        [1.997256e-01, 5.222774e-01, 4.331190e-01, ..., 4.744925e-02,...
2025-05-12 09:03:39.354643 test begin: paddle.nn.functional.embedding(Tensor([56, 86],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 86],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:40.441968 test begin: paddle.nn.functional.embedding(Tensor([56, 87],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 87],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:41.525414 test begin: paddle.nn.functional.embedding(Tensor([56, 88],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 88],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:42.661551 test begin: paddle.nn.functional.embedding(Tensor([56, 89],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 89],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:43.756033 test begin: paddle.nn.functional.embedding(Tensor([56, 90],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 90],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:44.870156 test begin: paddle.nn.functional.embedding(Tensor([56, 91],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([56, 91],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:45.981989 test begin: paddle.nn.functional.embedding(Tensor([568, 8],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([568, 8],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:47.059332 test begin: paddle.nn.functional.embedding(Tensor([568, 9],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([568, 9],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:48.152175 test begin: paddle.nn.functional.embedding(Tensor([584, 6],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([584, 6],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1020 / 1794048 (0.0569%)
Max absolute difference: 0.9985119
Max relative difference: 1.
 x: array([[[2.935354e-01, 4.415361e-01, 3.876770e-01, ..., 6.435642e-01,
         2.174703e-01, 9.627839e-01],
        [7.959646e-01, 3.466676e-01, 3.296345e-01, ..., 3.736776e-01,...
 y: array([[[2.935354e-01, 4.415361e-01, 3.876770e-01, ..., 6.435642e-01,
         2.174703e-01, 9.627839e-01],
        [7.959646e-01, 3.466676e-01, 3.296345e-01, ..., 3.736776e-01,...
2025-05-12 09:03:48.754689 test begin: paddle.nn.functional.embedding(Tensor([584, 7],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([584, 7],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:49.308325 test begin: paddle.nn.functional.embedding(Tensor([6, 1],"int64"), weight=Tensor([32000, 64],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([6, 1],"int64"), weight=Tensor([32000, 64],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:49.487680 test begin: paddle.nn.functional.embedding(Tensor([6, 3],"int32"), Tensor([10, 4],"float32"), padding_idx=5, scale_grad_by_freq=False, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([6, 3],"int32"), Tensor([10, 4],"float32"), padding_idx=5, scale_grad_by_freq=False, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 16 / 72 (22.2%)
Max absolute difference: 0.73774904
Max relative difference: 1.
 x: array([[[0.      , 0.      , 0.      , 0.      ],
        [0.749225, 0.284457, 0.141896, 0.679444],
        [0.      , 0.      , 0.      , 0.      ]],...
 y: array([[[0.044661, 0.370698, 0.225158, 0.737749],
        [0.749225, 0.284457, 0.141896, 0.679444],
        [0.044661, 0.370698, 0.225158, 0.737749]],...
2025-05-12 09:03:49.631450 test begin: paddle.nn.functional.embedding(Tensor([6, 3],"int32"), Tensor([10, 4],"float32"), padding_idx=5, scale_grad_by_freq=True, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([6, 3],"int32"), Tensor([10, 4],"float32"), padding_idx=5, scale_grad_by_freq=True, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4 / 72 (5.56%)
Max absolute difference: 0.62988937
Max relative difference: 1.
 x: array([[[0.689158, 0.059289, 0.353733, 0.590284],
        [0.394794, 0.80167 , 0.943609, 0.509461],
        [0.925735, 0.5269  , 0.13956 , 0.073233]],...
 y: array([[[0.689158, 0.059289, 0.353733, 0.590284],
        [0.394794, 0.80167 , 0.943609, 0.509461],
        [0.925735, 0.5269  , 0.13956 , 0.073233]],...
2025-05-12 09:03:49.778980 test begin: paddle.nn.functional.embedding(Tensor([6, 5],"int64"), weight=Tensor([32000, 64],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([6, 5],"int64"), weight=Tensor([32000, 64],"float32"), padding_idx=3, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:49.940178 test begin: paddle.nn.functional.embedding(Tensor([624, 7],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([624, 7],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:51.001330 test begin: paddle.nn.functional.embedding(Tensor([624, 8],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([624, 8],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:52.128797 test begin: paddle.nn.functional.embedding(Tensor([64, 14],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 14],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:52.716493 test begin: paddle.nn.functional.embedding(Tensor([64, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:53.245113 test begin: paddle.nn.functional.embedding(Tensor([64, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:53.812324 test begin: paddle.nn.functional.embedding(Tensor([64, 23],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 23],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:54.395086 test begin: paddle.nn.functional.embedding(Tensor([64, 24],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 24],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:54.950919 test begin: paddle.nn.functional.embedding(Tensor([64, 25],"int64"), weight=Tensor([6627, 512],"float16"), padding_idx=6626, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 25],"int64"), weight=Tensor([6627, 512],"float16"), padding_idx=6626, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:55.298858 test begin: paddle.nn.functional.embedding(Tensor([64, 25],"int64"), weight=Tensor([6627, 512],"float32"), padding_idx=6626, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 25],"int64"), weight=Tensor([6627, 512],"float32"), padding_idx=6626, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:55.571663 test begin: paddle.nn.functional.embedding(Tensor([64, 27],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 27],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:56.121117 test begin: paddle.nn.functional.embedding(Tensor([64, 29],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 29],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:56.702085 test begin: paddle.nn.functional.embedding(Tensor([64, 30],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 30],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:57.661750 test begin: paddle.nn.functional.embedding(Tensor([64, 31],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 31],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:58.224459 test begin: paddle.nn.functional.embedding(Tensor([64, 32],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 32],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:59.217326 test begin: paddle.nn.functional.embedding(Tensor([64, 33],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 33],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:03:59.772429 test begin: paddle.nn.functional.embedding(Tensor([64, 34],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 34],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:00.755960 test begin: paddle.nn.functional.embedding(Tensor([64, 34],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 34],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:01.406672 test begin: paddle.nn.functional.embedding(Tensor([64, 35],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 35],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:02.380648 test begin: paddle.nn.functional.embedding(Tensor([64, 35],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 35],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:02.963913 test begin: paddle.nn.functional.embedding(Tensor([64, 36],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 36],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:03.929580 test begin: paddle.nn.functional.embedding(Tensor([64, 37],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 37],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:04.910437 test begin: paddle.nn.functional.embedding(Tensor([64, 38],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 38],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:05.923697 test begin: paddle.nn.functional.embedding(Tensor([64, 38],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 38],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:06.504518 test begin: paddle.nn.functional.embedding(Tensor([64, 40],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([64, 40],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 509 / 1310720 (0.0388%)
Max absolute difference: 0.99836034
Max relative difference: 1.
 x: array([[[0.00131 , 0.574969, 0.746494, ..., 0.494278, 0.142557,
         0.405438],
        [0.989879, 0.565553, 0.324051, ..., 0.397343, 0.916543,...
 y: array([[[0.00131 , 0.574969, 0.746494, ..., 0.494278, 0.142557,
         0.405438],
        [0.989879, 0.565553, 0.324051, ..., 0.397343, 0.916543,...
2025-05-12 09:04:07.121094 test begin: paddle.nn.functional.embedding(Tensor([64, 41],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 41],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:08.107465 test begin: paddle.nn.functional.embedding(Tensor([64, 41],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 41],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:08.681922 test begin: paddle.nn.functional.embedding(Tensor([64, 42],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 42],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:09.276081 test begin: paddle.nn.functional.embedding(Tensor([64, 43],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 43],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:09.857981 test begin: paddle.nn.functional.embedding(Tensor([64, 44],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 44],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:10.863143 test begin: paddle.nn.functional.embedding(Tensor([64, 44],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 44],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:11.410407 test begin: paddle.nn.functional.embedding(Tensor([64, 45],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 45],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:12.013977 test begin: paddle.nn.functional.embedding(Tensor([64, 46],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 46],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:12.615466 test begin: paddle.nn.functional.embedding(Tensor([64, 47],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 47],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:13.602850 test begin: paddle.nn.functional.embedding(Tensor([64, 47],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([64, 47],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 509 / 1540096 (0.033%)
Max absolute difference: 0.99990255
Max relative difference: 1.
 x: array([[[0.339137, 0.76875 , 0.364924, ..., 0.670108, 0.425385,
         0.706654],
        [0.537689, 0.607272, 0.177667, ..., 0.387013, 0.981331,...
 y: array([[[0.339137, 0.76875 , 0.364924, ..., 0.670108, 0.425385,
         0.706654],
        [0.537689, 0.607272, 0.177667, ..., 0.387013, 0.981331,...
2025-05-12 09:04:14.195947 test begin: paddle.nn.functional.embedding(Tensor([64, 48],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([64, 48],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 509 / 1572864 (0.0324%)
Max absolute difference: 0.9999444
Max relative difference: 1.
 x: array([[[3.979314e-01, 4.280641e-01, 2.115211e-01, ..., 4.875025e-01,
         9.939860e-01, 3.398617e-01],
        [6.496464e-02, 7.981876e-03, 2.525699e-01, ..., 5.390906e-02,...
 y: array([[[3.979314e-01, 4.280641e-01, 2.115211e-01, ..., 4.875025e-01,
         9.939860e-01, 3.398617e-01],
        [6.496464e-02, 7.981876e-03, 2.525699e-01, ..., 5.390906e-02,...
2025-05-12 09:04:14.781840 test begin: paddle.nn.functional.embedding(Tensor([64, 49],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 49],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:15.350849 test begin: paddle.nn.functional.embedding(Tensor([64, 50],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 50],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:15.918137 test begin: paddle.nn.functional.embedding(Tensor([64, 51],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 51],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:16.891976 test begin: paddle.nn.functional.embedding(Tensor([64, 51],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 51],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:17.494145 test begin: paddle.nn.functional.embedding(Tensor([64, 52],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 52],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:18.091732 test begin: paddle.nn.functional.embedding(Tensor([64, 53],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 53],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:18.678908 test begin: paddle.nn.functional.embedding(Tensor([64, 54],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 54],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:19.686797 test begin: paddle.nn.functional.embedding(Tensor([64, 54],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 54],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:20.283023 test begin: paddle.nn.functional.embedding(Tensor([64, 55],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 55],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:21.249884 test begin: paddle.nn.functional.embedding(Tensor([64, 55],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 55],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:21.831777 test begin: paddle.nn.functional.embedding(Tensor([64, 56],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 56],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:22.437456 test begin: paddle.nn.functional.embedding(Tensor([64, 57],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 57],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:23.438525 test begin: paddle.nn.functional.embedding(Tensor([64, 57],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 57],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:24.015345 test begin: paddle.nn.functional.embedding(Tensor([64, 58],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 58],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:24.588170 test begin: paddle.nn.functional.embedding(Tensor([64, 59],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 59],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:25.572405 test begin: paddle.nn.functional.embedding(Tensor([64, 59],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 59],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:26.185549 test begin: paddle.nn.functional.embedding(Tensor([64, 60],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 60],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:27.180202 test begin: paddle.nn.functional.embedding(Tensor([64, 60],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 60],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:27.766933 test begin: paddle.nn.functional.embedding(Tensor([64, 61],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 61],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:28.811696 test begin: paddle.nn.functional.embedding(Tensor([64, 61],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 61],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:29.439800 test begin: paddle.nn.functional.embedding(Tensor([64, 62],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 62],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:30.445800 test begin: paddle.nn.functional.embedding(Tensor([64, 62],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([64, 62],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 508 / 2031616 (0.025%)
Max absolute difference: 0.998738
Max relative difference: 1.
 x: array([[[0.070251, 0.400931, 0.187531, ..., 0.952123, 0.166342,
         0.34153 ],
        [0.014074, 0.133894, 0.444024, ..., 0.029252, 0.209778,...
 y: array([[[0.070251, 0.400931, 0.187531, ..., 0.952123, 0.166342,
         0.34153 ],
        [0.014074, 0.133894, 0.444024, ..., 0.029252, 0.209778,...
2025-05-12 09:04:31.104130 test begin: paddle.nn.functional.embedding(Tensor([64, 63],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 63],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:32.115544 test begin: paddle.nn.functional.embedding(Tensor([64, 63],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 63],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:32.727154 test begin: paddle.nn.functional.embedding(Tensor([64, 64],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 64],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:33.745173 test begin: paddle.nn.functional.embedding(Tensor([64, 64],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 64],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:34.385905 test begin: paddle.nn.functional.embedding(Tensor([64, 65],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([64, 65],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1016 / 4259840 (0.0239%)
Max absolute difference: 0.9981263
Max relative difference: 1.
 x: array([[[0.111895, 0.840948, 0.136936, ..., 0.643796, 0.908754,
         0.018237],
        [0.160982, 0.057327, 0.940482, ..., 0.11724 , 0.312517,...
 y: array([[[0.111895, 0.840948, 0.136936, ..., 0.643796, 0.908754,
         0.018237],
        [0.160982, 0.057327, 0.940482, ..., 0.11724 , 0.312517,...
2025-05-12 09:04:35.552015 test begin: paddle.nn.functional.embedding(Tensor([64, 66],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 66],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:36.613081 test begin: paddle.nn.functional.embedding(Tensor([64, 67],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 67],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:37.749054 test begin: paddle.nn.functional.embedding(Tensor([64, 68],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 68],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:38.819974 test begin: paddle.nn.functional.embedding(Tensor([64, 69],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 69],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:39.892530 test begin: paddle.nn.functional.embedding(Tensor([64, 70],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 70],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:40.993120 test begin: paddle.nn.functional.embedding(Tensor([64, 71],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([64, 71],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1015 / 4653056 (0.0218%)
Max absolute difference: 0.9976133
Max relative difference: 1.
 x: array([[[0.379821, 0.770877, 0.074684, ..., 0.134094, 0.295459,
         0.953361],
        [0.057778, 0.812686, 0.191199, ..., 0.902716, 0.97041 ,...
 y: array([[[0.379821, 0.770877, 0.074684, ..., 0.134094, 0.295459,
         0.953361],
        [0.057778, 0.812686, 0.191199, ..., 0.902716, 0.97041 ,...
2025-05-12 09:04:42.114488 test begin: paddle.nn.functional.embedding(Tensor([64, 72],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 72],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:43.218991 test begin: paddle.nn.functional.embedding(Tensor([64, 73],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 73],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:44.277934 test begin: paddle.nn.functional.embedding(Tensor([64, 74],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 74],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:45.400792 test begin: paddle.nn.functional.embedding(Tensor([64, 75],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 75],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:46.487199 test begin: paddle.nn.functional.embedding(Tensor([64, 76],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 76],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:47.768566 test begin: paddle.nn.functional.embedding(Tensor([64, 77],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 77],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:48.886392 test begin: paddle.nn.functional.embedding(Tensor([64, 78],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 78],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:49.989060 test begin: paddle.nn.functional.embedding(Tensor([64, 79],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([64, 79],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1013 / 5177344 (0.0196%)
Max absolute difference: 0.99991655
Max relative difference: 1.
 x: array([[[0.704555, 0.199175, 0.969149, ..., 0.499598, 0.987635,
         0.415076],
        [0.882927, 0.28438 , 0.896233, ..., 0.438432, 0.81554 ,...
 y: array([[[0.704555, 0.199175, 0.969149, ..., 0.499598, 0.987635,
         0.415076],
        [0.882927, 0.28438 , 0.896233, ..., 0.438432, 0.81554 ,...
2025-05-12 09:04:51.161297 test begin: paddle.nn.functional.embedding(Tensor([64, 80],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 80],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:52.254465 test begin: paddle.nn.functional.embedding(Tensor([64, 8],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([64, 8],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:52.838215 test begin: paddle.nn.functional.embedding(Tensor([640, 6],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([640, 6],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1018 / 3932160 (0.0259%)
Max absolute difference: 0.9995066
Max relative difference: 1.
 x: array([[[0.211422, 0.136834, 0.805355, ..., 0.709001, 0.888981,
         0.308985],
        [0.261978, 0.715478, 0.582919, ..., 0.010775, 0.0718  ,...
 y: array([[[0.211422, 0.136834, 0.805355, ..., 0.709001, 0.888981,
         0.308985],
        [0.261978, 0.715478, 0.582919, ..., 0.010775, 0.0718  ,...
2025-05-12 09:04:53.915064 test begin: paddle.nn.functional.embedding(Tensor([640, 7],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([640, 7],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:55.019846 test begin: paddle.nn.functional.embedding(Tensor([640, 8],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([640, 8],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:56.117112 test begin: paddle.nn.functional.embedding(Tensor([680, 6],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([680, 6],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:56.737294 test begin: paddle.nn.functional.embedding(Tensor([7, 165],"int64"), weight=Tensor([50000, 1024],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([7, 165],"int64"), weight=Tensor([50000, 1024],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:04:57.992014 test begin: paddle.nn.functional.embedding(Tensor([7, 186],"int64"), weight=Tensor([50000, 1024],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([7, 186],"int64"), weight=Tensor([50000, 1024],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2026 / 1333248 (0.152%)
Max absolute difference: 0.9970022
Max relative difference: 1.
 x: array([[[0.131673, 0.124568, 0.189498, ..., 0.638681, 0.9224  ,
         0.518806],
        [0.477125, 0.865104, 0.467214, ..., 0.605525, 0.534643,...
 y: array([[[0.131673, 0.124568, 0.189498, ..., 0.638681, 0.9224  ,
         0.518806],
        [0.477125, 0.865104, 0.467214, ..., 0.605525, 0.534643,...
2025-05-12 09:04:59.285785 test begin: paddle.nn.functional.embedding(Tensor([7, 206],"int64"), weight=Tensor([50000, 1024],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([7, 206],"int64"), weight=Tensor([50000, 1024],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:00.572583 test begin: paddle.nn.functional.embedding(Tensor([7, 209],"int64"), weight=Tensor([50000, 1024],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([7, 209],"int64"), weight=Tensor([50000, 1024],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:01.846785 test begin: paddle.nn.functional.embedding(Tensor([7, 220],"int64"), weight=Tensor([50000, 1024],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([7, 220],"int64"), weight=Tensor([50000, 1024],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:03.120439 test begin: paddle.nn.functional.embedding(Tensor([7, 286],"int64"), weight=Tensor([50000, 1024],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([7, 286],"int64"), weight=Tensor([50000, 1024],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:04.408726 test begin: paddle.nn.functional.embedding(Tensor([7, 435],"int64"), weight=Tensor([50000, 1024],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([7, 435],"int64"), weight=Tensor([50000, 1024],"float32"), padding_idx=1, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:05.734434 test begin: paddle.nn.functional.embedding(Tensor([72, 10],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 10],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:06.282763 test begin: paddle.nn.functional.embedding(Tensor([72, 15],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 15],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:06.850361 test begin: paddle.nn.functional.embedding(Tensor([72, 26],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 26],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:07.795101 test begin: paddle.nn.functional.embedding(Tensor([72, 26],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 26],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:08.345844 test begin: paddle.nn.functional.embedding(Tensor([72, 28],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 28],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:09.305910 test begin: paddle.nn.functional.embedding(Tensor([72, 33],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 33],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:10.299527 test begin: paddle.nn.functional.embedding(Tensor([72, 36],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 36],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:10.900675 test begin: paddle.nn.functional.embedding(Tensor([72, 37],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 37],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:11.489054 test begin: paddle.nn.functional.embedding(Tensor([72, 39],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([72, 39],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 505 / 1437696 (0.0351%)
Max absolute difference: 0.9991214
Max relative difference: 1.
 x: array([[[0.484554, 0.524771, 0.574352, ..., 0.917382, 0.784791,
         0.589001],
        [0.021792, 0.861097, 0.185751, ..., 0.438543, 0.91547 ,...
 y: array([[[0.484554, 0.524771, 0.574352, ..., 0.917382, 0.784791,
         0.589001],
        [0.021792, 0.861097, 0.185751, ..., 0.438543, 0.91547 ,...
2025-05-12 09:05:12.119932 test begin: paddle.nn.functional.embedding(Tensor([72, 40],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([72, 40],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 503 / 1474560 (0.0341%)
Max absolute difference: 0.9985523
Max relative difference: 1.
 x: array([[[0.575775, 0.423683, 0.503631, ..., 0.5878  , 0.827351,
         0.225258],
        [0.54781 , 0.554804, 0.696709, ..., 0.836437, 0.45208 ,...
 y: array([[[0.575775, 0.423683, 0.503631, ..., 0.5878  , 0.827351,
         0.225258],
        [0.54781 , 0.554804, 0.696709, ..., 0.836437, 0.45208 ,...
2025-05-12 09:05:12.726539 test begin: paddle.nn.functional.embedding(Tensor([72, 41],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 41],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:13.295833 test begin: paddle.nn.functional.embedding(Tensor([72, 42],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 42],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:13.866941 test begin: paddle.nn.functional.embedding(Tensor([72, 43],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 43],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:14.840513 test begin: paddle.nn.functional.embedding(Tensor([72, 43],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 43],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:15.553669 test begin: paddle.nn.functional.embedding(Tensor([72, 44],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 44],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:16.126543 test begin: paddle.nn.functional.embedding(Tensor([72, 45],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 45],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:16.740680 test begin: paddle.nn.functional.embedding(Tensor([72, 46],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 46],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:17.732494 test begin: paddle.nn.functional.embedding(Tensor([72, 46],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 46],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:18.353106 test begin: paddle.nn.functional.embedding(Tensor([72, 47],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 47],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:18.942793 test begin: paddle.nn.functional.embedding(Tensor([72, 48],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 48],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:19.957953 test begin: paddle.nn.functional.embedding(Tensor([72, 48],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 48],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:20.563577 test begin: paddle.nn.functional.embedding(Tensor([72, 49],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 49],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:21.571609 test begin: paddle.nn.functional.embedding(Tensor([72, 49],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 49],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:22.161394 test begin: paddle.nn.functional.embedding(Tensor([72, 50],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([72, 50],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2022 / 3686400 (0.0549%)
Max absolute difference: 0.99916774
Max relative difference: 1.
 x: array([[[0.095524, 0.793666, 0.588999, ..., 0.37692 , 0.745179,
         0.888449],
        [0.875998, 0.31643 , 0.424479, ..., 0.770717, 0.811319,...
 y: array([[[0.095524, 0.793666, 0.588999, ..., 0.37692 , 0.745179,
         0.888449],
        [0.875998, 0.31643 , 0.424479, ..., 0.770717, 0.811319,...
2025-05-12 09:05:23.195727 test begin: paddle.nn.functional.embedding(Tensor([72, 50],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 50],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:23.775075 test begin: paddle.nn.functional.embedding(Tensor([72, 51],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 51],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:24.793104 test begin: paddle.nn.functional.embedding(Tensor([72, 51],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 51],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:25.407415 test begin: paddle.nn.functional.embedding(Tensor([72, 52],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 52],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:26.426982 test begin: paddle.nn.functional.embedding(Tensor([72, 52],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([72, 52],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 509 / 1916928 (0.0266%)
Max absolute difference: 0.9969249
Max relative difference: 1.
 x: array([[[0.726198, 0.932873, 0.171866, ..., 0.279654, 0.912216,
         0.754775],
        [0.909822, 0.759029, 0.713076, ..., 0.781661, 0.375829,...
 y: array([[[0.726198, 0.932873, 0.171866, ..., 0.279654, 0.912216,
         0.754775],
        [0.909822, 0.759029, 0.713076, ..., 0.781661, 0.375829,...
2025-05-12 09:05:27.096722 test begin: paddle.nn.functional.embedding(Tensor([72, 53],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 53],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:28.121305 test begin: paddle.nn.functional.embedding(Tensor([72, 53],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([72, 53],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 507 / 1953792 (0.0259%)
Max absolute difference: 0.99997926
Max relative difference: 1.
 x: array([[[5.013481e-01, 1.398658e-01, 7.876198e-01, ..., 5.719339e-02,
         9.497964e-01, 1.515899e-01],
        [2.274801e-01, 2.297930e-01, 4.454932e-02, ..., 8.423737e-01,...
 y: array([[[5.013481e-01, 1.398658e-01, 7.876198e-01, ..., 5.719339e-02,
         9.497964e-01, 1.515899e-01],
        [2.274801e-01, 2.297930e-01, 4.454932e-02, ..., 8.423737e-01,...
2025-05-12 09:05:28.757010 test begin: paddle.nn.functional.embedding(Tensor([72, 54],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 54],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:29.735564 test begin: paddle.nn.functional.embedding(Tensor([72, 54],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 54],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:30.312685 test begin: paddle.nn.functional.embedding(Tensor([72, 55],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 55],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:31.305886 test begin: paddle.nn.functional.embedding(Tensor([72, 55],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 55],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:31.894046 test begin: paddle.nn.functional.embedding(Tensor([72, 56],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 56],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:32.937576 test begin: paddle.nn.functional.embedding(Tensor([72, 56],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 56],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:33.565055 test begin: paddle.nn.functional.embedding(Tensor([72, 57],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 57],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:34.635867 test begin: paddle.nn.functional.embedding(Tensor([72, 58],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 58],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:35.745778 test begin: paddle.nn.functional.embedding(Tensor([72, 59],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 59],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:36.852320 test begin: paddle.nn.functional.embedding(Tensor([72, 60],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 60],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:37.943373 test begin: paddle.nn.functional.embedding(Tensor([72, 61],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([72, 61],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1015 / 4497408 (0.0226%)
Max absolute difference: 0.999321
Max relative difference: 1.
 x: array([[[0.537812, 0.389983, 0.868355, ..., 0.525762, 0.207676,
         0.434552],
        [0.288136, 0.009858, 0.624518, ..., 0.459691, 0.978963,...
 y: array([[[0.537812, 0.389983, 0.868355, ..., 0.525762, 0.207676,
         0.434552],
        [0.288136, 0.009858, 0.624518, ..., 0.459691, 0.978963,...
2025-05-12 09:05:39.066783 test begin: paddle.nn.functional.embedding(Tensor([72, 62],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 62],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:40.145994 test begin: paddle.nn.functional.embedding(Tensor([72, 63],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 63],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:41.218931 test begin: paddle.nn.functional.embedding(Tensor([72, 64],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 64],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:42.282148 test begin: paddle.nn.functional.embedding(Tensor([72, 65],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 65],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:43.363178 test begin: paddle.nn.functional.embedding(Tensor([72, 66],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([72, 66],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1019 / 4866048 (0.0209%)
Max absolute difference: 0.99823487
Max relative difference: 1.
 x: array([[[0.676532, 0.106638, 0.040772, ..., 0.960263, 0.082711,
         0.315903],
        [0.88676 , 0.691278, 0.602023, ..., 0.312449, 0.674628,...
 y: array([[[0.676532, 0.106638, 0.040772, ..., 0.960263, 0.082711,
         0.315903],
        [0.88676 , 0.691278, 0.602023, ..., 0.312449, 0.674628,...
2025-05-12 09:05:44.499762 test begin: paddle.nn.functional.embedding(Tensor([72, 67],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 67],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:45.620928 test begin: paddle.nn.functional.embedding(Tensor([72, 68],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 68],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:46.777675 test begin: paddle.nn.functional.embedding(Tensor([72, 69],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([72, 69],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1014 / 5087232 (0.0199%)
Max absolute difference: 0.998294
Max relative difference: 1.
 x: array([[[0.817107, 0.131854, 0.398335, ..., 0.281309, 0.176428,
         0.407302],
        [0.833007, 0.594165, 0.985487, ..., 0.569769, 0.18076 ,...
 y: array([[[0.817107, 0.131854, 0.398335, ..., 0.281309, 0.176428,
         0.407302],
        [0.833007, 0.594165, 0.985487, ..., 0.569769, 0.18076 ,...
2025-05-12 09:05:47.937236 test begin: paddle.nn.functional.embedding(Tensor([72, 70],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 70],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:49.038989 test begin: paddle.nn.functional.embedding(Tensor([72, 71],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([72, 71],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:50.130125 test begin: paddle.nn.functional.embedding(Tensor([728, 7],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([728, 7],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1014 / 5218304 (0.0194%)
Max absolute difference: 0.99907416
Max relative difference: 1.
 x: array([[[0.693859, 0.559564, 0.877858, ..., 0.059788, 0.391952,
         0.331527],
        [0.267804, 0.229609, 0.586399, ..., 0.683671, 0.161279,...
 y: array([[[0.693859, 0.559564, 0.877858, ..., 0.059788, 0.391952,
         0.331527],
        [0.267804, 0.229609, 0.586399, ..., 0.683671, 0.161279,...
2025-05-12 09:05:51.306312 test begin: paddle.nn.functional.embedding(Tensor([8, 234],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([8, 234],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:52.252294 test begin: paddle.nn.functional.embedding(Tensor([8, 244],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([8, 244],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:53.220424 test begin: paddle.nn.functional.embedding(Tensor([8, 25],"int64"), weight=Tensor([6627, 512],"float32"), padding_idx=6626, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([8, 25],"int64"), weight=Tensor([6627, 512],"float32"), padding_idx=6626, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:53.443317 test begin: paddle.nn.functional.embedding(Tensor([80, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 14],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:54.373250 test begin: paddle.nn.functional.embedding(Tensor([80, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 18],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:54.932021 test begin: paddle.nn.functional.embedding(Tensor([80, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 19],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:55.888220 test begin: paddle.nn.functional.embedding(Tensor([80, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 20],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:56.453742 test begin: paddle.nn.functional.embedding(Tensor([80, 21],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 21],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:57.010917 test begin: paddle.nn.functional.embedding(Tensor([80, 22],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 22],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:57.532706 test begin: paddle.nn.functional.embedding(Tensor([80, 23],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 23],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:58.481033 test begin: paddle.nn.functional.embedding(Tensor([80, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 24],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:05:59.435682 test begin: paddle.nn.functional.embedding(Tensor([80, 25],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 25],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:00.020991 test begin: paddle.nn.functional.embedding(Tensor([80, 27],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 27],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:00.962551 test begin: paddle.nn.functional.embedding(Tensor([80, 28],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 28],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:01.512330 test begin: paddle.nn.functional.embedding(Tensor([80, 29],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 29],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:02.475134 test begin: paddle.nn.functional.embedding(Tensor([80, 30],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 30],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:03.173317 test begin: paddle.nn.functional.embedding(Tensor([80, 31],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 31],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:04.242093 test begin: paddle.nn.functional.embedding(Tensor([80, 31],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 31],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:04.838633 test begin: paddle.nn.functional.embedding(Tensor([80, 32],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 32],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:05.481126 test begin: paddle.nn.functional.embedding(Tensor([80, 33],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 33],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:06.471217 test begin: paddle.nn.functional.embedding(Tensor([80, 34],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 34],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:07.054512 test begin: paddle.nn.functional.embedding(Tensor([80, 35],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 35],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:07.623083 test begin: paddle.nn.functional.embedding(Tensor([80, 36],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 36],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:08.191259 test begin: paddle.nn.functional.embedding(Tensor([80, 37],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 37],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:08.760644 test begin: paddle.nn.functional.embedding(Tensor([80, 38],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 38],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:09.318169 test begin: paddle.nn.functional.embedding(Tensor([80, 39],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 39],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:09.932715 test begin: paddle.nn.functional.embedding(Tensor([80, 40],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 40],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:10.532373 test begin: paddle.nn.functional.embedding(Tensor([80, 41],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 41],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:11.126497 test begin: paddle.nn.functional.embedding(Tensor([80, 42],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 42],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:12.147158 test begin: paddle.nn.functional.embedding(Tensor([80, 42],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 42],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:12.787097 test begin: paddle.nn.functional.embedding(Tensor([80, 43],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 43],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:13.381995 test begin: paddle.nn.functional.embedding(Tensor([80, 44],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 44],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:13.954952 test begin: paddle.nn.functional.embedding(Tensor([80, 45],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 45],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:14.946484 test begin: paddle.nn.functional.embedding(Tensor([80, 45],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 45],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:15.520452 test begin: paddle.nn.functional.embedding(Tensor([80, 46],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 46],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:16.554385 test begin: paddle.nn.functional.embedding(Tensor([80, 46],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 46],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:17.208569 test begin: paddle.nn.functional.embedding(Tensor([80, 47],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 47],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:18.228802 test begin: paddle.nn.functional.embedding(Tensor([80, 47],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 47],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:18.840407 test begin: paddle.nn.functional.embedding(Tensor([80, 48],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 48],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:19.846694 test begin: paddle.nn.functional.embedding(Tensor([80, 48],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 48],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:20.466451 test begin: paddle.nn.functional.embedding(Tensor([80, 49],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 49],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:21.485662 test begin: paddle.nn.functional.embedding(Tensor([80, 49],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 49],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:22.095902 test begin: paddle.nn.functional.embedding(Tensor([80, 50],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 50],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:23.118792 test begin: paddle.nn.functional.embedding(Tensor([80, 50],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([80, 50],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 510 / 2048000 (0.0249%)
Max absolute difference: 0.999058
Max relative difference: 1.
 x: array([[[0.589531, 0.246483, 0.029958, ..., 0.967176, 0.266153,
         0.969761],
        [0.797239, 0.721996, 0.401061, ..., 0.896975, 0.433571,...
 y: array([[[0.589531, 0.246483, 0.029958, ..., 0.967176, 0.266153,
         0.969761],
        [0.797239, 0.721996, 0.401061, ..., 0.896975, 0.433571,...
2025-05-12 09:06:23.760001 test begin: paddle.nn.functional.embedding(Tensor([80, 51],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([80, 51],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1018 / 4177920 (0.0244%)
Max absolute difference: 0.99607885
Max relative difference: 1.
 x: array([[[4.781577e-02, 4.207853e-02, 3.590483e-01, ..., 6.659569e-01,
         4.306808e-01, 1.624978e-01],
        [9.585657e-01, 7.530223e-01, 3.034915e-01, ..., 7.714497e-01,...
 y: array([[[4.781577e-02, 4.207853e-02, 3.590483e-01, ..., 6.659569e-01,
         4.306808e-01, 1.624978e-01],
        [9.585657e-01, 7.530223e-01, 3.034915e-01, ..., 7.714497e-01,...
2025-05-12 09:06:24.841853 test begin: paddle.nn.functional.embedding(Tensor([80, 51],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 51],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:25.460383 test begin: paddle.nn.functional.embedding(Tensor([80, 52],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 52],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:26.517256 test begin: paddle.nn.functional.embedding(Tensor([80, 53],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 53],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:27.586821 test begin: paddle.nn.functional.embedding(Tensor([80, 54],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 54],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:28.672629 test begin: paddle.nn.functional.embedding(Tensor([80, 55],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 55],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:29.740098 test begin: paddle.nn.functional.embedding(Tensor([80, 56],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 56],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:30.829359 test begin: paddle.nn.functional.embedding(Tensor([80, 57],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 57],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:31.900365 test begin: paddle.nn.functional.embedding(Tensor([80, 58],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 58],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:33.004626 test begin: paddle.nn.functional.embedding(Tensor([80, 59],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 59],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:34.103146 test begin: paddle.nn.functional.embedding(Tensor([80, 60],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 60],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:35.195267 test begin: paddle.nn.functional.embedding(Tensor([80, 61],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([80, 61],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1015 / 4997120 (0.0203%)
Max absolute difference: 0.9993122
Max relative difference: 1.
 x: array([[[0.283639, 0.186904, 0.52338 , ..., 0.342101, 0.368303,
         0.206721],
        [0.932774, 0.350595, 0.126158, ..., 0.779502, 0.695026,...
 y: array([[[0.283639, 0.186904, 0.52338 , ..., 0.342101, 0.368303,
         0.206721],
        [0.932774, 0.350595, 0.126158, ..., 0.779502, 0.695026,...
2025-05-12 09:06:36.344944 test begin: paddle.nn.functional.embedding(Tensor([80, 62],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 62],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:37.581957 test begin: paddle.nn.functional.embedding(Tensor([80, 63],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 63],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:38.699985 test begin: paddle.nn.functional.embedding(Tensor([80, 64],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([80, 64],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:39.960781 test begin: paddle.nn.functional.embedding(Tensor([848, 6],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([848, 6],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:41.196634 test begin: paddle.nn.functional.embedding(Tensor([88, 12],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 12],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:41.764731 test begin: paddle.nn.functional.embedding(Tensor([88, 14],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 14],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:42.355574 test begin: paddle.nn.functional.embedding(Tensor([88, 15],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 15],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:43.289865 test begin: paddle.nn.functional.embedding(Tensor([88, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:43.862146 test begin: paddle.nn.functional.embedding(Tensor([88, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 17],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:44.426703 test begin: paddle.nn.functional.embedding(Tensor([88, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 20],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:45.358783 test begin: paddle.nn.functional.embedding(Tensor([88, 27],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 27],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:45.930669 test begin: paddle.nn.functional.embedding(Tensor([88, 29],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 29],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:46.500805 test begin: paddle.nn.functional.embedding(Tensor([88, 31],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 31],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:47.157307 test begin: paddle.nn.functional.embedding(Tensor([88, 32],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 32],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:47.752221 test begin: paddle.nn.functional.embedding(Tensor([88, 33],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 33],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:48.333121 test begin: paddle.nn.functional.embedding(Tensor([88, 34],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 34],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:49.333186 test begin: paddle.nn.functional.embedding(Tensor([88, 34],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 34],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:49.933088 test begin: paddle.nn.functional.embedding(Tensor([88, 35],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 35],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:50.532683 test begin: paddle.nn.functional.embedding(Tensor([88, 36],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 36],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:51.542131 test begin: paddle.nn.functional.embedding(Tensor([88, 36],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 36],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:52.143329 test begin: paddle.nn.functional.embedding(Tensor([88, 37],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 37],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:53.120306 test begin: paddle.nn.functional.embedding(Tensor([88, 37],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 37],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:53.692017 test begin: paddle.nn.functional.embedding(Tensor([88, 38],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 38],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:54.443323 test begin: paddle.nn.functional.embedding(Tensor([88, 39],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 39],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:55.451032 test begin: paddle.nn.functional.embedding(Tensor([88, 39],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 39],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:56.053122 test begin: paddle.nn.functional.embedding(Tensor([88, 40],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 40],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:57.062424 test begin: paddle.nn.functional.embedding(Tensor([88, 40],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 40],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:57.664857 test begin: paddle.nn.functional.embedding(Tensor([88, 41],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([88, 41],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1014 / 3694592 (0.0274%)
Max absolute difference: 0.9990623
Max relative difference: 1.
 x: array([[[0.706503, 0.617208, 0.854088, ..., 0.002439, 0.311135,
         0.391895],
        [0.363502, 0.291938, 0.182097, ..., 0.191022, 0.82026 ,...
 y: array([[[0.706503, 0.617208, 0.854088, ..., 0.002439, 0.311135,
         0.391895],
        [0.363502, 0.291938, 0.182097, ..., 0.191022, 0.82026 ,...
2025-05-12 09:06:58.732623 test begin: paddle.nn.functional.embedding(Tensor([88, 41],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 41],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:06:59.329926 test begin: paddle.nn.functional.embedding(Tensor([88, 42],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 42],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:00.343426 test begin: paddle.nn.functional.embedding(Tensor([88, 42],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 42],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:00.942158 test begin: paddle.nn.functional.embedding(Tensor([88, 43],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 43],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:01.964012 test begin: paddle.nn.functional.embedding(Tensor([88, 43],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 43],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:02.566714 test begin: paddle.nn.functional.embedding(Tensor([88, 44],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 44],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:03.563649 test begin: paddle.nn.functional.embedding(Tensor([88, 44],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 44],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:04.178921 test begin: paddle.nn.functional.embedding(Tensor([88, 45],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 45],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:05.192790 test begin: paddle.nn.functional.embedding(Tensor([88, 45],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([88, 45],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 508 / 2027520 (0.0251%)
Max absolute difference: 0.999755
Max relative difference: 1.
 x: array([[[0.779351, 0.142121, 0.063701, ..., 0.385444, 0.853593,
         0.071112],
        [0.616442, 0.367344, 0.432437, ..., 0.865988, 0.063903,...
 y: array([[[0.779351, 0.142121, 0.063701, ..., 0.385444, 0.853593,
         0.071112],
        [0.616442, 0.367344, 0.432437, ..., 0.865988, 0.063903,...
2025-05-12 09:07:05.802779 test begin: paddle.nn.functional.embedding(Tensor([88, 46],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 46],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:06.806740 test begin: paddle.nn.functional.embedding(Tensor([88, 46],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 46],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:07.443972 test begin: paddle.nn.functional.embedding(Tensor([88, 47],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 47],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:08.477730 test begin: paddle.nn.functional.embedding(Tensor([88, 48],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 48],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:09.555304 test begin: paddle.nn.functional.embedding(Tensor([88, 49],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 49],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:10.633002 test begin: paddle.nn.functional.embedding(Tensor([88, 50],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 50],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:11.697160 test begin: paddle.nn.functional.embedding(Tensor([88, 51],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 51],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:12.789855 test begin: paddle.nn.functional.embedding(Tensor([88, 52],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 52],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:13.857422 test begin: paddle.nn.functional.embedding(Tensor([88, 53],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 53],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:14.915804 test begin: paddle.nn.functional.embedding(Tensor([88, 54],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([88, 54],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1018 / 4866048 (0.0209%)
Max absolute difference: 0.9990483
Max relative difference: 1.
 x: array([[[0.684402, 0.380295, 0.149353, ..., 0.742397, 0.384815,
         0.990426],
        [0.889755, 0.445797, 0.03246 , ..., 0.66265 , 0.526247,...
 y: array([[[0.684402, 0.380295, 0.149353, ..., 0.742397, 0.384815,
         0.990426],
        [0.889755, 0.445797, 0.03246 , ..., 0.66265 , 0.526247,...
2025-05-12 09:07:16.062720 test begin: paddle.nn.functional.embedding(Tensor([88, 55],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 55],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:17.166926 test begin: paddle.nn.functional.embedding(Tensor([88, 56],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 56],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:18.273926 test begin: paddle.nn.functional.embedding(Tensor([88, 57],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 57],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:19.384652 test begin: paddle.nn.functional.embedding(Tensor([88, 58],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 58],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:20.490271 test begin: paddle.nn.functional.embedding(Tensor([88, 8],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([88, 8],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:21.438690 test begin: paddle.nn.functional.embedding(Tensor([96, 10],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 10],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:22.394251 test begin: paddle.nn.functional.embedding(Tensor([96, 11],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 11],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:22.969820 test begin: paddle.nn.functional.embedding(Tensor([96, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 16],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:23.545635 test begin: paddle.nn.functional.embedding(Tensor([96, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 18],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:24.486822 test begin: paddle.nn.functional.embedding(Tensor([96, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 19],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:25.037543 test begin: paddle.nn.functional.embedding(Tensor([96, 22],"int64"), weight=Tensor([6629, 384],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 22],"int64"), weight=Tensor([6629, 384],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:25.293909 test begin: paddle.nn.functional.embedding(Tensor([96, 27],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 27],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:26.264448 test begin: paddle.nn.functional.embedding(Tensor([96, 28],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 28],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:26.854399 test begin: paddle.nn.functional.embedding(Tensor([96, 29],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 29],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:27.459427 test begin: paddle.nn.functional.embedding(Tensor([96, 30],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 30],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:28.053311 test begin: paddle.nn.functional.embedding(Tensor([96, 31],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 31],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:29.040424 test begin: paddle.nn.functional.embedding(Tensor([96, 31],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 31],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:29.634222 test begin: paddle.nn.functional.embedding(Tensor([96, 32],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 32],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:30.230442 test begin: paddle.nn.functional.embedding(Tensor([96, 33],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 33],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:30.851839 test begin: paddle.nn.functional.embedding(Tensor([96, 34],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 34],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:31.424309 test begin: paddle.nn.functional.embedding(Tensor([96, 35],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 35],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:32.437674 test begin: paddle.nn.functional.embedding(Tensor([96, 35],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 35],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:33.043649 test begin: paddle.nn.functional.embedding(Tensor([96, 36],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 36],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:33.636750 test begin: paddle.nn.functional.embedding(Tensor([96, 37],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 37],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:34.647729 test begin: paddle.nn.functional.embedding(Tensor([96, 37],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 37],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:35.241100 test begin: paddle.nn.functional.embedding(Tensor([96, 38],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 38],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:36.261080 test begin: paddle.nn.functional.embedding(Tensor([96, 38],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 38],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:36.866730 test begin: paddle.nn.functional.embedding(Tensor([96, 39],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 39],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:37.893216 test begin: paddle.nn.functional.embedding(Tensor([96, 39],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([96, 39],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 507 / 1916928 (0.0264%)
Max absolute difference: 0.99923944
Max relative difference: 1.
 x: array([[[0.689024, 0.692437, 0.943486, ..., 0.922136, 0.205863,
         0.727146],
        [0.92868 , 0.76906 , 0.285615, ..., 0.94214 , 0.715856,...
 y: array([[[0.689024, 0.692437, 0.943486, ..., 0.922136, 0.205863,
         0.727146],
        [0.92868 , 0.76906 , 0.285615, ..., 0.94214 , 0.715856,...
2025-05-12 09:07:38.529899 test begin: paddle.nn.functional.embedding(Tensor([96, 40],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 40],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:39.536523 test begin: paddle.nn.functional.embedding(Tensor([96, 40],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 40],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:40.121918 test begin: paddle.nn.functional.embedding(Tensor([96, 41],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 41],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:41.146040 test begin: paddle.nn.functional.embedding(Tensor([96, 41],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([96, 41],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 508 / 2015232 (0.0252%)
Max absolute difference: 0.99612594
Max relative difference: 1.
 x: array([[[0.75806 , 0.311308, 0.073474, ..., 0.178977, 0.66454 ,
         0.922499],
        [0.924976, 0.655953, 0.055174, ..., 0.967363, 0.941432,...
 y: array([[[0.75806 , 0.311308, 0.073474, ..., 0.178977, 0.66454 ,
         0.922499],
        [0.924976, 0.655953, 0.055174, ..., 0.967363, 0.941432,...
2025-05-12 09:07:41.787978 test begin: paddle.nn.functional.embedding(Tensor([96, 42],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 42],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:42.804224 test begin: paddle.nn.functional.embedding(Tensor([96, 42],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 42],"int64"), weight=Tensor([33712, 512],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:43.424528 test begin: paddle.nn.functional.embedding(Tensor([96, 43],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.embedding(Tensor([96, 43],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1010 / 4227072 (0.0239%)
Max absolute difference: 0.9992238
Max relative difference: 1.
 x: array([[[0.437676, 0.344062, 0.264841, ..., 0.283169, 0.763823,
         0.116133],
        [0.419559, 0.926679, 0.399328, ..., 0.305236, 0.658304,...
 y: array([[[0.437676, 0.344062, 0.264841, ..., 0.283169, 0.763823,
         0.116133],
        [0.419559, 0.926679, 0.399328, ..., 0.305236, 0.658304,...
2025-05-12 09:07:44.502643 test begin: paddle.nn.functional.embedding(Tensor([96, 44],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 44],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:45.581756 test begin: paddle.nn.functional.embedding(Tensor([96, 45],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 45],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:46.674439 test begin: paddle.nn.functional.embedding(Tensor([96, 46],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 46],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:47.739974 test begin: paddle.nn.functional.embedding(Tensor([96, 46],"int64"), weight=Tensor([50006, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 46],"int64"), weight=Tensor([50006, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:49.156060 test begin: paddle.nn.functional.embedding(Tensor([96, 47],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 47],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:50.226273 test begin: paddle.nn.functional.embedding(Tensor([96, 48],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 48],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:51.295486 test begin: paddle.nn.functional.embedding(Tensor([96, 49],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 49],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:52.454923 test begin: paddle.nn.functional.embedding(Tensor([96, 50],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 50],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:53.549451 test begin: paddle.nn.functional.embedding(Tensor([96, 51],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 51],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:54.650965 test begin: paddle.nn.functional.embedding(Tensor([96, 52],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 52],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:55.754882 test begin: paddle.nn.functional.embedding(Tensor([96, 53],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 53],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:56.920246 test begin: paddle.nn.functional.embedding(Tensor([96, 9],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([96, 9],"int64"), weight=Tensor([33712, 1024],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
2025-05-12 09:07:57.854479 test begin: paddle.nn.functional.embedding(Tensor([],"int64"), weight=Tensor([39980, 8],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
One of the differentiated Tensors does not require grad
[Pass] paddle.nn.functional.embedding(Tensor([],"int64"), weight=Tensor([39980, 8],"float32"), padding_idx=0, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
