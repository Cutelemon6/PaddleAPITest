paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([1, 8, 64, 16],"float32"), Tensor([1, 2, 64, 16],"float32"), Tensor([1, 2, 64, 16],"float32"), Tensor([1],"int32"), Tensor([1],"int32"), Tensor([1, 1, 64, 64],"float32"), 0.25, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 35, 64],"float16"), Tensor([2, 1, 35, 64],"float16"), Tensor([2, 1, 35, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 36, 64],"float16"), Tensor([2, 1, 36, 64],"float16"), Tensor([2, 1, 36, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 37, 64],"float16"), Tensor([2, 1, 37, 64],"float16"), Tensor([2, 1, 37, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 38, 64],"float16"), Tensor([2, 1, 38, 64],"float16"), Tensor([2, 1, 38, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 39, 64],"float16"), Tensor([2, 1, 39, 64],"float16"), Tensor([2, 1, 39, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 45, 64],"float16"), Tensor([2, 1, 45, 64],"float16"), Tensor([2, 1, 45, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 47, 64],"float16"), Tensor([2, 1, 47, 64],"float16"), Tensor([2, 1, 47, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 50, 64],"float16"), Tensor([2, 1, 50, 64],"float16"), Tensor([2, 1, 50, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 51, 64],"float16"), Tensor([2, 1, 51, 64],"float16"), Tensor([2, 1, 51, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 52, 64],"float16"), Tensor([2, 1, 52, 64],"float16"), Tensor([2, 1, 52, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 57, 64],"float16"), Tensor([2, 1, 57, 64],"float16"), Tensor([2, 1, 57, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 59, 64],"float16"), Tensor([2, 1, 59, 64],"float16"), Tensor([2, 1, 59, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 38, 128],"float16"), Tensor([2, 2, 38, 128],"float16"), Tensor([2, 2, 38, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 39, 128],"float16"), Tensor([2, 2, 39, 128],"float16"), Tensor([2, 2, 39, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 40, 128],"float16"), Tensor([2, 2, 40, 128],"float16"), Tensor([2, 2, 40, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 41, 128],"float16"), Tensor([2, 2, 41, 128],"float16"), Tensor([2, 2, 41, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 47, 128],"float16"), Tensor([2, 2, 47, 128],"float16"), Tensor([2, 2, 47, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 51, 128],"float16"), Tensor([2, 2, 51, 128],"float16"), Tensor([2, 2, 51, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 53, 128],"float16"), Tensor([2, 2, 53, 128],"float16"), Tensor([2, 2, 53, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 54, 128],"float16"), Tensor([2, 2, 54, 128],"float16"), Tensor([2, 2, 54, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 57, 128],"float16"), Tensor([2, 2, 57, 128],"float16"), Tensor([2, 2, 57, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 107, 96],"float16"), Tensor([2, 8, 107, 96],"float16"), Tensor([2, 8, 107, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 107, 96],"float16"), Tensor([2, 8, 235, 96],"float16"), Tensor([2, 8, 235, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 109, 96],"float16"), Tensor([2, 8, 109, 96],"float16"), Tensor([2, 8, 109, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 109, 96],"float16"), Tensor([2, 8, 237, 96],"float16"), Tensor([2, 8, 237, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 110, 96],"float16"), Tensor([2, 8, 110, 96],"float16"), Tensor([2, 8, 110, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 110, 96],"float16"), Tensor([2, 8, 238, 96],"float16"), Tensor([2, 8, 238, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 111, 96],"float16"), Tensor([2, 8, 111, 96],"float16"), Tensor([2, 8, 111, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 111, 96],"float16"), Tensor([2, 8, 239, 96],"float16"), Tensor([2, 8, 239, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 112, 96],"float16"), Tensor([2, 8, 112, 96],"float16"), Tensor([2, 8, 112, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 112, 96],"float16"), Tensor([2, 8, 240, 96],"float16"), Tensor([2, 8, 240, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 74, 96],"float16"), Tensor([2, 8, 202, 96],"float16"), Tensor([2, 8, 202, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 74, 96],"float16"), Tensor([2, 8, 74, 96],"float16"), Tensor([2, 8, 74, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 79, 96],"float16"), Tensor([2, 8, 207, 96],"float16"), Tensor([2, 8, 207, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 79, 96],"float16"), Tensor([2, 8, 79, 96],"float16"), Tensor([2, 8, 79, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 80, 96],"float16"), Tensor([2, 8, 208, 96],"float16"), Tensor([2, 8, 208, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 80, 96],"float16"), Tensor([2, 8, 80, 96],"float16"), Tensor([2, 8, 80, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 82, 96],"float16"), Tensor([2, 8, 210, 96],"float16"), Tensor([2, 8, 210, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 82, 96],"float16"), Tensor([2, 8, 82, 96],"float16"), Tensor([2, 8, 82, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 91, 96],"float16"), Tensor([2, 8, 219, 96],"float16"), Tensor([2, 8, 219, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 91, 96],"float16"), Tensor([2, 8, 91, 96],"float16"), Tensor([2, 8, 91, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([3, 16, 64, 32],"float16"), Tensor([3, 2, 64, 32],"float16"), Tensor([3, 2, 64, 32],"float16"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([3, 1, 64, 64],"float16"), 0.17677669529663687, )

2025-05-14 12:07:47.821275 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([1, 8, 64, 16],"float32"), Tensor([1, 2, 64, 16],"float32"), Tensor([1, 2, 64, 16],"float32"), Tensor([1],"int32"), Tensor([1],"int32"), Tensor([1, 1, 64, 64],"float32"), 0.25, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([1, 8, 64, 16],"float32"), Tensor([1, 2, 64, 16],"float32"), Tensor([1, 2, 64, 16],"float32"), Tensor([1],"int32"), Tensor([1],"int32"), Tensor([1, 1, 64, 64],"float32"), 0.25, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],...
 DESIRED: array([[[[ 0.338653, -0.18054 , -0.257099, ..., -0.141157, -0.211918,
           0.390092],
         [ 0.159117,  0.00303 , -0.085863, ..., -0.28183 , -0.419381,...
2025-05-14 12:07:47.941086 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 232, 64],"float16"), Tensor([2, 1, 232, 64],"float16"), Tensor([2, 1, 232, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
[Pass] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 232, 64],"float16"), Tensor([2, 1, 232, 64],"float16"), Tensor([2, 1, 232, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
2025-05-14 12:07:48.656905 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 35, 64],"float16"), Tensor([2, 1, 35, 64],"float16"), Tensor([2, 1, 35, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 35, 64],"float16"), Tensor([2, 1, 35, 64],"float16"), Tensor([2, 1, 35, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1570 / 4480 (35%)
Max absolute difference among violations: 0.4998
Max relative difference among violations: inf
 ACTUAL: array([[[[-0.3306 , -0.05765,  0.4265 , ...,  0.2424 , -0.04257,
           0.09863],
         [-0.2688 ,  0.367  , -0.4539 , ...,  0.4521 , -0.10333,...
 DESIRED: array([[[[-0.3306 , -0.05765,  0.4265 , ...,  0.2424 , -0.04257,
           0.09863],
         [-0.2688 ,  0.367  , -0.4539 , ...,  0.4521 , -0.10333,...
2025-05-14 12:07:49.365928 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 36, 64],"float16"), Tensor([2, 1, 36, 64],"float16"), Tensor([2, 1, 36, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 36, 64],"float16"), Tensor([2, 1, 36, 64],"float16"), Tensor([2, 1, 36, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2275 / 4608 (49.4%)
Max absolute difference among violations: 0.4988
Max relative difference among violations: inf
 ACTUAL: array([[[[ 0.04175,  0.4883 ,  0.2158 , ..., -0.2096 , -0.297  ,
           0.2173 ],
         [ 0.04175,  0.4883 ,  0.2158 , ..., -0.2096 , -0.297  ,...
 DESIRED: array([[[[ 0.04175,  0.4883 ,  0.2158 , ..., -0.2096 , -0.297  ,
           0.2173 ],
         [ 0.04175,  0.4883 ,  0.2158 , ..., -0.2096 , -0.297  ,...
2025-05-14 12:07:50.077581 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 37, 64],"float16"), Tensor([2, 1, 37, 64],"float16"), Tensor([2, 1, 37, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 37, 64],"float16"), Tensor([2, 1, 37, 64],"float16"), Tensor([2, 1, 37, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2332 / 4736 (49.2%)
Max absolute difference among violations: 0.4998
Max relative difference among violations: inf
 ACTUAL: array([[[[ 0.1482  , -0.009926,  0.1525  , ..., -0.094   ,  0.3096  ,
          -0.07965 ],
         [-0.03152 ,  0.2489  , -0.1761  , ...,  0.144   , -0.431   ,...
 DESIRED: array([[[[ 0.1482  , -0.009926,  0.1525  , ..., -0.094   ,  0.3096  ,
          -0.07965 ],
         [-0.03119 ,  0.2493  , -0.1758  , ...,  0.1442  , -0.4321  ,...
2025-05-14 12:07:50.762036 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 38, 64],"float16"), Tensor([2, 1, 38, 64],"float16"), Tensor([2, 1, 38, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 38, 64],"float16"), Tensor([2, 1, 38, 64],"float16"), Tensor([2, 1, 38, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2265 / 4864 (46.6%)
Max absolute difference among violations: 0.4998
Max relative difference among violations: inf
 ACTUAL: array([[[[-0.3413  ,  0.04077 , -0.126   , ...,  0.1466  , -0.3826  ,
           0.3489  ],
         [-0.341   ,  0.04074 , -0.126   , ...,  0.1466  , -0.3823  ,...
 DESIRED: array([[[[-0.3413 ,  0.04077, -0.126  , ...,  0.1466 , -0.3826 ,
           0.3489 ],
         [-0.3413 ,  0.04077, -0.126  , ...,  0.1466 , -0.3826 ,...
2025-05-14 12:07:51.473031 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 39, 64],"float16"), Tensor([2, 1, 39, 64],"float16"), Tensor([2, 1, 39, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 39, 64],"float16"), Tensor([2, 1, 39, 64],"float16"), Tensor([2, 1, 39, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1180 / 4992 (23.6%)
Max absolute difference among violations: 0.4988
Max relative difference among violations: inf
 ACTUAL: array([[[[ 0.367  ,  0.4456 , -0.1371 , ..., -0.2343 ,  0.3855 ,
           0.3264 ],
         [-0.07196,  0.4172 , -0.2537 , ..., -0.3306 , -0.1577 ,...
 DESIRED: array([[[[ 0.367  ,  0.4456 , -0.1371 , ..., -0.2343 ,  0.3855 ,
           0.3264 ],
         [-0.07196,  0.4172 , -0.2537 , ..., -0.3306 , -0.1577 ,...
2025-05-14 12:07:52.187167 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 45, 64],"float16"), Tensor([2, 1, 45, 64],"float16"), Tensor([2, 1, 45, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 45, 64],"float16"), Tensor([2, 1, 45, 64],"float16"), Tensor([2, 1, 45, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4431 / 5760 (76.9%)
Max absolute difference among violations: 0.5
Max relative difference among violations: inf
 ACTUAL: array([[[[-3.364e-01,  2.515e-01, -4.949e-01, ...,  4.285e-01,
           2.285e-01,  2.107e-01],
         [-3.364e-01,  2.515e-01, -4.949e-01, ...,  4.285e-01,...
 DESIRED: array([[[[-0.3364 ,  0.2515 , -0.4949 , ...,  0.4285 ,  0.2285 ,
           0.2107 ],
         [-0.3364 ,  0.2515 , -0.4949 , ...,  0.4285 ,  0.2285 ,...
2025-05-14 12:07:52.874678 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 47, 64],"float16"), Tensor([2, 1, 47, 64],"float16"), Tensor([2, 1, 47, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 47, 64],"float16"), Tensor([2, 1, 47, 64],"float16"), Tensor([2, 1, 47, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1551 / 6016 (25.8%)
Max absolute difference among violations: 0.5
Max relative difference among violations: inf
 ACTUAL: array([[[[ 2.2217e-01,  2.8027e-01,  1.2231e-01, ...,  3.8208e-02,
           3.6194e-02,  4.7949e-01],
         [ 4.8608e-01, -4.4629e-01,  2.2192e-01, ...,  1.7236e-01,...
 DESIRED: array([[[[ 2.2217e-01,  2.8027e-01,  1.2231e-01, ...,  3.8208e-02,
           3.6194e-02,  4.7949e-01],
         [ 4.8608e-01, -4.4629e-01,  2.2192e-01, ...,  1.7236e-01,...
2025-05-14 12:07:53.574955 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 50, 64],"float16"), Tensor([2, 1, 50, 64],"float16"), Tensor([2, 1, 50, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 50, 64],"float16"), Tensor([2, 1, 50, 64],"float16"), Tensor([2, 1, 50, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4943 / 6400 (77.2%)
Max absolute difference among violations: 0.4998
Max relative difference among violations: inf
 ACTUAL: array([[[[ 3.7256e-01,  4.7632e-01,  3.6938e-01, ...,  5.0934e-02,
          -4.8193e-01, -3.8550e-01],
         [-2.4304e-01, -5.2094e-02, -2.4524e-01, ..., -5.1910e-02,...
 DESIRED: array([[[[ 0.3726 ,  0.4763 ,  0.3694 , ...,  0.05093, -0.482  ,
          -0.3855 ],
         [-0.243  , -0.0521 , -0.2452 , ..., -0.0519 , -0.2097 ,...
2025-05-14 12:07:54.310672 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 51, 64],"float16"), Tensor([2, 1, 51, 64],"float16"), Tensor([2, 1, 51, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 51, 64],"float16"), Tensor([2, 1, 51, 64],"float16"), Tensor([2, 1, 51, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 3495 / 6528 (53.5%)
Max absolute difference among violations: 0.4998
Max relative difference among violations: inf
 ACTUAL: array([[[[ 0.2725 ,  0.01328, -0.2566 , ..., -0.4717 , -0.4302 ,
           0.3528 ],
         [-0.107  ,  0.01813,  0.0985 , ...,  0.138  ,  0.1055 ,...
 DESIRED: array([[[[ 0.2725 ,  0.01328, -0.2566 , ..., -0.4717 , -0.4302 ,
           0.3528 ],
         [-0.107  ,  0.01813,  0.0985 , ...,  0.138  ,  0.1055 ,...
2025-05-14 12:07:55.012866 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 52, 64],"float16"), Tensor([2, 1, 52, 64],"float16"), Tensor([2, 1, 52, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 52, 64],"float16"), Tensor([2, 1, 52, 64],"float16"), Tensor([2, 1, 52, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4433 / 6656 (66.6%)
Max absolute difference among violations: 0.4998
Max relative difference among violations: inf
 ACTUAL: array([[[[-0.0044  ,  0.4216  , -0.2744  , ...,  0.1344  ,  0.499   ,
           0.005543],
         [ 0.0711  ,  0.4211  , -0.03513 , ..., -0.3894  ,  0.3904  ,...
 DESIRED: array([[[[-0.0044  ,  0.4216  , -0.2744  , ...,  0.1344  ,  0.499   ,
           0.005543],
         [ 0.0711  ,  0.4211  , -0.03513 , ..., -0.3894  ,  0.3904  ,...
2025-05-14 12:07:55.678937 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 57, 64],"float16"), Tensor([2, 1, 57, 64],"float16"), Tensor([2, 1, 57, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 57, 64],"float16"), Tensor([2, 1, 57, 64],"float16"), Tensor([2, 1, 57, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 588 / 7296 (8.06%)
Max absolute difference among violations: 0.5
Max relative difference among violations: 0.545
 ACTUAL: array([[[[ 0.00926 , -0.3357  , -0.1748  , ...,  0.3027  , -0.3306  ,
          -0.3506  ],
         [-0.07306 , -0.4746  ,  0.4214  , ...,  0.15    ,  0.05167 ,...
 DESIRED: array([[[[ 0.00926, -0.3357 , -0.1748 , ...,  0.3027 , -0.3306 ,
          -0.3506 ],
         [-0.07306, -0.4746 ,  0.4214 , ...,  0.15   ,  0.05167,...
2025-05-14 12:07:56.383840 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 59, 64],"float16"), Tensor([2, 1, 59, 64],"float16"), Tensor([2, 1, 59, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 59, 64],"float16"), Tensor([2, 1, 59, 64],"float16"), Tensor([2, 1, 59, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

nan location mismatch:
 ACTUAL: array([[[[ 1.4148e-01,  3.8867e-01,  1.2366e-01, ..., -4.9097e-01,
           2.9004e-01,  2.2827e-01],
         [-3.9453e-01, -3.9038e-01,  1.9592e-01, ...,  3.7524e-01,...
 DESIRED: array([[[[ 0.1415  ,  0.3887  ,  0.12366 , ..., -0.491   ,  0.29    ,
           0.2283  ],
         [-0.3945  , -0.3904  ,  0.1959  , ...,  0.3752  , -0.354   ,...
2025-05-14 12:07:57.143140 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 38, 128],"float16"), Tensor([2, 2, 38, 128],"float16"), Tensor([2, 2, 38, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 38, 128],"float16"), Tensor([2, 2, 38, 128],"float16"), Tensor([2, 2, 38, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 27167 / 38912 (69.8%)
Max absolute difference among violations: 32752.
Max relative difference among violations: 3064.
 ACTUAL: array([[[[ 3.5327e-01,  3.0591e-01, -5.5573e-02, ...,  5.2704e-02,
          -1.9800e-01,  1.4355e-01],
         [-4.1919e-01, -1.6565e-01, -3.0688e-01, ..., -2.4512e-01,...
 DESIRED: array([[[[ 0.3533  ,  0.306   , -0.05557 , ...,  0.0527  , -0.198   ,
           0.1436  ],
         [-0.4192  , -0.1656  , -0.307   , ..., -0.2451  ,  0.4714  ,...
2025-05-14 12:08:49.709875 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 39, 128],"float16"), Tensor([2, 2, 39, 128],"float16"), Tensor([2, 2, 39, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 39, 128],"float16"), Tensor([2, 2, 39, 128],"float16"), Tensor([2, 2, 39, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 23697 / 39936 (59.3%)
Max absolute difference among violations: 32736.
Max relative difference among violations: inf
 ACTUAL: array([[[[-4.5142e-01,  4.3408e-01, -1.1157e-01, ..., -9.8694e-02,
          -1.5527e-01,  1.6693e-02],
         [-4.5142e-01,  4.3408e-01, -1.1157e-01, ..., -9.8694e-02,...
 DESIRED: array([[[[-0.4514  ,  0.434   , -0.1116  , ..., -0.0987  , -0.1553  ,
           0.0167  ],
         [-0.4514  ,  0.434   , -0.1116  , ..., -0.0987  , -0.1553  ,...
2025-05-14 12:09:27.278734 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 40, 128],"float16"), Tensor([2, 2, 40, 128],"float16"), Tensor([2, 2, 40, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 40, 128],"float16"), Tensor([2, 2, 40, 128],"float16"), Tensor([2, 2, 40, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 22845 / 40960 (55.8%)
Max absolute difference among violations: 0.9785
Max relative difference among violations: 19168.
 ACTUAL: array([[[[ 0.3323  ,  0.299   , -0.299   , ..., -0.3926  ,  0.4238  ,
           0.4395  ],
         [-0.3723  ,  0.2678  ,  0.3171  , ..., -0.0623  ,  0.347   ,...
 DESIRED: array([[[[ 0.3323 ,  0.299  , -0.299  , ..., -0.3926 ,  0.4238 ,
           0.4395 ],
         [-0.3723 ,  0.2678 ,  0.3171 , ..., -0.0623 ,  0.347  ,...
2025-05-14 12:10:08.525153 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 41, 128],"float16"), Tensor([2, 2, 41, 128],"float16"), Tensor([2, 2, 41, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 41, 128],"float16"), Tensor([2, 2, 41, 128],"float16"), Tensor([2, 2, 41, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 38729 / 41984 (92.2%)
Max absolute difference among violations: 32752.
Max relative difference among violations: 298.5
 ACTUAL: array([[[[-3.1909e-01, -8.0750e-02, -3.4009e-01, ..., -2.9688e-01,
          -4.4360e-01, -1.0138e-01],
         [-6.1890e-02,  1.4954e-01,  2.7368e-01, ...,  3.7231e-01,...
 DESIRED: array([[[[-0.319   , -0.08075 , -0.34    , ..., -0.2969  , -0.4436  ,
          -0.1014  ],
         [-0.0619  ,  0.1495  ,  0.2737  , ...,  0.3723  ,  0.31    ,...
2025-05-14 12:10:50.737743 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 47, 128],"float16"), Tensor([2, 2, 47, 128],"float16"), Tensor([2, 2, 47, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 47, 128],"float16"), Tensor([2, 2, 47, 128],"float16"), Tensor([2, 2, 47, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 36228 / 48128 (75.3%)
Max absolute difference among violations: 32752.
Max relative difference among violations: 961.5
 ACTUAL: array([[[[-3.1714e-01,  3.6987e-01,  1.0406e-01, ...,  3.3862e-01,
          -2.4124e-02,  3.4937e-01],
         [-1.3965e-01, -4.8340e-01,  1.4148e-01, ...,  7.7820e-03,...
 DESIRED: array([[[[-0.3171  ,  0.3699  ,  0.10406 , ...,  0.3386  , -0.02412 ,
           0.3494  ],
         [-0.1396  , -0.4834  ,  0.1415  , ...,  0.007782, -0.2338  ,...
2025-05-14 12:11:28.216301 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 51, 128],"float16"), Tensor([2, 2, 51, 128],"float16"), Tensor([2, 2, 51, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 51, 128],"float16"), Tensor([2, 2, 51, 128],"float16"), Tensor([2, 2, 51, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 35437 / 52224 (67.9%)
Max absolute difference among violations: 32752.
Max relative difference among violations: 7112.
 ACTUAL: array([[[[ 4.7424e-02, -1.5915e-02,  5.0232e-02, ...,  4.1382e-01,
           1.6589e-01,  6.1981e-02],
         [-1.3452e-01,  1.9324e-01, -3.8232e-01, ...,  1.0925e-01,...
 DESIRED: array([[[[ 0.04742 , -0.01591 ,  0.05023 , ...,  0.4138  ,  0.1659  ,
           0.06198 ],
         [-0.1345  ,  0.1932  , -0.3823  , ...,  0.10925 , -0.2896  ,...
2025-05-14 12:12:11.609317 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 53, 128],"float16"), Tensor([2, 2, 53, 128],"float16"), Tensor([2, 2, 53, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 53, 128],"float16"), Tensor([2, 2, 53, 128],"float16"), Tensor([2, 2, 53, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 40507 / 54272 (74.6%)
Max absolute difference among violations: 32752.
Max relative difference among violations: 29728.
 ACTUAL: array([[[[ 0.11285 ,  0.006207, -0.3984  , ..., -0.3708  , -0.498   ,
          -0.259   ],
         [ 0.3545  , -0.09344 ,  0.2676  , ..., -0.17    , -0.495   ,...
 DESIRED: array([[[[ 0.11285 ,  0.006207, -0.3984  , ..., -0.3708  , -0.498   ,
          -0.259   ],
         [ 0.3545  , -0.09344 ,  0.2676  , ..., -0.17    , -0.495   ,...
2025-05-14 12:12:56.919481 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 54, 128],"float16"), Tensor([2, 2, 54, 128],"float16"), Tensor([2, 2, 54, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 54, 128],"float16"), Tensor([2, 2, 54, 128],"float16"), Tensor([2, 2, 54, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 35352 / 55296 (63.9%)
Max absolute difference among violations: 32752.
Max relative difference among violations: inf
 ACTUAL: array([[[[ 3.5059e-01, -1.6858e-01, -4.7070e-01, ...,  3.6438e-02,
           1.4209e-01,  4.2456e-01],
         [-4.6948e-01, -2.0630e-02,  3.1689e-01, ...,  3.3594e-01,...
 DESIRED: array([[[[ 0.3506 , -0.1686 , -0.4707 , ...,  0.03644,  0.1421 ,
           0.4246 ],
         [-0.4695 , -0.02063,  0.317  , ...,  0.336  ,  0.4668 ,...
2025-05-14 12:13:39.767257 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 57, 128],"float16"), Tensor([2, 2, 57, 128],"float16"), Tensor([2, 2, 57, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 57, 128],"float16"), Tensor([2, 2, 57, 128],"float16"), Tensor([2, 2, 57, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 44311 / 58368 (75.9%)
Max absolute difference among violations: 32752.
Max relative difference among violations: 6416.
 ACTUAL: array([[[[-9.7168e-02, -3.6938e-01,  2.0239e-01, ..., -2.6318e-01,
           1.5430e-01,  1.6724e-01],
         [ 8.8745e-02,  4.2578e-01,  4.7607e-01, ...,  3.1079e-01,...
 DESIRED: array([[[[-0.09717, -0.3694 ,  0.2024 , ..., -0.2632 ,  0.1543 ,
           0.1672 ],
         [ 0.08875,  0.4258 ,  0.476  , ...,  0.3108 , -0.01034,...
2025-05-14 12:14:22.798132 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 107, 96],"float16"), Tensor([2, 8, 107, 96],"float16"), Tensor([2, 8, 107, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 107, 96],"float16"), Tensor([2, 8, 107, 96],"float16"), Tensor([2, 8, 107, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 100608 / 164352 (61.2%)
Max absolute difference among violations: 32752.
Max relative difference among violations: inf
 ACTUAL: array([[[[ 5.2490e-02, -4.3896e-01, -2.5005e-03, ...,  3.8696e-01,
           3.8635e-02,  6.9275e-02],
         [ 2.6245e-01,  4.1553e-01,  3.5522e-01, ..., -4.7144e-01,...
 DESIRED: array([[[[ 0.0525  , -0.439   , -0.0025  , ...,  0.387   ,  0.03864 ,
           0.0693  ],
         [ 0.2625  ,  0.4155  ,  0.3552  , ..., -0.4714  ,  0.4934  ,...
2025-05-14 12:14:23.641222 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 107, 96],"float16"), Tensor([2, 8, 235, 96],"float16"), Tensor([2, 8, 235, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 107, 96],"float16"), Tensor([2, 8, 235, 96],"float16"), Tensor([2, 8, 235, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 86135 / 164352 (52.4%)
Max absolute difference among violations: 32752.
Max relative difference among violations: 8.055
 ACTUAL: array([[[[-2.8735e-01,  3.3276e-01, -2.0905e-02, ...,  1.7554e-01,
           3.8940e-02,  3.0493e-01],
         [ 1.3306e-01, -1.2793e-01, -2.3834e-02, ..., -3.9966e-01,...
 DESIRED: array([[[[-0.289   ,  0.3325  , -0.02031 , ...,  0.1768  ,  0.03943 ,
           0.303   ],
         [ 0.133   , -0.1279  , -0.02383 , ..., -0.3997  , -0.3752  ,...
2025-05-14 12:14:24.439609 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 109, 96],"float16"), Tensor([2, 8, 109, 96],"float16"), Tensor([2, 8, 109, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 109, 96],"float16"), Tensor([2, 8, 109, 96],"float16"), Tensor([2, 8, 109, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 83455 / 167424 (49.8%)
Max absolute difference among violations: 0.5
Max relative difference among violations: inf
 ACTUAL: array([[[[-0.2764  ,  0.3584  ,  0.1984  , ...,  0.4268  , -0.3267  ,
          -0.4702  ],
         [ 0.2158  , -0.4146  ,  0.466   , ..., -0.2856  , -0.1912  ,...
 DESIRED: array([[[[-0.2764  ,  0.3584  ,  0.1984  , ...,  0.4268  , -0.3267  ,
          -0.4702  ],
         [ 0.2158  , -0.4146  ,  0.466   , ..., -0.2856  , -0.1912  ,...
2025-05-14 12:14:25.211582 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 109, 96],"float16"), Tensor([2, 8, 237, 96],"float16"), Tensor([2, 8, 237, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 109, 96],"float16"), Tensor([2, 8, 237, 96],"float16"), Tensor([2, 8, 237, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 75376 / 167424 (45%)
Max absolute difference among violations: 32752.
Max relative difference among violations: 4.688
 ACTUAL: array([[[[-4.6582e-01,  4.3750e-01, -9.4788e-02, ..., -3.4155e-01,
           4.0625e-01, -1.0590e-01],
         [ 1.9055e-01, -7.5798e-03,  3.2861e-01, ...,  7.1602e-03,...
 DESIRED: array([[[[-0.4658  ,  0.4375  , -0.0948  , ..., -0.3416  ,  0.4062  ,
          -0.1059  ],
         [ 0.1906  , -0.00758 ,  0.3286  , ...,  0.00716 ,  0.1764  ,...
2025-05-14 12:14:26.000282 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 110, 96],"float16"), Tensor([2, 8, 110, 96],"float16"), Tensor([2, 8, 110, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 110, 96],"float16"), Tensor([2, 8, 110, 96],"float16"), Tensor([2, 8, 110, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 71572 / 168960 (42.4%)
Max absolute difference among violations: 0.5
Max relative difference among violations: inf
 ACTUAL: array([[[[ 0.1007  ,  0.4546  , -0.09094 , ...,  0.2036  , -0.3484  ,
          -0.2025  ],
         [-0.1337  ,  0.4558  ,  0.1334  , ...,  0.408   , -0.4353  ,...
 DESIRED: array([[[[ 0.1007  ,  0.4546  , -0.09094 , ...,  0.2036  , -0.3484  ,
          -0.2025  ],
         [-0.1337  ,  0.4558  ,  0.1334  , ...,  0.408   , -0.4353  ,...
2025-05-14 12:14:26.783221 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 110, 96],"float16"), Tensor([2, 8, 238, 96],"float16"), Tensor([2, 8, 238, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 110, 96],"float16"), Tensor([2, 8, 238, 96],"float16"), Tensor([2, 8, 238, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 110256 / 168960 (65.3%)
Max absolute difference among violations: 32752.
Max relative difference among violations: 6.023
 ACTUAL: array([[[[ 2.6855e-01,  3.1958e-01,  1.7554e-01, ...,  3.0005e-01,
           4.8486e-01, -1.9128e-01],
         [ 2.5562e-01, -1.3757e-01, -3.5913e-01, ...,  4.3384e-01,...
 DESIRED: array([[[[ 0.2686  ,  0.3196  ,  0.1755  , ...,  0.3     ,  0.4849  ,
          -0.1913  ],
         [ 0.2556  , -0.1376  , -0.3591  , ...,  0.4338  , -0.1029  ,...
2025-05-14 12:14:27.523072 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 111, 96],"float16"), Tensor([2, 8, 111, 96],"float16"), Tensor([2, 8, 111, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 111, 96],"float16"), Tensor([2, 8, 111, 96],"float16"), Tensor([2, 8, 111, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 82738 / 170496 (48.5%)
Max absolute difference among violations: 0.5
Max relative difference among violations: inf
 ACTUAL: array([[[[-0.3792  ,  0.05225 , -0.1827  , ...,  0.4011  ,  0.02776 ,
           0.2313  ],
         [ 0.322   ,  0.1206  ,  0.3667  , ..., -0.3125  ,  0.2106  ,...
 DESIRED: array([[[[-0.3792  ,  0.05225 , -0.1827  , ...,  0.4011  ,  0.02776 ,
           0.2313  ],
         [ 0.322   ,  0.1206  ,  0.3667  , ..., -0.3125  ,  0.2106  ,...
2025-05-14 12:14:28.293329 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 111, 96],"float16"), Tensor([2, 8, 239, 96],"float16"), Tensor([2, 8, 239, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 111, 96],"float16"), Tensor([2, 8, 239, 96],"float16"), Tensor([2, 8, 239, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 85307 / 170496 (50%)
Max absolute difference among violations: 32752.
Max relative difference among violations: 0.1153
 ACTUAL: array([[[[ 1.8164e-01,  4.7974e-01, -2.9251e-02, ..., -2.7759e-01,
          -2.9956e-01,  2.8369e-01],
         [ 6.3171e-02, -3.0005e-01,  3.2349e-01, ..., -1.7957e-01,...
 DESIRED: array([[[[ 0.1816  ,  0.4797  , -0.02925 , ..., -0.2776  , -0.2996  ,
           0.2837  ],
         [ 0.0632  , -0.3     ,  0.3235  , ..., -0.1796  ,  0.2417  ,...
2025-05-14 12:14:29.029291 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 112, 96],"float16"), Tensor([2, 8, 112, 96],"float16"), Tensor([2, 8, 112, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 112, 96],"float16"), Tensor([2, 8, 112, 96],"float16"), Tensor([2, 8, 112, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 35365 / 172032 (20.6%)
Max absolute difference among violations: 0.5
Max relative difference among violations: inf
 ACTUAL: array([[[[ 0.347   ,  0.4438  , -0.3022  , ...,  0.3806  , -0.4402  ,
           0.472   ],
         [ 0.1043  ,  0.0509  ,  0.1047  , ...,  0.2893  ,  0.1395  ,...
 DESIRED: array([[[[ 0.347   ,  0.4438  , -0.3022  , ...,  0.3806  , -0.4402  ,
           0.472   ],
         [ 0.1043  ,  0.0509  ,  0.1047  , ...,  0.2893  ,  0.1395  ,...
2025-05-14 12:14:29.796270 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 112, 96],"float16"), Tensor([2, 8, 240, 96],"float16"), Tensor([2, 8, 240, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 112, 96],"float16"), Tensor([2, 8, 240, 96],"float16"), Tensor([2, 8, 240, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 113801 / 172032 (66.2%)
Max absolute difference among violations: 32752.
Max relative difference among violations: inf
 ACTUAL: array([[[[ 1.2988e-01,  2.6978e-01,  2.4304e-01, ...,  2.3572e-01,
           4.6240e-01,  3.7720e-01],
         [-3.3008e-01,  8.4839e-02, -1.0498e-01, ..., -3.4277e-01,...
 DESIRED: array([[[[ 1.2988e-01,  2.6978e-01,  2.4304e-01, ...,  2.3572e-01,
           4.6240e-01,  3.7720e-01],
         [-3.3008e-01,  8.4839e-02, -1.0498e-01, ..., -3.4277e-01,...
2025-05-14 12:14:30.581148 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 74, 96],"float16"), Tensor([2, 8, 202, 96],"float16"), Tensor([2, 8, 202, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 74, 96],"float16"), Tensor([2, 8, 202, 96],"float16"), Tensor([2, 8, 202, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 97092 / 113664 (85.4%)
Max absolute difference among violations: 0.5
Max relative difference among violations: inf
 ACTUAL: array([[[[-0.129   , -0.1577  ,  0.1812  , ...,  0.0891  , -0.2474  ,
           0.2532  ],
         [ 0.10376 , -0.3909  ,  0.4114  , ..., -0.07043 ,  0.3757  ,...
 DESIRED: array([[[[-0.129  , -0.1577 ,  0.1812 , ...,  0.0891 , -0.2474 ,
           0.2532 ],
         [ 0.10376, -0.3909 ,  0.4114 , ..., -0.07043,  0.3757 ,...
2025-05-14 12:14:31.357709 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 74, 96],"float16"), Tensor([2, 8, 74, 96],"float16"), Tensor([2, 8, 74, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 74, 96],"float16"), Tensor([2, 8, 74, 96],"float16"), Tensor([2, 8, 74, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 50453 / 113664 (44.4%)
Max absolute difference among violations: 0.5
Max relative difference among violations: inf
 ACTUAL: array([[[[ 2.2266e-01, -2.7271e-01, -4.3652e-01, ...,  3.5767e-01,
           1.4954e-01, -1.7896e-01],
         [ 3.1372e-01, -1.1005e-01,  7.9102e-02, ...,  1.0339e-01,...
 DESIRED: array([[[[ 2.2266e-01, -2.7271e-01, -4.3652e-01, ...,  3.5767e-01,
           1.4954e-01, -1.7896e-01],
         [ 3.1372e-01, -1.1005e-01,  7.9102e-02, ...,  1.0339e-01,...
2025-05-14 12:14:32.121538 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 79, 96],"float16"), Tensor([2, 8, 207, 96],"float16"), Tensor([2, 8, 207, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 79, 96],"float16"), Tensor([2, 8, 207, 96],"float16"), Tensor([2, 8, 207, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 94805 / 121344 (78.1%)
Max absolute difference among violations: 0.5
Max relative difference among violations: inf
 ACTUAL: array([[[[ 0.4631  ,  0.2686  , -0.2444  , ...,  0.1973  ,  0.4114  ,
          -0.4316  ],
         [ 0.2032  , -0.4202  , -0.3108  , ...,  0.274   ,  0.3828  ,...
 DESIRED: array([[[[ 0.4631  ,  0.2686  , -0.2444  , ...,  0.1973  ,  0.4114  ,
          -0.4316  ],
         [ 0.2032  , -0.4202  , -0.3108  , ...,  0.274   ,  0.3828  ,...
2025-05-14 12:14:32.901384 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 79, 96],"float16"), Tensor([2, 8, 79, 96],"float16"), Tensor([2, 8, 79, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 79, 96],"float16"), Tensor([2, 8, 79, 96],"float16"), Tensor([2, 8, 79, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 62449 / 121344 (51.5%)
Max absolute difference among violations: 0.5
Max relative difference among violations: inf
 ACTUAL: array([[[[-0.2656  , -0.4238  ,  0.4446  , ..., -0.271   , -0.07    ,
           0.4475  ],
         [-0.1192  ,  0.0698  , -0.3835  , ..., -0.00777 , -0.3284  ,...
 DESIRED: array([[[[-0.2656  , -0.4238  ,  0.4446  , ..., -0.271   , -0.07    ,
           0.4475  ],
         [-0.1192  ,  0.0698  , -0.3835  , ..., -0.00777 , -0.3284  ,...
2025-05-14 12:14:33.675487 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 80, 96],"float16"), Tensor([2, 8, 208, 96],"float16"), Tensor([2, 8, 208, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 80, 96],"float16"), Tensor([2, 8, 208, 96],"float16"), Tensor([2, 8, 208, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 74313 / 122880 (60.5%)
Max absolute difference among violations: 0.5
Max relative difference among violations: 0.151
 ACTUAL: array([[[[ 0.4116  , -0.4573  ,  0.2957  , ..., -0.1931  ,  0.002548,
          -0.2467  ],
         [ 0.2905  ,  0.4702  ,  0.10205 , ..., -0.454   , -0.1765  ,...
 DESIRED: array([[[[ 0.4116  , -0.4573  ,  0.2957  , ..., -0.1931  ,  0.002548,
          -0.2467  ],
         [ 0.2905  ,  0.4702  ,  0.10205 , ..., -0.454   , -0.1765  ,...
2025-05-14 12:14:34.455539 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 80, 96],"float16"), Tensor([2, 8, 80, 96],"float16"), Tensor([2, 8, 80, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 80, 96],"float16"), Tensor([2, 8, 80, 96],"float16"), Tensor([2, 8, 80, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 49678 / 122880 (40.4%)
Max absolute difference among violations: 0.5
Max relative difference among violations: inf
 ACTUAL: array([[[[-0.1147  , -0.1641  , -0.11334 , ..., -0.3833  ,  0.1584  ,
           0.1267  ],
         [-0.2854  ,  0.01369 , -0.1908  , ..., -0.1581  , -0.372   ,...
 DESIRED: array([[[[-0.1147  , -0.1641  , -0.11334 , ..., -0.3833  ,  0.1584  ,
           0.1267  ],
         [-0.2854  ,  0.01369 , -0.1908  , ..., -0.1581  , -0.372   ,...
2025-05-14 12:14:35.182478 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 82, 96],"float16"), Tensor([2, 8, 210, 96],"float16"), Tensor([2, 8, 210, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 82, 96],"float16"), Tensor([2, 8, 210, 96],"float16"), Tensor([2, 8, 210, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 81814 / 125952 (65%)
Max absolute difference among violations: 0.5
Max relative difference among violations: 0.4714
 ACTUAL: array([[[[-0.0554  ,  0.1769  , -0.4207  , ...,  0.1749  ,  0.3066  ,
           0.3843  ],
         [ 0.1196  ,  0.1454  ,  0.00859 , ...,  0.2198  , -0.4512  ,...
 DESIRED: array([[[[-0.0554  ,  0.1769  , -0.4207  , ...,  0.1749  ,  0.3066  ,
           0.3843  ],
         [ 0.1196  ,  0.1454  ,  0.00859 , ...,  0.2198  , -0.4512  ,...
2025-05-14 12:14:35.949904 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 82, 96],"float16"), Tensor([2, 8, 82, 96],"float16"), Tensor([2, 8, 82, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 82, 96],"float16"), Tensor([2, 8, 82, 96],"float16"), Tensor([2, 8, 82, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 31609 / 125952 (25.1%)
Max absolute difference among violations: 0.5
Max relative difference among violations: inf
 ACTUAL: array([[[[-0.02118 , -0.1603  ,  0.2998  , ...,  0.4426  , -0.3352  ,
          -0.2817  ],
         [ 0.0723  , -0.2856  , -0.00557 , ...,  0.0655  ,  0.1326  ,...
 DESIRED: array([[[[-0.02118, -0.1603 ,  0.2998 , ...,  0.4426 , -0.3352 ,
          -0.2817 ],
         [ 0.0723 , -0.2856 , -0.00557, ...,  0.0655 ,  0.1326 ,...
2025-05-14 12:14:36.720907 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 91, 96],"float16"), Tensor([2, 8, 219, 96],"float16"), Tensor([2, 8, 219, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 91, 96],"float16"), Tensor([2, 8, 219, 96],"float16"), Tensor([2, 8, 219, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 76693 / 139776 (54.9%)
Max absolute difference among violations: 0.5
Max relative difference among violations: inf
 ACTUAL: array([[[[-0.1522  ,  0.1316  ,  0.4844  , ..., -0.04987 , -0.09375 ,
           0.2479  ],
         [-0.1259  , -0.1825  , -0.4685  , ..., -0.1478  , -0.2822  ,...
 DESIRED: array([[[[-0.1522  ,  0.1316  ,  0.4844  , ..., -0.04987 , -0.09375 ,
           0.2479  ],
         [-0.1259  , -0.1825  , -0.4685  , ..., -0.1478  , -0.2822  ,...
2025-05-14 12:14:37.449419 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 91, 96],"float16"), Tensor([2, 8, 91, 96],"float16"), Tensor([2, 8, 91, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 91, 96],"float16"), Tensor([2, 8, 91, 96],"float16"), Tensor([2, 8, 91, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 103876 / 139776 (74.3%)
Max absolute difference among violations: 0.5
Max relative difference among violations: inf
 ACTUAL: array([[[[-0.1768  , -0.43    , -0.1493  , ..., -0.05545 ,  0.2412  ,
          -0.2566  ],
         [ 0.401   , -0.3281  , -0.398   , ..., -0.2114  , -0.00968 ,...
 DESIRED: array([[[[-0.1768  , -0.43    , -0.1493  , ..., -0.05545 ,  0.2412  ,
          -0.2566  ],
         [ 0.401   , -0.3281  , -0.398   , ..., -0.2114  , -0.00968 ,...
2025-05-14 12:14:38.205894 GPU 0 109595 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([3, 16, 64, 32],"float16"), Tensor([3, 2, 64, 32],"float16"), Tensor([3, 2, 64, 32],"float16"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([3, 1, 64, 64],"float16"), 0.17677669529663687, )
[accuracy error] paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([3, 16, 64, 32],"float16"), Tensor([3, 2, 64, 32],"float16"), Tensor([3, 2, 64, 32],"float16"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([3, 1, 64, 64],"float16"), 0.17677669529663687, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 72239 / 98304 (73.5%)
Max absolute difference among violations: 0.9707
Max relative difference among violations: inf
 ACTUAL: array([[[[ 4.8682e-01, -4.7827e-01,  2.8955e-01, ...,  1.3843e-01,
           3.6108e-01,  4.9561e-01],
         [ 3.5059e-01,  3.6621e-01, -1.6492e-01, ...,  3.1464e-02,...
 DESIRED: array([[[[ 4.8682e-01, -4.7827e-01,  2.8955e-01, ...,  1.3843e-01,
           3.6108e-01,  4.9561e-01],
         [ 3.5059e-01,  3.6621e-01, -1.6492e-01, ...,  3.1464e-02,...
