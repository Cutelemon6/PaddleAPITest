paddle.nn.functional.hsigmoid_loss(Tensor([4, 8],"float64"), Tensor([4],"int64"), 6, Tensor([5, 8],"float64"), Tensor([5, 1],"float64"), Tensor([4, 5],"int64"), Tensor([4, 5],"int64"), True, )
 
 aistudio@jupyter-3165291-8843119:~/PaddleAPITest$ python engine.py --paddle_only=True --api_config='paddle.nn.functional.hsigmoid_loss(Tensor([4, 8],"float64"), Tensor([4],"int64"), 6, Tensor([5, 8],"float64"), Tensor([5, 1],"float64"), Tensor([4, 5],"int64"), Tensor([4, 5],"int64"), True, )'
test begin: paddle.nn.functional.hsigmoid_loss(Tensor([4, 8],"float64"), Tensor([4],"int64"), 6, Tensor([5, 8],"float64"), Tensor([5, 1],"float64"), Tensor([4, 5],"int64"), Tensor([4, 5],"int64"), True, )
W0408 07:27:59.446331 45970 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0408 07:27:59.447310 45970 gpu_resources.cc:164] device: 0, cuDNN Version: 8.9.


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   HsigmoidLossGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::hsigmoid_loss_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, paddle::optional<paddle::Tensor> const&, paddle::optional<paddle::Tensor> const&, paddle::Tensor const&, paddle::Tensor const&, int, bool, paddle::Tensor*, paddle::Tensor*, paddle::Tensor*)
4   phi::funcs::MatrixBitCodeFunctor<double>::MulGradWeight(phi::DenseTensor const&, phi::SelectedRows*, phi::DenseTensor const&)
5   void phi::funcs::MatrixBitCodeFunctorMulGradWeightSR<double>::operator()<phi::funcs::CustomCodeTable<long> >(phi::funcs::CustomCodeTable<long> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1744097279 (unix time) try "date -d @1744097279" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x10) received by PID 45899 (TID 0x7f87fdfeb700) from PID 16 ***]

Segmentation fault (core dumped)