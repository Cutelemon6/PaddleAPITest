2025-06-05 15:05:11.885354 GPU 0 25238 test begin: paddle.Tensor.amax(Tensor([0, 2, 4, 5],"float32"), axis=-1, keepdim=True, )
[paddle error] paddle.Tensor.amax(Tensor([0, 2, 4, 5],"float32"), axis=-1, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:05:11.955571 GPU 0 25233 test begin: paddle.Tensor.amax(Tensor([0, 2, 5, 4],"float32"), axis=2, keepdim=True, )
[paddle error] paddle.Tensor.amax(Tensor([0, 2, 5, 4],"float32"), axis=2, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:05:12.148725 GPU 0 25224 test begin: paddle.Tensor.amax(Tensor([0, 2, 5, 4],"float32"), axis=tuple(1,2,), keepdim=True, )
[paddle error] paddle.Tensor.amax(Tensor([0, 2, 5, 4],"float32"), axis=tuple(1,2,), keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:05:12.170687 GPU 0 25227 test begin: paddle.Tensor.amax(Tensor([3, 0, 4, 5],"float32"), axis=-1, keepdim=True, )
[paddle error] paddle.Tensor.amax(Tensor([3, 0, 4, 5],"float32"), axis=-1, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:05:12.279597 GPU 1 25221 test begin: paddle.Tensor.amax(Tensor([3, 0, 5, 4],"float32"), axis=2, keepdim=True, )
[paddle error] paddle.Tensor.amax(Tensor([3, 0, 5, 4],"float32"), axis=2, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:05:12.301260 GPU 1 25225 test begin: paddle.Tensor.amax(Tensor([3, 2, 0, 5],"float32"), axis=-1, keepdim=True, )
[paddle error] paddle.Tensor.amax(Tensor([3, 2, 0, 5],"float32"), axis=-1, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:05:12.485979 GPU 1 25234 test begin: paddle.Tensor.amax(Tensor([3, 2, 5, 0],"float32"), axis=2, keepdim=True, )
[paddle error] paddle.Tensor.amax(Tensor([3, 2, 5, 0],"float32"), axis=2, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:05:12.511303 GPU 1 25239 test begin: paddle.Tensor.amax(Tensor([3, 2, 5, 0],"float32"), axis=tuple(1,2,), keepdim=True, )
[paddle error] paddle.Tensor.amax(Tensor([3, 2, 5, 0],"float32"), axis=tuple(1,2,), keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:05:12.566078 GPU 0 25232 test begin: paddle.Tensor.amin(Tensor([0, 2, 4, 5],"float32"), axis=-1, keepdim=True, )
[paddle error] paddle.Tensor.amin(Tensor([0, 2, 4, 5],"float32"), axis=-1, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:05:12.622029 GPU 0 25222 test begin: paddle.Tensor.amin(Tensor([0, 2, 5, 4],"float32"), axis=2, keepdim=True, )
[paddle error] paddle.Tensor.amin(Tensor([0, 2, 5, 4],"float32"), axis=2, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:05:12.816399 GPU 0 25240 test begin: paddle.Tensor.amin(Tensor([0, 2, 5, 4],"float32"), axis=tuple(1,2,), keepdim=True, )
[paddle error] paddle.Tensor.amin(Tensor([0, 2, 5, 4],"float32"), axis=tuple(1,2,), keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:05:12.862396 GPU 1 25242 test begin: paddle.Tensor.amin(Tensor([3, 0, 4, 5],"float32"), axis=-1, keepdim=True, )
[paddle error] paddle.Tensor.amin(Tensor([3, 0, 4, 5],"float32"), axis=-1, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:05:12.878980 GPU 0 25226 test begin: paddle.Tensor.amin(Tensor([3, 0, 5, 4],"float32"), axis=2, keepdim=True, )
[paddle error] paddle.Tensor.amin(Tensor([3, 0, 5, 4],"float32"), axis=2, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:05:12.888311 GPU 1 25235 test begin: paddle.Tensor.amin(Tensor([3, 2, 0, 5],"float32"), axis=-1, keepdim=True, )
[paddle error] paddle.Tensor.amin(Tensor([3, 2, 0, 5],"float32"), axis=-1, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:05:12.905283 GPU 1 25228 test begin: paddle.Tensor.amin(Tensor([3, 2, 5, 0],"float32"), axis=2, keepdim=True, )
[paddle error] paddle.Tensor.amin(Tensor([3, 2, 5, 0],"float32"), axis=2, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:05:13.007001 GPU 0 25237 test begin: paddle.Tensor.amin(Tensor([3, 2, 5, 0],"float32"), axis=tuple(1,2,), keepdim=True, )
[paddle error] paddle.Tensor.amin(Tensor([3, 2, 5, 0],"float32"), axis=tuple(1,2,), keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:05:13.037677 GPU 0 25230 test begin: paddle.Tensor.argmax(Tensor([0, 1, 10285],"float32"), axis=-2, )
[paddle error] paddle.Tensor.argmax(Tensor([0, 1, 10285],"float32"), axis=-2, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:05:13.064916 GPU 0 25223 test begin: paddle.Tensor.argmax(Tensor([0, 1, 24276],"float32"), axis=-2, )
[paddle error] paddle.Tensor.argmax(Tensor([0, 1, 24276],"float32"), axis=-2, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:05:13.074886 GPU 1 25241 test begin: paddle.Tensor.argmax(Tensor([0, 100, 8000],"float32"), axis=2, )
[paddle error] paddle.Tensor.argmax(Tensor([0, 100, 8000],"float32"), axis=2, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:05:13.075519 GPU 1 25229 test begin: paddle.Tensor.argmax(Tensor([0, 101, 8000],"float32"), axis=2, )
[paddle error] paddle.Tensor.argmax(Tensor([0, 101, 8000],"float32"), axis=2, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:05:13.112999 GPU 1 25231 test begin: paddle.Tensor.argmax(Tensor([0, 10],"float32"), axis=1, )
[paddle error] paddle.Tensor.argmax(Tensor([0, 10],"float32"), axis=1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:05:13.130074 GPU 1 25236 test begin: paddle.Tensor.argmax(Tensor([0, 157920, 2],"float32"), axis=-1, )
[paddle error] paddle.Tensor.argmax(Tensor([0, 157920, 2],"float32"), axis=-1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:05:26.555867 GPU 0 25238 test begin: paddle.Tensor.argmax(Tensor([0, 3, 3],"float32"), 1, )
[paddle error] paddle.Tensor.argmax(Tensor([0, 3, 3],"float32"), 1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:05:26.716998 GPU 0 25224 test begin: paddle.Tensor.argmax(Tensor([0, 3],"float32"), 1, )
[paddle error] paddle.Tensor.argmax(Tensor([0, 3],"float32"), 1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:05:26.828833 GPU 0 25233 test begin: paddle.Tensor.argmax(Tensor([0, 4],"float32"), axis=-1, )
[paddle error] paddle.Tensor.argmax(Tensor([0, 4],"float32"), axis=-1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:05:26.943218 GPU 0 25238 test begin: paddle.Tensor.argmax(Tensor([0, 77],"int64"), axis=-1, )
[paddle error] paddle.Tensor.argmax(Tensor([0, 77],"int64"), axis=-1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:05:27.067787 GPU 0 25224 test begin: paddle.Tensor.argmax(Tensor([0, 7],"int32"), -1, )
[paddle error] paddle.Tensor.argmax(Tensor([0, 7],"int32"), -1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:05:27.103950 GPU 0 25233 test begin: paddle.Tensor.argmax(Tensor([0, 90, 22400],"float32"), axis=1, )
[paddle error] paddle.Tensor.argmax(Tensor([0, 90, 22400],"float32"), axis=1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:05:27.445990 GPU 0 25224 test begin: paddle.Tensor.argmax(Tensor([1, 1, 0],"float32"), axis=-2, )
[paddle error] paddle.Tensor.argmax(Tensor([1, 1, 0],"float32"), axis=-2, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:05:27.457064 GPU 0 25233 test begin: paddle.Tensor.argmax(Tensor([13, 3, 0],"float32"), 1, )
[paddle error] paddle.Tensor.argmax(Tensor([13, 3, 0],"float32"), 1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:05:27.465528 GPU 0 25238 test begin: paddle.Tensor.argmax(Tensor([30, 0, 8000],"float32"), axis=2, )
[paddle error] paddle.Tensor.argmax(Tensor([30, 0, 8000],"float32"), axis=2, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:05:27.579991 GPU 0 25227 test begin: paddle.Tensor.argmax(Tensor([4, 0, 2],"float32"), axis=-1, )
[paddle error] paddle.Tensor.argmax(Tensor([4, 0, 2],"float32"), axis=-1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:05:27.651543 GPU 0 25224 test begin: paddle.Tensor.argmax(Tensor([4, 90, 0],"float32"), axis=1, )
[paddle error] paddle.Tensor.argmax(Tensor([4, 90, 0],"float32"), axis=1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:05:27.913889 GPU 0 25238 test begin: paddle.Tensor.bmm(Tensor([0, 108472, 3],"float32"), Tensor([0, 3, 2],"float32"), )
W0605 15:05:28.278622 25238 backward.cc:437] While running Node (BmmGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.bmm(Tensor([0, 108472, 3],"float32"), Tensor([0, 3, 2],"float32"), ) 
 (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 24, memory's size is 0.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):24 > memory_size():0.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)


2025-06-05 15:05:27.921319 GPU 0 25233 test begin: paddle.Tensor.bmm(Tensor([0, 1156, 3],"float32"), Tensor([0, 3, 2],"float32"), )
W0605 15:05:28.449019 25233 backward.cc:437] While running Node (BmmGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.bmm(Tensor([0, 1156, 3],"float32"), Tensor([0, 3, 2],"float32"), ) 
 (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 24, memory's size is 0.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):24 > memory_size():0.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)


2025-06-05 15:05:28.128917 GPU 0 25224 test begin: paddle.Tensor.bmm(Tensor([1, 0, 3],"float32"), Tensor([1, 3, 2],"float32"), )
W0605 15:05:28.627125 25224 backward.cc:437] While running Node (BmmGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.bmm(Tensor([1, 0, 3],"float32"), Tensor([1, 3, 2],"float32"), ) 
 (InvalidArgument) Pointer A should not be null.
  [Hint: A should not be null.] (at ../paddle/phi/kernels/funcs/blas/blas_impl.h:1399)


2025-06-05 15:05:28.149982 GPU 0 25227 test begin: paddle.Tensor.bmm(Tensor([1, 108472, 3],"float32"), Tensor([1, 3, 0],"float32"), )
W0605 15:05:28.620581 25227 backward.cc:437] While running Node (BmmGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.bmm(Tensor([1, 108472, 3],"float32"), Tensor([1, 3, 0],"float32"), ) 
 (InvalidArgument) Pointer A should not be null.
  [Hint: A should not be null.] (at ../paddle/phi/kernels/funcs/blas/blas_impl.h:1399)


2025-06-05 15:05:28.378855 GPU 0 25238 test begin: paddle.Tensor.bmm(Tensor([1, 1156, 3],"float32"), Tensor([1, 3, 0],"float32"), )
W0605 15:05:28.623024 25238 backward.cc:437] While running Node (BmmGradNode) raises an EnforceNotMet exception
[paddle error] paddle.Tensor.bmm(Tensor([1, 1156, 3],"float32"), Tensor([1, 3, 0],"float32"), ) 
 (InvalidArgument) Pointer A should not be null.
  [Hint: A should not be null.] (at ../paddle/phi/kernels/funcs/blas/blas_impl.h:1399)


2025-06-05 15:05:28.602395 GPU 0 25233 test begin: paddle.Tensor.cholesky_solve(x=Tensor([0, 2, 4, 3],"float64"), y=Tensor([0, 2, 4, 4],"float64"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/autograd/graph.py:823: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:180.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[paddle error] paddle.Tensor.cholesky_solve(x=Tensor([0, 2, 4, 3],"float64"), y=Tensor([0, 2, 4, 4],"float64"), ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:05:28.773991 GPU 0 25227 test begin: paddle.Tensor.cholesky_solve(x=Tensor([0, 2, 4, 3],"float64"), y=Tensor([0, 2, 4, 4],"float64"), upper=True, )
[paddle error] paddle.Tensor.cholesky_solve(x=Tensor([0, 2, 4, 3],"float64"), y=Tensor([0, 2, 4, 4],"float64"), upper=True, ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:05:28.774117 GPU 0 25238 test begin: paddle.Tensor.cholesky_solve(x=Tensor([0, 4, 3],"float64"), y=Tensor([0, 4, 4],"float64"), )
[paddle error] paddle.Tensor.cholesky_solve(x=Tensor([0, 4, 3],"float64"), y=Tensor([0, 4, 4],"float64"), ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:05:28.782824 GPU 0 25224 test begin: paddle.Tensor.cholesky_solve(x=Tensor([4, 0],"float32"), y=Tensor([4, 4],"float32"), )
[paddle error] paddle.Tensor.cholesky_solve(x=Tensor([4, 0],"float32"), y=Tensor([4, 4],"float32"), ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:05:29.756434 GPU 0 25232 test begin: paddle.Tensor.cholesky_solve(x=Tensor([4, 0],"float64"), y=Tensor([4, 4],"float64"), )
[paddle error] paddle.Tensor.cholesky_solve(x=Tensor([4, 0],"float64"), y=Tensor([4, 4],"float64"), ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:05:29.899502 GPU 1 25221 test begin: paddle.Tensor.cholesky_solve(x=Tensor([5, 0, 4, 3],"float64"), y=Tensor([5, 0, 4, 4],"float64"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/autograd/graph.py:823: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:180.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[paddle error] paddle.Tensor.cholesky_solve(x=Tensor([5, 0, 4, 3],"float64"), y=Tensor([5, 0, 4, 4],"float64"), ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:05:29.981340 GPU 0 25240 test begin: paddle.Tensor.cholesky_solve(x=Tensor([5, 0, 4, 3],"float64"), y=Tensor([5, 0, 4, 4],"float64"), upper=True, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/autograd/graph.py:823: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:180.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[paddle error] paddle.Tensor.cholesky_solve(x=Tensor([5, 0, 4, 3],"float64"), y=Tensor([5, 0, 4, 4],"float64"), upper=True, ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:05:30.001154 GPU 1 25225 test begin: paddle.Tensor.cholesky_solve(x=Tensor([5, 2, 4, 0],"float64"), y=Tensor([5, 2, 4, 4],"float64"), )
[paddle error] paddle.Tensor.cholesky_solve(x=Tensor([5, 2, 4, 0],"float64"), y=Tensor([5, 2, 4, 4],"float64"), ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:05:30.197387 GPU 0 25222 test begin: paddle.Tensor.cholesky_solve(x=Tensor([5, 2, 4, 0],"float64"), y=Tensor([5, 2, 4, 4],"float64"), upper=True, )
[paddle error] paddle.Tensor.cholesky_solve(x=Tensor([5, 2, 4, 0],"float64"), y=Tensor([5, 2, 4, 4],"float64"), upper=True, ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:05:30.199174 GPU 0 25223 test begin: paddle.Tensor.cholesky_solve(x=Tensor([5, 4, 0],"float64"), y=Tensor([5, 4, 4],"float64"), )
[paddle error] paddle.Tensor.cholesky_solve(x=Tensor([5, 4, 0],"float64"), y=Tensor([5, 4, 4],"float64"), ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:05:30.204725 GPU 1 25236 test begin: paddle.Tensor.chunk(Tensor([0, 1, 1, 4],"float32"), 4, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107131 (unix time) try "date -d @1749107131" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 25236 (TID 0x7f03c8307740) from PID 24 ***]


2025-06-05 15:05:30.220310 GPU 1 25234 test begin: paddle.Tensor.chunk(Tensor([0, 1, 10164, 2],"float32"), 2, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107131 (unix time) try "date -d @1749107131" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 25234 (TID 0x7fcdae701740) from PID 24 ***]


2025-06-05 15:05:30.348264 GPU 1 25242 test begin: paddle.Tensor.chunk(Tensor([0, 1, 10285, 2],"float32"), 2, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107131 (unix time) try "date -d @1749107131" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 25242 (TID 0x7f1928c34740) from PID 24 ***]


2025-06-05 15:05:30.348676 GPU 0 25226 test begin: paddle.Tensor.chunk(Tensor([0, 1, 2048],"float32"), 2, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107131 (unix time) try "date -d @1749107131" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 25226 (TID 0x7f81a9c13740) from PID 24 ***]


2025-06-05 15:05:30.502494 GPU 1 25231 test begin: paddle.Tensor.chunk(Tensor([0, 10, 1, 4],"float32"), 4, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107131 (unix time) try "date -d @1749107131" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 25231 (TID 0x7fc0cd54e740) from PID 24 ***]


2025-06-05 15:05:31.456831 GPU 1 25229 test begin: paddle.Tensor.chunk(Tensor([0, 10, 2048],"float32"), 2, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107131 (unix time) try "date -d @1749107131" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 25229 (TID 0x7f8e42c94740) from PID 24 ***]


2025-06-05 15:05:31.614705 GPU 0 25230 test begin: paddle.Tensor.chunk(Tensor([0, 128, 1007],"float32"), 2, axis=1, )

2025-06-05 15:05:31.780268 GPU 1 25241 test begin: paddle.Tensor.chunk(Tensor([0, 128, 10],"float32"), 2, axis=1, )

2025-06-05 15:05:32.195109 GPU 1 25239 test begin: paddle.Tensor.chunk(Tensor([0, 160, 16, 12],"float32"), 2, axis=1, )

2025-06-05 15:05:32.287838 GPU 1 25228 test begin: paddle.Tensor.chunk(Tensor([0, 160, 8, 6],"float32"), 2, axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107132 (unix time) try "date -d @1749107132" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 25228 (TID 0x7fcb6066c740) from PID 24 ***]


2025-06-05 15:05:32.300578 GPU 0 25237 test begin: paddle.Tensor.chunk(Tensor([0, 196, 768],"float32"), 3, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107132 (unix time) try "date -d @1749107132" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 25237 (TID 0x7ff3d08dd740) from PID 24 ***]


2025-06-05 15:05:32.570552 GPU 1 25235 test begin: paddle.Tensor.chunk(Tensor([0, 300, 101],"float32"), 16, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107132 (unix time) try "date -d @1749107132" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 25235 (TID 0x7fd5f2ac5740) from PID 24 ***]


2025-06-05 15:05:35.998143 GPU 0 25227 test begin: paddle.Tensor.chunk(Tensor([0, 3136, 192],"float32"), 3, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107136 (unix time) try "date -d @1749107136" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xa9c6ff20) received by PID 25227 (TID 0x7fe7874c5740) from PID 18446744072262975264 ***]


2025-06-05 15:05:36.039997 GPU 0 25224 test begin: paddle.Tensor.chunk(Tensor([0, 4],"float32"), 2, axis=1, )

2025-06-05 15:05:36.115418 GPU 0 25233 test begin: paddle.Tensor.chunk(Tensor([0, 8, 32],"float32"), 8, axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107136 (unix time) try "date -d @1749107136" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f377dbec450) received by PID 25233 (TID 0x7f377e7ca740) from PID 2109654096 ***]


2025-06-05 15:05:36.140592 GPU 0 25238 test begin: paddle.Tensor.chunk(Tensor([1, 0, 1, 4],"float32"), 4, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107136 (unix time) try "date -d @1749107136" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fa98bcbd390) received by PID 25238 (TID 0x7fa98c89b740) from PID 18446744071759975312 ***]


2025-06-05 15:05:37.454719 GPU 0 25232 test begin: paddle.Tensor.chunk(Tensor([1, 0, 10164, 2],"float32"), 2, axis=-1, )

2025-06-05 15:05:38.313057 GPU 1 25225 test begin: paddle.Tensor.chunk(Tensor([1, 0, 10285, 2],"float32"), 2, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107138 (unix time) try "date -d @1749107138" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 25225 (TID 0x7fe147d42740) from PID 24 ***]


2025-06-05 15:05:38.392168 GPU 0 26000 test begin: paddle.Tensor.chunk(Tensor([1, 0, 2048],"float32"), 2, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107157 (unix time) try "date -d @1749107157" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 26000 (TID 0x7fd08727a740) from PID 24 ***]


2025-06-05 15:05:38.496196 GPU 1 26032 test begin: paddle.Tensor.chunk(Tensor([1, 0],"float32"), 2, axis=1, )

2025-06-05 15:05:38.535862 GPU 1 26013 test begin: paddle.Tensor.chunk(Tensor([1, 1, 0, 2],"float32"), 2, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107157 (unix time) try "date -d @1749107157" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 26013 (TID 0x7efef76d5740) from PID 24 ***]


2025-06-05 15:05:38.595084 GPU 1 26001 test begin: paddle.Tensor.chunk(Tensor([1, 1, 0, 4],"float32"), 4, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107158 (unix time) try "date -d @1749107158" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f692e63d370) received by PID 26001 (TID 0x7f692f21b740) from PID 778294128 ***]


2025-06-05 15:05:38.597497 GPU 1 25221 test begin: paddle.Tensor.chunk(Tensor([1, 1, 0],"float32"), 2, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107138 (unix time) try "date -d @1749107138" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 25221 (TID 0x7fbe937b6740) from PID 0 ***]


2025-06-05 15:05:38.817733 GPU 0 25222 test begin: paddle.Tensor.chunk(Tensor([1, 1, 1, 0],"float32"), 4, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107138 (unix time) try "date -d @1749107138" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f4ba966c390) received by PID 25222 (TID 0x7f4baa24a740) from PID 18446744072256668560 ***]


2025-06-05 15:05:38.883174 GPU 1 25987 test begin: paddle.Tensor.chunk(Tensor([1, 1, 10164, 0],"float32"), 2, axis=-1, )

2025-06-05 15:05:39.401037 GPU 0 25240 test begin: paddle.Tensor.chunk(Tensor([1, 1, 10285, 0],"float32"), 2, axis=-1, )

2025-06-05 15:05:39.688643 GPU 0 25223 test begin: paddle.Tensor.chunk(Tensor([1, 10, 0, 4],"float32"), 4, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107139 (unix time) try "date -d @1749107139" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fdb4b5a73b0) received by PID 25223 (TID 0x7fdb4c185740) from PID 1264219056 ***]


2025-06-05 15:05:41.374889 GPU 0 26069 test begin: paddle.Tensor.chunk(Tensor([1, 10, 0],"float32"), 2, axis=-1, )

2025-06-05 15:05:41.573023 GPU 1 26070 test begin: paddle.Tensor.chunk(Tensor([1, 10, 1, 0],"float32"), 4, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107163 (unix time) try "date -d @1749107163" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 26070 (TID 0x7f2ee688a740) from PID 24 ***]


2025-06-05 15:05:42.339398 GPU 1 26080 test begin: paddle.Tensor.chunk(Tensor([128, 0, 768],"float32"), 3, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107163 (unix time) try "date -d @1749107163" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 26080 (TID 0x7f405d29a740) from PID 0 ***]


2025-06-05 15:05:43.517661 GPU 0 26090 test begin: paddle.Tensor.chunk(Tensor([128, 196, 0],"float32"), 3, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107166 (unix time) try "date -d @1749107166" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xa6924858) received by PID 26090 (TID 0x7f8ed8ad6740) from PID 18446744072209188952 ***]


2025-06-05 15:05:43.920965 GPU 1 26117 test begin: paddle.Tensor.chunk(Tensor([128, 3136, 0],"float32"), 3, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107165 (unix time) try "date -d @1749107165" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x482) received by PID 26117 (TID 0x7f6eda221740) from PID 1154 ***]


2025-06-05 15:05:44.221608 GPU 1 26100 test begin: paddle.Tensor.chunk(Tensor([13, 0, 1007],"float32"), 2, axis=1, )

2025-06-05 15:05:44.746669 GPU 0 26182 test begin: paddle.Tensor.chunk(Tensor([13, 0, 10],"float32"), 2, axis=1, )

2025-06-05 15:05:44.877713 GPU 0 26208 test begin: paddle.Tensor.chunk(Tensor([13, 0, 32],"float32"), 8, axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107168 (unix time) try "date -d @1749107168" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x2018) received by PID 26208 (TID 0x7f36b7226740) from PID 8216 ***]


2025-06-05 15:05:45.723046 GPU 0 26183 test begin: paddle.Tensor.chunk(Tensor([13, 128, 0],"float32"), 2, axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107167 (unix time) try "date -d @1749107167" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 26183 (TID 0x7fb4275f8740) from PID 24 ***]


2025-06-05 15:05:45.887597 GPU 0 26213 test begin: paddle.Tensor.chunk(Tensor([13, 8, 0],"float32"), 8, axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107168 (unix time) try "date -d @1749107168" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xa5) received by PID 26213 (TID 0x7f7dafab1740) from PID 165 ***]


2025-06-05 15:05:45.929480 GPU 0 26223 test begin: paddle.Tensor.chunk(Tensor([16, 0, 101],"float32"), 16, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107169 (unix time) try "date -d @1749107169" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xa5) received by PID 26223 (TID 0x7f9374f05740) from PID 165 ***]


2025-06-05 15:05:47.942577 GPU 1 26352 test begin: paddle.Tensor.chunk(Tensor([16, 0, 16, 12],"float32"), 2, axis=1, )

2025-06-05 15:05:48.018265 GPU 0 26331 test begin: paddle.Tensor.chunk(Tensor([16, 0, 8, 6],"float32"), 2, axis=1, )

2025-06-05 15:05:48.095973 GPU 1 26342 test begin: paddle.Tensor.chunk(Tensor([16, 160, 0, 12],"float32"), 2, axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107169 (unix time) try "date -d @1749107169" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f825a264db0) received by PID 26342 (TID 0x7f8470924740) from PID 1512459696 ***]


2025-06-05 15:05:48.415576 GPU 0 26330 test begin: paddle.Tensor.chunk(Tensor([16, 160, 0, 6],"float32"), 2, axis=1, )

2025-06-05 15:05:48.664784 GPU 0 26371 test begin: paddle.Tensor.chunk(Tensor([16, 160, 16, 0],"float32"), 2, axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107171 (unix time) try "date -d @1749107171" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 26371 (TID 0x7f1ec09c2740) from PID 24 ***]


2025-06-05 15:06:07.369881 GPU 1 27055 test begin: paddle.Tensor.chunk(Tensor([16, 160, 8, 0],"float32"), 2, axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107187 (unix time) try "date -d @1749107187" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 27055 (TID 0x7f4d3d58f740) from PID 0 ***]


2025-06-05 15:06:07.516634 GPU 1 27138 test begin: paddle.Tensor.chunk(Tensor([16, 300, 0],"float32"), 16, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107188 (unix time) try "date -d @1749107188" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xdb) received by PID 27138 (TID 0x7f9960e99740) from PID 219 ***]


2025-06-05 15:06:07.557228 GPU 1 27127 test begin: paddle.Tensor.expand_as(Tensor([0, 1, 1, 1],"float32"), Tensor([0, 3, 28, 28],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([0, 1, 1, 1],"float32"), Tensor([0, 3, 28, 28],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/impl/expand_as_kernel_impl.h:42)


2025-06-05 15:06:07.687306 GPU 0 27054 test begin: paddle.Tensor.expand_as(Tensor([0, 1, 1, 1],"float32"), Tensor([0, 3, 280, 350],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([0, 1, 1, 1],"float32"), Tensor([0, 3, 280, 350],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/impl/expand_as_kernel_impl.h:42)


2025-06-05 15:06:07.802668 GPU 1 27137 test begin: paddle.Tensor.expand_as(Tensor([0, 1, 32],"float32"), Tensor([0, 4, 32],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([0, 1, 32],"float32"), Tensor([0, 4, 32],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/impl/expand_as_kernel_impl.h:42)


2025-06-05 15:06:07.933126 GPU 0 27194 test begin: paddle.Tensor.expand_as(Tensor([0, 128],"int32"), Tensor([0, 128],"int64"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.expand_as(Tensor([0, 128],"int32"), Tensor([0, 128],"int64"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/impl/expand_as_kernel_impl.h:42)


2025-06-05 15:06:13.239720 GPU 1 27215 test begin: paddle.Tensor.expand_as(Tensor([0, 1],"int32"), Tensor([0, 1],"int64"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.expand_as(Tensor([0, 1],"int32"), Tensor([0, 1],"int64"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/impl/expand_as_kernel_impl.h:42)


2025-06-05 15:06:13.564417 GPU 1 27214 test begin: paddle.Tensor.expand_as(Tensor([1, 0, 1, 1],"float32"), Tensor([1, 0, 28, 28],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([1, 0, 1, 1],"float32"), Tensor([1, 0, 28, 28],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/impl/expand_as_kernel_impl.h:42)


2025-06-05 15:06:14.448442 GPU 1 27303 test begin: paddle.Tensor.expand_as(Tensor([1, 0, 1, 1],"float32"), Tensor([1, 0, 280, 350],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([1, 0, 1, 1],"float32"), Tensor([1, 0, 280, 350],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/impl/expand_as_kernel_impl.h:42)


2025-06-05 15:06:14.775663 GPU 0 27281 test begin: paddle.Tensor.expand_as(Tensor([1, 0],"int32"), Tensor([5, 0],"int64"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.expand_as(Tensor([1, 0],"int32"), Tensor([5, 0],"int64"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/impl/expand_as_kernel_impl.h:42)


2025-06-05 15:06:14.826255 GPU 0 27280 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 0, 1],"float32"), Tensor([1, 3, 0, 28],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([1, 1, 0, 1],"float32"), Tensor([1, 3, 0, 28],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/impl/expand_as_kernel_impl.h:42)


2025-06-05 15:06:14.914576 GPU 1 27295 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 0, 1],"float32"), Tensor([1, 3, 0, 350],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([1, 1, 0, 1],"float32"), Tensor([1, 3, 0, 350],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/impl/expand_as_kernel_impl.h:42)


2025-06-05 15:06:15.423379 GPU 0 27356 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 0],"float32"), Tensor([1, 3, 28, 0],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([1, 1, 1, 0],"float32"), Tensor([1, 3, 28, 0],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/impl/expand_as_kernel_impl.h:42)


2025-06-05 15:06:16.039947 GPU 0 27425 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 0],"float32"), Tensor([1, 3, 280, 0],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([1, 1, 1, 0],"float32"), Tensor([1, 3, 280, 0],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/impl/expand_as_kernel_impl.h:42)


2025-06-05 15:06:16.247265 GPU 0 27450 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([0, 3, 28, 28],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([0, 3, 28, 28],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/impl/expand_as_kernel_impl.h:42)


2025-06-05 15:06:16.300729 GPU 1 27403 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([0, 3, 280, 350],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([0, 3, 280, 350],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/impl/expand_as_kernel_impl.h:42)


2025-06-05 15:06:17.541900 GPU 0 27475 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 0, 28, 28],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 0, 28, 28],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/impl/expand_as_kernel_impl.h:42)


2025-06-05 15:06:17.760505 GPU 1 27487 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 0, 280, 350],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 0, 280, 350],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/impl/expand_as_kernel_impl.h:42)


2025-06-05 15:06:18.996998 GPU 0 27502 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 0, 28],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 0, 28],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/impl/expand_as_kernel_impl.h:42)


2025-06-05 15:06:19.001713 GPU 0 27539 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 0, 350],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 0, 350],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/impl/expand_as_kernel_impl.h:42)


2025-06-05 15:06:19.216358 GPU 1 27503 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 28, 0],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 28, 0],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/impl/expand_as_kernel_impl.h:42)


2025-06-05 15:06:19.365107 GPU 0 27554 test begin: paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 280, 0],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([1, 1, 1, 1],"float32"), Tensor([1, 3, 280, 0],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/impl/expand_as_kernel_impl.h:42)


2025-06-05 15:06:27.810226 GPU 1 27137 test begin: paddle.Tensor.expand_as(Tensor([1, 128],"int32"), Tensor([0, 128],"int64"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.expand_as(Tensor([1, 128],"int32"), Tensor([0, 128],"int64"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/impl/expand_as_kernel_impl.h:42)


2025-06-05 15:06:28.022893 GPU 0 27054 test begin: paddle.Tensor.expand_as(Tensor([1, 1],"int32"), Tensor([0, 1],"int64"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.expand_as(Tensor([1, 1],"int32"), Tensor([0, 1],"int64"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/impl/expand_as_kernel_impl.h:42)


2025-06-05 15:06:28.069327 GPU 0 27194 test begin: paddle.Tensor.expand_as(Tensor([1, 1],"int32"), Tensor([5, 0],"int64"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.expand_as(Tensor([1, 1],"int32"), Tensor([5, 0],"int64"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/impl/expand_as_kernel_impl.h:42)


2025-06-05 15:06:28.182707 GPU 1 27127 test begin: paddle.Tensor.expand_as(Tensor([2, 0, 32],"float32"), Tensor([2, 0, 32],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([2, 0, 32],"float32"), Tensor([2, 0, 32],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/impl/expand_as_kernel_impl.h:42)


2025-06-05 15:06:28.235864 GPU 1 27137 test begin: paddle.Tensor.expand_as(Tensor([2, 1, 0],"float32"), Tensor([2, 4, 0],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([2, 1, 0],"float32"), Tensor([2, 4, 0],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/impl/expand_as_kernel_impl.h:42)


2025-06-05 15:06:28.334782 GPU 0 27194 test begin: paddle.Tensor.expand_as(Tensor([2, 1, 32],"float32"), Tensor([2, 0, 32],"float32"), )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[paddle error] paddle.Tensor.expand_as(Tensor([2, 1, 32],"float32"), Tensor([2, 0, 32],"float32"), ) 
 (InvalidArgument) The value of target shape cannot be zero.
  [Hint: Expected target_shape[i] != 0, but received target_shape[i]:0 == 0:0.] (at ../paddle/phi/kernels/impl/expand_as_kernel_impl.h:42)


2025-06-05 15:06:28.456906 GPU 0 27054 test begin: paddle.Tensor.inner(x=Tensor([0],"float64"), y=Tensor([0],"float64"), )
[paddle error] paddle.Tensor.inner(x=Tensor([0],"float64"), y=Tensor([0],"float64"), ) 
 (InvalidArgument) can not reshape 0 to -1, 0, because the unspecified dimension 0 can be any number and is ambiguous
  [Hint: Expected unk_dim_idx == -1, but received unk_dim_idx:0 != -1:-1.] (at ../paddle/phi/infermeta/unary.cc:2209)


2025-06-05 15:06:28.525579 GPU 1 27137 test begin: paddle.Tensor.inner(x=Tensor([2, 5, 3, 0],"float64"), y=Tensor([3, 2, 5, 0],"float64"), )
[paddle error] paddle.Tensor.inner(x=Tensor([2, 5, 3, 0],"float64"), y=Tensor([3, 2, 5, 0],"float64"), ) 
 (InvalidArgument) can not reshape 2, 5, 3, 0 to -1, 0, because the unspecified dimension 0 can be any number and is ambiguous
  [Hint: Expected unk_dim_idx == -1, but received unk_dim_idx:0 != -1:-1.] (at ../paddle/phi/infermeta/unary.cc:2209)


2025-06-05 15:06:29.321269 GPU 1 27127 test begin: paddle.Tensor.inner(x=Tensor([3, 0],"float64"), y=Tensor([5, 0],"float64"), )
[paddle error] paddle.Tensor.inner(x=Tensor([3, 0],"float64"), y=Tensor([5, 0],"float64"), ) 
 (InvalidArgument) can not reshape 3, 0 to -1, 0, because the unspecified dimension 0 can be any number and is ambiguous
  [Hint: Expected unk_dim_idx == -1, but received unk_dim_idx:0 != -1:-1.] (at ../paddle/phi/infermeta/unary.cc:2209)


2025-06-05 15:06:29.399731 GPU 1 27137 test begin: paddle.Tensor.inner(x=Tensor([4, 0],"float32"), y=Tensor([4, 0],"float32"), )
[paddle error] paddle.Tensor.inner(x=Tensor([4, 0],"float32"), y=Tensor([4, 0],"float32"), ) 
 (InvalidArgument) can not reshape 4, 0 to -1, 0, because the unspecified dimension 0 can be any number and is ambiguous
  [Hint: Expected unk_dim_idx == -1, but received unk_dim_idx:0 != -1:-1.] (at ../paddle/phi/infermeta/unary.cc:2209)


2025-06-05 15:06:29.486356 GPU 0 27194 test begin: paddle.Tensor.inner(x=Tensor([5, 3, 0],"float64"), y=Tensor([2, 5, 0],"float64"), )
[paddle error] paddle.Tensor.inner(x=Tensor([5, 3, 0],"float64"), y=Tensor([2, 5, 0],"float64"), ) 
 (InvalidArgument) can not reshape 5, 3, 0 to -1, 0, because the unspecified dimension 0 can be any number and is ambiguous
  [Hint: Expected unk_dim_idx == -1, but received unk_dim_idx:0 != -1:-1.] (at ../paddle/phi/infermeta/unary.cc:2209)


2025-06-05 15:06:30.251155 GPU 1 27137 test begin: paddle.Tensor.kthvalue(Tensor([2, 200, 0],"float32"), k=200, axis=1, )
element 1 of tensors does not require grad and does not have a grad_fn


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_kthvalue(_object*, _object*, _object*)
1   kthvalue_ad_func(paddle::Tensor const&, int, int, bool)
2   paddle::experimental::kthvalue(paddle::Tensor const&, int, int, bool)
3   void phi::KthvalueKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, int, int, bool, phi::DenseTensor*, phi::DenseTensor*)
4   phi::funcs::Transpose<phi::CPUContext, float, 3>::operator()(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor*, std::vector<int, std::allocator<int> > const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107190 (unix time) try "date -d @1749107190" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7ff2ba7d60ef) received by PID 27137 (TID 0x7ff3cdaad740) from PID 18446744072543363311 ***]


2025-06-05 15:06:30.303560 GPU 0 27194 test begin: paddle.Tensor.lerp(x=Tensor([0, 5, 4, 3],"float64"), y=Tensor([0, 5, 4, 3],"float64"), weight=0.0, )
[paddle error] paddle.Tensor.lerp(x=Tensor([0, 5, 4, 3],"float64"), y=Tensor([0, 5, 4, 3],"float64"), weight=0.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:06:30.336781 GPU 1 27127 test begin: paddle.Tensor.lerp(x=Tensor([0, 5, 4, 3],"float64"), y=Tensor([0, 5, 4, 3],"float64"), weight=0.5, )
[paddle error] paddle.Tensor.lerp(x=Tensor([0, 5, 4, 3],"float64"), y=Tensor([0, 5, 4, 3],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:06:30.501507 GPU 0 27054 test begin: paddle.Tensor.lerp(x=Tensor([0, 5, 4, 3],"float64"), y=Tensor([0, 5, 4, 3],"float64"), weight=1.0, )
[paddle error] paddle.Tensor.lerp(x=Tensor([0, 5, 4, 3],"float64"), y=Tensor([0, 5, 4, 3],"float64"), weight=1.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:06:30.592975 GPU 0 27194 test begin: paddle.Tensor.lerp(x=Tensor([0, 5, 4],"float64"), y=Tensor([0, 5, 4],"float64"), weight=0.5, )
[paddle error] paddle.Tensor.lerp(x=Tensor([0, 5, 4],"float64"), y=Tensor([0, 5, 4],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:06:30.681630 GPU 1 27127 test begin: paddle.Tensor.lerp(x=Tensor([0, 5],"float64"), y=Tensor([0, 5],"float64"), weight=0.5, )
[paddle error] paddle.Tensor.lerp(x=Tensor([0, 5],"float64"), y=Tensor([0, 5],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:06:30.850172 GPU 0 27054 test begin: paddle.Tensor.lerp(x=Tensor([0, 5],"float64"), y=Tensor([1],"float64"), weight=0.2, )
[paddle error] paddle.Tensor.lerp(x=Tensor([0, 5],"float64"), y=Tensor([1],"float64"), weight=0.2, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:06:30.903607 GPU 0 27194 test begin: paddle.Tensor.lerp(x=Tensor([0],"float32"), y=Tensor([0],"float32"), weight=0.5, )
[paddle error] paddle.Tensor.lerp(x=Tensor([0],"float32"), y=Tensor([0],"float32"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:06:31.024618 GPU 1 27127 test begin: paddle.Tensor.lerp(x=Tensor([0],"float64"), y=Tensor([0],"float64"), weight=0.5, )
[paddle error] paddle.Tensor.lerp(x=Tensor([0],"float64"), y=Tensor([0],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:06:31.280954 GPU 0 27194 test begin: paddle.Tensor.lerp(x=Tensor([4, 0, 4, 3],"float64"), y=Tensor([4, 0, 4, 3],"float64"), weight=0.0, )
[paddle error] paddle.Tensor.lerp(x=Tensor([4, 0, 4, 3],"float64"), y=Tensor([4, 0, 4, 3],"float64"), weight=0.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:06:31.329675 GPU 1 27127 test begin: paddle.Tensor.lerp(x=Tensor([4, 0, 4, 3],"float64"), y=Tensor([4, 0, 4, 3],"float64"), weight=0.5, )
[paddle error] paddle.Tensor.lerp(x=Tensor([4, 0, 4, 3],"float64"), y=Tensor([4, 0, 4, 3],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:06:31.364149 GPU 0 27054 test begin: paddle.Tensor.lerp(x=Tensor([4, 0, 4, 3],"float64"), y=Tensor([4, 0, 4, 3],"float64"), weight=1.0, )
[paddle error] paddle.Tensor.lerp(x=Tensor([4, 0, 4, 3],"float64"), y=Tensor([4, 0, 4, 3],"float64"), weight=1.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:06:31.535703 GPU 0 27194 test begin: paddle.Tensor.lerp(x=Tensor([4, 0, 4],"float64"), y=Tensor([4, 0, 4],"float64"), weight=0.5, )
[paddle error] paddle.Tensor.lerp(x=Tensor([4, 0, 4],"float64"), y=Tensor([4, 0, 4],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:06:31.564685 GPU 1 27127 test begin: paddle.Tensor.lerp(x=Tensor([4, 0],"float64"), y=Tensor([1],"float64"), weight=0.2, )
[paddle error] paddle.Tensor.lerp(x=Tensor([4, 0],"float64"), y=Tensor([1],"float64"), weight=0.2, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:06:31.653921 GPU 0 27054 test begin: paddle.Tensor.lerp(x=Tensor([4, 0],"float64"), y=Tensor([4, 0],"float64"), weight=0.5, )
[paddle error] paddle.Tensor.lerp(x=Tensor([4, 0],"float64"), y=Tensor([4, 0],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:06:31.768097 GPU 0 27194 test begin: paddle.Tensor.lerp(x=Tensor([4, 5, 0, 3],"float64"), y=Tensor([4, 5, 0, 3],"float64"), weight=0.0, )
[paddle error] paddle.Tensor.lerp(x=Tensor([4, 5, 0, 3],"float64"), y=Tensor([4, 5, 0, 3],"float64"), weight=0.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:06:31.802911 GPU 1 27127 test begin: paddle.Tensor.lerp(x=Tensor([4, 5, 0, 3],"float64"), y=Tensor([4, 5, 0, 3],"float64"), weight=0.5, )
[paddle error] paddle.Tensor.lerp(x=Tensor([4, 5, 0, 3],"float64"), y=Tensor([4, 5, 0, 3],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:06:31.912141 GPU 0 27054 test begin: paddle.Tensor.lerp(x=Tensor([4, 5, 0, 3],"float64"), y=Tensor([4, 5, 0, 3],"float64"), weight=1.0, )
[paddle error] paddle.Tensor.lerp(x=Tensor([4, 5, 0, 3],"float64"), y=Tensor([4, 5, 0, 3],"float64"), weight=1.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:06:32.035639 GPU 0 27194 test begin: paddle.Tensor.lerp(x=Tensor([4, 5, 0],"float64"), y=Tensor([4, 5, 0],"float64"), weight=0.5, )
[paddle error] paddle.Tensor.lerp(x=Tensor([4, 5, 0],"float64"), y=Tensor([4, 5, 0],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:06:32.050382 GPU 1 27127 test begin: paddle.Tensor.lerp(x=Tensor([4, 5, 4, 0],"float64"), y=Tensor([4, 5, 4, 0],"float64"), weight=0.0, )
[paddle error] paddle.Tensor.lerp(x=Tensor([4, 5, 4, 0],"float64"), y=Tensor([4, 5, 4, 0],"float64"), weight=0.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:06:32.264494 GPU 0 27054 test begin: paddle.Tensor.lerp(x=Tensor([4, 5, 4, 0],"float64"), y=Tensor([4, 5, 4, 0],"float64"), weight=0.5, )
[paddle error] paddle.Tensor.lerp(x=Tensor([4, 5, 4, 0],"float64"), y=Tensor([4, 5, 4, 0],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:06:32.756630 GPU 1 27215 test begin: paddle.Tensor.lerp(x=Tensor([4, 5, 4, 0],"float64"), y=Tensor([4, 5, 4, 0],"float64"), weight=1.0, )
[paddle error] paddle.Tensor.lerp(x=Tensor([4, 5, 4, 0],"float64"), y=Tensor([4, 5, 4, 0],"float64"), weight=1.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:06:32.862363 GPU 1 27127 test begin: paddle.Tensor.lu(Tensor([0, 3, 2, 2],"float64"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/_tensor.py:902: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.
LU, pivots = torch.lu(A, compute_pivots)
should be replaced with
LU, pivots = torch.linalg.lu_factor(A, compute_pivots)
and
LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)
should be replaced with
LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2053.)
  LU, pivots, infos = torch._lu_with_info(
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.lu(Tensor([0, 3, 2, 2],"float64"), ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/lu_kernel_impl.h:532)


2025-06-05 15:06:32.866171 GPU 0 27194 test begin: paddle.Tensor.lu(Tensor([0, 3, 3],"float64"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/_tensor.py:902: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.
LU, pivots = torch.lu(A, compute_pivots)
should be replaced with
LU, pivots = torch.linalg.lu_factor(A, compute_pivots)
and
LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)
should be replaced with
LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2053.)
  LU, pivots, infos = torch._lu_with_info(
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.lu(Tensor([0, 3, 3],"float64"), ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/lu_kernel_impl.h:532)


2025-06-05 15:06:32.909177 GPU 0 27054 test begin: paddle.Tensor.lu(Tensor([0, 3],"float32"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/_tensor.py:902: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.
LU, pivots = torch.lu(A, compute_pivots)
should be replaced with
LU, pivots = torch.linalg.lu_factor(A, compute_pivots)
and
LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)
should be replaced with
LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2053.)
  LU, pivots, infos = torch._lu_with_info(
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.lu(Tensor([0, 3],"float32"), ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/lu_kernel_impl.h:532)


2025-06-05 15:06:33.229921 GPU 1 27215 test begin: paddle.Tensor.lu(Tensor([0, 3],"float64"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/_tensor.py:902: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.
LU, pivots = torch.lu(A, compute_pivots)
should be replaced with
LU, pivots = torch.linalg.lu_factor(A, compute_pivots)
and
LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)
should be replaced with
LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2053.)
  LU, pivots, infos = torch._lu_with_info(
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.lu(Tensor([0, 3],"float64"), ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/lu_kernel_impl.h:532)


2025-06-05 15:06:33.430562 GPU 1 27127 test begin: paddle.Tensor.lu(Tensor([3, 0, 3],"float64"), )
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.lu(Tensor([3, 0, 3],"float64"), ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/lu_kernel_impl.h:532)


2025-06-05 15:06:33.447895 GPU 0 27194 test begin: paddle.Tensor.lu(Tensor([3, 0],"float32"), )
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.lu(Tensor([3, 0],"float32"), ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/lu_kernel_impl.h:532)


2025-06-05 15:06:33.507451 GPU 0 27054 test begin: paddle.Tensor.lu(Tensor([3, 0],"float64"), )
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.lu(Tensor([3, 0],"float64"), ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/lu_kernel_impl.h:532)


2025-06-05 15:06:33.703042 GPU 1 27127 test begin: paddle.Tensor.lu(Tensor([3, 3, 0],"float64"), )
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.lu(Tensor([3, 3, 0],"float64"), ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/lu_kernel_impl.h:532)


2025-06-05 15:06:33.748240 GPU 0 27194 test begin: paddle.Tensor.lu(Tensor([4, 0, 2, 2],"float64"), )
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.lu(Tensor([4, 0, 2, 2],"float64"), ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/lu_kernel_impl.h:532)


2025-06-05 15:06:33.796805 GPU 1 27215 test begin: paddle.Tensor.lu(Tensor([4, 3, 0, 2],"float64"), )
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.lu(Tensor([4, 3, 0, 2],"float64"), ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/lu_kernel_impl.h:532)


2025-06-05 15:06:33.879707 GPU 0 27054 test begin: paddle.Tensor.lu(Tensor([4, 3, 2, 0],"float64"), )
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.lu(Tensor([4, 3, 2, 0],"float64"), ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/lu_kernel_impl.h:532)


2025-06-05 15:06:33.990677 GPU 0 27194 test begin: paddle.Tensor.matmul(Tensor([0, 100, 1],"float64"), Tensor([0, 1, 40],"float64"), )
[accuracy error] paddle.Tensor.matmul(Tensor([0, 100, 1],"float64"), Tensor([0, 1, 40],"float64"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'shape' do not match: torch.Size([0, 100, 1, 40]) != torch.Size([0, 100, 40]).
ACTUAL: (shape=torch.Size([0, 100, 1, 40]), dtype=torch.float64)
tensor([], size=(0, 100, 1, 40), dtype=torch.float64)
DESIRED: (shape=torch.Size([0, 100, 40]), dtype=torch.float64)
tensor([], size=(0, 100, 40), dtype=torch.float64)

2025-06-05 15:06:34.014731 GPU 1 27127 test begin: paddle.Tensor.matmul(Tensor([0, 100, 1],"float64"), Tensor([0, 1, 4],"float64"), )
[accuracy error] paddle.Tensor.matmul(Tensor([0, 100, 1],"float64"), Tensor([0, 1, 4],"float64"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'shape' do not match: torch.Size([0, 100, 1, 4]) != torch.Size([0, 100, 4]).
ACTUAL: (shape=torch.Size([0, 100, 1, 4]), dtype=torch.float64)
tensor([], size=(0, 100, 1, 4), dtype=torch.float64)
DESIRED: (shape=torch.Size([0, 100, 4]), dtype=torch.float64)
tensor([], size=(0, 100, 4), dtype=torch.float64)

2025-06-05 15:06:34.151587 GPU 0 27054 test begin: paddle.Tensor.matmul(Tensor([0, 100, 1],"float64"), Tensor([1, 1, 40],"float64"), )
[accuracy error] paddle.Tensor.matmul(Tensor([0, 100, 1],"float64"), Tensor([1, 1, 40],"float64"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'shape' do not match: torch.Size([0, 100, 1, 40]) != torch.Size([0, 100, 40]).
ACTUAL: (shape=torch.Size([0, 100, 1, 40]), dtype=torch.float64)
tensor([], size=(0, 100, 1, 40), dtype=torch.float64)
DESIRED: (shape=torch.Size([0, 100, 40]), dtype=torch.float64)
tensor([], size=(0, 100, 40), dtype=torch.float64)

2025-06-05 15:06:34.251023 GPU 0 27194 test begin: paddle.Tensor.matmul(Tensor([0, 100, 1],"float64"), Tensor([1, 1, 4],"float64"), )
[accuracy error] paddle.Tensor.matmul(Tensor([0, 100, 1],"float64"), Tensor([1, 1, 4],"float64"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'shape' do not match: torch.Size([0, 100, 1, 4]) != torch.Size([0, 100, 4]).
ACTUAL: (shape=torch.Size([0, 100, 1, 4]), dtype=torch.float64)
tensor([], size=(0, 100, 1, 4), dtype=torch.float64)
DESIRED: (shape=torch.Size([0, 100, 4]), dtype=torch.float64)
tensor([], size=(0, 100, 4), dtype=torch.float64)

2025-06-05 15:06:34.262256 GPU 1 27215 test begin: paddle.Tensor.matmul(Tensor([0, 12, 197, 197],"float32"), Tensor([0, 12, 197, 64],"float32"), )
[accuracy error] paddle.Tensor.matmul(Tensor([0, 12, 197, 197],"float32"), Tensor([0, 12, 197, 64],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'shape' do not match: torch.Size([0, 12, 197, 12, 197, 64]) != torch.Size([0, 12, 197, 64]).
ACTUAL: (shape=torch.Size([0, 12, 197, 12, 197, 64]), dtype=torch.float32)
tensor([], size=(0, 12, 197, 12, 197, 64))
DESIRED: (shape=torch.Size([0, 12, 197, 64]), dtype=torch.float32)
tensor([], size=(0, 12, 197, 64))

2025-06-05 15:06:34.273818 GPU 1 27127 test begin: paddle.Tensor.matmul(Tensor([1, 0, 1],"float64"), Tensor([1, 1, 40],"float64"), )
[accuracy error] paddle.Tensor.matmul(Tensor([1, 0, 1],"float64"), Tensor([1, 1, 40],"float64"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'shape' do not match: torch.Size([1, 0, 1, 40]) != torch.Size([1, 0, 40]).
ACTUAL: (shape=torch.Size([1, 0, 1, 40]), dtype=torch.float64)
tensor([], size=(1, 0, 1, 40), dtype=torch.float64)
DESIRED: (shape=torch.Size([1, 0, 40]), dtype=torch.float64)
tensor([], size=(1, 0, 40), dtype=torch.float64)

2025-06-05 15:06:34.445618 GPU 0 27054 test begin: paddle.Tensor.matmul(Tensor([1, 0, 1],"float64"), Tensor([1, 1, 4],"float64"), )
[accuracy error] paddle.Tensor.matmul(Tensor([1, 0, 1],"float64"), Tensor([1, 1, 4],"float64"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'shape' do not match: torch.Size([1, 0, 1, 4]) != torch.Size([1, 0, 4]).
ACTUAL: (shape=torch.Size([1, 0, 1, 4]), dtype=torch.float64)
tensor([], size=(1, 0, 1, 4), dtype=torch.float64)
DESIRED: (shape=torch.Size([1, 0, 4]), dtype=torch.float64)
tensor([], size=(1, 0, 4), dtype=torch.float64)

2025-06-05 15:06:34.499267 GPU 1 27214 test begin: paddle.Tensor.matmul(Tensor([1, 100, 1],"float64"), Tensor([0, 1, 40],"float64"), )
[accuracy error] paddle.Tensor.matmul(Tensor([1, 100, 1],"float64"), Tensor([0, 1, 40],"float64"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'shape' do not match: torch.Size([1, 100, 1, 40]) != torch.Size([0, 100, 40]).
ACTUAL: (shape=torch.Size([1, 100, 1, 40]), dtype=torch.float64)
tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
            0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00, 4.9407e-324,  ...,  0.0000e+00,
            0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
            0.0000e+00,  0.0000e+00]],

         ...,

         [[1.3751e-314, 4.9407e-324, 1.3751e-314,  ..., 9.6837e-322,
            0.0000e+00, 1.1858e-322]],

         [[6.9084e-310, 4.9407e-324,  0.0000e+00,  ..., 3.3952e-313,
           5.7294e-313, 1.1858e-322]],

         [[6.9081e-310, 4.9407e-324,  0.0000e+00,  ..., 4.9407e-324,
            0.0000e+00, 1.6976e-313]]]], dtype=torch.float64)
DESIRED: (shape=torch.Size([0, 100, 40]), dtype=torch.float64)
tensor([], size=(0, 100, 40), dtype=torch.float64)

2025-06-05 15:06:34.529601 GPU 1 27127 test begin: paddle.Tensor.matmul(Tensor([1, 100, 1],"float64"), Tensor([0, 1, 4],"float64"), )
[accuracy error] paddle.Tensor.matmul(Tensor([1, 100, 1],"float64"), Tensor([0, 1, 4],"float64"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'shape' do not match: torch.Size([1, 100, 1, 4]) != torch.Size([0, 100, 4]).
ACTUAL: (shape=torch.Size([1, 100, 1, 4]), dtype=torch.float64)
tensor([[[[0., 0., 0., 0.]],

         [[0., 0., 0., 0.]],

         [[0., 0., 0., 0.]],

         ...,

         [[0., 0., 0., 0.]],

         [[0., 0., 0., 0.]],

         [[0., 0., 0., 0.]]]], dtype=torch.float64)
DESIRED: (shape=torch.Size([0, 100, 4]), dtype=torch.float64)
tensor([], size=(0, 100, 4), dtype=torch.float64)

2025-06-05 15:06:34.610449 GPU 0 27194 test begin: paddle.Tensor.matmul(Tensor([1, 100, 1],"float64"), Tensor([1, 1, 0],"float64"), )
[accuracy error] paddle.Tensor.matmul(Tensor([1, 100, 1],"float64"), Tensor([1, 1, 0],"float64"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'shape' do not match: torch.Size([1, 100, 1, 0]) != torch.Size([1, 100, 0]).
ACTUAL: (shape=torch.Size([1, 100, 1, 0]), dtype=torch.float64)
tensor([], size=(1, 100, 1, 0), dtype=torch.float64)
DESIRED: (shape=torch.Size([1, 100, 0]), dtype=torch.float64)
tensor([], size=(1, 100, 0), dtype=torch.float64)

2025-06-05 15:06:34.617238 GPU 1 27215 test begin: paddle.Tensor.matmul(Tensor([112, 0, 197, 197],"float32"), Tensor([112, 0, 197, 64],"float32"), )
[accuracy error] paddle.Tensor.matmul(Tensor([112, 0, 197, 197],"float32"), Tensor([112, 0, 197, 64],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'shape' do not match: torch.Size([112, 0, 197, 0, 197, 64]) != torch.Size([112, 0, 197, 64]).
ACTUAL: (shape=torch.Size([112, 0, 197, 0, 197, 64]), dtype=torch.float32)
tensor([], size=(112, 0, 197, 0, 197, 64))
DESIRED: (shape=torch.Size([112, 0, 197, 64]), dtype=torch.float32)
tensor([], size=(112, 0, 197, 64))

2025-06-05 15:06:34.801935 GPU 0 27054 test begin: paddle.Tensor.matmul(Tensor([112, 12, 0, 197],"float32"), Tensor([112, 12, 197, 64],"float32"), )
[accuracy error] paddle.Tensor.matmul(Tensor([112, 12, 0, 197],"float32"), Tensor([112, 12, 197, 64],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'shape' do not match: torch.Size([112, 12, 0, 12, 197, 64]) != torch.Size([112, 12, 0, 64]).
ACTUAL: (shape=torch.Size([112, 12, 0, 12, 197, 64]), dtype=torch.float32)
tensor([], size=(112, 12, 0, 12, 197, 64))
DESIRED: (shape=torch.Size([112, 12, 0, 64]), dtype=torch.float32)
tensor([], size=(112, 12, 0, 64))

2025-06-05 15:06:34.836141 GPU 1 27214 test begin: paddle.Tensor.matmul(Tensor([112, 12, 197, 197],"float32"), Tensor([112, 12, 197, 0],"float32"), )
[accuracy error] paddle.Tensor.matmul(Tensor([112, 12, 197, 197],"float32"), Tensor([112, 12, 197, 0],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'shape' do not match: torch.Size([112, 12, 197, 12, 197, 0]) != torch.Size([112, 12, 197, 0]).
ACTUAL: (shape=torch.Size([112, 12, 197, 12, 197, 0]), dtype=torch.float32)
tensor([], size=(112, 12, 197, 12, 197, 0))
DESIRED: (shape=torch.Size([112, 12, 197, 0]), dtype=torch.float32)
tensor([], size=(112, 12, 197, 0))

2025-06-05 15:06:34.849502 GPU 1 27127 test begin: paddle.Tensor.median(Tensor([0, 784],"float32"), )
[paddle error] paddle.Tensor.median(Tensor([0, 784],"float32"), ) 
 In median, the size of input x should not be 0.

2025-06-05 15:06:34.862666 GPU 1 27215 test begin: paddle.Tensor.median(Tensor([1000, 0],"float32"), )
[paddle error] paddle.Tensor.median(Tensor([1000, 0],"float32"), ) 
 In median, the size of input x should not be 0.

2025-06-05 15:06:34.881713 GPU 0 27194 test begin: paddle.Tensor.mode(Tensor([0, 2, 3],"float64"), )
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.mode(Tensor([0, 2, 3],"float64"), ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < in_dims[i], but received 0:0 >= in_dims[i]:0.] (at ../paddle/phi/kernels/cpu/mode_kernel.cc:33)


2025-06-05 15:06:35.218068 GPU 1 27303 test begin: paddle.Tensor.mode(Tensor([0, 2, 3],"float64"), axis=1, keepdim=False, )
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.mode(Tensor([0, 2, 3],"float64"), axis=1, keepdim=False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < in_dims[i], but received 0:0 >= in_dims[i]:0.] (at ../paddle/phi/kernels/cpu/mode_kernel.cc:33)


2025-06-05 15:06:35.230606 GPU 0 27280 test begin: paddle.Tensor.mode(Tensor([0, 2, 3],"float64"), axis=2, keepdim=True, )
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.mode(Tensor([0, 2, 3],"float64"), axis=2, keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < in_dims[i], but received 0:0 >= in_dims[i]:0.] (at ../paddle/phi/kernels/cpu/mode_kernel.cc:33)


2025-06-05 15:06:35.378098 GPU 0 27194 test begin: paddle.Tensor.mode(Tensor([3, 0, 3],"float64"), )
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.mode(Tensor([3, 0, 3],"float64"), ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < in_dims[i], but received 0:0 >= in_dims[i]:0.] (at ../paddle/phi/kernels/cpu/mode_kernel.cc:33)


2025-06-05 15:06:35.442775 GPU 0 27281 test begin: paddle.Tensor.mode(Tensor([3, 0, 3],"float64"), axis=2, keepdim=True, )
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.mode(Tensor([3, 0, 3],"float64"), axis=2, keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < in_dims[i], but received 0:0 >= in_dims[i]:0.] (at ../paddle/phi/kernels/cpu/mode_kernel.cc:33)


2025-06-05 15:06:35.485850 GPU 1 27303 test begin: paddle.Tensor.mode(Tensor([3, 2, 0],"float64"), axis=1, keepdim=False, )
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.mode(Tensor([3, 2, 0],"float64"), axis=1, keepdim=False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < in_dims[i], but received 0:0 >= in_dims[i]:0.] (at ../paddle/phi/kernels/cpu/mode_kernel.cc:33)


2025-06-05 15:06:35.540661 GPU 1 27127 test begin: paddle.Tensor.std(Tensor([0, 1024, 8],"float32"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0605 15:06:36.487180 27127 dygraph_functions.cc:85403] got different data type, run type promotion automatically, this may cause data type been changed.
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/paddle/tensor/stat.py:277: UserWarning: Degrees of freedom is <= 0.
  out = var(**locals())
[accuracy error] paddle.Tensor.std(Tensor([0, 1024, 8],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected nan but got -0.0.
Absolute difference: nan (up to 0.01 allowed)
Relative difference: nan (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
-0.0
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
nan

2025-06-05 15:06:35.629822 GPU 0 27280 test begin: paddle.Tensor.std(Tensor([0, 1024, 8],"float64"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0605 15:06:36.445768 27280 dygraph_functions.cc:85403] got different data type, run type promotion automatically, this may cause data type been changed.
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/paddle/tensor/stat.py:277: UserWarning: Degrees of freedom is <= 0.
  out = var(**locals())
[accuracy error] paddle.Tensor.std(Tensor([0, 1024, 8],"float64"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected nan but got -0.0.
Absolute difference: nan (up to 0.01 allowed)
Relative difference: nan (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float64)
-0.0
DESIRED: (shape=torch.Size([]), dtype=torch.float64)
nan

2025-06-05 15:06:35.872645 GPU 0 27194 test begin: paddle.Tensor.std(Tensor([1, 1, 0],"float32"), axis=-1, keepdim=True, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0605 15:06:36.361812 27194 dygraph_functions.cc:85403] got different data type, run type promotion automatically, this may cause data type been changed.
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/paddle/tensor/stat.py:277: UserWarning: Degrees of freedom is <= 0.
  out = var(**locals())
[accuracy error] paddle.Tensor.std(Tensor([1, 1, 0],"float32"), axis=-1, keepdim=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 1 / 1 (100.0%)
Greatest absolute difference: nan at index (0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1, 1]), dtype=torch.float32)
tensor([[[-0.]]])
DESIRED: (shape=torch.Size([1, 1, 1]), dtype=torch.float32)
tensor([[[nan]]])

2025-06-05 15:06:35.923235 GPU 1 28416 test begin: paddle.Tensor.std(Tensor([1024, 0, 8],"float32"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0605 15:06:58.616395 28416 dygraph_functions.cc:85403] got different data type, run type promotion automatically, this may cause data type been changed.
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/paddle/tensor/stat.py:277: UserWarning: Degrees of freedom is <= 0.
  out = var(**locals())
[accuracy error] paddle.Tensor.std(Tensor([1024, 0, 8],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected nan but got -0.0.
Absolute difference: nan (up to 0.01 allowed)
Relative difference: nan (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
-0.0
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
nan

2025-06-05 15:06:35.973772 GPU 1 27303 test begin: paddle.Tensor.std(Tensor([1024, 0, 8],"float64"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0605 15:06:36.361833 27303 dygraph_functions.cc:85403] got different data type, run type promotion automatically, this may cause data type been changed.
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/paddle/tensor/stat.py:277: UserWarning: Degrees of freedom is <= 0.
  out = var(**locals())
[accuracy error] paddle.Tensor.std(Tensor([1024, 0, 8],"float64"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected nan but got -0.0.
Absolute difference: nan (up to 0.01 allowed)
Relative difference: nan (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float64)
-0.0
DESIRED: (shape=torch.Size([]), dtype=torch.float64)
nan

2025-06-05 15:06:35.974900 GPU 0 27356 test begin: paddle.Tensor.std(Tensor([1024, 1024, 0],"float32"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0605 15:06:36.487661 27356 dygraph_functions.cc:85403] got different data type, run type promotion automatically, this may cause data type been changed.
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/paddle/tensor/stat.py:277: UserWarning: Degrees of freedom is <= 0.
  out = var(**locals())
[accuracy error] paddle.Tensor.std(Tensor([1024, 1024, 0],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected nan but got -0.0.
Absolute difference: nan (up to 0.01 allowed)
Relative difference: nan (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
-0.0
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
nan

2025-06-05 15:06:35.985842 GPU 1 27215 test begin: paddle.Tensor.std(Tensor([1024, 1024, 0],"float64"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0605 15:06:36.445549 27215 dygraph_functions.cc:85403] got different data type, run type promotion automatically, this may cause data type been changed.
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/paddle/tensor/stat.py:277: UserWarning: Degrees of freedom is <= 0.
  out = var(**locals())
[accuracy error] paddle.Tensor.std(Tensor([1024, 1024, 0],"float64"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected nan but got -0.0.
Absolute difference: nan (up to 0.01 allowed)
Relative difference: nan (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float64)
-0.0
DESIRED: (shape=torch.Size([]), dtype=torch.float64)
nan

2025-06-05 15:06:36.115618 GPU 0 27281 test begin: paddle.Tensor.topk(Tensor([0, 1000],"float32"), 5, 1, True, True, )
element 1 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.topk(Tensor([0, 1000],"float32"), 5, 1, True, True, ) 
 (InvalidArgument) x has only 0 element, can not find 5 top values.
  [Hint: Expected x.numel() >= k, but received x.numel():0 < k:5.] (at ../paddle/phi/kernels/cpu/top_k_kernel.cc:156)


2025-06-05 15:06:36.380277 GPU 0 27054 test begin: paddle.Tensor.var(Tensor([0, 2, 3],"float32"), axis=0, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0605 15:06:36.901901 27054 dygraph_functions.cc:85403] got different data type, run type promotion automatically, this may cause data type been changed.
/root/paddlejob/PaddleAPITest-dev/tester/accuracy.py:197: UserWarning: Degrees of freedom is <= 0.
  paddle_output = api(*self.paddle_args[1:], **self.paddle_kwargs)
[accuracy error] paddle.Tensor.var(Tensor([0, 2, 3],"float32"), axis=0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 6 / 6 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 3]), dtype=torch.float32)
tensor([[-0., -0., -0.],
        [-0., -0., -0.]])
DESIRED: (shape=torch.Size([2, 3]), dtype=torch.float32)
tensor([[nan, nan, nan],
        [nan, nan, nan]])

2025-06-05 15:06:36.555740 GPU 1 28432 test begin: paddle.Tensor.var(Tensor([0, 2, 3],"float64"), axis=0, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0605 15:07:00.874969 28432 dygraph_functions.cc:85403] got different data type, run type promotion automatically, this may cause data type been changed.
/root/paddlejob/PaddleAPITest-dev/tester/accuracy.py:197: UserWarning: Degrees of freedom is <= 0.
  paddle_output = api(*self.paddle_args[1:], **self.paddle_kwargs)
[accuracy error] paddle.Tensor.var(Tensor([0, 2, 3],"float64"), axis=0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 6 / 6 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 3]), dtype=torch.float64)
tensor([[-0., -0., -0.],
        [-0., -0., -0.]], dtype=torch.float64)
DESIRED: (shape=torch.Size([2, 3]), dtype=torch.float64)
tensor([[nan, nan, nan],
        [nan, nan, nan]], dtype=torch.float64)

2025-06-05 15:06:36.566558 GPU 1 27215 test begin: paddle.Tensor.var(Tensor([0, 4],"float64"), axis=0, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
/root/paddlejob/PaddleAPITest-dev/tester/accuracy.py:197: UserWarning: Degrees of freedom is <= 0.
  paddle_output = api(*self.paddle_args[1:], **self.paddle_kwargs)
[accuracy error] paddle.Tensor.var(Tensor([0, 4],"float64"), axis=0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: nan at index (0,) (up to 0.01 allowed)
Greatest relative difference: nan at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4]), dtype=torch.float64)
tensor([-0., -0., -0., -0.], dtype=torch.float64)
DESIRED: (shape=torch.Size([4]), dtype=torch.float64)
tensor([nan, nan, nan, nan], dtype=torch.float64)

2025-06-05 15:06:36.582619 GPU 0 27280 test begin: paddle.Tensor.var(Tensor([0, 784],"float32"), axis=0, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
/root/paddlejob/PaddleAPITest-dev/tester/accuracy.py:197: UserWarning: Degrees of freedom is <= 0.
  paddle_output = api(*self.paddle_args[1:], **self.paddle_kwargs)
[accuracy error] paddle.Tensor.var(Tensor([0, 784],"float32"), axis=0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 784 / 784 (100.0%)
Greatest absolute difference: nan at index (0,) (up to 0.01 allowed)
Greatest relative difference: nan at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([784]), dtype=torch.float32)
tensor([-0., -0., -0.,  ..., -0., -0., -0.])
DESIRED: (shape=torch.Size([784]), dtype=torch.float32)
tensor([nan, nan, nan,  ..., nan, nan, nan])

2025-06-05 15:06:36.600195 GPU 1 27303 test begin: paddle.Tensor.var(Tensor([0],"float32"), axis=0, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
/root/paddlejob/PaddleAPITest-dev/tester/accuracy.py:197: UserWarning: Degrees of freedom is <= 0.
  paddle_output = api(*self.paddle_args[1:], **self.paddle_kwargs)
[accuracy error] paddle.Tensor.var(Tensor([0],"float32"), axis=0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected nan but got -0.0.
Absolute difference: nan (up to 0.01 allowed)
Relative difference: nan (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
-0.0
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
nan

2025-06-05 15:06:36.623647 GPU 0 27281 test begin: paddle.Tensor.var(Tensor([0],"float64"), axis=0, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0605 15:06:36.968961 27281 dygraph_functions.cc:85403] got different data type, run type promotion automatically, this may cause data type been changed.
/root/paddlejob/PaddleAPITest-dev/tester/accuracy.py:197: UserWarning: Degrees of freedom is <= 0.
  paddle_output = api(*self.paddle_args[1:], **self.paddle_kwargs)
[accuracy error] paddle.Tensor.var(Tensor([0],"float64"), axis=0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected nan but got -0.0.
Absolute difference: nan (up to 0.01 allowed)
Relative difference: nan (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float64)
-0.0
DESIRED: (shape=torch.Size([]), dtype=torch.float64)
nan

2025-06-05 15:06:36.630504 GPU 1 27295 test begin: paddle.addmm(input=Tensor([1, 1],"float64"), x=Tensor([0, 4],"float64"), y=Tensor([4, 5],"float64"), beta=-3.3, alpha=3.3, )
[paddle error] paddle.addmm(input=Tensor([1, 1],"float64"), x=Tensor([0, 4],"float64"), y=Tensor([4, 5],"float64"), beta=-3.3, alpha=3.3, ) 
 (PreconditionNotMet) The Input variable 'x' has not been initialized. You may need to confirm if you put exe.run(startup_program) after optimizer.minimize function.
  [Hint: Expected product(x_dims) != 0, but received product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/ternary.cc:109)


2025-06-05 15:06:36.633761 GPU 1 27127 test begin: paddle.addmm(input=Tensor([1, 1],"float64"), x=Tensor([5, 4],"float64"), y=Tensor([4, 0],"float64"), beta=-3.3, alpha=3.3, )
[paddle error] paddle.addmm(input=Tensor([1, 1],"float64"), x=Tensor([5, 4],"float64"), y=Tensor([4, 0],"float64"), beta=-3.3, alpha=3.3, ) 
 (PreconditionNotMet) The Input variable 'y' has not been initialized. You may need to confirm if you put exe.run(startup_program) after optimizer.minimize function.
  [Hint: Expected product(y_dims) != 0, but received product(y_dims):0 == 0:0.] (at ../paddle/phi/infermeta/ternary.cc:117)


2025-06-05 15:06:36.636350 GPU 0 27356 test begin: paddle.addmm(input=Tensor([5, 1],"float64"), x=Tensor([5, 4],"float64"), y=Tensor([4, 0],"float64"), beta=-3.3, alpha=3.3, )
[paddle error] paddle.addmm(input=Tensor([5, 1],"float64"), x=Tensor([5, 4],"float64"), y=Tensor([4, 0],"float64"), beta=-3.3, alpha=3.3, ) 
 (PreconditionNotMet) The Input variable 'y' has not been initialized. You may need to confirm if you put exe.run(startup_program) after optimizer.minimize function.
  [Hint: Expected product(y_dims) != 0, but received product(y_dims):0 == 0:0.] (at ../paddle/phi/infermeta/ternary.cc:117)


2025-06-05 15:06:36.637640 GPU 1 28446 test begin: paddle.amax(Tensor([0, 10, 10],"float32"), axis=list[-1,-2,], keepdim=False, )
[paddle error] paddle.amax(Tensor([0, 10, 10],"float32"), axis=list[-1,-2,], keepdim=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:06:36.664490 GPU 0 27194 test begin: paddle.amax(Tensor([0, 2, 4, 5],"float32"), axis=-1, keepdim=True, )
[paddle error] paddle.amax(Tensor([0, 2, 4, 5],"float32"), axis=-1, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:06:36.894231 GPU 1 27214 test begin: paddle.amax(Tensor([0, 2, 5, 4],"float32"), axis=2, keepdim=True, )
[paddle error] paddle.amax(Tensor([0, 2, 5, 4],"float32"), axis=2, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:06:36.905937 GPU 1 27215 test begin: paddle.amax(Tensor([0, 2, 5, 4],"float32"), axis=tuple(1,2,), keepdim=True, )
[paddle error] paddle.amax(Tensor([0, 2, 5, 4],"float32"), axis=tuple(1,2,), keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:06:36.971198 GPU 0 27280 test begin: paddle.amax(Tensor([0, 4],"float64"), 1, True, )
[paddle error] paddle.amax(Tensor([0, 4],"float64"), 1, True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:06:36.996879 GPU 0 27194 test begin: paddle.amax(Tensor([10, 0, 10],"float32"), axis=list[-1,0,], keepdim=False, )
[paddle error] paddle.amax(Tensor([10, 0, 10],"float32"), axis=list[-1,0,], keepdim=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:06:37.013941 GPU 1 27127 test begin: paddle.amax(Tensor([10, 10, 0],"float32"), axis=list[0,1,], keepdim=False, )
[paddle error] paddle.amax(Tensor([10, 10, 0],"float32"), axis=list[0,1,], keepdim=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:06:37.049524 GPU 0 27054 test begin: paddle.amax(Tensor([2, 0],"float64"), 0, False, )
[paddle error] paddle.amax(Tensor([2, 0],"float64"), 0, False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:06:37.079644 GPU 1 27303 test begin: paddle.amax(Tensor([2, 2, 0],"int32"), tuple(0,1,), False, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.amax(Tensor([2, 2, 0],"int32"), tuple(0,1,), False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:06:37.102877 GPU 1 27295 test begin: paddle.amax(Tensor([3, 0, 4, 5],"float32"), axis=-1, keepdim=True, )
[paddle error] paddle.amax(Tensor([3, 0, 4, 5],"float32"), axis=-1, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:06:37.169973 GPU 0 27281 test begin: paddle.amax(Tensor([3, 0, 5, 4],"float32"), axis=2, keepdim=True, )
[paddle error] paddle.amax(Tensor([3, 0, 5, 4],"float32"), axis=2, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:06:37.180241 GPU 0 27356 test begin: paddle.amax(Tensor([3, 2, 0, 5],"float32"), axis=-1, keepdim=True, )
[paddle error] paddle.amax(Tensor([3, 2, 0, 5],"float32"), axis=-1, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:06:37.189457 GPU 0 27280 test begin: paddle.amax(Tensor([3, 2, 5, 0],"float32"), axis=2, keepdim=True, )
[paddle error] paddle.amax(Tensor([3, 2, 5, 0],"float32"), axis=2, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:06:37.225020 GPU 1 27214 test begin: paddle.amax(Tensor([3, 2, 5, 0],"float32"), axis=tuple(1,2,), keepdim=True, )
[paddle error] paddle.amax(Tensor([3, 2, 5, 0],"float32"), axis=tuple(1,2,), keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:06:37.254726 GPU 1 27127 test begin: paddle.amin(Tensor([0, 10, 10],"float32"), axis=list[-1,-2,], keepdim=False, )
[paddle error] paddle.amin(Tensor([0, 10, 10],"float32"), axis=list[-1,-2,], keepdim=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:06:37.260138 GPU 0 27194 test begin: paddle.amin(Tensor([0, 2, 4, 5],"float32"), axis=-1, keepdim=True, )
[paddle error] paddle.amin(Tensor([0, 2, 4, 5],"float32"), axis=-1, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:06:37.264468 GPU 1 27215 test begin: paddle.amin(Tensor([0, 2, 5, 4],"float32"), axis=2, keepdim=True, )
[paddle error] paddle.amin(Tensor([0, 2, 5, 4],"float32"), axis=2, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:06:37.405347 GPU 1 27303 test begin: paddle.amin(Tensor([0, 2, 5, 4],"float32"), axis=tuple(1,2,), keepdim=True, )
[paddle error] paddle.amin(Tensor([0, 2, 5, 4],"float32"), axis=tuple(1,2,), keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:06:37.430995 GPU 0 27054 test begin: paddle.amin(Tensor([0, 4],"float64"), 1, True, )
[paddle error] paddle.amin(Tensor([0, 4],"float64"), 1, True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:06:37.436490 GPU 0 27280 test begin: paddle.amin(Tensor([10, 0, 10],"float32"), axis=list[-1,0,], keepdim=False, )
[paddle error] paddle.amin(Tensor([10, 0, 10],"float32"), axis=list[-1,0,], keepdim=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:06:37.448891 GPU 1 27295 test begin: paddle.amin(Tensor([10, 10, 0],"float32"), axis=list[0,1,], keepdim=False, )
[paddle error] paddle.amin(Tensor([10, 10, 0],"float32"), axis=list[0,1,], keepdim=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:06:37.556770 GPU 1 27127 test begin: paddle.amin(Tensor([2, 0],"float64"), 0, False, )
[paddle error] paddle.amin(Tensor([2, 0],"float64"), 0, False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:06:37.590676 GPU 1 27215 test begin: paddle.amin(Tensor([2, 2, 0],"int32"), tuple(0,1,), False, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.amin(Tensor([2, 2, 0],"int32"), tuple(0,1,), False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:06:37.607050 GPU 0 27281 test begin: paddle.amin(Tensor([3, 0, 4, 5],"float32"), axis=-1, keepdim=True, )
[paddle error] paddle.amin(Tensor([3, 0, 4, 5],"float32"), axis=-1, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:06:37.683392 GPU 0 27194 test begin: paddle.amin(Tensor([3, 0, 5, 4],"float32"), axis=2, keepdim=True, )
[paddle error] paddle.amin(Tensor([3, 0, 5, 4],"float32"), axis=2, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:06:37.714283 GPU 1 27303 test begin: paddle.amin(Tensor([3, 2, 0, 5],"float32"), axis=-1, keepdim=True, )
[paddle error] paddle.amin(Tensor([3, 2, 0, 5],"float32"), axis=-1, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:06:37.724333 GPU 1 27214 test begin: paddle.amin(Tensor([3, 2, 5, 0],"float32"), axis=2, keepdim=True, )
[paddle error] paddle.amin(Tensor([3, 2, 5, 0],"float32"), axis=2, keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:06:37.724430 GPU 0 27280 test begin: paddle.amin(Tensor([3, 2, 5, 0],"float32"), axis=tuple(1,2,), keepdim=True, )
[paddle error] paddle.amin(Tensor([3, 2, 5, 0],"float32"), axis=tuple(1,2,), keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:06:37.729890 GPU 0 27356 test begin: paddle.argmax(Tensor([0, 1000],"float32"), axis=1, )
[paddle error] paddle.argmax(Tensor([0, 1000],"float32"), axis=1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:37.732591 GPU 0 27054 test begin: paddle.argmax(Tensor([0, 100],"float32"), axis=-1, )
[paddle error] paddle.argmax(Tensor([0, 100],"float32"), axis=-1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:37.861928 GPU 1 27295 test begin: paddle.argmax(Tensor([0, 10],"float32"), axis=-1, keepdim=True, )
[paddle error] paddle.argmax(Tensor([0, 10],"float32"), axis=-1, keepdim=True, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:37.902457 GPU 0 27450 test begin: paddle.argmax(Tensor([0, 10],"float32"), axis=1, )
[paddle error] paddle.argmax(Tensor([0, 10],"float32"), axis=1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:37.929796 GPU 1 27215 test begin: paddle.argmax(Tensor([0, 2, 4, 16, 2],"float32"), axis=-1, )
[paddle error] paddle.argmax(Tensor([0, 2, 4, 16, 2],"float32"), axis=-1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.035652 GPU 1 27127 test begin: paddle.argmax(Tensor([0, 256],"float32"), axis=-1, )
[paddle error] paddle.argmax(Tensor([0, 256],"float32"), axis=-1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.091028 GPU 0 27054 test begin: paddle.argmax(Tensor([0, 3, 4],"float64"), axis=-1, keepdim=True, )
[paddle error] paddle.argmax(Tensor([0, 3, 4],"float64"), axis=-1, keepdim=True, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.105188 GPU 0 27425 test begin: paddle.argmax(Tensor([0, 32, 64],"float32"), axis=1, )
[paddle error] paddle.argmax(Tensor([0, 32, 64],"float32"), axis=1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.123923 GPU 0 27194 test begin: paddle.argmax(Tensor([0, 7, 99],"float32"), axis=-1, )
[paddle error] paddle.argmax(Tensor([0, 7, 99],"float32"), axis=-1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.130433 GPU 1 27303 test begin: paddle.argmax(Tensor([0, 8, 14, 12],"float32"), axis=1, keepdim=True, )
[paddle error] paddle.argmax(Tensor([0, 8, 14, 12],"float32"), axis=1, keepdim=True, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.165785 GPU 0 27281 test begin: paddle.argmax(Tensor([1, 8, 0, 12],"float32"), axis=1, keepdim=True, )
[paddle error] paddle.argmax(Tensor([1, 8, 0, 12],"float32"), axis=1, keepdim=True, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.198878 GPU 0 27450 test begin: paddle.argmax(Tensor([1, 8, 14, 0],"float32"), axis=1, keepdim=True, )
[paddle error] paddle.argmax(Tensor([1, 8, 14, 0],"float32"), axis=1, keepdim=True, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.219569 GPU 1 27295 test begin: paddle.argmax(Tensor([12988, 32, 0],"float32"), axis=1, )
[paddle error] paddle.argmax(Tensor([12988, 32, 0],"float32"), axis=1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.253753 GPU 1 27214 test begin: paddle.argmax(Tensor([13, 0, 4, 16, 2],"float32"), axis=-1, )
[paddle error] paddle.argmax(Tensor([13, 0, 4, 16, 2],"float32"), axis=-1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.282481 GPU 1 27215 test begin: paddle.argmax(Tensor([13, 0, 99],"float32"), axis=-1, )
[paddle error] paddle.argmax(Tensor([13, 0, 99],"float32"), axis=-1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.323505 GPU 0 27356 test begin: paddle.argmax(Tensor([13, 2, 0, 16, 2],"float32"), axis=-1, )
[paddle error] paddle.argmax(Tensor([13, 2, 0, 16, 2],"float32"), axis=-1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.378812 GPU 1 27127 test begin: paddle.argmax(Tensor([13, 2, 4, 0, 2],"float32"), axis=-1, )
[paddle error] paddle.argmax(Tensor([13, 2, 4, 0, 2],"float32"), axis=-1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.390685 GPU 0 27194 test begin: paddle.argmax(Tensor([2, 0, 4],"float64"), axis=-1, keepdim=True, )
[paddle error] paddle.argmax(Tensor([2, 0, 4],"float64"), axis=-1, keepdim=True, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.424698 GPU 0 27280 test begin: paddle.argmax(Tensor([3, 0, 3, 3, 3, 3],"float64"), axis=0, )
[paddle error] paddle.argmax(Tensor([3, 0, 3, 3, 3, 3],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.427725 GPU 0 27054 test begin: paddle.argmax(Tensor([3, 3, 0, 3, 3, 3],"float64"), axis=0, )
[paddle error] paddle.argmax(Tensor([3, 3, 0, 3, 3, 3],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.430414 GPU 1 27303 test begin: paddle.argmax(Tensor([3, 3, 3, 0, 3, 3],"float64"), axis=0, )
[paddle error] paddle.argmax(Tensor([3, 3, 3, 0, 3, 3],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.434396 GPU 0 27425 test begin: paddle.argmax(Tensor([3, 3, 3, 3, 0, 3],"float64"), axis=0, )
[paddle error] paddle.argmax(Tensor([3, 3, 3, 3, 0, 3],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.556523 GPU 0 27450 test begin: paddle.argmax(Tensor([3, 3, 3, 3, 3, 0],"float64"), axis=0, )
[paddle error] paddle.argmax(Tensor([3, 3, 3, 3, 3, 0],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.604963 GPU 1 27295 test begin: paddle.argmax(Tensor([4, 0, 4, 4, 4],"float64"), axis=0, )
[paddle error] paddle.argmax(Tensor([4, 0, 4, 4, 4],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.608820 GPU 1 27127 test begin: paddle.argmax(Tensor([4, 4, 0, 4, 4],"float64"), axis=0, )
[paddle error] paddle.argmax(Tensor([4, 4, 0, 4, 4],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.619133 GPU 0 27281 test begin: paddle.argmax(Tensor([4, 4, 4, 0, 4],"float64"), axis=0, )
[paddle error] paddle.argmax(Tensor([4, 4, 4, 0, 4],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.656562 GPU 1 27215 test begin: paddle.argmax(Tensor([4, 4, 4, 4, 0],"float64"), axis=0, )
[paddle error] paddle.argmax(Tensor([4, 4, 4, 4, 0],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.662361 GPU 0 27475 test begin: paddle.argmax(Tensor([5, 0, 5, 5],"float64"), axis=0, )
[paddle error] paddle.argmax(Tensor([5, 0, 5, 5],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.674659 GPU 0 27194 test begin: paddle.argmax(Tensor([5, 5, 0, 5],"float64"), axis=0, )
[paddle error] paddle.argmax(Tensor([5, 5, 0, 5],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.693287 GPU 1 27403 test begin: paddle.argmax(Tensor([5, 5, 5, 0],"float64"), axis=0, )
[paddle error] paddle.argmax(Tensor([5, 5, 5, 0],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.737778 GPU 1 27214 test begin: paddle.argmax(x=Tensor([0, 3, 4],"float64"), axis=1, keepdim=False, )
[paddle error] paddle.argmax(x=Tensor([0, 3, 4],"float64"), axis=1, keepdim=False, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.754021 GPU 0 27280 test begin: paddle.argmax(x=Tensor([0, 3],"int64"), axis=-1, )
[paddle error] paddle.argmax(x=Tensor([0, 3],"int64"), axis=-1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.764147 GPU 0 27054 test begin: paddle.argmax(x=Tensor([3, 0],"int64"), axis=-2, )
[paddle error] paddle.argmax(x=Tensor([3, 0],"int64"), axis=-2, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.791473 GPU 0 27425 test begin: paddle.argmax(x=Tensor([3, 3, 0],"float64"), axis=1, keepdim=False, )
[paddle error] paddle.argmax(x=Tensor([3, 3, 0],"float64"), axis=1, keepdim=False, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.795552 GPU 0 27356 test begin: paddle.argmin(Tensor([0, 10],"float32"), axis=-1, )
[paddle error] paddle.argmin(Tensor([0, 10],"float32"), axis=-1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.795633 GPU 1 27303 test begin: paddle.argmin(Tensor([0, 10],"float32"), axis=-1, keepdim=True, )
[paddle error] paddle.argmin(Tensor([0, 10],"float32"), axis=-1, keepdim=True, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.829522 GPU 1 27295 test begin: paddle.argmin(Tensor([0, 10],"float32"), axis=1, )
[paddle error] paddle.argmin(Tensor([0, 10],"float32"), axis=1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.831685 GPU 1 27127 test begin: paddle.argmin(Tensor([3, 0, 3, 3, 3, 3],"float64"), axis=0, )
[paddle error] paddle.argmin(Tensor([3, 0, 3, 3, 3, 3],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.839175 GPU 0 27450 test begin: paddle.argmin(Tensor([3, 3, 0, 3, 3, 3],"float64"), axis=0, )
[paddle error] paddle.argmin(Tensor([3, 3, 0, 3, 3, 3],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.889838 GPU 1 27215 test begin: paddle.argmin(Tensor([3, 3, 3, 0, 3, 3],"float64"), axis=0, )
[paddle error] paddle.argmin(Tensor([3, 3, 3, 0, 3, 3],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.909755 GPU 0 27475 test begin: paddle.argmin(Tensor([3, 3, 3, 3, 0, 3],"float64"), axis=0, )
[paddle error] paddle.argmin(Tensor([3, 3, 3, 3, 0, 3],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.914793 GPU 0 27194 test begin: paddle.argmin(Tensor([3, 3, 3, 3, 3, 0],"float64"), axis=0, )
[paddle error] paddle.argmin(Tensor([3, 3, 3, 3, 3, 0],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.915245 GPU 1 27403 test begin: paddle.argmin(Tensor([4, 0, 4, 4, 4],"float64"), axis=0, )
[paddle error] paddle.argmin(Tensor([4, 0, 4, 4, 4],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:38.992394 GPU 0 27281 test begin: paddle.argmin(Tensor([4, 4, 0, 4, 4],"float64"), axis=0, )
[paddle error] paddle.argmin(Tensor([4, 4, 0, 4, 4],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:39.241157 GPU 0 27280 test begin: paddle.argmin(Tensor([4, 4, 4, 0, 4],"float64"), axis=0, )
[paddle error] paddle.argmin(Tensor([4, 4, 4, 0, 4],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:39.254192 GPU 1 27127 test begin: paddle.argmin(Tensor([4, 4, 4, 4, 0],"float64"), axis=0, )
[paddle error] paddle.argmin(Tensor([4, 4, 4, 4, 0],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:39.263446 GPU 1 27303 test begin: paddle.argmin(Tensor([5, 0, 5, 5],"float64"), axis=0, )
[paddle error] paddle.argmin(Tensor([5, 0, 5, 5],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:39.265046 GPU 0 27425 test begin: paddle.argmin(Tensor([5, 5, 0, 5],"float64"), axis=0, )
[paddle error] paddle.argmin(Tensor([5, 5, 0, 5],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:39.270366 GPU 0 27450 test begin: paddle.argmin(Tensor([5, 5, 5, 0],"float64"), axis=0, )
[paddle error] paddle.argmin(Tensor([5, 5, 5, 0],"float64"), axis=0, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:39.296196 GPU 1 27214 test begin: paddle.argmin(x=Tensor([0, 3, 4],"float64"), axis=1, keepdim=False, )
[paddle error] paddle.argmin(x=Tensor([0, 3, 4],"float64"), axis=1, keepdim=False, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:39.306669 GPU 0 27054 test begin: paddle.argmin(x=Tensor([0, 3],"int64"), axis=-1, )
[paddle error] paddle.argmin(x=Tensor([0, 3],"int64"), axis=-1, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:39.310788 GPU 1 27295 test begin: paddle.argmin(x=Tensor([3, 0],"int64"), axis=-2, )
[paddle error] paddle.argmin(x=Tensor([3, 0],"int64"), axis=-2, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:39.349228 GPU 1 27487 test begin: paddle.argmin(x=Tensor([3, 3, 0],"float64"), axis=1, keepdim=False, )
[paddle error] paddle.argmin(x=Tensor([3, 3, 0],"float64"), axis=1, keepdim=False, ) 
 (InvalidArgument) argmin/argmax input numel must > 0, bug got 0
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/cpu/arg_min_max_kernel.cc:156)


2025-06-05 15:06:40.724521 GPU 1 27303 test begin: paddle.bmm(Tensor([0, 300, 128],"float32"), Tensor([0, 128, 30976],"float32"), )
W0605 15:06:40.845695 27303 backward.cc:437] While running Node (BmmGradNode) raises an EnforceNotMet exception
[paddle error] paddle.bmm(Tensor([0, 300, 128],"float32"), Tensor([0, 128, 30976],"float32"), ) 
 (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 15859712, memory's size is 0.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):15859712 > memory_size():0.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)


2025-06-05 15:06:40.743435 GPU 0 27425 test begin: paddle.bmm(Tensor([0, 300, 128],"float32"), Tensor([0, 128, 33856],"float32"), )
W0605 15:06:40.866091 27425 backward.cc:437] While running Node (BmmGradNode) raises an EnforceNotMet exception
[paddle error] paddle.bmm(Tensor([0, 300, 128],"float32"), Tensor([0, 128, 33856],"float32"), ) 
 (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 17334272, memory's size is 0.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):17334272 > memory_size():0.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)


2025-06-05 15:06:40.768097 GPU 0 27194 test begin: paddle.bmm(Tensor([1, 0, 128],"float32"), Tensor([1, 128, 30976],"float32"), )
W0605 15:06:41.071470 27194 backward.cc:437] While running Node (BmmGradNode) raises an EnforceNotMet exception
[paddle error] paddle.bmm(Tensor([1, 0, 128],"float32"), Tensor([1, 128, 30976],"float32"), ) 
 (InvalidArgument) Pointer A should not be null.
  [Hint: A should not be null.] (at ../paddle/phi/kernels/funcs/blas/blas_impl.h:1399)


2025-06-05 15:06:40.816152 GPU 0 27280 test begin: paddle.bmm(Tensor([1, 0, 128],"float32"), Tensor([1, 128, 33856],"float32"), )
W0605 15:06:41.100683 27280 backward.cc:437] While running Node (BmmGradNode) raises an EnforceNotMet exception
[paddle error] paddle.bmm(Tensor([1, 0, 128],"float32"), Tensor([1, 128, 33856],"float32"), ) 
 (InvalidArgument) Pointer A should not be null.
  [Hint: A should not be null.] (at ../paddle/phi/kernels/funcs/blas/blas_impl.h:1399)


2025-06-05 15:06:40.829839 GPU 1 27215 test begin: paddle.bmm(Tensor([1, 300, 128],"float32"), Tensor([1, 128, 0],"float32"), )
W0605 15:06:40.980175 27215 backward.cc:437] While running Node (BmmGradNode) raises an EnforceNotMet exception
[paddle error] paddle.bmm(Tensor([1, 300, 128],"float32"), Tensor([1, 128, 0],"float32"), ) 
 (InvalidArgument) Pointer A should not be null.
  [Hint: A should not be null.] (at ../paddle/phi/kernels/funcs/blas/blas_impl.h:1399)


2025-06-05 15:06:40.832810 GPU 1 27487 test begin: paddle.bmm(x=Tensor([0, 2, 3],"float32"), y=Tensor([0, 3, 2],"float32"), )
W0605 15:06:41.006058 27487 backward.cc:437] While running Node (BmmGradNode) raises an EnforceNotMet exception
[paddle error] paddle.bmm(x=Tensor([0, 2, 3],"float32"), y=Tensor([0, 3, 2],"float32"), ) 
 (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 24, memory's size is 0.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):24 > memory_size():0.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)


2025-06-05 15:06:40.860157 GPU 0 27475 test begin: paddle.bmm(x=Tensor([0, 2, 3],"float64"), y=Tensor([0, 3, 2],"float64"), )
W0605 15:06:40.989357 27475 backward.cc:437] While running Node (BmmGradNode) raises an EnforceNotMet exception
[paddle error] paddle.bmm(x=Tensor([0, 2, 3],"float64"), y=Tensor([0, 3, 2],"float64"), ) 
 (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 48, memory's size is 0.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):48 > memory_size():0.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)


2025-06-05 15:06:40.871919 GPU 0 27356 test begin: paddle.bmm(x=Tensor([2, 0, 3],"float32"), y=Tensor([2, 3, 2],"float32"), )
W0605 15:06:41.054508 27356 backward.cc:437] While running Node (BmmGradNode) raises an EnforceNotMet exception
[paddle error] paddle.bmm(x=Tensor([2, 0, 3],"float32"), y=Tensor([2, 3, 2],"float32"), ) 
 (InvalidArgument) Pointer A should not be null.
  [Hint: A should not be null.] (at ../paddle/phi/kernels/funcs/blas/blas_impl.h:1399)


2025-06-05 15:06:40.876125 GPU 0 27281 test begin: paddle.bmm(x=Tensor([2, 0, 3],"float64"), y=Tensor([2, 3, 2],"float64"), )
W0605 15:06:41.005499 27281 backward.cc:437] While running Node (BmmGradNode) raises an EnforceNotMet exception
[paddle error] paddle.bmm(x=Tensor([2, 0, 3],"float64"), y=Tensor([2, 3, 2],"float64"), ) 
 (InvalidArgument) Pointer A should not be null.
  [Hint: A should not be null.] (at ../paddle/phi/kernels/funcs/blas/blas_impl.h:1399)


2025-06-05 15:06:40.928816 GPU 0 27054 test begin: paddle.bmm(x=Tensor([2, 2, 3],"float32"), y=Tensor([2, 3, 0],"float32"), )
W0605 15:06:41.061400 27054 backward.cc:437] While running Node (BmmGradNode) raises an EnforceNotMet exception
[paddle error] paddle.bmm(x=Tensor([2, 2, 3],"float32"), y=Tensor([2, 3, 0],"float32"), ) 
 (InvalidArgument) Pointer A should not be null.
  [Hint: A should not be null.] (at ../paddle/phi/kernels/funcs/blas/blas_impl.h:1399)


2025-06-05 15:06:40.942796 GPU 1 27403 test begin: paddle.bmm(x=Tensor([2, 2, 3],"float64"), y=Tensor([2, 3, 0],"float64"), )
W0605 15:06:41.129979 27403 backward.cc:437] While running Node (BmmGradNode) raises an EnforceNotMet exception
[paddle error] paddle.bmm(x=Tensor([2, 2, 3],"float64"), y=Tensor([2, 3, 0],"float64"), ) 
 (InvalidArgument) Pointer A should not be null.
  [Hint: A should not be null.] (at ../paddle/phi/kernels/funcs/blas/blas_impl.h:1399)


2025-06-05 15:06:40.944073 GPU 1 27127 test begin: paddle.chunk(Tensor([0, 1, 1, 64],"float16"), 2, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<phi::dtype::float16, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, phi::dtype::float16>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107201 (unix time) try "date -d @1749107201" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 27127 (TID 0x7f98508fb740) from PID 0 ***]


2025-06-05 15:06:40.952968 GPU 0 27450 test begin: paddle.chunk(Tensor([0, 1, 64, 64],"float16"), 2, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<phi::dtype::float16, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, phi::dtype::float16>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107201 (unix time) try "date -d @1749107201" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 27450 (TID 0x7f5f31bc5740) from PID 0 ***]


2025-06-05 15:06:40.967299 GPU 1 27295 test begin: paddle.chunk(Tensor([0, 108, 64, 64],"float16"), 3, axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<phi::dtype::float16, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, phi::dtype::float16>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107201 (unix time) try "date -d @1749107201" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 27295 (TID 0x7f98aafbe740) from PID 24 ***]


2025-06-05 15:06:40.981200 GPU 0 27425 test begin: paddle.chunk(Tensor([0, 108, 64, 64],"float32"), 3, axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107201 (unix time) try "date -d @1749107201" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f01a6413ff0) received by PID 27425 (TID 0x7f01a6ff2740) from PID 18446744072203878384 ***]


2025-06-05 15:06:40.992595 GPU 1 27214 test begin: paddle.chunk(Tensor([0, 11, 1024],"float32"), chunks=2, axis=-1, )

2025-06-05 15:06:40.995226 GPU 1 27303 test begin: paddle.chunk(Tensor([0, 128, 25500],"float32"), 2, axis=1, )

2025-06-05 15:06:41.108300 GPU 0 27475 test begin: paddle.chunk(Tensor([0, 16, 128],"float32"), chunks=2, axis=-1, )

2025-06-05 15:06:41.121548 GPU 0 27281 test begin: paddle.chunk(Tensor([0, 21, 32],"float32"), 3, axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107201 (unix time) try "date -d @1749107201" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fd5f5f26120) received by PID 27281 (TID 0x7fd5f6b04740) from PID 18446744073540886816 ***]


2025-06-05 15:06:41.129168 GPU 1 27215 test begin: paddle.chunk(Tensor([0, 21, 8],"float32"), 3, axis=1, )

2025-06-05 15:06:41.131210 GPU 1 27487 test begin: paddle.chunk(Tensor([0, 4, 1],"float32"), 4, axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107201 (unix time) try "date -d @1749107201" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f68f909b0f0) received by PID 27487 (TID 0x7f68f9c79740) from PID 18446744073592746224 ***]


2025-06-05 15:06:41.186942 GPU 0 27356 test begin: paddle.chunk(Tensor([0, 4, 20, 24],"float32"), 3, axis=-1, )

2025-06-05 15:06:41.187282 GPU 0 27054 test begin: paddle.chunk(Tensor([0, 4, 7, 24],"float32"), 3, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107201 (unix time) try "date -d @1749107201" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xa4b3c010) received by PID 27054 (TID 0x7f00da802740) from PID 18446744072177827856 ***]


2025-06-05 15:06:41.222498 GPU 0 27280 test begin: paddle.chunk(Tensor([0, 4],"float32"), 2, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107201 (unix time) try "date -d @1749107201" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 27280 (TID 0x7f8a4d06f740) from PID 0 ***]


2025-06-05 15:06:41.225060 GPU 0 27194 test begin: paddle.chunk(Tensor([0, 56, 72],"float32"), 3, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107201 (unix time) try "date -d @1749107201" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xa7f15160) received by PID 27194 (TID 0x7f3ec2470740) from PID 18446744072232194400 ***]


2025-06-05 15:06:41.277836 GPU 1 27403 test begin: paddle.chunk(Tensor([1, 0, 1, 64],"float16"), 2, axis=-1, )

2025-06-05 15:06:41.372843 GPU 1 27503 test begin: paddle.chunk(Tensor([1, 0, 1024],"float32"), chunks=2, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107201 (unix time) try "date -d @1749107201" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 27503 (TID 0x7f37089b0740) from PID 24 ***]


2025-06-05 15:06:41.644345 GPU 0 27502 test begin: paddle.chunk(Tensor([1, 0, 20, 24],"float32"), 3, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107202 (unix time) try "date -d @1749107202" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 27502 (TID 0x7f1e54da0740) from PID 0 ***]


2025-06-05 15:06:41.967956 GPU 0 27539 test begin: paddle.chunk(Tensor([1, 0, 64, 64],"float16"), 2, axis=-1, )

2025-06-05 15:06:42.268915 GPU 0 27554 test begin: paddle.chunk(Tensor([1, 1, 0, 64],"float16"), 2, axis=-1, )

2025-06-05 15:06:50.741055 GPU 0 28939 test begin: paddle.chunk(Tensor([1, 1, 1, 0],"float16"), 2, axis=-1, )

2025-06-05 15:06:51.176746 GPU 0 28929 test begin: paddle.chunk(Tensor([1, 1, 64, 0],"float16"), 2, axis=-1, )

2025-06-05 15:06:51.430252 GPU 0 28963 test begin: paddle.chunk(Tensor([1, 11, 0],"float32"), chunks=2, axis=-1, )

2025-06-05 15:06:51.529261 GPU 1 28940 test begin: paddle.chunk(Tensor([1, 4, 0, 24],"float32"), 3, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107233 (unix time) try "date -d @1749107233" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fc7a0118040) received by PID 28940 (TID 0x7fc7a0cf6740) from PID 18446744072100085824 ***]


2025-06-05 15:06:52.022044 GPU 0 28975 test begin: paddle.chunk(Tensor([1, 4, 20, 0],"float32"), 3, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107233 (unix time) try "date -d @1749107233" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f9381a05100) received by PID 28975 (TID 0x7f93825e3740) from PID 18446744071589351680 ***]


2025-06-05 15:06:53.234515 GPU 1 28964 test begin: paddle.chunk(Tensor([13, 0, 128],"float32"), chunks=2, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107235 (unix time) try "date -d @1749107235" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 28964 (TID 0x7f010742f740) from PID 24 ***]


2025-06-05 15:06:54.058156 GPU 1 28985 test begin: paddle.chunk(Tensor([13, 0, 1],"float32"), 4, axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107235 (unix time) try "date -d @1749107235" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 28985 (TID 0x7f28fac31740) from PID 24 ***]


2025-06-05 15:06:54.548583 GPU 0 28996 test begin: paddle.chunk(Tensor([13, 0, 32],"float32"), 3, axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107237 (unix time) try "date -d @1749107237" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f217ce68390) received by PID 28996 (TID 0x7f217da46740) from PID 2095481744 ***]


2025-06-05 15:06:54.971675 GPU 0 29030 test begin: paddle.chunk(Tensor([13, 0, 7, 24],"float32"), 3, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107237 (unix time) try "date -d @1749107237" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 29030 (TID 0x7f4239479740) from PID 0 ***]


2025-06-05 15:06:55.263635 GPU 1 29016 test begin: paddle.chunk(Tensor([13, 0, 72],"float32"), 3, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107239 (unix time) try "date -d @1749107239" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f18cca5a3a0) received by PID 29016 (TID 0x7f18cd638740) from PID 18446744072847991712 ***]


2025-06-05 15:06:55.511581 GPU 0 29080 test begin: paddle.chunk(Tensor([13, 16, 0],"float32"), chunks=2, axis=-1, )

2025-06-05 15:06:55.642542 GPU 0 29052 test begin: paddle.chunk(Tensor([13, 21, 0],"float32"), 3, axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107236 (unix time) try "date -d @1749107236" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 29052 (TID 0x7f9cc84eb740) from PID 0 ***]


2025-06-05 15:06:55.656094 GPU 1 29032 test begin: paddle.chunk(Tensor([13, 4, 0, 24],"float32"), 3, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107237 (unix time) try "date -d @1749107237" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x65) received by PID 29032 (TID 0x7f3251aff740) from PID 101 ***]


2025-06-05 15:06:56.071536 GPU 0 29065 test begin: paddle.chunk(Tensor([13, 4, 0],"float32"), 4, axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107237 (unix time) try "date -d @1749107237" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 29065 (TID 0x7f6985b08740) from PID 24 ***]


2025-06-05 15:06:56.081584 GPU 1 29131 test begin: paddle.chunk(Tensor([13, 4, 7, 0],"float32"), 3, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107238 (unix time) try "date -d @1749107238" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xa777b950) received by PID 29131 (TID 0x7f6e3f6f2740) from PID 18446744072224225616 ***]


2025-06-05 15:06:56.083762 GPU 1 29095 test begin: paddle.chunk(Tensor([13, 56, 0],"float32"), 3, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107236 (unix time) try "date -d @1749107236" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f9fac1413a0) received by PID 29095 (TID 0x7f9facd1f740) from PID 18446744072301581216 ***]


2025-06-05 15:06:56.252906 GPU 1 29135 test begin: paddle.chunk(Tensor([16, 0, 25500],"float32"), 2, axis=1, )

2025-06-05 15:06:56.318112 GPU 0 29079 test begin: paddle.chunk(Tensor([16, 128, 0],"float32"), 2, axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107239 (unix time) try "date -d @1749107239" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 29079 (TID 0x7f9ca3e8f740) from PID 24 ***]


2025-06-05 15:06:58.864718 GPU 1 28416 test begin: paddle.chunk(Tensor([2048, 0],"float32"), 2, axis=-1, )

2025-06-05 15:07:00.428050 GPU 1 28446 test begin: paddle.chunk(Tensor([4, 0, 64, 64],"float16"), 3, axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<phi::dtype::float16, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, phi::dtype::float16>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107221 (unix time) try "date -d @1749107221" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 28446 (TID 0x7fee674ae740) from PID 24 ***]


2025-06-05 15:07:01.082745 GPU 1 28432 test begin: paddle.chunk(Tensor([4, 0, 64, 64],"float32"), 3, axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107221 (unix time) try "date -d @1749107221" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xa5137590) received by PID 28432 (TID 0x7f889a367740) from PID 18446744072184100240 ***]


2025-06-05 15:07:04.748875 GPU 0 29424 test begin: paddle.chunk(Tensor([4, 108, 0, 64],"float32"), 3, axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107243 (unix time) try "date -d @1749107243" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fa85550e0a0) received by PID 29424 (TID 0x7fa8560ec740) from PID 1431363744 ***]


2025-06-05 15:07:09.422950 GPU 1 29666 test begin: paddle.chunk(Tensor([4, 108, 64, 0],"float16"), 3, axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<phi::dtype::float16, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, phi::dtype::float16>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107247 (unix time) try "date -d @1749107247" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 29666 (TID 0x7f146caa1740) from PID 24 ***]


2025-06-05 15:07:10.284813 GPU 1 29723 test begin: paddle.chunk(Tensor([4, 108, 64, 0],"float32"), 3, axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107247 (unix time) try "date -d @1749107247" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f44f96192d0) received by PID 29723 (TID 0x7f44fa1f7740) from PID 18446744073598505680 ***]


2025-06-05 15:07:18.403451 GPU 1 29899 test begin: paddle.chunk(Tensor([52, 21, 0],"float32"), 3, axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107259 (unix time) try "date -d @1749107259" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fd72ef20340) received by PID 29899 (TID 0x7fd72fafe740) from PID 787612480 ***]


2025-06-05 15:07:21.342671 GPU 0 29909 test begin: paddle.chunk(Tensor([8192, 0],"float32"), 2, axis=-1, )

2025-06-05 15:07:22.534028 GPU 1 29910 test begin: paddle.chunk(x=Tensor([0, 3],"float16"), chunks=3, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107263 (unix time) try "date -d @1749107263" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xa63c6ae0) received by PID 29910 (TID 0x7f634b5c2740) from PID 18446744072203561696 ***]


2025-06-05 15:07:23.507699 GPU 0 29950 test begin: paddle.chunk(x=Tensor([0, 3],"float32"), chunks=3, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107263 (unix time) try "date -d @1749107263" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xa48e9600) received by PID 29950 (TID 0x7f0b01db7740) from PID 18446744072175392256 ***]


2025-06-05 15:07:23.571675 GPU 0 29930 test begin: paddle.chunk(x=Tensor([3, 0],"float32"), chunks=3, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107264 (unix time) try "date -d @1749107264" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 29930 (TID 0x7f1d1ffe7740) from PID 0 ***]


2025-06-05 15:07:23.865855 GPU 0 29929 test begin: paddle.column_stack(list[Tensor([0, 1, 1, 1],"float64"),Tensor([0, 1, 1, 1],"float64"),Tensor([0, 1, 1, 1],"float64"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107264 (unix time) try "date -d @1749107264" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f9c3f8ac2f0) received by PID 29929 (TID 0x7f9c4048a740) from PID 1066058480 ***]


2025-06-05 15:07:23.878830 GPU 1 30010 test begin: paddle.column_stack(list[Tensor([0, 1, 1, 1],"float64"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107263 (unix time) try "date -d @1749107263" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 30010 (TID 0x7f9709c84740) from PID 0 ***]


2025-06-05 15:07:24.083599 GPU 1 30032 test begin: paddle.column_stack(list[Tensor([0, 1, 1],"float64"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107263 (unix time) try "date -d @1749107263" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 30032 (TID 0x7f936afab740) from PID 0 ***]


2025-06-05 15:07:24.342176 GPU 0 30060 test begin: paddle.column_stack(list[Tensor([0, 1],"float64"),], )

2025-06-05 15:07:26.151545 GPU 0 30077 test begin: paddle.column_stack(list[Tensor([0, 2],"float64"),], )

2025-06-05 15:07:26.708978 GPU 0 30094 test begin: paddle.column_stack(list[Tensor([0, 4, 2, 5],"float64"),], )

2025-06-05 15:07:27.044978 GPU 0 30082 test begin: paddle.column_stack(list[Tensor([0, 4, 2],"float64"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107267 (unix time) try "date -d @1749107267" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 30082 (TID 0x7fbea7e05740) from PID 0 ***]


2025-06-05 15:07:27.145799 GPU 0 30131 test begin: paddle.column_stack(list[Tensor([0],"float64"),], )

2025-06-05 15:07:27.265599 GPU 1 30104 test begin: paddle.column_stack(list[Tensor([1, 0, 1, 1],"float64"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107268 (unix time) try "date -d @1749107268" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 30104 (TID 0x7f5fbb14b740) from PID 0 ***]


2025-06-05 15:07:27.574992 GPU 0 30206 test begin: paddle.column_stack(list[Tensor([1, 0, 1],"float64"),], )

2025-06-05 15:07:27.612283 GPU 1 30129 test begin: paddle.column_stack(list[Tensor([1, 0],"float64"),], )

2025-06-05 15:07:27.641950 GPU 1 30148 test begin: paddle.column_stack(list[Tensor([1, 1, 0, 1],"float64"),], )

2025-06-05 15:07:28.013299 GPU 1 30178 test begin: paddle.column_stack(list[Tensor([1, 1, 0],"float64"),], )

2025-06-05 15:07:29.199463 GPU 1 30252 test begin: paddle.column_stack(list[Tensor([1, 1, 1, 0],"float64"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107269 (unix time) try "date -d @1749107269" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 30252 (TID 0x7f5bcfcca740) from PID 0 ***]


2025-06-05 15:07:33.200387 GPU 0 30442 test begin: paddle.column_stack(list[Tensor([3, 0, 2, 5],"float64"),Tensor([3, 0, 2, 5],"float64"),Tensor([3, 0, 2, 5],"float64"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107273 (unix time) try "date -d @1749107273" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 30442 (TID 0x7f1459f5a740) from PID 24 ***]


2025-06-05 15:07:37.889938 GPU 1 30619 test begin: paddle.column_stack(list[Tensor([3, 0, 2, 5],"float64"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107275 (unix time) try "date -d @1749107275" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 30619 (TID 0x7f30ee767740) from PID 0 ***]


2025-06-05 15:07:38.343369 GPU 1 30670 test begin: paddle.column_stack(list[Tensor([3, 0, 2],"float64"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107275 (unix time) try "date -d @1749107275" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 30670 (TID 0x7fb412b72740) from PID 0 ***]


2025-06-05 15:07:45.238894 GPU 1 30886 test begin: paddle.column_stack(list[Tensor([3, 0],"float64"),], )

2025-06-05 15:07:50.332332 GPU 1 30942 test begin: paddle.column_stack(list[Tensor([3, 4, 0, 5],"float64"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107291 (unix time) try "date -d @1749107291" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 30942 (TID 0x7f718d5bf740) from PID 0 ***]


2025-06-05 15:07:50.479876 GPU 1 30953 test begin: paddle.column_stack(list[Tensor([3, 4, 0],"float64"),], )

2025-06-05 15:07:51.604992 GPU 1 30985 test begin: paddle.column_stack(list[Tensor([3, 4, 2, 0],"float64"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107292 (unix time) try "date -d @1749107292" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f09a07c25b0) received by PID 30985 (TID 0x7f0b882d5740) from PID 18446744072107074992 ***]


2025-06-05 15:07:51.687475 GPU 0 30963 test begin: paddle.concat(list[Tensor([0, 1, 1, 16],"float32"),Tensor([0, 1, 1, 16],"float32"),], axis=-1, )

2025-06-05 15:07:52.013621 GPU 0 30974 test begin: paddle.concat(list[Tensor([0, 1, 1, 1],"float64"),Tensor([0, 1, 1, 1],"float64"),Tensor([0, 1, 1, 1],"float64"),], axis=1, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107292 (unix time) try "date -d @1749107292" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f55df1a7090) received by PID 30974 (TID 0x7f55dfd85740) from PID 18446744073157636240 ***]


2025-06-05 15:07:53.653848 GPU 0 31025 test begin: paddle.concat(list[Tensor([0, 1, 1, 1],"float64"),], axis=1, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107295 (unix time) try "date -d @1749107295" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f487e4aebf0) received by PID 31025 (TID 0x7f4a88f04740) from PID 2118839280 ***]


2025-06-05 15:07:54.778154 GPU 0 31050 test begin: paddle.concat(list[Tensor([0, 1, 1, 1],"float64"),], axis=2, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107295 (unix time) try "date -d @1749107295" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 31050 (TID 0x7fdb2ee16740) from PID 0 ***]


2025-06-05 15:07:55.697740 GPU 0 31040 test begin: paddle.concat(list[Tensor([0, 1, 10285, 1],"float32"),Tensor([0, 1, 10285, 1],"float32"),Tensor([0, 1, 10285, 1],"float32"),Tensor([0, 1, 10285, 1],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107299 (unix time) try "date -d @1749107299" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fa89f1092a0) received by PID 31040 (TID 0x7fa89fce7740) from PID 18446744072083247776 ***]


2025-06-05 15:07:57.866743 GPU 0 31116 test begin: paddle.concat(list[Tensor([0, 1, 1],"float16"),], axis=2, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<phi::dtype::float16, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, phi::dtype::float16>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107299 (unix time) try "date -d @1749107299" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 31116 (TID 0x7f6348bd5740) from PID 0 ***]


2025-06-05 15:07:57.887318 GPU 1 31202 test begin: paddle.concat(list[Tensor([0, 1, 1],"float32"),], axis=2, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107299 (unix time) try "date -d @1749107299" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 31202 (TID 0x7fd30ce5b740) from PID 0 ***]


2025-06-05 15:07:57.919295 GPU 1 31225 test begin: paddle.concat(list[Tensor([0, 1, 1],"float64"),Tensor([0, 1, 1],"float64"),Tensor([0, 1, 1],"float64"),], axis=1, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107301 (unix time) try "date -d @1749107301" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f22b30d10d0) received by PID 31225 (TID 0x7f22b3caf740) from PID 18446744072418562256 ***]


2025-06-05 15:07:58.218042 GPU 0 31187 test begin: paddle.concat(list[Tensor([0, 1, 1],"float64"),], axis=1, name=None, )

2025-06-05 15:07:58.221392 GPU 0 31201 test begin: paddle.concat(list[Tensor([0, 1, 24276, 1],"float32"),Tensor([0, 1, 24276, 1],"float32"),Tensor([0, 1, 24276, 1],"float32"),Tensor([0, 1, 24276, 1],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107300 (unix time) try "date -d @1749107300" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7ff3e2dc0310) received by PID 31201 (TID 0x7ff3e399e740) from PID 18446744073220653840 ***]


2025-06-05 15:07:58.552877 GPU 0 31314 test begin: paddle.concat(list[Tensor([0, 1, 2704],"float32"),Tensor([0, 1, 676],"float32"),Tensor([0, 1, 169],"float32"),Tensor([0, 1, 49],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107302 (unix time) try "date -d @1749107302" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f7ca3816330) received by PID 31314 (TID 0x7f7ca43f4740) from PID 18446744072157750064 ***]


2025-06-05 15:07:59.044712 GPU 1 31328 test begin: paddle.concat(list[Tensor([0, 1, 27648],"float32"),Tensor([0, 1, 6912],"float32"),Tensor([0, 1, 1728],"float32"),Tensor([0, 1, 432],"float32"),Tensor([0, 1, 108],"float32"),Tensor([0, 1, 30],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107301 (unix time) try "date -d @1749107301" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f86a0fc82e0) received by PID 31328 (TID 0x7f86a1ba6740) from PID 18446744072115487456 ***]


2025-06-05 15:08:00.491241 GPU 1 31327 test begin: paddle.concat(list[Tensor([0, 1, 28800],"float32"),Tensor([0, 1, 7200],"float32"),Tensor([0, 1, 1800],"float32"),Tensor([0, 1, 450],"float32"),Tensor([0, 1, 117],"float32"),Tensor([0, 1, 35],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107304 (unix time) try "date -d @1749107304" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7ff30e7b3260) received by PID 31327 (TID 0x7ff30f391740) from PID 242954848 ***]


2025-06-05 15:08:01.981122 GPU 1 31412 test begin: paddle.concat(list[Tensor([0, 1, 3, 1],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107302 (unix time) try "date -d @1749107302" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 31412 (TID 0x7f096f0d3740) from PID 0 ***]


2025-06-05 15:08:02.404244 GPU 0 31448 test begin: paddle.concat(list[Tensor([0, 1, 3136],"float32"),Tensor([0, 1, 784],"float32"),Tensor([0, 1, 196],"float32"),Tensor([0, 1, 49],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107303 (unix time) try "date -d @1749107303" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f09089ae1a0) received by PID 31448 (TID 0x7f090958c740) from PID 144368032 ***]


2025-06-05 15:08:06.471243 GPU 1 31519 test begin: paddle.concat(list[Tensor([0, 1, 4800],"float32"),Tensor([0, 1, 1200],"float32"),Tensor([0, 1, 300],"float32"),Tensor([0, 1, 80],"float32"),Tensor([0, 1, 20],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107308 (unix time) try "date -d @1749107308" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f50131962d0) received by PID 31519 (TID 0x7f5013d74740) from PID 320430800 ***]


2025-06-05 15:08:07.787680 GPU 1 31586 test begin: paddle.concat(list[Tensor([0, 1, 6408],"float32"),Tensor([0, 1, 1620],"float32"),Tensor([0, 1, 414],"float32"),Tensor([0, 1, 108],"float32"),Tensor([0, 1, 30],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107309 (unix time) try "date -d @1749107309" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f9d5a3eaca0) received by PID 31586 (TID 0x7f9d5afc9740) from PID 1514056864 ***]


2025-06-05 15:08:13.963747 GPU 1 31822 test begin: paddle.concat(list[Tensor([0, 1, 8, 4],"int64"),Tensor([0, 1, 8, 4],"int64"),], axis=3, )
element 0 of tensors does not require grad and does not have a grad_fn


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<long, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, long>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107319 (unix time) try "date -d @1749107319" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 31822 (TID 0x7f25df2f1740) from PID 24 ***]


2025-06-05 15:08:21.860900 GPU 0 31966 test begin: paddle.concat(list[Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),], axis=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107334 (unix time) try "date -d @1749107334" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fb129953470) received by PID 31966 (TID 0x7fb12a531740) from PID 697644144 ***]


2025-06-05 15:08:21.964951 GPU 0 31958 test begin: paddle.concat(list[Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),Tensor([0, 1, 8],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107331 (unix time) try "date -d @1749107331" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fb7f43313a0) received by PID 31958 (TID 0x7fb7f4f0f740) from PID 18446744073511572384 ***]


2025-06-05 15:08:22.031877 GPU 1 31948 test begin: paddle.concat(list[Tensor([0, 10, 1, 2],"float32"),Tensor([0, 10, 1, 2],"float32"),], axis=-2, )

2025-06-05 15:08:22.105811 GPU 1 31916 test begin: paddle.concat(list[Tensor([0, 100, 256],"float32"),Tensor([0, 300, 256],"float32"),], 1, )

2025-06-05 15:08:22.694340 GPU 1 31929 test begin: paddle.concat(list[Tensor([0, 1024, 18, 18],"float32"),Tensor([0, 768, 18, 18],"float32"),Tensor([0, 768, 18, 18],"float32"),Tensor([0, 768, 18, 18],"float32"),Tensor([0, 768, 18, 18],"float32"),Tensor([0, 768, 18, 18],"float32"),Tensor([0, 768, 18, 18],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107336 (unix time) try "date -d @1749107336" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f35684e92b0) received by PID 31929 (TID 0x7f35690c7740) from PID 1749979824 ***]


2025-06-05 15:08:28.091623 GPU 0 32035 test begin: paddle.concat(list[Tensor([0, 1024, 20, 20],"float32"),Tensor([0, 768, 20, 20],"float32"),Tensor([0, 768, 20, 20],"float32"),Tensor([0, 768, 20, 20],"float32"),Tensor([0, 768, 20, 20],"float32"),Tensor([0, 768, 20, 20],"float32"),Tensor([0, 768, 20, 20],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107343 (unix time) try "date -d @1749107343" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7ff452b802d0) received by PID 32035 (TID 0x7ff45375e740) from PID 1387791056 ***]


2025-06-05 15:08:28.740740 GPU 0 32039 test begin: paddle.concat(list[Tensor([0, 103680, 1],"float32"),Tensor([0, 25920, 1],"float32"),Tensor([0, 6480, 1],"float32"),Tensor([0, 1620, 1],"float32"),Tensor([0, 420, 1],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107341 (unix time) try "date -d @1749107341" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f84ae8742d0) received by PID 32039 (TID 0x7f84af452740) from PID 18446744072342684368 ***]


2025-06-05 15:08:32.117154 GPU 0 32469 test begin: paddle.concat(list[Tensor([0, 103680, 4],"float32"),Tensor([0, 25920, 4],"float32"),Tensor([0, 6480, 4],"float32"),Tensor([0, 1620, 4],"float32"),Tensor([0, 420, 4],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107346 (unix time) try "date -d @1749107346" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f7574ffd330) received by PID 32469 (TID 0x7f7575bdb740) from PID 1962922800 ***]


2025-06-05 15:08:32.256118 GPU 0 32471 test begin: paddle.concat(list[Tensor([0, 10],"float32"),], 1, )

2025-06-05 15:08:34.151792 GPU 1 32569 test begin: paddle.concat(list[Tensor([0, 1100, 128],"float32"),Tensor([0, 1100, 128],"float32"),Tensor([0, 1100, 128],"float32"),Tensor([0, 1100, 128],"float32"),], axis=2, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107346 (unix time) try "date -d @1749107346" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f9b349681b0) received by PID 32569 (TID 0x7f9b35546740) from PID 882278832 ***]


2025-06-05 15:08:35.677466 GPU 0 32617 test begin: paddle.concat(list[Tensor([0, 128, 256, 256],"float32"),Tensor([0, 128, 256, 256],"float32"),Tensor([0, 128, 256, 256],"float32"),Tensor([0, 128, 256, 256],"float32"),], 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107349 (unix time) try "date -d @1749107349" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f2572ef2180) received by PID 32617 (TID 0x7f2573ad0740) from PID 1928274304 ***]


2025-06-05 15:08:35.702338 GPU 1 32629 test begin: paddle.concat(list[Tensor([0, 128, 32, 32],"float32"),Tensor([0, 32, 32, 32],"float32"),Tensor([0, 32, 32, 32],"float32"),Tensor([0, 32, 32, 32],"float32"),Tensor([0, 32, 32, 32],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107346 (unix time) try "date -d @1749107346" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fa4158e12e0) received by PID 32629 (TID 0x7fa4164bf740) from PID 361632480 ***]


2025-06-05 15:08:35.773138 GPU 0 32568 test begin: paddle.concat(list[Tensor([0, 1280, 7, 7],"float32"),Tensor([0, 288, 7, 7],"float32"),Tensor([0, 288, 7, 7],"float32"),Tensor([0, 288, 7, 7],"float32"),Tensor([0, 288, 7, 7],"float32"),Tensor([0, 288, 7, 7],"float32"),Tensor([0, 288, 7, 7],"float32"),Tensor([0, 288, 7, 7],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107351 (unix time) try "date -d @1749107351" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7ff6a2dd2300) received by PID 32568 (TID 0x7ff6a39b0740) from PID 18446744072146985728 ***]


2025-06-05 15:08:36.071140 GPU 0 32666 test begin: paddle.concat(list[Tensor([0, 128],"float32"),Tensor([0, 128],"float32"),Tensor([0, 128],"float32"),Tensor([0, 128],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107346 (unix time) try "date -d @1749107346" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f84ea1f82e0) received by PID 32666 (TID 0x7f84eadd6740) from PID 18446744073342517984 ***]


2025-06-05 15:08:36.303677 GPU 1 32673 test begin: paddle.concat(list[Tensor([0, 12],"float64"),Tensor([0, 12],"float64"),Tensor([0, 12],"float64"),Tensor([0, 12],"float64"),Tensor([0, 12],"float64"),Tensor([0, 12],"float64"),Tensor([0, 12],"float64"),Tensor([0, 12],"float64"),Tensor([0, 12],"float64"),Tensor([0, 12],"float64"),Tensor([0, 12],"float64"),Tensor([0, 12],"float64"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107347 (unix time) try "date -d @1749107347" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f9a6d2f9320) received by PID 32673 (TID 0x7f9a6ded7740) from PID 1831834400 ***]


2025-06-05 15:08:36.477400 GPU 1 32686 test begin: paddle.concat(list[Tensor([0, 15, 15, 2],"float32"),Tensor([0, 15, 15, 2],"float32"),], -1, )

2025-06-05 15:08:37.151118 GPU 0 32753 test begin: paddle.concat(list[Tensor([0, 16, 14, 14, 192],"float16"),Tensor([0, 16, 14, 14, 192],"float16"),Tensor([0, 16, 14, 14, 192],"float16"),Tensor([0, 16, 14, 14, 192],"float16"),], -1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107350 (unix time) try "date -d @1749107350" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fe47e2c62a0) received by PID 32753 (TID 0x7fe47eea4740) from PID 2116838048 ***]


2025-06-05 15:08:39.105091 GPU 0 32763 test begin: paddle.concat(list[Tensor([0, 16, 14, 14, 192],"float32"),Tensor([0, 16, 14, 14, 192],"float32"),Tensor([0, 16, 14, 14, 192],"float32"),Tensor([0, 16, 14, 14, 192],"float32"),], -1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107349 (unix time) try "date -d @1749107349" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fc0ebe45310) received by PID 32763 (TID 0x7fc0eca23740) from PID 18446744073372193552 ***]


2025-06-05 15:08:39.813410 GPU 1 32764 test begin: paddle.concat(list[Tensor([0, 16, 64],"float32"),Tensor([0, 16, 64],"float32"),Tensor([0, 16, 64],"float32"),Tensor([0, 16, 64],"float32"),Tensor([0, 16, 64],"float32"),Tensor([0, 16, 64],"float32"),Tensor([0, 16, 64],"float32"),Tensor([0, 16, 64],"float32"),Tensor([0, 16, 64],"float32"),Tensor([0, 16, 64],"float32"),Tensor([0, 16, 64],"float32"),Tensor([0, 16, 64],"float32"),Tensor([0, 16, 64],"float32"),], axis=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107350 (unix time) try "date -d @1749107350" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f0dfc502330) received by PID 32764 (TID 0x7f0dfd0e0740) from PID 18446744073647694640 ***]


2025-06-05 15:08:45.244467 GPU 1 32894 test begin: paddle.concat(list[Tensor([0, 160, 18, 18],"float32"),Tensor([0, 160, 18, 18],"float32"),], 1, )

2025-06-05 15:08:49.158251 GPU 1 32932 test begin: paddle.concat(list[Tensor([0, 160, 56, 56],"float32"),Tensor([0, 192, 56, 56],"float32"),Tensor([0, 192, 56, 56],"float32"),Tensor([0, 192, 56, 56],"float32"),Tensor([0, 192, 56, 56],"float32"),Tensor([0, 192, 56, 56],"float32"),Tensor([0, 192, 56, 56],"float32"),Tensor([0, 192, 56, 56],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107355 (unix time) try "date -d @1749107355" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f28aaf5c1f0) received by PID 32932 (TID 0x7f28abb3a740) from PID 18446744072282817008 ***]


2025-06-05 15:09:05.718405 GPU 1 33609 test begin: paddle.concat(list[Tensor([0, 18, 128],"float32"),Tensor([0, 18, 128],"float32"),Tensor([0, 18, 128],"float32"),Tensor([0, 18, 128],"float32"),], axis=2, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107373 (unix time) try "date -d @1749107373" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f9e2260e0c0) received by PID 33609 (TID 0x7f9e231ec740) from PID 576774336 ***]


2025-06-05 15:09:05.743020 GPU 0 33596 test begin: paddle.concat(list[Tensor([0, 188, 140, 1, 2, 7],"float32"),Tensor([0, 188, 140, 1, 2, 7],"float32"),Tensor([0, 188, 140, 1, 2, 7],"float32"),], axis=-3, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107374 (unix time) try "date -d @1749107374" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fca4bd67fb0) received by PID 33596 (TID 0x7fca4c946740) from PID 1272348592 ***]


2025-06-05 15:09:05.876326 GPU 0 33673 test begin: paddle.concat(list[Tensor([0, 192, 20, 20],"float32"),Tensor([0, 192, 20, 20],"float32"),Tensor([0, 192, 20, 20],"float32"),Tensor([0, 192, 20, 20],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107374 (unix time) try "date -d @1749107374" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fbe8c1391f0) received by PID 33673 (TID 0x7fbe8cd17740) from PID 18446744071764677104 ***]


2025-06-05 15:09:05.988735 GPU 1 33643 test begin: paddle.concat(list[Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),], axis=1, )
element 0 of tensors does not require grad and does not have a grad_fn


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<bool, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, bool>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107373 (unix time) try "date -d @1749107373" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 33643 (TID 0x7fc4d3e3b740) from PID 24 ***]


2025-06-05 15:09:06.347987 GPU 1 33632 test begin: paddle.concat(list[Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),], axis=-1, )
element 0 of tensors does not require grad and does not have a grad_fn


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<bool, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, bool>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107374 (unix time) try "date -d @1749107374" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 33632 (TID 0x7fd7877b8740) from PID 24 ***]


2025-06-05 15:09:07.006444 GPU 1 33706 test begin: paddle.concat(list[Tensor([0, 1],"float16"),], axis=1, name=None, )

2025-06-05 15:09:16.775985 GPU 0 33862 test begin: paddle.concat(list[Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),], 0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107382 (unix time) try "date -d @1749107382" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 33862 (TID 0x7ff5e8443740) from PID 0 ***]


2025-06-05 15:09:20.260458 GPU 0 34026 test begin: paddle.concat(list[Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107388 (unix time) try "date -d @1749107388" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f5e1f8443b0) received by PID 34026 (TID 0x7f5e20422740) from PID 528761776 ***]


2025-06-05 15:09:20.362257 GPU 1 33977 test begin: paddle.concat(list[Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),], 0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107386 (unix time) try "date -d @1749107386" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f24795692b0) received by PID 33977 (TID 0x7f247a147740) from PID 2035716784 ***]


2025-06-05 15:09:20.367021 GPU 0 34000 test begin: paddle.concat(list[Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107386 (unix time) try "date -d @1749107386" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7ff9817251f0) received by PID 34000 (TID 0x7ff982303740) from PID 18446744071586337264 ***]


2025-06-05 15:09:20.768674 GPU 1 34008 test begin: paddle.concat(list[Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107386 (unix time) try "date -d @1749107386" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fb75d0ca0e0) received by PID 34008 (TID 0x7fb75dca8740) from PID 1561108704 ***]


2025-06-05 15:09:20.921995 GPU 0 34030 test begin: paddle.concat(list[Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),], -1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107387 (unix time) try "date -d @1749107387" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fcc7e8382f0) received by PID 34030 (TID 0x7fcc7f416740) from PID 2122547952 ***]


2025-06-05 15:09:21.335513 GPU 0 34171 test begin: paddle.concat(list[Tensor([0, 1],"float32"),Tensor([0, 1],"float32"),], 1, )

2025-06-05 15:09:21.542778 GPU 1 34057 test begin: paddle.concat(list[Tensor([0, 1],"float64"),Tensor([0, 1],"float64"),Tensor([0, 1],"float64"),], axis=1, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107387 (unix time) try "date -d @1749107387" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f1564ddd1a0) received by PID 34057 (TID 0x7f15659bb740) from PID 1692258720 ***]


2025-06-05 15:09:21.720835 GPU 0 34202 test begin: paddle.concat(list[Tensor([0, 1],"int32"),Tensor([0, 1],"int32"),Tensor([0, 1],"int32"),Tensor([0, 1],"int32"),Tensor([0, 1],"int32"),Tensor([0, 1],"int32"),Tensor([0, 1],"int32"),Tensor([0, 1],"int32"),Tensor([0, 1],"int32"),Tensor([0, 1],"int32"),Tensor([0, 1],"int32"),Tensor([0, 1],"int32"),Tensor([0, 1],"int32"),Tensor([0, 1],"int32"),Tensor([0, 1],"int32"),Tensor([0, 1],"int32"),], )
element 0 of tensors does not require grad and does not have a grad_fn


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107387 (unix time) try "date -d @1749107387" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f1fa77603b0) received by PID 34202 (TID 0x7f1fa833e740) from PID 18446744072224113584 ***]


2025-06-05 15:09:21.801093 GPU 0 34136 test begin: paddle.concat(list[Tensor([0, 1],"int64"),Tensor([0, 1],"int64"),Tensor([0, 1],"int64"),Tensor([0, 1],"int64"),Tensor([0, 1],"int64"),Tensor([0, 1],"int64"),Tensor([0, 1],"int64"),Tensor([0, 1],"int64"),Tensor([0, 1],"int64"),Tensor([0, 1],"int64"),Tensor([0, 1],"int64"),Tensor([0, 1],"int64"),Tensor([0, 1],"int64"),Tensor([0, 1],"int64"),Tensor([0, 1],"int64"),Tensor([0, 1],"int64"),Tensor([0, 1],"int64"),Tensor([0, 1],"int64"),Tensor([0, 1],"int64"),Tensor([0, 1],"int64"),Tensor([0, 1],"int64"),Tensor([0, 1],"int64"),Tensor([0, 1],"int64"),Tensor([0, 1],"int64"),Tensor([0, 1],"int64"),], axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<long, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, long>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107387 (unix time) try "date -d @1749107387" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 34136 (TID 0x7ff289c65740) from PID 0 ***]


2025-06-05 15:09:22.206811 GPU 1 34150 test begin: paddle.concat(list[Tensor([0, 1],"int64"),Tensor([0, 1],"int64"),], axis=1, )
element 0 of tensors does not require grad and does not have a grad_fn

2025-06-05 15:09:22.271761 GPU 1 34149 test begin: paddle.concat(list[Tensor([0, 1],"int64"),Tensor([0, 2],"int64"),], axis=1, )
element 0 of tensors does not require grad and does not have a grad_fn


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<long, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, long>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107391 (unix time) try "date -d @1749107391" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 34149 (TID 0x7fd64466e740) from PID 24 ***]


2025-06-05 15:09:22.471128 GPU 0 34249 test begin: paddle.concat(list[Tensor([0, 2, 1, 4, 16],"float32"),Tensor([0, 2, 15, 4, 16],"float32"),], axis=2, )

2025-06-05 15:09:22.696128 GPU 1 34235 test begin: paddle.concat(list[Tensor([0, 2, 16, 4],"int64"),Tensor([0, 2, 16, 4],"int64"),], axis=3, )
element 0 of tensors does not require grad and does not have a grad_fn


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<long, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, long>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107389 (unix time) try "date -d @1749107389" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 34235 (TID 0x7f0db3d96740) from PID 24 ***]


2025-06-05 15:09:23.719768 GPU 1 34312 test begin: paddle.concat(list[Tensor([0, 20, 15, 384],"float32"),Tensor([0, 20, 15, 384],"float32"),Tensor([0, 20, 15, 384],"float32"),Tensor([0, 20, 15, 384],"float32"),], -1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107388 (unix time) try "date -d @1749107388" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f1c3a2740b0) received by PID 34312 (TID 0x7f1c3ae52740) from PID 975650992 ***]


2025-06-05 15:09:25.561008 GPU 0 34346 test begin: paddle.concat(list[Tensor([0, 21504, 2],"float32"),Tensor([0, 21504, 2],"float32"),Tensor([0, 21504, 1],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107389 (unix time) try "date -d @1749107389" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 34346 (TID 0x7f36499e4740) from PID 24 ***]


2025-06-05 15:09:45.760355 GPU 1 34668 test begin: paddle.concat(list[Tensor([0, 224, 28, 28],"float16"),Tensor([0, 128, 28, 28],"float16"),Tensor([0, 128, 28, 28],"float16"),Tensor([0, 128, 28, 28],"float16"),Tensor([0, 128, 28, 28],"float16"),Tensor([0, 128, 28, 28],"float16"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107408 (unix time) try "date -d @1749107408" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f4bc18ca260) received by PID 34668 (TID 0x7f4bc24a8740) from PID 18446744072661803616 ***]


2025-06-05 15:09:46.107561 GPU 0 34714 test begin: paddle.concat(list[Tensor([0, 224, 28, 28],"float32"),Tensor([0, 128, 28, 28],"float32"),Tensor([0, 128, 28, 28],"float32"),Tensor([0, 128, 28, 28],"float32"),Tensor([0, 128, 28, 28],"float32"),Tensor([0, 128, 28, 28],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107411 (unix time) try "date -d @1749107411" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f66727342d0) received by PID 34714 (TID 0x7f667330d740) from PID 1920156368 ***]


2025-06-05 15:09:46.210405 GPU 1 34684 test begin: paddle.concat(list[Tensor([0, 24, 18, 768],"float32"),Tensor([0, 24, 18, 768],"float32"),Tensor([0, 24, 18, 768],"float32"),Tensor([0, 24, 18, 768],"float32"),], -1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107411 (unix time) try "date -d @1749107411" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fab392c1300) received by PID 34684 (TID 0x7fab39e9f740) from PID 959189760 ***]


2025-06-05 15:09:46.228740 GPU 1 34680 test begin: paddle.concat(list[Tensor([0, 248, 1, 1, 2, 1],"float32"),Tensor([0, 248, 1, 1, 2, 1],"float32"),Tensor([0, 248, 1, 1, 2, 1],"float32"),Tensor([0, 248, 1, 1, 2, 3],"float32"),Tensor([0, 248, 1, 1, 2, 1],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107411 (unix time) try "date -d @1749107411" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f8741c62190) received by PID 34680 (TID 0x7f8742840740) from PID 1103503760 ***]


2025-06-05 15:09:46.738339 GPU 1 34703 test begin: paddle.concat(list[Tensor([0, 248, 216, 2, 7],"float32"),], axis=-2, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107412 (unix time) try "date -d @1749107412" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 34703 (TID 0x7f2fc1fdd740) from PID 0 ***]


2025-06-05 15:09:46.786838 GPU 0 34720 test begin: paddle.concat(list[Tensor([0, 248832, 1],"float32"),Tensor([0, 62208, 1],"float32"),Tensor([0, 15552, 1],"float32"),Tensor([0, 3888, 1],"float32"),Tensor([0, 972, 1],"float32"),Tensor([0, 270, 1],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107411 (unix time) try "date -d @1749107411" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f04751bd2e0) received by PID 34720 (TID 0x7f0475d9b740) from PID 1964757728 ***]


2025-06-05 15:09:49.158545 GPU 0 34912 test begin: paddle.concat(list[Tensor([0, 248832, 4],"float32"),Tensor([0, 62208, 4],"float32"),Tensor([0, 15552, 4],"float32"),Tensor([0, 3888, 4],"float32"),Tensor([0, 972, 4],"float32"),Tensor([0, 270, 4],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107414 (unix time) try "date -d @1749107414" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f7ec7cf4330) received by PID 34912 (TID 0x7f7ec88d2740) from PID 18446744072766833456 ***]


2025-06-05 15:10:00.158932 GPU 1 35143 test begin: paddle.concat(list[Tensor([0, 256, 124, 128],"float32"),Tensor([0, 256, 124, 128],"float32"),Tensor([0, 256, 124, 128],"float32"),Tensor([0, 256, 124, 128],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107422 (unix time) try "date -d @1749107422" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f35476d4330) received by PID 35143 (TID 0x7f35482b2740) from PID 1198342960 ***]


2025-06-05 15:10:00.486051 GPU 0 35171 test begin: paddle.concat(list[Tensor([0, 256, 62, 64],"float32"),Tensor([0, 256, 62, 64],"float32"),Tensor([0, 256, 62, 64],"float32"),Tensor([0, 256, 62, 64],"float32"),Tensor([0, 256, 62, 64],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107420 (unix time) try "date -d @1749107420" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f7b7fe432d0) received by PID 35171 (TID 0x7f7b80a21740) from PID 2145661648 ***]


2025-06-05 15:10:00.668790 GPU 0 35160 test begin: paddle.concat(list[Tensor([0, 256],"float32"),Tensor([0, 256],"float32"),Tensor([0, 256],"float32"),Tensor([0, 256],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107420 (unix time) try "date -d @1749107420" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fbfe44ee310) received by PID 35160 (TID 0x7fbfe50cc740) from PID 18446744073244959504 ***]


2025-06-05 15:10:00.970146 GPU 0 35119 test begin: paddle.concat(list[Tensor([0, 2704, 11],"float32"),Tensor([0, 676, 11],"float32"),Tensor([0, 169, 11],"float32"),Tensor([0, 49, 11],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107422 (unix time) try "date -d @1749107422" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f1994f3f0a0) received by PID 35119 (TID 0x7f1995b1d740) from PID 18446744071913599136 ***]


2025-06-05 15:10:01.755029 GPU 1 35216 test begin: paddle.concat(list[Tensor([0, 2704, 32],"float32"),Tensor([0, 676, 32],"float32"),Tensor([0, 169, 32],"float32"),Tensor([0, 49, 32],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107423 (unix time) try "date -d @1749107423" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f93f2ca9310) received by PID 35216 (TID 0x7f93f3887740) from PID 18446744073487946512 ***]


2025-06-05 15:10:01.784571 GPU 1 35257 test begin: paddle.concat(list[Tensor([0, 27648, 256],"float32"),Tensor([0, 6912, 256],"float32"),Tensor([0, 1728, 256],"float32"),Tensor([0, 432, 256],"float32"),Tensor([0, 108, 256],"float32"),], 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107423 (unix time) try "date -d @1749107423" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fd4f92fd1a0) received by PID 35257 (TID 0x7fd4f9edb740) from PID 18446744073595244960 ***]


2025-06-05 15:10:01.790023 GPU 0 35345 test begin: paddle.concat(list[Tensor([0, 27648, 2],"float32"),Tensor([0, 6912, 2],"float32"),Tensor([0, 1728, 2],"float32"),Tensor([0, 432, 2],"float32"),Tensor([0, 108, 2],"float32"),], 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107424 (unix time) try "date -d @1749107424" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f4f9ec931a0) received by PID 35345 (TID 0x7f4f9f871740) from PID 18446744072078569888 ***]


2025-06-05 15:10:01.927061 GPU 0 35181 test begin: paddle.concat(list[Tensor([0, 27648],"float32"),Tensor([0, 6912],"float32"),Tensor([0, 1728],"float32"),Tensor([0, 432],"float32"),Tensor([0, 108],"float32"),], 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107425 (unix time) try "date -d @1749107425" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f69b215c160) received by PID 35181 (TID 0x7f69b2d3a740) from PID 18446744072402354528 ***]


2025-06-05 15:10:01.957848 GPU 0 35236 test begin: paddle.concat(list[Tensor([0, 28800],"float32"),Tensor([0, 7200],"float32"),Tensor([0, 1800],"float32"),Tensor([0, 450],"float32"),Tensor([0, 117],"float32"),], 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107427 (unix time) try "date -d @1749107427" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f67b67f42a0) received by PID 35236 (TID 0x7f67b73d2740) from PID 18446744072476377760 ***]


2025-06-05 15:10:02.013389 GPU 1 35347 test begin: paddle.concat(list[Tensor([0, 2],"float32"),Tensor([0, 2],"float32"),], -1, )

2025-06-05 15:10:02.111065 GPU 1 35268 test begin: paddle.concat(list[Tensor([0, 2],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107426 (unix time) try "date -d @1749107426" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 35268 (TID 0x7f468fc98740) from PID 0 ***]


2025-06-05 15:10:02.223842 GPU 0 35193 test begin: paddle.concat(list[Tensor([0, 3, 10, 10, 1],"float32"),Tensor([0, 3, 10, 10, 1],"float32"),Tensor([0, 3, 10, 10, 1],"float32"),Tensor([0, 3, 10, 10, 1],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107427 (unix time) try "date -d @1749107427" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fb065f162f0) received by PID 35193 (TID 0x7fb066af4740) from PID 1710318320 ***]


2025-06-05 15:10:02.228914 GPU 1 35206 test begin: paddle.concat(list[Tensor([0, 3, 16, 16],"float32"),Tensor([0, 3, 16, 16],"float32"),Tensor([0, 2, 16, 16],"float32"),], 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107424 (unix time) try "date -d @1749107424" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f6845839ff0) received by PID 35206 (TID 0x7f6846418740) from PID 1166254064 ***]


2025-06-05 15:10:02.240575 GPU 1 35244 test begin: paddle.concat(list[Tensor([0, 3, 20, 20, 1],"float32"),Tensor([0, 3, 20, 20, 1],"float32"),Tensor([0, 3, 20, 20, 1],"float32"),Tensor([0, 3, 20, 20, 1],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107425 (unix time) try "date -d @1749107425" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f3779fb61c0) received by PID 35244 (TID 0x7f377ab94740) from PID 2046517696 ***]


2025-06-05 15:10:02.322013 GPU 0 35161 test begin: paddle.concat(list[Tensor([0, 3, 240, 240],"float32"),Tensor([0, 3, 240, 240],"float32"),Tensor([0, 3, 240, 240],"float32"),Tensor([0, 3, 240, 240],"float32"),], 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107424 (unix time) try "date -d @1749107424" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fec79f08330) received by PID 35161 (TID 0x7fec7aae6740) from PID 2045805360 ***]


2025-06-05 15:10:21.442427 GPU 0 35756 test begin: paddle.concat(list[Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),], 0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107450 (unix time) try "date -d @1749107450" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 35756 (TID 0x7f67ef138740) from PID 24 ***]


2025-06-05 15:10:21.464830 GPU 0 35739 test begin: paddle.concat(list[Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),Tensor([0, 3, 336, 336],"float32"),], 0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107449 (unix time) try "date -d @1749107449" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 35739 (TID 0x7f6251bc0740) from PID 24 ***]


2025-06-05 15:10:21.676503 GPU 1 35806 test begin: paddle.concat(list[Tensor([0, 3, 64],"float32"),Tensor([0, 3, 64],"float32"),Tensor([0, 3, 64],"float32"),Tensor([0, 3, 64],"float32"),Tensor([0, 3, 64],"float32"),Tensor([0, 3, 64],"float32"),Tensor([0, 3, 64],"float32"),Tensor([0, 3, 64],"float32"),Tensor([0, 3, 64],"float32"),Tensor([0, 3, 64],"float32"),Tensor([0, 3, 64],"float32"),Tensor([0, 3, 64],"float32"),Tensor([0, 3, 64],"float32"),], axis=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107449 (unix time) try "date -d @1749107449" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fafa84f82d0) received by PID 35806 (TID 0x7fafa90d6740) from PID 18446744072238367440 ***]


2025-06-05 15:10:21.794477 GPU 1 35757 test begin: paddle.concat(list[Tensor([0, 304, 918],"float16"),Tensor([0, 304, 918],"float16"),Tensor([0, 304, 918],"float16"),Tensor([0, 304, 918],"float16"),Tensor([0, 304, 918],"float16"),Tensor([0, 304, 918],"float16"),Tensor([0, 304, 918],"float16"),Tensor([0, 304, 918],"float16"),Tensor([0, 304, 918],"float16"),Tensor([0, 304, 918],"float16"),Tensor([0, 304, 918],"float16"),Tensor([0, 304, 918],"float16"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107452 (unix time) try "date -d @1749107452" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fd27eeb5330) received by PID 35757 (TID 0x7fd27fa93740) from PID 2129351472 ***]


2025-06-05 15:10:22.875497 GPU 1 35876 test begin: paddle.concat(list[Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107450 (unix time) try "date -d @1749107450" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 35876 (TID 0x7efeece99740) from PID 24 ***]


2025-06-05 15:10:23.498397 GPU 0 35892 test begin: paddle.concat(list[Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),Tensor([0, 32],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107452 (unix time) try "date -d @1749107452" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f6e5b759300) received by PID 35892 (TID 0x7f6e5c337740) from PID 1534432000 ***]


2025-06-05 15:10:35.152110 GPU 0 36317 test begin: paddle.concat(list[Tensor([0, 346, 918],"float16"),Tensor([0, 346, 918],"float16"),Tensor([0, 346, 918],"float16"),Tensor([0, 346, 918],"float16"),Tensor([0, 346, 918],"float16"),Tensor([0, 346, 918],"float16"),Tensor([0, 346, 918],"float16"),Tensor([0, 346, 918],"float16"),Tensor([0, 346, 918],"float16"),Tensor([0, 346, 918],"float16"),Tensor([0, 346, 918],"float16"),Tensor([0, 346, 918],"float16"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107459 (unix time) try "date -d @1749107459" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fd7d2314350) received by PID 36317 (TID 0x7fd7d2ef2740) from PID 18446744072941028176 ***]


2025-06-05 15:10:35.569601 GPU 0 36365 test begin: paddle.concat(list[Tensor([0, 36000, 1],"float32"),], axis=1, )

2025-06-05 15:10:35.675332 GPU 1 36412 test begin: paddle.concat(list[Tensor([0, 36000, 4],"float32"),], axis=1, )

2025-06-05 15:10:35.818725 GPU 0 36530 test begin: paddle.concat(list[Tensor([0, 4, 2, 5],"float64"),Tensor([0, 4, 2, 5],"float64"),Tensor([0, 4, 2, 5],"float64"),], axis=1, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107464 (unix time) try "date -d @1749107464" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f00c49f3110) received by PID 36530 (TID 0x7f00c55d1740) from PID 18446744072713351440 ***]


2025-06-05 15:10:35.962762 GPU 1 36500 test begin: paddle.concat(list[Tensor([0, 4, 2, 5],"float64"),], axis=1, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107460 (unix time) try "date -d @1749107460" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 36500 (TID 0x7f563d108740) from PID 0 ***]


2025-06-05 15:10:36.530227 GPU 0 36604 test begin: paddle.concat(list[Tensor([0, 4, 2, 5],"float64"),], axis=2, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107460 (unix time) try "date -d @1749107460" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 36604 (TID 0x7feb85ed4740) from PID 0 ***]


2025-06-05 15:10:36.596201 GPU 1 36565 test begin: paddle.concat(list[Tensor([0, 4, 2],"float64"),Tensor([0, 4, 2],"float64"),Tensor([0, 4, 2],"float64"),], axis=1, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107464 (unix time) try "date -d @1749107464" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xa3df4d40) received by PID 36565 (TID 0x7fed9797c740) from PID 18446744072163904832 ***]


2025-06-05 15:10:36.616854 GPU 1 36548 test begin: paddle.concat(list[Tensor([0, 4, 2],"float64"),], axis=1, name=None, )

2025-06-05 15:10:36.852708 GPU 0 36576 test begin: paddle.concat(list[Tensor([0, 400],"float32"),Tensor([0, 400],"float32"),Tensor([0, 400],"float32"),Tensor([0, 400],"float32"),Tensor([0, 400],"float32"),Tensor([0, 400],"float32"),Tensor([0, 400],"float32"),Tensor([0, 400],"float32"),Tensor([0, 400],"float32"),Tensor([0, 400],"float32"),Tensor([0, 400],"float32"),Tensor([0, 400],"float32"),Tensor([0, 400],"float32"),Tensor([0, 400],"float32"),Tensor([0, 400],"float32"),Tensor([0, 400],"float32"),Tensor([0, 400],"float32"),Tensor([0, 400],"float32"),Tensor([0, 400],"float32"),Tensor([0, 400],"float32"),Tensor([0, 400],"float32"),Tensor([0, 400],"float32"),Tensor([0, 400],"float32"),Tensor([0, 400],"float32"),Tensor([0, 400],"float32"),], axis=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107463 (unix time) try "date -d @1749107463" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xa5b83300) received by PID 36576 (TID 0x7f9c7ee52740) from PID 18446744072194896640 ***]


2025-06-05 15:10:37.008733 GPU 1 36662 test begin: paddle.concat(list[Tensor([0, 4096, 4],"float32"),Tensor([0, 1024, 4],"float32"),Tensor([0, 256, 4],"float32"),], 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107462 (unix time) try "date -d @1749107462" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f5edbf78120) received by PID 36662 (TID 0x7f5edcb56740) from PID 18446744073105015072 ***]


2025-06-05 15:10:37.115035 GPU 0 36720 test begin: paddle.concat(list[Tensor([0, 4800, 256],"float32"),Tensor([0, 1200, 256],"float32"),Tensor([0, 300, 256],"float32"),Tensor([0, 80, 256],"float32"),], 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107462 (unix time) try "date -d @1749107462" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f8282c3f0e0) received by PID 36720 (TID 0x7f828381d740) from PID 18446744071608463584 ***]


2025-06-05 15:10:37.179137 GPU 1 36617 test begin: paddle.concat(list[Tensor([0, 4800, 2],"float32"),Tensor([0, 1200, 2],"float32"),Tensor([0, 300, 2],"float32"),Tensor([0, 80, 2],"float32"),], 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107463 (unix time) try "date -d @1749107463" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fd2c13fd300) received by PID 36617 (TID 0x7fd2c1fdb740) from PID 18446744072656769792 ***]


2025-06-05 15:10:37.454011 GPU 1 36639 test begin: paddle.concat(list[Tensor([0, 4800],"float32"),Tensor([0, 1200],"float32"),Tensor([0, 300],"float32"),Tensor([0, 80],"float32"),], 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107465 (unix time) try "date -d @1749107465" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fb5f10be0a0) received by PID 36639 (TID 0x7fb5f1c9c740) from PID 18446744073458671776 ***]


2025-06-05 15:10:37.520866 GPU 0 36629 test begin: paddle.concat(list[Tensor([0, 4],"float32"),Tensor([0, 4],"float32"),Tensor([0, 4],"float32"),Tensor([0, 4],"float32"),Tensor([0, 4],"float32"),Tensor([0, 4],"float32"),Tensor([0, 4],"float32"),Tensor([0, 4],"float32"),Tensor([0, 4],"float32"),Tensor([0, 4],"float32"),Tensor([0, 4],"float32"),Tensor([0, 4],"float32"),Tensor([0, 4],"float32"),Tensor([0, 4],"float32"),Tensor([0, 4],"float32"),Tensor([0, 4],"float32"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107462 (unix time) try "date -d @1749107462" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f6f9a656390) received by PID 36629 (TID 0x7f6f9b234740) from PID 18446744072004920208 ***]


2025-06-05 15:10:37.776238 GPU 0 36728 test begin: paddle.concat(list[Tensor([0, 5, 1, 1],"float32"),Tensor([0, 5, 1, 3],"float32"),Tensor([0, 5, 1, 1],"float32"),], axis=3, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107465 (unix time) try "date -d @1749107465" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f0b59dca2a0) received by PID 36728 (TID 0x7f0b5a9a8740) from PID 1507631776 ***]


2025-06-05 15:10:37.971468 GPU 1 36665 test begin: paddle.concat(list[Tensor([0, 500, 1],"int64"),Tensor([0, 500, 1],"int64"),Tensor([0, 500, 1],"int64"),Tensor([0, 500, 1],"int64"),Tensor([0, 500, 1],"int64"),Tensor([0, 500, 1],"int64"),Tensor([0, 500, 1],"int64"),Tensor([0, 500, 1],"int64"),Tensor([0, 500, 1],"int64"),Tensor([0, 500, 1],"int64"),Tensor([0, 500, 1],"int64"),Tensor([0, 500, 1],"int64"),Tensor([0, 500, 1],"int64"),Tensor([0, 500, 1],"int64"),Tensor([0, 500, 1],"int64"),Tensor([0, 500, 1],"int64"),Tensor([0, 500, 1],"int64"),Tensor([0, 500, 1],"int64"),Tensor([0, 500, 1],"int64"),Tensor([0, 500, 1],"int64"),], axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107464 (unix time) try "date -d @1749107464" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7faebbf95350) received by PID 36665 (TID 0x7faebcb73740) from PID 18446744072568263504 ***]


2025-06-05 15:11:01.164507 GPU 0 37530 test begin: paddle.concat(list[Tensor([0, 512],"float16"),Tensor([0, 128],"float16"),Tensor([0, 128],"float16"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107487 (unix time) try "date -d @1749107487" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xc545340) received by PID 37530 (TID 0x7f000b3fe740) from PID 206852928 ***]


2025-06-05 15:11:01.556443 GPU 0 37491 test begin: paddle.concat(list[Tensor([0, 6408],"float32"),Tensor([0, 1620],"float32"),Tensor([0, 414],"float32"),Tensor([0, 108],"float32"),], 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107488 (unix time) try "date -d @1749107488" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fedb28f3310) received by PID 37491 (TID 0x7fedb34d1740) from PID 18446744072410313488 ***]


2025-06-05 15:11:01.852707 GPU 1 37531 test begin: paddle.concat(list[Tensor([0, 6],"float64"),Tensor([0, 6],"float64"),Tensor([0, 6],"float64"),Tensor([0, 6],"float64"),Tensor([0, 6],"float64"),Tensor([0, 6],"float64"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107488 (unix time) try "date -d @1749107488" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fdd09ae5300) received by PID 37531 (TID 0x7fdd0a6c3740) from PID 162419456 ***]


2025-06-05 15:11:01.986464 GPU 1 37518 test begin: paddle.concat(list[Tensor([0, 7],"int64"),Tensor([0, 10],"int64"),Tensor([0, 7],"int64"),], axis=1, )
element 0 of tensors does not require grad and does not have a grad_fn


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107488 (unix time) try "date -d @1749107488" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f1d02ebc150) received by PID 37518 (TID 0x7f1d03a9a740) from PID 49004880 ***]


2025-06-05 15:11:02.006675 GPU 1 37589 test begin: paddle.concat(list[Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107487 (unix time) try "date -d @1749107487" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7ff879e5b3a0) received by PID 37589 (TID 0x7ff87aa39740) from PID 2045096864 ***]


2025-06-05 15:11:04.177381 GPU 0 37637 test begin: paddle.concat(list[Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107488 (unix time) try "date -d @1749107488" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f71499443f0) received by PID 37637 (TID 0x7f714a522740) from PID 1234453488 ***]


2025-06-05 15:11:13.541914 GPU 1 37781 test begin: paddle.concat(list[Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),Tensor([0],"float16"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107496 (unix time) try "date -d @1749107496" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f1935dd4300) received by PID 37781 (TID 0x7f19369b2740) from PID 903693056 ***]


2025-06-05 15:11:13.583063 GPU 0 37825 test begin: paddle.concat(list[Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107497 (unix time) try "date -d @1749107497" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 37825 (TID 0x7f4abb773740) from PID 24 ***]


2025-06-05 15:11:13.625900 GPU 1 37793 test begin: paddle.concat(list[Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107496 (unix time) try "date -d @1749107496" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f32f698a3a0) received by PID 37793 (TID 0x7f32f7568740) from PID 18446744073551782816 ***]


2025-06-05 15:11:13.912405 GPU 0 37855 test begin: paddle.concat(list[Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107498 (unix time) try "date -d @1749107498" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fd9498512e0) received by PID 37855 (TID 0x7fd94a42f740) from PID 1233457888 ***]


2025-06-05 15:11:13.923269 GPU 1 37804 test begin: paddle.concat(list[Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107501 (unix time) try "date -d @1749107501" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f74e7ddb2c0) received by PID 37804 (TID 0x7f74e89b9740) from PID 18446744073304650432 ***]


2025-06-05 15:11:14.143742 GPU 0 37831 test begin: paddle.concat(list[Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),], axis=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107501 (unix time) try "date -d @1749107501" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xa5e211d0) received by PID 37831 (TID 0x7f4535bfd740) from PID 18446744072197640656 ***]


2025-06-05 15:11:14.557122 GPU 1 37943 test begin: paddle.concat(list[Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),], axis=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107500 (unix time) try "date -d @1749107500" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 37943 (TID 0x7fe6ee4be740) from PID 24 ***]


2025-06-05 15:11:14.574765 GPU 0 37990 test begin: paddle.concat(list[Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),], axis=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107504 (unix time) try "date -d @1749107504" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f4e6964f3d0) received by PID 37990 (TID 0x7f4e6a228740) from PID 1768223696 ***]


2025-06-05 15:11:14.616321 GPU 0 37942 test begin: paddle.concat(list[Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),], axis=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107499 (unix time) try "date -d @1749107499" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fe77eb95390) received by PID 37942 (TID 0x7fe77f773740) from PID 2126074768 ***]


2025-06-05 15:11:14.757969 GPU 0 37980 test begin: paddle.concat(list[Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),], axis=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107501 (unix time) try "date -d @1749107501" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f1d144993a0) received by PID 37980 (TID 0x7f1d15077740) from PID 340366240 ***]


2025-06-05 15:11:15.094574 GPU 1 38034 test begin: paddle.concat(list[Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),], axis=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107502 (unix time) try "date -d @1749107502" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f53396403a0) received by PID 38034 (TID 0x7f533a21e740) from PID 962855840 ***]


2025-06-05 15:11:15.162453 GPU 0 38071 test begin: paddle.concat(list[Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),], axis=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107501 (unix time) try "date -d @1749107501" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f4ecaa44320) received by PID 38071 (TID 0x7f4ecb622740) from PID 18446744072814347040 ***]


2025-06-05 15:11:15.208867 GPU 0 38020 test begin: paddle.concat(list[Tensor([0],"int64"),Tensor([0],"int64"),Tensor([0],"int64"),Tensor([0],"int64"),Tensor([0],"int64"),Tensor([0],"int64"),Tensor([0],"int64"),Tensor([0],"int64"),Tensor([0],"int64"),Tensor([0],"int64"),Tensor([0],"int64"),Tensor([0],"int64"),Tensor([0],"int64"),Tensor([0],"int64"),Tensor([0],"int64"),Tensor([0],"int64"),], )
element 0 of tensors does not require grad and does not have a grad_fn


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107501 (unix time) try "date -d @1749107501" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f05464d33a0) received by PID 38020 (TID 0x7f05470b1740) from PID 1179464608 ***]


2025-06-05 15:11:15.436399 GPU 1 38081 test begin: paddle.concat(list[Tensor([1, 0, 1, 16],"float32"),Tensor([1, 0, 1, 16],"float32"),], axis=-1, )

2025-06-05 15:11:15.537688 GPU 1 38061 test begin: paddle.concat(list[Tensor([1, 0, 1, 1],"float64"),Tensor([1, 0, 1, 1],"float64"),Tensor([1, 0, 1, 1],"float64"),], axis=1, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107501 (unix time) try "date -d @1749107501" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f994d869050) received by PID 38061 (TID 0x7f994e447740) from PID 1300664400 ***]


2025-06-05 15:11:15.557003 GPU 1 38024 test begin: paddle.concat(list[Tensor([1, 0, 1, 1],"float64"),], axis=1, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107501 (unix time) try "date -d @1749107501" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 38024 (TID 0x7fe2b8f5e740) from PID 0 ***]


2025-06-05 15:11:38.108262 GPU 0 38546 test begin: paddle.concat(list[Tensor([1, 0, 1, 1],"float64"),], axis=2, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107524 (unix time) try "date -d @1749107524" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 38546 (TID 0x7f7ab0a7d740) from PID 0 ***]


2025-06-05 15:11:38.374748 GPU 1 38560 test begin: paddle.concat(list[Tensor([1, 0, 100, 152],"float32"),Tensor([1, 0, 100, 152],"float32"),], axis=1, )

2025-06-05 15:11:38.723695 GPU 0 38649 test begin: paddle.concat(list[Tensor([1, 0, 10285, 1],"float32"),Tensor([1, 0, 10285, 1],"float32"),Tensor([1, 0, 10285, 1],"float32"),Tensor([1, 0, 10285, 1],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107523 (unix time) try "date -d @1749107523" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fcb1b887310) received by PID 38649 (TID 0x7fcb1c465740) from PID 461927184 ***]


2025-06-05 15:11:38.888768 GPU 1 38614 test begin: paddle.concat(list[Tensor([1, 0, 10],"float32"),Tensor([1, 0, 10],"float32"),Tensor([1, 0, 10],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107526 (unix time) try "date -d @1749107526" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f4c587f0190) received by PID 38614 (TID 0x7f4c593ce740) from PID 1484718480 ***]


2025-06-05 15:11:39.724241 GPU 0 38602 test begin: paddle.concat(list[Tensor([1, 0, 11],"float32"),Tensor([1, 0, 11],"float32"),Tensor([1, 0, 11],"float32"),Tensor([1, 0, 11],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107527 (unix time) try "date -d @1749107527" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fb342c16310) received by PID 38602 (TID 0x7fb3437f4740) from PID 1119970064 ***]


2025-06-05 15:11:40.575600 GPU 1 38676 test begin: paddle.concat(list[Tensor([1, 0, 124, 128],"float32"),Tensor([1, 0, 124, 128],"float32"),Tensor([1, 0, 124, 128],"float32"),Tensor([1, 0, 124, 128],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107528 (unix time) try "date -d @1749107528" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f375f3081f0) received by PID 38676 (TID 0x7f375fee6740) from PID 1597014512 ***]


2025-06-05 15:11:50.260491 GPU 1 38772 test begin: paddle.concat(list[Tensor([1, 0, 128],"float16"),Tensor([1, 0, 107],"float16"),], axis=2, )

2025-06-05 15:11:51.470361 GPU 0 38870 test begin: paddle.concat(list[Tensor([1, 0, 128],"float32"),Tensor([1, 0, 128],"float32"),Tensor([1, 0, 128],"float32"),Tensor([1, 0, 128],"float32"),], axis=2, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107534 (unix time) try "date -d @1749107534" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fd794035210) received by PID 38870 (TID 0x7fd794c13740) from PID 18446744071897829904 ***]


2025-06-05 15:11:51.870650 GPU 1 38992 test begin: paddle.concat(list[Tensor([1, 0, 14, 14, 192],"float16"),Tensor([1, 0, 14, 14, 192],"float16"),Tensor([1, 0, 14, 14, 192],"float16"),Tensor([1, 0, 14, 14, 192],"float16"),], -1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107536 (unix time) try "date -d @1749107536" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fa6ec5ce0e0) received by PID 38992 (TID 0x7fa6ed1ac740) from PID 18446744073380094176 ***]


2025-06-05 15:11:52.069103 GPU 0 38901 test begin: paddle.concat(list[Tensor([1, 0, 14, 14, 192],"float32"),Tensor([1, 0, 14, 14, 192],"float32"),Tensor([1, 0, 14, 14, 192],"float32"),Tensor([1, 0, 14, 14, 192],"float32"),], -1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107536 (unix time) try "date -d @1749107536" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fe36feaf2e0) received by PID 38901 (TID 0x7fe370a8d740) from PID 1877668576 ***]


2025-06-05 15:11:52.097953 GPU 0 38946 test begin: paddle.concat(list[Tensor([1, 0, 140, 1, 2, 7],"float32"),Tensor([1, 0, 140, 1, 2, 7],"float32"),Tensor([1, 0, 140, 1, 2, 7],"float32"),], axis=-3, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107537 (unix time) try "date -d @1749107537" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f487e720190) received by PID 38946 (TID 0x7f487f2fe740) from PID 2121400720 ***]


2025-06-05 15:11:52.102265 GPU 1 39083 test begin: paddle.concat(list[Tensor([1, 0, 15, 384],"float32"),Tensor([1, 0, 15, 384],"float32"),Tensor([1, 0, 15, 384],"float32"),Tensor([1, 0, 15, 384],"float32"),], -1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107538 (unix time) try "date -d @1749107538" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fa3ba288310) received by PID 39083 (TID 0x7fa3bae66740) from PID 18446744072537801488 ***]


2025-06-05 15:11:52.102578 GPU 1 38993 test begin: paddle.concat(list[Tensor([1, 0, 18, 18],"float32"),Tensor([1, 0, 18, 18],"float32"),Tensor([1, 0, 18, 18],"float32"),Tensor([1, 0, 18, 18],"float32"),Tensor([1, 0, 18, 18],"float32"),Tensor([1, 0, 18, 18],"float32"),Tensor([1, 0, 18, 18],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107537 (unix time) try "date -d @1749107537" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f311f6ce2c0) received by PID 38993 (TID 0x7f31202ac740) from PID 527229632 ***]


2025-06-05 15:11:52.128810 GPU 0 39015 test begin: paddle.concat(list[Tensor([1, 0, 18, 768],"float32"),Tensor([1, 0, 18, 768],"float32"),Tensor([1, 0, 18, 768],"float32"),Tensor([1, 0, 18, 768],"float32"),], -1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107537 (unix time) try "date -d @1749107537" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f2583c4c1a0) received by PID 39015 (TID 0x7f258482a740) from PID 18446744071625294240 ***]


2025-06-05 15:11:52.191218 GPU 1 38976 test begin: paddle.concat(list[Tensor([1, 0, 1],"float16"),], axis=2, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107538 (unix time) try "date -d @1749107538" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f045df0fcb0) received by PID 38976 (TID 0x7f06461ac740) from PID 1576074416 ***]


2025-06-05 15:11:52.258916 GPU 1 39037 test begin: paddle.concat(list[Tensor([1, 0, 1],"float32"),Tensor([1, 0, 1],"float32"),Tensor([1, 0, 1],"float32"),Tensor([1, 0, 1],"float32"),Tensor([1, 0, 1],"float32"),Tensor([1, 0, 1],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107538 (unix time) try "date -d @1749107538" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f25b45e9330) received by PID 39037 (TID 0x7f25b51c7740) from PID 18446744072440681264 ***]


2025-06-05 15:11:52.261015 GPU 1 39102 test begin: paddle.concat(list[Tensor([1, 0, 1],"float32"),Tensor([1, 0, 1],"float32"),Tensor([1, 0, 1],"float32"),Tensor([1, 0, 1],"float32"),Tensor([1, 0, 1],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107538 (unix time) try "date -d @1749107538" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fe026468310) received by PID 39102 (TID 0x7fe027046740) from PID 642155280 ***]


2025-06-05 15:11:52.266792 GPU 0 39054 test begin: paddle.concat(list[Tensor([1, 0, 1],"float32"),], axis=1, )

2025-06-05 15:11:52.378039 GPU 0 39026 test begin: paddle.concat(list[Tensor([1, 0, 1],"float32"),], axis=2, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107536 (unix time) try "date -d @1749107536" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 39026 (TID 0x7fdc4558b740) from PID 0 ***]


2025-06-05 15:11:52.605186 GPU 0 39071 test begin: paddle.concat(list[Tensor([1, 0, 1],"float64"),Tensor([1, 0, 1],"float64"),Tensor([1, 0, 1],"float64"),], axis=1, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107536 (unix time) try "date -d @1749107536" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fae5a8e20d0) received by PID 39071 (TID 0x7fae5b4bb740) from PID 1519263952 ***]


2025-06-05 15:11:54.678543 GPU 0 39147 test begin: paddle.concat(list[Tensor([1, 0, 1],"float64"),], axis=1, name=None, )

2025-06-05 15:11:57.246865 GPU 1 39204 test begin: paddle.concat(list[Tensor([1, 0, 1],"int64"),Tensor([1, 0, 1],"int64"),Tensor([1, 0, 1],"int64"),Tensor([1, 0, 1],"int64"),Tensor([1, 0, 1],"int64"),Tensor([1, 0, 1],"int64"),Tensor([1, 0, 1],"int64"),Tensor([1, 0, 1],"int64"),Tensor([1, 0, 1],"int64"),Tensor([1, 0, 1],"int64"),Tensor([1, 0, 1],"int64"),Tensor([1, 0, 1],"int64"),Tensor([1, 0, 1],"int64"),Tensor([1, 0, 1],"int64"),Tensor([1, 0, 1],"int64"),Tensor([1, 0, 1],"int64"),Tensor([1, 0, 1],"int64"),Tensor([1, 0, 1],"int64"),Tensor([1, 0, 1],"int64"),Tensor([1, 0, 1],"int64"),], axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<long, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, long>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107540 (unix time) try "date -d @1749107540" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 39204 (TID 0x7f1452d56740) from PID 24 ***]


2025-06-05 15:12:13.828051 GPU 1 39591 test begin: paddle.concat(list[Tensor([1, 0, 2, 8],"float32"),Tensor([1, 0, 1, 8],"float32"),], axis=2, )

2025-06-05 15:12:14.573970 GPU 0 39612 test begin: paddle.concat(list[Tensor([1, 0, 20, 20],"float32"),Tensor([1, 0, 20, 20],"float32"),Tensor([1, 0, 20, 20],"float32"),Tensor([1, 0, 20, 20],"float32"),Tensor([1, 0, 20, 20],"float32"),Tensor([1, 0, 20, 20],"float32"),Tensor([1, 0, 20, 20],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107568 (unix time) try "date -d @1749107568" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f48b8b27300) received by PID 39612 (TID 0x7f48b9705740) from PID 18446744072513286912 ***]


2025-06-05 15:12:14.719722 GPU 0 39634 test begin: paddle.concat(list[Tensor([1, 0, 20, 20],"float32"),Tensor([1, 0, 20, 20],"float32"),Tensor([1, 0, 20, 20],"float32"),Tensor([1, 0, 20, 20],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107571 (unix time) try "date -d @1749107571" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fdb59b77160) received by PID 39634 (TID 0x7fdb5a755740) from PID 1505194336 ***]


2025-06-05 15:12:15.823088 GPU 1 39709 test begin: paddle.concat(list[Tensor([1, 0, 216, 2, 7],"float32"),], axis=-2, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107571 (unix time) try "date -d @1749107571" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 39709 (TID 0x7fc94f91d740) from PID 0 ***]


2025-06-05 15:12:16.632965 GPU 0 39723 test begin: paddle.concat(list[Tensor([1, 0, 24276, 1],"float32"),Tensor([1, 0, 24276, 1],"float32"),Tensor([1, 0, 24276, 1],"float32"),Tensor([1, 0, 24276, 1],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107574 (unix time) try "date -d @1749107574" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f05a24062a0) received by PID 39723 (TID 0x7f05a2fe4740) from PID 18446744072136712864 ***]


2025-06-05 15:12:16.669810 GPU 1 39740 test begin: paddle.concat(list[Tensor([1, 0, 256, 256],"float32"),Tensor([1, 0, 256, 256],"float32"),Tensor([1, 0, 256, 256],"float32"),Tensor([1, 0, 256, 256],"float32"),], 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107574 (unix time) try "date -d @1749107574" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fc4fe8adca0) received by PID 39740 (TID 0x7fc4ff48c740) from PID 18446744073685097632 ***]


2025-06-05 15:12:33.482797 GPU 1 39823 test begin: paddle.concat(list[Tensor([1, 0, 256],"float32"),Tensor([1, 0, 256],"float32"),Tensor([1, 0, 256],"float32"),Tensor([1, 0, 256],"float32"),Tensor([1, 0, 256],"float32"),], 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107579 (unix time) try "date -d @1749107579" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f1678af62c0) received by PID 39823 (TID 0x7f16796d4740) from PID 2024760000 ***]


2025-06-05 15:12:36.213068 GPU 0 39898 test begin: paddle.concat(list[Tensor([1, 0, 256],"float32"),Tensor([1, 0, 256],"float32"),Tensor([1, 0, 256],"float32"),Tensor([1, 0, 256],"float32"),], 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107581 (unix time) try "date -d @1749107581" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f677e2a60a0) received by PID 39898 (TID 0x7f677ee84740) from PID 2116706464 ***]


2025-06-05 15:12:36.758298 GPU 1 39950 test begin: paddle.concat(list[Tensor([1, 0, 2704],"float32"),Tensor([1, 0, 676],"float32"),Tensor([1, 0, 169],"float32"),Tensor([1, 0, 49],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107582 (unix time) try "date -d @1749107582" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f1b8e5021a0) received by PID 39950 (TID 0x7f1b8f0e0740) from PID 18446744071802200480 ***]


2025-06-05 15:12:37.226573 GPU 0 40293 test begin: paddle.concat(list[Tensor([1, 0, 27648],"float32"),Tensor([1, 0, 6912],"float32"),Tensor([1, 0, 1728],"float32"),Tensor([1, 0, 432],"float32"),Tensor([1, 0, 108],"float32"),Tensor([1, 0, 30],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107582 (unix time) try "date -d @1749107582" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f38913b9330) received by PID 40293 (TID 0x7f3891f97740) from PID 18446744071851184944 ***]


2025-06-05 15:12:37.338256 GPU 0 40354 test begin: paddle.concat(list[Tensor([1, 0, 28800],"float32"),Tensor([1, 0, 7200],"float32"),Tensor([1, 0, 1800],"float32"),Tensor([1, 0, 450],"float32"),Tensor([1, 0, 117],"float32"),Tensor([1, 0, 35],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107583 (unix time) try "date -d @1749107583" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fb35757c330) received by PID 40354 (TID 0x7fb35815a740) from PID 1465369392 ***]


2025-06-05 15:12:37.425603 GPU 1 40401 test begin: paddle.concat(list[Tensor([1, 0, 2],"float32"),Tensor([1, 0, 2],"float32"),Tensor([1, 0, 2],"float32"),Tensor([1, 0, 2],"float32"),Tensor([1, 0, 2],"float32"),], 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107581 (unix time) try "date -d @1749107581" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fee2171a160) received by PID 40401 (TID 0x7fee222f8740) from PID 561095008 ***]


2025-06-05 15:12:37.690054 GPU 0 39962 test begin: paddle.concat(list[Tensor([1, 0, 2],"float32"),Tensor([1, 0, 2],"float32"),Tensor([1, 0, 2],"float32"),Tensor([1, 0, 2],"float32"),], 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107583 (unix time) try "date -d @1749107583" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f804fb5c1c0) received by PID 39962 (TID 0x7f805073a740) from PID 1337311680 ***]


2025-06-05 15:12:37.844825 GPU 0 40445 test begin: paddle.concat(list[Tensor([1, 0, 3136],"float32"),Tensor([1, 0, 784],"float32"),Tensor([1, 0, 196],"float32"),Tensor([1, 0, 49],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107584 (unix time) try "date -d @1749107584" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f3bc13f6330) received by PID 40445 (TID 0x7f3bc1fd4740) from PID 18446744072656741168 ***]


2025-06-05 15:12:38.010177 GPU 1 40433 test begin: paddle.concat(list[Tensor([1, 0, 32, 32],"float32"),Tensor([1, 0, 32, 32],"float32"),Tensor([1, 0, 32, 32],"float32"),Tensor([1, 0, 32, 32],"float32"),Tensor([1, 0, 32, 32],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107584 (unix time) try "date -d @1749107584" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fca1a7fa310) received by PID 40433 (TID 0x7fca1b3d8740) from PID 444572432 ***]


2025-06-05 15:12:38.275599 GPU 0 40326 test begin: paddle.concat(list[Tensor([1, 0, 32],"float32"),Tensor([1, 0, 32],"float32"),Tensor([1, 0, 32],"float32"),Tensor([1, 0, 32],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107584 (unix time) try "date -d @1749107584" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fcd81a8a310) received by PID 40326 (TID 0x7fcd82663740) from PID 18446744071589896976 ***]


2025-06-05 15:12:38.288533 GPU 1 40406 test begin: paddle.concat(list[Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),], 0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107582 (unix time) try "date -d @1749107582" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 40406 (TID 0x7ff8be135740) from PID 24 ***]


2025-06-05 15:12:38.304806 GPU 1 40331 test begin: paddle.concat(list[Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),Tensor([1, 0, 336, 336],"float32"),], 0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107586 (unix time) try "date -d @1749107586" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 40331 (TID 0x7f5fb0ce9740) from PID 24 ***]


2025-06-05 15:12:38.351336 GPU 1 40449 test begin: paddle.concat(list[Tensor([1, 0, 4800],"float32"),Tensor([1, 0, 1200],"float32"),Tensor([1, 0, 300],"float32"),Tensor([1, 0, 80],"float32"),Tensor([1, 0, 20],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107584 (unix time) try "date -d @1749107584" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f0db5ddc330) received by PID 40449 (TID 0x7f0db69ba740) from PID 18446744072465793840 ***]


2025-06-05 15:12:38.369966 GPU 0 40535 test begin: paddle.concat(list[Tensor([1, 0, 4],"float32"),Tensor([1, 0, 4],"float32"),Tensor([1, 0, 4],"float32"),Tensor([1, 0, 4],"float32"),Tensor([1, 0, 4],"float32"),Tensor([1, 0, 4],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107585 (unix time) try "date -d @1749107585" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f4c089242a0) received by PID 40535 (TID 0x7f4c09502740) from PID 143803040 ***]


2025-06-05 15:12:38.479863 GPU 0 40375 test begin: paddle.concat(list[Tensor([1, 0, 4],"float32"),Tensor([1, 0, 4],"float32"),Tensor([1, 0, 4],"float32"),Tensor([1, 0, 4],"float32"),Tensor([1, 0, 4],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107584 (unix time) try "date -d @1749107584" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fbde5c72310) received by PID 40375 (TID 0x7fbde6850740) from PID 18446744073269617424 ***]


2025-06-05 15:12:48.689187 GPU 1 40568 test begin: paddle.concat(list[Tensor([1, 0, 4],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107590 (unix time) try "date -d @1749107590" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 40568 (TID 0x7f0bcee87740) from PID 0 ***]


2025-06-05 15:12:59.240336 GPU 1 41310 test begin: paddle.concat(list[Tensor([1, 0, 62, 64],"float32"),Tensor([1, 0, 62, 64],"float32"),Tensor([1, 0, 62, 64],"float32"),Tensor([1, 0, 62, 64],"float32"),Tensor([1, 0, 62, 64],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107604 (unix time) try "date -d @1749107604" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f747f549150) received by PID 41310 (TID 0x7f7480127740) from PID 2136248656 ***]


2025-06-05 15:12:59.256996 GPU 0 41326 test begin: paddle.concat(list[Tensor([1, 0, 64, 64],"float32"),Tensor([1, 0, 64, 64],"float32"),], 1, )

2025-06-05 15:13:01.307901 GPU 0 41377 test begin: paddle.concat(list[Tensor([1, 0, 6408],"float32"),Tensor([1, 0, 1620],"float32"),Tensor([1, 0, 414],"float32"),Tensor([1, 0, 108],"float32"),Tensor([1, 0, 30],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107606 (unix time) try "date -d @1749107606" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f9b8de5a310) received by PID 41377 (TID 0x7f9b8ea38740) from PID 18446744071795221264 ***]


2025-06-05 15:13:02.091932 GPU 1 41395 test begin: paddle.concat(list[Tensor([1, 0, 64],"float32"),Tensor([1, 0, 64],"float32"),Tensor([1, 0, 64],"float32"),Tensor([1, 0, 64],"float32"),Tensor([1, 0, 64],"float32"),Tensor([1, 0, 64],"float32"),Tensor([1, 0, 64],"float32"),Tensor([1, 0, 64],"float32"),Tensor([1, 0, 64],"float32"),Tensor([1, 0, 64],"float32"),Tensor([1, 0, 64],"float32"),Tensor([1, 0, 64],"float32"),Tensor([1, 0, 64],"float32"),], axis=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107605 (unix time) try "date -d @1749107605" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f9390de12d0) received by PID 41395 (TID 0x7f93919bf740) from PID 18446744071845057232 ***]


2025-06-05 15:13:04.161291 GPU 1 41465 test begin: paddle.concat(list[Tensor([1, 0],"bool"),Tensor([1, 0],"bool"),], axis=-1, )
element 0 of tensors does not require grad and does not have a grad_fn


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<bool, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, bool>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107613 (unix time) try "date -d @1749107613" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 41465 (TID 0x7fccbc935740) from PID 24 ***]


2025-06-05 15:13:05.500007 GPU 0 41455 test begin: paddle.concat(list[Tensor([1, 0],"float16"),], axis=1, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<phi::dtype::float16, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, phi::dtype::float16>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107611 (unix time) try "date -d @1749107611" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 41455 (TID 0x7f9b2c1e1740) from PID 0 ***]


2025-06-05 15:13:11.791599 GPU 1 41573 test begin: paddle.concat(list[Tensor([1, 0],"float32"),Tensor([1, 0],"float32"),Tensor([1, 0],"float32"),Tensor([1, 0],"float32"),Tensor([1, 0],"float32"),Tensor([1, 0],"float32"),Tensor([1, 0],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107616 (unix time) try "date -d @1749107616" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f36be25e2d0) received by PID 41573 (TID 0x7f36bee3c740) from PID 18446744072604738256 ***]


2025-06-05 15:13:14.101346 GPU 0 41714 test begin: paddle.concat(list[Tensor([1, 0],"float32"),Tensor([1, 0],"float32"),Tensor([1, 0],"float32"),Tensor([1, 0],"float32"),Tensor([1, 0],"float32"),], 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107618 (unix time) try "date -d @1749107618" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f3ff1e4e330) received by PID 41714 (TID 0x7f3ff2a2c740) from PID 18446744073472893744 ***]


2025-06-05 15:13:14.138872 GPU 1 41631 test begin: paddle.concat(list[Tensor([1, 0],"float32"),Tensor([1, 0],"float32"),Tensor([1, 0],"float32"),Tensor([1, 0],"float32"),], 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107618 (unix time) try "date -d @1749107618" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f854e11b2d0) received by PID 41631 (TID 0x7f854ecf9740) from PID 1309782736 ***]


2025-06-05 15:13:14.285588 GPU 0 41644 test begin: paddle.concat(list[Tensor([1, 0],"float32"),Tensor([1, 0],"float32"),Tensor([1, 0],"float32"),Tensor([1, 0],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107617 (unix time) try "date -d @1749107617" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fdcc97b4330) received by PID 41644 (TID 0x7fdcca392740) from PID 18446744072794882864 ***]


2025-06-05 15:13:14.641959 GPU 0 41696 test begin: paddle.concat(list[Tensor([1, 0],"float32"),Tensor([2, 0],"float32"),Tensor([2, 0],"float32"),Tensor([5, 0],"float32"),Tensor([8, 0],"float32"),Tensor([22, 0],"float32"),Tensor([5, 0],"float32"),Tensor([5, 0],"float32"),Tensor([18, 0],"float32"),Tensor([3, 0],"float32"),Tensor([9, 0],"float32"),Tensor([4, 0],"float32"),Tensor([1, 0],"float32"),Tensor([2, 0],"float32"),Tensor([11, 0],"float32"),Tensor([3, 0],"float32"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107620 (unix time) try "date -d @1749107620" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f7e7afcb350) received by PID 41696 (TID 0x7f7e7bba9740) from PID 2063381328 ***]


2025-06-05 15:13:14.674524 GPU 1 41725 test begin: paddle.concat(list[Tensor([1, 0],"float32"),], axis=1, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107621 (unix time) try "date -d @1749107621" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fe9a813af30) received by PID 41725 (TID 0x7feb903f9740) from PID 18446744072234446640 ***]


2025-06-05 15:13:14.943757 GPU 1 41755 test begin: paddle.concat(list[Tensor([1, 0],"float64"),Tensor([1, 0],"float64"),Tensor([1, 0],"float64"),], axis=1, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107620 (unix time) try "date -d @1749107620" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 41755 (TID 0x7fea2521b740) from PID 24 ***]


2025-06-05 15:13:15.157691 GPU 0 41819 test begin: paddle.concat(list[Tensor([1, 0],"int32"),Tensor([2, 0],"int32"),Tensor([2, 0],"int32"),Tensor([5, 0],"int32"),Tensor([8, 0],"int32"),Tensor([22, 0],"int32"),Tensor([5, 0],"int32"),Tensor([5, 0],"int32"),Tensor([18, 0],"int32"),Tensor([3, 0],"int32"),Tensor([9, 0],"int32"),Tensor([4, 0],"int32"),Tensor([1, 0],"int32"),Tensor([2, 0],"int32"),Tensor([11, 0],"int32"),Tensor([3, 0],"int32"),], )
element 0 of tensors does not require grad and does not have a grad_fn


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107620 (unix time) try "date -d @1749107620" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f94cc8573a0) received by PID 41819 (TID 0x7f94cd435740) from PID 18446744072845882272 ***]


2025-06-05 15:13:16.390156 GPU 0 41791 test begin: paddle.concat(list[Tensor([1, 0],"int64"),Tensor([1, 0],"int64"),], axis=1, )
element 0 of tensors does not require grad and does not have a grad_fn


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107622 (unix time) try "date -d @1749107622" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xa7274c20) received by PID 41791 (TID 0x7ffa7d521740) from PID 18446744072218954784 ***]


2025-06-05 15:13:16.844463 GPU 1 41781 test begin: paddle.concat(list[Tensor([1, 1, 0, 136],"float32"),Tensor([1, 1, 0, 136],"float32"),], axis=1, )

2025-06-05 15:13:16.957652 GPU 0 41792 test begin: paddle.concat(list[Tensor([1, 1, 0, 1],"float32"),Tensor([1, 1, 0, 1],"float32"),Tensor([1, 1, 0, 1],"float32"),Tensor([1, 1, 0, 1],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107625 (unix time) try "date -d @1749107625" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f83fc2b2330) received by PID 41792 (TID 0x7f83fce90740) from PID 18446744073645269808 ***]


2025-06-05 15:13:17.068171 GPU 1 41839 test begin: paddle.concat(list[Tensor([1, 1, 0, 1],"float64"),Tensor([1, 1, 0, 1],"float64"),Tensor([1, 1, 0, 1],"float64"),], axis=1, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107622 (unix time) try "date -d @1749107622" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f74525a51f0) received by PID 41839 (TID 0x7f7453183740) from PID 1381650928 ***]


2025-06-05 15:13:17.332032 GPU 1 41868 test begin: paddle.concat(list[Tensor([1, 1, 0, 1],"float64"),], axis=1, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107622 (unix time) try "date -d @1749107622" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 41868 (TID 0x7f581ac98740) from PID 0 ***]


2025-06-05 15:13:17.406831 GPU 0 41835 test begin: paddle.concat(list[Tensor([1, 1, 0, 1],"float64"),], axis=2, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107622 (unix time) try "date -d @1749107622" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 41835 (TID 0x7fdeaf4a5740) from PID 0 ***]


2025-06-05 15:13:27.170938 GPU 1 42010 test begin: paddle.concat(list[Tensor([1, 1, 0],"float16"),], axis=2, name=None, )

2025-06-05 15:13:28.025441 GPU 0 42194 test begin: paddle.concat(list[Tensor([1, 1, 0],"float32"),Tensor([1, 1, 0],"float32"),Tensor([1, 1, 0],"float32"),Tensor([1, 1, 0],"float32"),Tensor([1, 1, 0],"float32"),Tensor([1, 1, 0],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107631 (unix time) try "date -d @1749107631" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f3c6f6bc330) received by PID 42194 (TID 0x7f3c7029a740) from PID 1869333296 ***]


2025-06-05 15:13:36.512534 GPU 1 42350 test begin: paddle.concat(list[Tensor([1, 1, 0],"float32"),Tensor([1, 1, 0],"float32"),Tensor([1, 1, 0],"float32"),Tensor([1, 1, 0],"float32"),Tensor([1, 1, 0],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107640 (unix time) try "date -d @1749107640" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fbcc518d2a0) received by PID 42350 (TID 0x7fbcc5d6b740) from PID 18446744072721322656 ***]


2025-06-05 15:13:37.872562 GPU 0 42364 test begin: paddle.concat(list[Tensor([1, 1, 0],"float32"),Tensor([1, 1, 0],"float32"),Tensor([1, 1, 0],"float32"),Tensor([1, 1, 0],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107645 (unix time) try "date -d @1749107645" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f10b40cb180) received by PID 42364 (TID 0x7f10b4ca9740) from PID 18446744072435315072 ***]


2025-06-05 15:13:37.990929 GPU 0 42395 test begin: paddle.concat(list[Tensor([1, 1, 0],"float32"),Tensor([1, 225, 0],"float32"),], axis=1, )

2025-06-05 15:13:46.892367 GPU 1 42537 test begin: paddle.concat(list[Tensor([1, 1, 0],"float32"),], axis=2, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107651 (unix time) try "date -d @1749107651" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 42537 (TID 0x7efcaaf3b740) from PID 0 ***]


2025-06-05 15:13:48.226112 GPU 0 42660 test begin: paddle.concat(list[Tensor([1, 1, 0],"float64"),Tensor([1, 1, 0],"float64"),Tensor([1, 1, 0],"float64"),], axis=1, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107651 (unix time) try "date -d @1749107651" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 42660 (TID 0x7f1e00c08740) from PID 24 ***]


2025-06-05 15:13:48.229315 GPU 1 42617 test begin: paddle.concat(list[Tensor([1, 1, 0],"float64"),], axis=1, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107652 (unix time) try "date -d @1749107652" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 42617 (TID 0x7f73c5f8e740) from PID 0 ***]


2025-06-05 15:13:49.443150 GPU 1 42678 test begin: paddle.concat(list[Tensor([1, 1, 1, 0],"float64"),], axis=1, name=None, )

2025-06-05 15:13:49.995080 GPU 0 42643 test begin: paddle.concat(list[Tensor([1, 1, 1, 0],"float64"),], axis=2, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107655 (unix time) try "date -d @1749107655" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 42643 (TID 0x7f2c6dd87740) from PID 0 ***]


2025-06-05 15:13:50.563774 GPU 1 42760 test begin: paddle.concat(list[Tensor([1, 1, 100, 0],"float32"),Tensor([1, 1, 100, 0],"float32"),], axis=1, )

2025-06-05 15:13:50.591730 GPU 0 42718 test begin: paddle.concat(list[Tensor([1, 1, 10285, 0],"float32"),Tensor([1, 1, 10285, 0],"float32"),Tensor([1, 1, 10285, 0],"float32"),Tensor([1, 1, 10285, 0],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107656 (unix time) try "date -d @1749107656" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f1e4e0b40d0) received by PID 42718 (TID 0x7f1e4ec92740) from PID 1309360336 ***]


2025-06-05 15:13:50.781655 GPU 0 42730 test begin: paddle.concat(list[Tensor([1, 1, 24276, 0],"float32"),Tensor([1, 1, 24276, 0],"float32"),Tensor([1, 1, 24276, 0],"float32"),Tensor([1, 1, 24276, 0],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107656 (unix time) try "date -d @1749107656" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f023c007190) received by PID 42730 (TID 0x7f023cbe5740) from PID 1006662032 ***]


2025-06-05 15:13:50.866639 GPU 1 42780 test begin: paddle.concat(list[Tensor([1, 100, 0],"float32"),Tensor([1, 300, 0],"float32"),], 1, )

2025-06-05 15:13:51.820496 GPU 0 42821 test begin: paddle.concat(list[Tensor([1, 1024, 0, 18],"float32"),Tensor([1, 768, 0, 18],"float32"),Tensor([1, 768, 0, 18],"float32"),Tensor([1, 768, 0, 18],"float32"),Tensor([1, 768, 0, 18],"float32"),Tensor([1, 768, 0, 18],"float32"),Tensor([1, 768, 0, 18],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107657 (unix time) try "date -d @1749107657" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f5945f68300) received by PID 42821 (TID 0x7f5946b46740) from PID 1173783296 ***]


2025-06-05 15:13:51.962301 GPU 1 42847 test begin: paddle.concat(list[Tensor([1, 1024, 0, 20],"float32"),Tensor([1, 768, 0, 20],"float32"),Tensor([1, 768, 0, 20],"float32"),Tensor([1, 768, 0, 20],"float32"),Tensor([1, 768, 0, 20],"float32"),Tensor([1, 768, 0, 20],"float32"),Tensor([1, 768, 0, 20],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107657 (unix time) try "date -d @1749107657" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f464f5be2c0) received by PID 42847 (TID 0x7f465019c740) from PID 1331421888 ***]


2025-06-05 15:13:51.984494 GPU 1 42836 test begin: paddle.concat(list[Tensor([1, 1024, 18, 0],"float32"),Tensor([1, 768, 18, 0],"float32"),Tensor([1, 768, 18, 0],"float32"),Tensor([1, 768, 18, 0],"float32"),Tensor([1, 768, 18, 0],"float32"),Tensor([1, 768, 18, 0],"float32"),Tensor([1, 768, 18, 0],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107659 (unix time) try "date -d @1749107659" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f7d3cf152b0) received by PID 42836 (TID 0x7f7d3daee740) from PID 1022448304 ***]


2025-06-05 15:13:52.278064 GPU 0 42820 test begin: paddle.concat(list[Tensor([1, 1024, 20, 0],"float32"),Tensor([1, 768, 20, 0],"float32"),Tensor([1, 768, 20, 0],"float32"),Tensor([1, 768, 20, 0],"float32"),Tensor([1, 768, 20, 0],"float32"),Tensor([1, 768, 20, 0],"float32"),Tensor([1, 768, 20, 0],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107660 (unix time) try "date -d @1749107660" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f0daaa262d0) received by PID 42820 (TID 0x7f0dab604740) from PID 18446744072277353168 ***]


2025-06-05 15:13:52.378489 GPU 1 42870 test begin: paddle.concat(list[Tensor([1, 103680, 0],"float32"),Tensor([1, 25920, 0],"float32"),Tensor([1, 6480, 0],"float32"),Tensor([1, 1620, 0],"float32"),Tensor([1, 420, 0],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107658 (unix time) try "date -d @1749107658" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f0747adf320) received by PID 42870 (TID 0x7f07486bd740) from PID 1202582304 ***]


2025-06-05 15:13:56.666844 GPU 0 42933 test begin: paddle.concat(list[Tensor([1, 109, 0],"float16"),Tensor([1, 109, 0],"float16"),], axis=2, )

2025-06-05 15:14:02.172473 GPU 1 43139 test begin: paddle.concat(list[Tensor([1, 1100, 0],"float32"),Tensor([1, 1100, 0],"float32"),Tensor([1, 1100, 0],"float32"),Tensor([1, 1100, 0],"float32"),], axis=2, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107667 (unix time) try "date -d @1749107667" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fb2c80170d0) received by PID 43139 (TID 0x7fb2c8bf5740) from PID 18446744072770121936 ***]


2025-06-05 15:14:02.867060 GPU 0 43254 test begin: paddle.concat(list[Tensor([1, 128, 0, 256],"float32"),Tensor([1, 128, 0, 256],"float32"),Tensor([1, 128, 0, 256],"float32"),Tensor([1, 128, 0, 256],"float32"),], 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107666 (unix time) try "date -d @1749107666" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f915e50e310) received by PID 43254 (TID 0x7f915f0ec740) from PID 1582359312 ***]


2025-06-05 15:14:11.901101 GPU 1 43339 test begin: paddle.concat(list[Tensor([1, 128, 0, 32],"float32"),Tensor([1, 32, 0, 32],"float32"),Tensor([1, 32, 0, 32],"float32"),Tensor([1, 32, 0, 32],"float32"),Tensor([1, 32, 0, 32],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107678 (unix time) try "date -d @1749107678" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f58a6a042b0) received by PID 43339 (TID 0x7f58a75e2740) from PID 18446744072210105008 ***]


2025-06-05 15:14:12.044911 GPU 1 43328 test begin: paddle.concat(list[Tensor([1, 128, 256, 0],"float32"),Tensor([1, 128, 256, 0],"float32"),Tensor([1, 128, 256, 0],"float32"),Tensor([1, 128, 256, 0],"float32"),], 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107679 (unix time) try "date -d @1749107679" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7ff71c268310) received by PID 43328 (TID 0x7ff71ce46740) from PID 472285968 ***]


2025-06-05 15:14:12.151502 GPU 0 43482 test begin: paddle.concat(list[Tensor([1, 128, 32, 0],"float32"),Tensor([1, 32, 32, 0],"float32"),Tensor([1, 32, 32, 0],"float32"),Tensor([1, 32, 32, 0],"float32"),Tensor([1, 32, 32, 0],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107677 (unix time) try "date -d @1749107677" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f1f4076f2e0) received by PID 43482 (TID 0x7f1f4134d740) from PID 1081537248 ***]


2025-06-05 15:14:12.214368 GPU 0 43338 test begin: paddle.concat(list[Tensor([1, 128, 64, 0],"float32"),Tensor([1, 128, 64, 0],"float32"),], 1, )

2025-06-05 15:14:14.305471 GPU 0 43520 test begin: paddle.concat(list[Tensor([1, 15, 0, 2],"float32"),Tensor([1, 15, 0, 2],"float32"),], -1, )

2025-06-05 15:14:24.312737 GPU 1 43699 test begin: paddle.concat(list[Tensor([1, 16, 0, 14, 192],"float16"),Tensor([1, 16, 0, 14, 192],"float16"),Tensor([1, 16, 0, 14, 192],"float16"),Tensor([1, 16, 0, 14, 192],"float16"),], -1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107690 (unix time) try "date -d @1749107690" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fec8d8ad2f0) received by PID 43699 (TID 0x7fec8e48b740) from PID 18446744071789269744 ***]


2025-06-05 15:14:24.493305 GPU 0 43631 test begin: paddle.concat(list[Tensor([1, 16, 0, 14, 192],"float32"),Tensor([1, 16, 0, 14, 192],"float32"),Tensor([1, 16, 0, 14, 192],"float32"),Tensor([1, 16, 0, 14, 192],"float32"),], -1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107689 (unix time) try "date -d @1749107689" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f1acfa0e1c0) received by PID 43631 (TID 0x7f1ad05ec740) from PID 18446744072898011584 ***]


2025-06-05 15:14:26.713640 GPU 0 43775 test begin: paddle.concat(list[Tensor([1, 16, 0],"float32"),Tensor([1, 16, 0],"float32"),Tensor([1, 16, 0],"float32"),Tensor([1, 16, 0],"float32"),Tensor([1, 16, 0],"float32"),Tensor([1, 16, 0],"float32"),Tensor([1, 16, 0],"float32"),Tensor([1, 16, 0],"float32"),Tensor([1, 16, 0],"float32"),Tensor([1, 16, 0],"float32"),Tensor([1, 16, 0],"float32"),Tensor([1, 16, 0],"float32"),Tensor([1, 16, 0],"float32"),], axis=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107694 (unix time) try "date -d @1749107694" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xa5b899f0) received by PID 43775 (TID 0x7f65f3376740) from PID 18446744072194922992 ***]


2025-06-05 15:14:26.728511 GPU 0 43821 test begin: paddle.concat(list[Tensor([1, 16, 14, 0, 192],"float16"),Tensor([1, 16, 14, 0, 192],"float16"),Tensor([1, 16, 14, 0, 192],"float16"),Tensor([1, 16, 14, 0, 192],"float16"),], -1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107694 (unix time) try "date -d @1749107694" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f20555b8300) received by PID 43821 (TID 0x7f2056196740) from PID 1432060672 ***]


2025-06-05 15:14:27.164442 GPU 1 43795 test begin: paddle.concat(list[Tensor([1, 16, 14, 0, 192],"float32"),Tensor([1, 16, 14, 0, 192],"float32"),Tensor([1, 16, 14, 0, 192],"float32"),Tensor([1, 16, 14, 0, 192],"float32"),], -1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107694 (unix time) try "date -d @1749107694" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7ff204fa40f0) received by PID 43795 (TID 0x7ff205b82740) from PID 83509488 ***]


2025-06-05 15:14:27.166835 GPU 1 43716 test begin: paddle.concat(list[Tensor([1, 16, 14, 14, 0],"float16"),Tensor([1, 16, 14, 14, 0],"float16"),Tensor([1, 16, 14, 14, 0],"float16"),Tensor([1, 16, 14, 14, 0],"float16"),], -1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107691 (unix time) try "date -d @1749107691" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7ff9ffbb12e0) received by PID 43716 (TID 0x7ffa0078f740) from PID 18446744073705034464 ***]


2025-06-05 15:14:28.132619 GPU 0 44026 test begin: paddle.concat(list[Tensor([1, 16, 14, 14, 0],"float32"),Tensor([1, 16, 14, 14, 0],"float32"),Tensor([1, 16, 14, 14, 0],"float32"),Tensor([1, 16, 14, 14, 0],"float32"),], -1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107696 (unix time) try "date -d @1749107696" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f2132fbd2e0) received by PID 44026 (TID 0x7f2133b9b740) from PID 855364320 ***]


2025-06-05 15:14:28.292749 GPU 1 44185 test begin: paddle.concat(list[Tensor([1, 16, 16, 0],"float32"),Tensor([1, 16, 16, 0],"float32"),], -1, )

2025-06-05 15:14:29.164876 GPU 1 44140 test begin: paddle.concat(list[Tensor([1, 160, 0, 18],"float32"),Tensor([1, 160, 0, 18],"float32"),], 1, )

2025-06-05 15:14:29.971068 GPU 1 44204 test begin: paddle.concat(list[Tensor([1, 18, 0],"float32"),Tensor([1, 18, 0],"float32"),Tensor([1, 18, 0],"float32"),Tensor([1, 18, 0],"float32"),], axis=2, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107700 (unix time) try "date -d @1749107700" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fb7b693c2c0) received by PID 44204 (TID 0x7fb7b751a740) from PID 18446744072477721280 ***]


2025-06-05 15:14:30.126985 GPU 0 44216 test begin: paddle.concat(list[Tensor([1, 188, 140, 0, 7],"float32"),Tensor([1, 188, 140, 0, 7],"float32"),Tensor([1, 188, 140, 0, 7],"float32"),], axis=-2, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107699 (unix time) try "date -d @1749107699" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 44216 (TID 0x7f3164225740) from PID 24 ***]


2025-06-05 15:14:30.424317 GPU 1 44265 test begin: paddle.concat(list[Tensor([1, 188, 140, 0],"float32"),Tensor([1, 188, 140, 0],"float32"),Tensor([1, 188, 140, 0],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107698 (unix time) try "date -d @1749107698" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fb9d0a2c110) received by PID 44265 (TID 0x7fb9d160a740) from PID 18446744072914911504 ***]


2025-06-05 15:14:31.761116 GPU 0 44282 test begin: paddle.concat(list[Tensor([1, 188, 140, 1, 0, 7],"float32"),Tensor([1, 188, 140, 1, 0, 7],"float32"),Tensor([1, 188, 140, 1, 0, 7],"float32"),], axis=-3, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107697 (unix time) try "date -d @1749107697" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f4d35df72a0) received by PID 44282 (TID 0x7f4d369d5740) from PID 903836320 ***]


2025-06-05 15:14:34.169489 GPU 0 44300 test begin: paddle.concat(list[Tensor([1, 188, 140, 2, 0],"float32"),Tensor([1, 188, 140, 2, 0],"float32"),Tensor([1, 188, 140, 2, 0],"float32"),], axis=-2, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107700 (unix time) try "date -d @1749107700" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fe14e9a3190) received by PID 44300 (TID 0x7fe14f581740) from PID 1318728080 ***]


2025-06-05 15:14:37.230920 GPU 1 44331 test begin: paddle.concat(list[Tensor([1, 192, 0, 20],"float32"),Tensor([1, 192, 0, 20],"float32"),Tensor([1, 192, 0, 20],"float32"),Tensor([1, 192, 0, 20],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107702 (unix time) try "date -d @1749107702" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f224e5e60b0) received by PID 44331 (TID 0x7f224f1c4740) from PID 1314807984 ***]


2025-06-05 15:14:39.316704 GPU 0 44526 test begin: paddle.concat(list[Tensor([1, 192, 20, 0],"float32"),Tensor([1, 192, 20, 0],"float32"),Tensor([1, 192, 20, 0],"float32"),Tensor([1, 192, 20, 0],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107704 (unix time) try "date -d @1749107704" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fd5305cb2d0) received by PID 44526 (TID 0x7fd5311a9740) from PID 811381456 ***]


2025-06-05 15:14:40.889302 GPU 1 44561 test begin: paddle.concat(list[Tensor([1, 2, 0],"float64"),Tensor([1, 2, 0],"float64"),], axis=2, name=None, )

2025-06-05 15:14:50.072595 GPU 0 45053 test begin: paddle.concat(list[Tensor([1, 20, 0, 384],"float32"),Tensor([1, 20, 0, 384],"float32"),Tensor([1, 20, 0, 384],"float32"),Tensor([1, 20, 0, 384],"float32"),], -1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107715 (unix time) try "date -d @1749107715" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fd78b7ad310) received by PID 45053 (TID 0x7fd78c38b740) from PID 18446744071754666768 ***]


2025-06-05 15:14:50.090598 GPU 0 45189 test begin: paddle.concat(list[Tensor([1, 20, 15, 0],"float32"),Tensor([1, 20, 15, 0],"float32"),Tensor([1, 20, 15, 0],"float32"),Tensor([1, 20, 15, 0],"float32"),], -1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107715 (unix time) try "date -d @1749107715" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f45a86cb2a0) received by PID 45189 (TID 0x7f45a92a9740) from PID 18446744072240280224 ***]


2025-06-05 15:14:50.190656 GPU 0 45109 test begin: paddle.concat(list[Tensor([1, 24, 0, 768],"float32"),Tensor([1, 24, 0, 768],"float32"),Tensor([1, 24, 0, 768],"float32"),Tensor([1, 24, 0, 768],"float32"),], -1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107715 (unix time) try "date -d @1749107715" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f1febb4b0c0) received by PID 45109 (TID 0x7f1fec729740) from PID 18446744073369071808 ***]


2025-06-05 15:14:50.343730 GPU 1 45090 test begin: paddle.concat(list[Tensor([1, 24, 18, 0],"float32"),Tensor([1, 24, 18, 0],"float32"),Tensor([1, 24, 18, 0],"float32"),Tensor([1, 24, 18, 0],"float32"),], -1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107715 (unix time) try "date -d @1749107715" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fa69d0300e0) received by PID 45090 (TID 0x7fa69dc0e740) from PID 18446744072048804064 ***]


2025-06-05 15:14:50.519668 GPU 1 45089 test begin: paddle.concat(list[Tensor([1, 248, 0, 2, 7],"float32"),], axis=-2, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107715 (unix time) try "date -d @1749107715" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 45089 (TID 0x7f9ef7000740) from PID 0 ***]


2025-06-05 15:15:02.829569 GPU 0 45415 test begin: paddle.concat(list[Tensor([1, 248, 216, 0, 7],"float32"),], axis=-2, )

2025-06-05 15:15:02.897591 GPU 1 45393 test begin: paddle.concat(list[Tensor([1, 248, 216, 2, 0],"float32"),], axis=-2, )

2025-06-05 15:15:03.806895 GPU 1 45459 test begin: paddle.concat(list[Tensor([1, 248832, 0],"float32"),Tensor([1, 62208, 0],"float32"),Tensor([1, 15552, 0],"float32"),Tensor([1, 3888, 0],"float32"),Tensor([1, 972, 0],"float32"),Tensor([1, 270, 0],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107727 (unix time) try "date -d @1749107727" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7ff6a5cf12a0) received by PID 45459 (TID 0x7ff6a68cf740) from PID 18446744072196395680 ***]


2025-06-05 15:15:03.993965 GPU 1 45483 test begin: paddle.concat(list[Tensor([1, 256, 0, 128],"float32"),Tensor([1, 256, 0, 128],"float32"),Tensor([1, 256, 0, 128],"float32"),Tensor([1, 256, 0, 128],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107725 (unix time) try "date -d @1749107725" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f0006d6f2a0) received by PID 45483 (TID 0x7f000794d740) from PID 114750112 ***]


2025-06-05 15:15:04.098560 GPU 0 45494 test begin: paddle.concat(list[Tensor([1, 256, 0, 64],"float32"),Tensor([1, 256, 0, 64],"float32"),Tensor([1, 256, 0, 64],"float32"),Tensor([1, 256, 0, 64],"float32"),Tensor([1, 256, 0, 64],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107726 (unix time) try "date -d @1749107726" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f7f64813160) received by PID 45494 (TID 0x7f7f653f1740) from PID 1686188384 ***]


2025-06-05 15:15:04.113399 GPU 0 45469 test begin: paddle.concat(list[Tensor([1, 256, 124, 0],"float32"),Tensor([1, 256, 124, 0],"float32"),Tensor([1, 256, 124, 0],"float32"),Tensor([1, 256, 124, 0],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107726 (unix time) try "date -d @1749107726" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f813b85a0e0) received by PID 45469 (TID 0x7f813c438740) from PID 998613216 ***]


2025-06-05 15:15:04.145808 GPU 1 45496 test begin: paddle.concat(list[Tensor([1, 256, 62, 0],"float32"),Tensor([1, 256, 62, 0],"float32"),Tensor([1, 256, 62, 0],"float32"),Tensor([1, 256, 62, 0],"float32"),Tensor([1, 256, 62, 0],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107727 (unix time) try "date -d @1749107727" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f0b67cc0160) received by PID 45496 (TID 0x7f0b6889e740) from PID 1741422944 ***]


2025-06-05 15:15:06.550530 GPU 0 45553 test begin: paddle.concat(list[Tensor([1, 2704, 0],"float32"),Tensor([1, 676, 0],"float32"),Tensor([1, 169, 0],"float32"),Tensor([1, 49, 0],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107728 (unix time) try "date -d @1749107728" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f778f60b1a0) received by PID 45553 (TID 0x7f77901e9740) from PID 18446744071820063136 ***]


2025-06-05 15:15:12.993928 GPU 0 45625 test begin: paddle.concat(list[Tensor([1, 27648, 0],"float32"),Tensor([1, 6912, 0],"float32"),Tensor([1, 1728, 0],"float32"),Tensor([1, 432, 0],"float32"),Tensor([1, 108, 0],"float32"),], 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107731 (unix time) try "date -d @1749107731" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f1ff85ae310) received by PID 45625 (TID 0x7f1ff918c740) from PID 18446744073581290256 ***]


2025-06-05 15:15:13.057866 GPU 1 45599 test begin: paddle.concat(list[Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),], 0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107732 (unix time) try "date -d @1749107732" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 45599 (TID 0x7f2a62497740) from PID 24 ***]


2025-06-05 15:15:13.905318 GPU 1 45601 test begin: paddle.concat(list[Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),Tensor([1, 3, 0, 336],"float32"),], 0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107734 (unix time) try "date -d @1749107734" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 45601 (TID 0x7fd2edbb8740) from PID 24 ***]


2025-06-05 15:15:13.979820 GPU 1 45646 test begin: paddle.concat(list[Tensor([1, 3, 0],"float32"),Tensor([1, 3, 0],"float32"),Tensor([1, 3, 0],"float32"),Tensor([1, 3, 0],"float32"),Tensor([1, 3, 0],"float32"),Tensor([1, 3, 0],"float32"),Tensor([1, 3, 0],"float32"),Tensor([1, 3, 0],"float32"),Tensor([1, 3, 0],"float32"),Tensor([1, 3, 0],"float32"),Tensor([1, 3, 0],"float32"),Tensor([1, 3, 0],"float32"),Tensor([1, 3, 0],"float32"),], axis=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107734 (unix time) try "date -d @1749107734" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fee4098f340) received by PID 45646 (TID 0x7fee4156d740) from PID 1083765568 ***]


2025-06-05 15:15:14.159673 GPU 0 45626 test begin: paddle.concat(list[Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),], 0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107735 (unix time) try "date -d @1749107735" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 45626 (TID 0x7f3589b29740) from PID 24 ***]


2025-06-05 15:15:15.295185 GPU 1 45748 test begin: paddle.concat(list[Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),Tensor([1, 3, 336, 0],"float32"),], 0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107736 (unix time) try "date -d @1749107736" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x2000000a5) received by PID 45748 (TID 0x7ff888f6a740) from PID 165 ***]


2025-06-05 15:15:15.402345 GPU 0 45905 test begin: paddle.concat(list[Tensor([1, 3600, 0],"float32"),Tensor([1, 900, 0],"float32"),Tensor([1, 225, 0],"float32"),], 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107736 (unix time) try "date -d @1749107736" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 45905 (TID 0x7fb1ad08b740) from PID 24 ***]


2025-06-05 15:15:15.852854 GPU 0 45981 test begin: paddle.concat(list[Tensor([1, 36000, 0],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107738 (unix time) try "date -d @1749107738" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f39181760f0) received by PID 45981 (TID 0x7f3b0184f740) from PID 404185328 ***]


2025-06-05 15:15:16.110475 GPU 1 45917 test begin: paddle.concat(list[Tensor([1, 4, 1, 0],"float32"),Tensor([1, 4, 1, 0],"float32"),], axis=2, )

2025-06-05 15:15:24.804973 GPU 0 46163 test begin: paddle.concat(list[Tensor([1, 4, 2, 0],"float32"),Tensor([1, 4, 1, 0],"float32"),], axis=2, )

2025-06-05 15:15:25.014834 GPU 1 46175 test begin: paddle.concat(list[Tensor([1, 4096, 0],"float32"),Tensor([1, 1024, 0],"float32"),Tensor([1, 256, 0],"float32"),], 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107746 (unix time) try "date -d @1749107746" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f6f9cbc31b0) received by PID 46175 (TID 0x7f6f9d7a1740) from PID 18446744072044163504 ***]


2025-06-05 15:15:25.169724 GPU 1 46220 test begin: paddle.concat(list[Tensor([1, 4800, 0],"float32"),Tensor([1, 1200, 0],"float32"),Tensor([1, 300, 0],"float32"),Tensor([1, 80, 0],"float32"),], 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107746 (unix time) try "date -d @1749107746" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f08746832c0) received by PID 46220 (TID 0x7f0875261740) from PID 1952985792 ***]


2025-06-05 15:15:25.240556 GPU 0 46195 test begin: paddle.concat(list[Tensor([1, 5, 0],"float64"),Tensor([1, 5, 0],"float64"),Tensor([1, 5, 0],"float64"),], axis=2, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107744 (unix time) try "date -d @1749107744" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f26eccf1330) received by PID 46195 (TID 0x7f26ed8cf740) from PID 18446744073387578160 ***]


2025-06-05 15:15:25.377225 GPU 0 46161 test begin: paddle.concat(list[Tensor([1, 500, 0],"int64"),Tensor([1, 500, 0],"int64"),Tensor([1, 500, 0],"int64"),Tensor([1, 500, 0],"int64"),Tensor([1, 500, 0],"int64"),Tensor([1, 500, 0],"int64"),Tensor([1, 500, 0],"int64"),Tensor([1, 500, 0],"int64"),Tensor([1, 500, 0],"int64"),Tensor([1, 500, 0],"int64"),Tensor([1, 500, 0],"int64"),Tensor([1, 500, 0],"int64"),Tensor([1, 500, 0],"int64"),Tensor([1, 500, 0],"int64"),Tensor([1, 500, 0],"int64"),Tensor([1, 500, 0],"int64"),Tensor([1, 500, 0],"int64"),Tensor([1, 500, 0],"int64"),Tensor([1, 500, 0],"int64"),Tensor([1, 500, 0],"int64"),], axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107746 (unix time) try "date -d @1749107746" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fd90240d330) received by PID 46161 (TID 0x7fd902feb740) from PID 37802800 ***]


2025-06-05 15:15:34.586066 GPU 0 46391 test begin: paddle.concat(list[Tensor([10, 0],"float32"),Tensor([10, 0],"float32"),Tensor([10, 0],"float32"),Tensor([10, 0],"float32"),Tensor([10, 0],"float32"),Tensor([10, 0],"float32"),Tensor([10, 0],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107756 (unix time) try "date -d @1749107756" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f2e379c42a0) received by PID 46391 (TID 0x7f2e385a2740) from PID 932987552 ***]


2025-06-05 15:15:34.876309 GPU 0 46439 test begin: paddle.concat(list[Tensor([100, 0],"float32"),Tensor([100, 0],"float32"),Tensor([100, 0],"float32"),Tensor([100, 0],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107755 (unix time) try "date -d @1749107755" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fd0593640b0) received by PID 46439 (TID 0x7fd059f42740) from PID 1496727728 ***]


2025-06-05 15:15:34.953483 GPU 1 46416 test begin: paddle.concat(list[Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([10240, 0],"float32"),Tensor([1820, 0],"float32"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107756 (unix time) try "date -d @1749107756" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 46416 (TID 0x7f5f59b46740) from PID 24 ***]


2025-06-05 15:15:35.099956 GPU 1 46472 test begin: paddle.concat(list[Tensor([11, 0],"float32"),Tensor([11, 0],"float32"),Tensor([11, 0],"float32"),Tensor([11, 0],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107755 (unix time) try "date -d @1749107755" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f673faed0a0) received by PID 46472 (TID 0x7f67406cb740) from PID 1068421280 ***]


2025-06-05 15:15:35.186143 GPU 0 46440 test begin: paddle.concat(list[Tensor([12, 0, 10, 10, 1],"float32"),Tensor([12, 0, 10, 10, 1],"float32"),Tensor([12, 0, 10, 10, 1],"float32"),Tensor([12, 0, 10, 10, 1],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107756 (unix time) try "date -d @1749107756" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f720d23f0e0) received by PID 46440 (TID 0x7f720de1d740) from PID 220459232 ***]


2025-06-05 15:15:35.645718 GPU 1 46525 test begin: paddle.concat(list[Tensor([12, 0, 20, 20, 1],"float32"),Tensor([12, 0, 20, 20, 1],"float32"),Tensor([12, 0, 20, 20, 1],"float32"),Tensor([12, 0, 20, 20, 1],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107757 (unix time) try "date -d @1749107757" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f1ec37a0300) received by PID 46525 (TID 0x7f1ec437e740) from PID 18446744072694137600 ***]


2025-06-05 15:15:36.072831 GPU 1 46539 test begin: paddle.concat(list[Tensor([12, 3, 0, 10, 1],"float32"),Tensor([12, 3, 0, 10, 1],"float32"),Tensor([12, 3, 0, 10, 1],"float32"),Tensor([12, 3, 0, 10, 1],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107757 (unix time) try "date -d @1749107757" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f747b2971e0) received by PID 46539 (TID 0x7f747be75740) from PID 2066313696 ***]


2025-06-05 15:15:36.552805 GPU 0 46549 test begin: paddle.concat(list[Tensor([12, 3, 0, 20, 1],"float32"),Tensor([12, 3, 0, 20, 1],"float32"),Tensor([12, 3, 0, 20, 1],"float32"),Tensor([12, 3, 0, 20, 1],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107758 (unix time) try "date -d @1749107758" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f5391bb10a0) received by PID 46549 (TID 0x7f539278f740) from PID 18446744071859540128 ***]


2025-06-05 15:15:41.112273 GPU 0 46591 test begin: paddle.concat(list[Tensor([12, 3, 10, 0, 1],"float32"),Tensor([12, 3, 10, 0, 1],"float32"),Tensor([12, 3, 10, 0, 1],"float32"),Tensor([12, 3, 10, 0, 1],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107761 (unix time) try "date -d @1749107761" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fcecd24f330) received by PID 46591 (TID 0x7fcecde2d740) from PID 18446744072856335152 ***]


2025-06-05 15:15:44.132159 GPU 1 46641 test begin: paddle.concat(list[Tensor([12, 3, 10, 10, 0],"float32"),Tensor([12, 3, 10, 10, 0],"float32"),Tensor([12, 3, 10, 10, 0],"float32"),Tensor([12, 3, 10, 10, 0],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107762 (unix time) try "date -d @1749107762" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f2dc4555330) received by PID 46641 (TID 0x7f2dc5133740) from PID 18446744072708510512 ***]


2025-06-05 15:15:44.839692 GPU 0 46753 test begin: paddle.concat(list[Tensor([12, 3, 20, 0, 1],"float32"),Tensor([12, 3, 20, 0, 1],"float32"),Tensor([12, 3, 20, 0, 1],"float32"),Tensor([12, 3, 20, 0, 1],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107762 (unix time) try "date -d @1749107762" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f9a147c51d0) received by PID 46753 (TID 0x7f9a153a3740) from PID 343691728 ***]


2025-06-05 15:15:45.288090 GPU 1 46754 test begin: paddle.concat(list[Tensor([12, 3, 20, 20, 0],"float32"),Tensor([12, 3, 20, 20, 0],"float32"),Tensor([12, 3, 20, 20, 0],"float32"),Tensor([12, 3, 20, 20, 0],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107766 (unix time) try "date -d @1749107766" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f62ddf87310) received by PID 46754 (TID 0x7f62deb65740) from PID 18446744073138631440 ***]


2025-06-05 15:15:45.320280 GPU 0 46951 test begin: paddle.concat(list[Tensor([128, 0, 28, 28],"float16"),Tensor([128, 0, 28, 28],"float16"),Tensor([128, 0, 28, 28],"float16"),Tensor([128, 0, 28, 28],"float16"),Tensor([128, 0, 28, 28],"float16"),Tensor([128, 0, 28, 28],"float16"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107767 (unix time) try "date -d @1749107767" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f87399141c0) received by PID 46951 (TID 0x7f873a4f2740) from PID 965820864 ***]


2025-06-05 15:15:45.368172 GPU 1 46905 test begin: paddle.concat(list[Tensor([128, 0, 28, 28],"float32"),Tensor([128, 0, 28, 28],"float32"),Tensor([128, 0, 28, 28],"float32"),Tensor([128, 0, 28, 28],"float32"),Tensor([128, 0, 28, 28],"float32"),Tensor([128, 0, 28, 28],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107767 (unix time) try "date -d @1749107767" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fa7e5ca5330) received by PID 46905 (TID 0x7fa7e6883740) from PID 18446744073269826352 ***]


2025-06-05 15:15:45.411231 GPU 1 46852 test begin: paddle.concat(list[Tensor([128, 224, 0, 28],"float16"),Tensor([128, 128, 0, 28],"float16"),Tensor([128, 128, 0, 28],"float16"),Tensor([128, 128, 0, 28],"float16"),Tensor([128, 128, 0, 28],"float16"),Tensor([128, 128, 0, 28],"float16"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107763 (unix time) try "date -d @1749107763" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fd0dbb5a190) received by PID 46852 (TID 0x7fd0dc738740) from PID 18446744073100698000 ***]


2025-06-05 15:15:45.515674 GPU 1 46842 test begin: paddle.concat(list[Tensor([128, 224, 0, 28],"float32"),Tensor([128, 128, 0, 28],"float32"),Tensor([128, 128, 0, 28],"float32"),Tensor([128, 128, 0, 28],"float32"),Tensor([128, 128, 0, 28],"float32"),Tensor([128, 128, 0, 28],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107766 (unix time) try "date -d @1749107766" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fb638b26290) received by PID 46842 (TID 0x7fb639704740) from PID 951214736 ***]


2025-06-05 15:15:45.654351 GPU 0 46968 test begin: paddle.concat(list[Tensor([128, 224, 28, 0],"float16"),Tensor([128, 128, 28, 0],"float16"),Tensor([128, 128, 28, 0],"float16"),Tensor([128, 128, 28, 0],"float16"),Tensor([128, 128, 28, 0],"float16"),Tensor([128, 128, 28, 0],"float16"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107765 (unix time) try "date -d @1749107765" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fa4651512e0) received by PID 46968 (TID 0x7fa465d2f740) from PID 1695879904 ***]


2025-06-05 15:15:54.528887 GPU 0 47212 test begin: paddle.concat(list[Tensor([128, 224, 28, 0],"float32"),Tensor([128, 128, 28, 0],"float32"),Tensor([128, 128, 28, 0],"float32"),Tensor([128, 128, 28, 0],"float32"),Tensor([128, 128, 28, 0],"float32"),Tensor([128, 128, 28, 0],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107775 (unix time) try "date -d @1749107775" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f0ee78f72d0) received by PID 47212 (TID 0x7f0ee84d5740) from PID 18446744073299522256 ***]


2025-06-05 15:15:55.108099 GPU 0 47188 test begin: paddle.concat(list[Tensor([13, 0, 16, 4],"int64"),Tensor([13, 0, 16, 4],"int64"),], axis=3, )
element 0 of tensors does not require grad and does not have a grad_fn


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<long, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, long>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107776 (unix time) try "date -d @1749107776" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 47188 (TID 0x7f346a39c740) from PID 24 ***]


2025-06-05 15:15:55.328081 GPU 1 47235 test begin: paddle.concat(list[Tensor([13, 0, 3, 1],"float32"),], axis=1, )

2025-06-05 15:15:55.848498 GPU 1 47202 test begin: paddle.concat(list[Tensor([13, 0, 4, 16, 1],"float32"),Tensor([13, 0, 4, 16, 1],"float32"),], axis=-1, )

2025-06-05 15:16:03.906072 GPU 0 47454 test begin: paddle.concat(list[Tensor([13, 0, 8, 4, 16],"float32"),Tensor([13, 0, 8, 4, 16],"float32"),], axis=3, )

2025-06-05 15:16:04.017536 GPU 0 47421 test begin: paddle.concat(list[Tensor([13, 0, 8, 4],"int64"),Tensor([13, 0, 8, 4],"int64"),], axis=3, )
element 0 of tensors does not require grad and does not have a grad_fn


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107790 (unix time) try "date -d @1749107790" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fc507e72da0) received by PID 47421 (TID 0x7fc72a521740) from PID 132591008 ***]


2025-06-05 15:16:04.027715 GPU 1 47490 test begin: paddle.concat(list[Tensor([13, 1, 0, 1],"float32"),], axis=1, )

2025-06-05 15:16:04.080381 GPU 0 47456 test begin: paddle.concat(list[Tensor([13, 1, 0, 4],"int64"),Tensor([13, 1, 0, 4],"int64"),], axis=3, )
element 0 of tensors does not require grad and does not have a grad_fn


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107788 (unix time) try "date -d @1749107788" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xa72f5580) received by PID 47456 (TID 0x7f20da992740) from PID 18446744072219481472 ***]


2025-06-05 15:16:04.095460 GPU 1 47400 test begin: paddle.concat(list[Tensor([13, 1, 3, 0],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107787 (unix time) try "date -d @1749107787" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fa53c0c84e0) received by PID 47400 (TID 0x7fa6a12dd740) from PID 1007453408 ***]


2025-06-05 15:16:04.174961 GPU 0 47437 test begin: paddle.concat(list[Tensor([13, 1, 8, 0],"int64"),Tensor([13, 1, 8, 0],"int64"),], axis=3, )
element 0 of tensors does not require grad and does not have a grad_fn


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107789 (unix time) try "date -d @1749107789" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f866c17e620) received by PID 47437 (TID 0x7f8855f53740) from PID 1813505568 ***]


2025-06-05 15:16:04.306233 GPU 1 47545 test begin: paddle.concat(list[Tensor([13, 13, 0],"float32"),Tensor([13, 3, 0],"float32"),], axis=-2, )

2025-06-05 15:16:05.644060 GPU 0 47564 test begin: paddle.concat(list[Tensor([13, 2, 0, 4],"int64"),Tensor([13, 2, 0, 4],"int64"),], axis=3, )
element 0 of tensors does not require grad and does not have a grad_fn


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107785 (unix time) try "date -d @1749107785" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xa2b442c0) received by PID 47564 (TID 0x7f216c1fd740) from PID 18446744072144306880 ***]


2025-06-05 15:16:05.774329 GPU 1 47576 test begin: paddle.concat(list[Tensor([13, 2, 1, 0, 16],"float32"),Tensor([13, 2, 15, 0, 16],"float32"),], axis=2, )

2025-06-05 15:16:12.366029 GPU 0 47626 test begin: paddle.concat(list[Tensor([13, 2, 16, 0, 16],"float32"),Tensor([13, 2, 16, 0, 16],"float32"),], axis=3, )

2025-06-05 15:16:12.594151 GPU 0 47675 test begin: paddle.concat(list[Tensor([13, 2, 16, 0],"int64"),Tensor([13, 2, 16, 0],"int64"),], axis=3, )
element 0 of tensors does not require grad and does not have a grad_fn


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<long, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, long>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107798 (unix time) try "date -d @1749107798" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 47675 (TID 0x7f10bd95d740) from PID 24 ***]


2025-06-05 15:16:12.599026 GPU 1 47638 test begin: paddle.concat(list[Tensor([13, 2, 16, 4, 0],"float32"),Tensor([13, 2, 16, 4, 0],"float32"),], axis=3, )

2025-06-05 15:16:12.869102 GPU 0 47832 test begin: paddle.concat(list[Tensor([13, 2, 4, 0, 1],"float32"),Tensor([13, 2, 4, 0, 1],"float32"),], axis=-1, )

2025-06-05 15:16:13.148239 GPU 1 47790 test begin: paddle.concat(list[Tensor([13, 2, 8, 0, 16],"float32"),Tensor([13, 2, 8, 0, 16],"float32"),], axis=3, )

2025-06-05 15:16:15.886638 GPU 1 47931 test begin: paddle.concat(list[Tensor([13, 2, 8, 4, 0],"float32"),Tensor([13, 2, 8, 4, 0],"float32"),], axis=3, )

2025-06-05 15:16:16.009766 GPU 1 47895 test begin: paddle.concat(list[Tensor([13, 3, 0],"float32"),Tensor([13, 3, 0],"float32"),Tensor([13, 3, 0],"float32"),], axis=2, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107799 (unix time) try "date -d @1749107799" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fd083ba42a0) received by PID 47895 (TID 0x7fd084782740) from PID 18446744071624606368 ***]


2025-06-05 15:16:16.555073 GPU 1 47945 test begin: paddle.concat(list[Tensor([13, 4, 0, 5, 1, 8],"float32"),Tensor([13, 4, 0, 5, 1, 8],"float32"),Tensor([13, 4, 0, 5, 1, 8],"float32"),], axis=2, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107800 (unix time) try "date -d @1749107800" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f721b8e1140) received by PID 47945 (TID 0x7f721c4bf740) from PID 462295360 ***]


2025-06-05 15:16:16.957341 GPU 0 47955 test begin: paddle.concat(list[Tensor([13, 4, 0, 8],"float32"),Tensor([13, 4, 0, 8],"float32"),Tensor([13, 4, 0, 8],"float32"),], axis=2, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107799 (unix time) try "date -d @1749107799" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fef63876120) received by PID 47955 (TID 0x7fef64454740) from PID 1669816608 ***]


2025-06-05 15:16:27.050360 GPU 0 48185 test begin: paddle.concat(list[Tensor([13, 4, 1, 5, 0, 8],"float32"),Tensor([13, 4, 3, 5, 0, 8],"float32"),Tensor([13, 4, 1, 5, 0, 8],"float32"),], axis=2, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107811 (unix time) try "date -d @1749107811" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 48185 (TID 0x7f8130bdd740) from PID 24 ***]


2025-06-05 15:16:27.922639 GPU 1 48597 test begin: paddle.concat(list[Tensor([13, 4, 3, 0, 1, 8],"float32"),Tensor([13, 4, 3, 0, 1, 8],"float32"),Tensor([13, 4, 3, 0, 1, 8],"float32"),], axis=3, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107811 (unix time) try "date -d @1749107811" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xa4c60750) received by PID 48597 (TID 0x7f1f823e7740) from PID 18446744072179025744 ***]


2025-06-05 15:16:28.036113 GPU 0 48395 test begin: paddle.concat(list[Tensor([13, 4, 3, 1, 0, 8],"float32"),Tensor([13, 4, 3, 1, 0, 8],"float32"),Tensor([13, 4, 3, 1, 0, 8],"float32"),], axis=3, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107812 (unix time) try "date -d @1749107812" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f15efbdd190) received by PID 48395 (TID 0x7f15f07bb740) from PID 18446744073436778896 ***]


2025-06-05 15:16:28.199954 GPU 1 48219 test begin: paddle.concat(list[Tensor([13, 5, 0, 1],"float32"),Tensor([13, 5, 0, 3],"float32"),Tensor([13, 5, 0, 1],"float32"),], axis=3, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107813 (unix time) try "date -d @1749107813" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fb36294b1b0) received by PID 48219 (TID 0x7fb363529740) from PID 1653911984 ***]


2025-06-05 15:16:38.129503 GPU 1 48719 test begin: paddle.concat(list[Tensor([13125, 0],"float32"),Tensor([13125, 0],"float32"),Tensor([13125, 0],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107824 (unix time) try "date -d @1749107824" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xa73485a0) received by PID 48719 (TID 0x7f1a3dd9a740) from PID 18446744072219821472 ***]


2025-06-05 15:16:38.634785 GPU 1 48756 test begin: paddle.concat(list[Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),Tensor([15000, 0],"bool"),], axis=1, )
element 0 of tensors does not require grad and does not have a grad_fn


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107824 (unix time) try "date -d @1749107824" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fa823162420) received by PID 48756 (TID 0x7fa823d40740) from PID 588653600 ***]


2025-06-05 15:16:38.837149 GPU 0 48717 test begin: paddle.concat(list[Tensor([1536, 0],"float16"),Tensor([1536, 0],"float16"),Tensor([1536, 0],"float16"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107823 (unix time) try "date -d @1749107823" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xa5583710) received by PID 48717 (TID 0x7fecd59ca740) from PID 18446744072188606224 ***]


2025-06-05 15:16:39.982153 GPU 1 48812 test begin: paddle.concat(list[Tensor([16, 0, 1, 2],"float32"),Tensor([16, 0, 1, 2],"float32"),], axis=-2, )

2025-06-05 15:16:40.066846 GPU 0 48729 test begin: paddle.concat(list[Tensor([16, 0, 640, 640],"float16"),Tensor([16, 0, 640, 640],"float16"),Tensor([16, 0, 640, 640],"float16"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107824 (unix time) try "date -d @1749107824" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f179923b050) received by PID 48729 (TID 0x7f1799e19740) from PID 18446744071983837264 ***]


2025-06-05 15:16:40.171435 GPU 0 48858 test begin: paddle.concat(list[Tensor([16, 0, 640, 640],"float32"),Tensor([16, 0, 640, 640],"float32"),Tensor([16, 0, 640, 640],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107825 (unix time) try "date -d @1749107825" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xa54e21b0) received by PID 48858 (TID 0x7fcbbfce9740) from PID 18446744072187945392 ***]


2025-06-05 15:16:40.409041 GPU 1 48843 test begin: paddle.concat(list[Tensor([16, 1, 0, 64, 2],"float32"),Tensor([16, 10, 0, 64, 2],"float32"),], axis=1, )

2025-06-05 15:16:40.664604 GPU 0 48860 test begin: paddle.concat(list[Tensor([16, 1, 640, 0],"float16"),Tensor([16, 1, 640, 0],"float16"),Tensor([16, 1, 640, 0],"float16"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107825 (unix time) try "date -d @1749107825" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fbdf137d200) received by PID 48860 (TID 0x7fbdf1f5b740) from PID 18446744073461551616 ***]


2025-06-05 15:16:40.845143 GPU 0 48889 test begin: paddle.concat(list[Tensor([16, 10, 0, 2],"float32"),Tensor([16, 10, 0, 2],"float32"),], axis=-2, )

2025-06-05 15:16:49.651045 GPU 0 48992 test begin: paddle.concat(list[Tensor([16, 10, 1, 0],"float32"),Tensor([16, 10, 1, 0],"float32"),], axis=-2, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107832 (unix time) try "date -d @1749107832" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 48992 (TID 0x7fd65355f740) from PID 24 ***]


2025-06-05 15:16:50.451631 GPU 1 49094 test begin: paddle.concat(list[Tensor([18, 0],"float32"),Tensor([18, 0],"float32"),], -1, )

2025-06-05 15:16:50.488130 GPU 0 49127 test begin: paddle.concat(list[Tensor([1820, 0],"float32"),Tensor([1820, 0],"float32"),Tensor([1820, 0],"float32"),], -1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107833 (unix time) try "date -d @1749107833" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fdd539db1d0) received by PID 49127 (TID 0x7fdd545b9740) from PID 1402843600 ***]


2025-06-05 15:16:50.560290 GPU 0 49050 test begin: paddle.concat(list[Tensor([2, 0, 240, 240],"float32"),Tensor([2, 0, 240, 240],"float32"),Tensor([2, 0, 240, 240],"float32"),Tensor([2, 0, 240, 240],"float32"),], 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107835 (unix time) try "date -d @1749107835" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f7da76882d0) received by PID 49050 (TID 0x7f7da8266740) from PID 18446744072223228624 ***]


2025-06-05 15:16:50.663420 GPU 1 49588 test begin: paddle.concat(list[Tensor([2, 0, 8],"float32"),Tensor([2, 0, 8],"float32"),Tensor([2, 0, 8],"float32"),Tensor([2, 0, 8],"float32"),Tensor([2, 0, 8],"float32"),Tensor([2, 0, 8],"float32"),Tensor([2, 0, 8],"float32"),Tensor([2, 0, 8],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107834 (unix time) try "date -d @1749107834" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f1095bc72c0) received by PID 49588 (TID 0x7f10967a5740) from PID 18446744071926739648 ***]


2025-06-05 15:16:50.915600 GPU 1 49356 test begin: paddle.concat(list[Tensor([2, 0],"float32"),Tensor([2, 0],"float32"),Tensor([2, 0],"float32"),Tensor([2, 0],"float32"),Tensor([2, 0],"float32"),Tensor([2, 0],"float32"),Tensor([2, 0],"float32"),Tensor([2, 0],"float32"),Tensor([2, 0],"float32"),Tensor([2, 0],"float32"),Tensor([2, 0],"float32"),Tensor([2, 0],"float32"),Tensor([2, 0],"float32"),Tensor([2, 0],"float32"),Tensor([2, 0],"float32"),Tensor([2, 0],"float32"),Tensor([2, 0],"float32"),Tensor([2, 0],"float32"),Tensor([2, 0],"float32"),Tensor([2, 0],"float32"),Tensor([2, 0],"float32"),Tensor([2, 0],"float32"),Tensor([2, 0],"float32"),Tensor([2, 0],"float32"),Tensor([2, 0],"float32"),], axis=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107835 (unix time) try "date -d @1749107835" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f46ff119350) received by PID 49356 (TID 0x7f46ffcf7740) from PID 18446744073693926224 ***]


2025-06-05 15:16:50.915891 GPU 1 49565 test begin: paddle.concat(list[Tensor([2, 0],"float64"),Tensor([2, 0],"float64"),Tensor([2, 0],"float64"),Tensor([2, 0],"float64"),Tensor([2, 0],"float64"),Tensor([2, 0],"float64"),Tensor([2, 0],"float64"),Tensor([2, 0],"float64"),Tensor([2, 0],"float64"),Tensor([2, 0],"float64"),Tensor([2, 0],"float64"),Tensor([2, 0],"float64"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107838 (unix time) try "date -d @1749107838" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f97072ed340) received by PID 49565 (TID 0x7f9707ecb740) from PID 120509248 ***]


2025-06-05 15:16:51.025462 GPU 0 49517 test begin: paddle.concat(list[Tensor([2, 0],"int64"),Tensor([2, 0],"int64"),Tensor([2, 0],"int64"),Tensor([2, 0],"int64"),Tensor([2, 0],"int64"),Tensor([2, 0],"int64"),Tensor([2, 0],"int64"),Tensor([2, 0],"int64"),Tensor([2, 0],"int64"),Tensor([2, 0],"int64"),Tensor([2, 0],"int64"),Tensor([2, 0],"int64"),Tensor([2, 0],"int64"),Tensor([2, 0],"int64"),Tensor([2, 0],"int64"),Tensor([2, 0],"int64"),Tensor([2, 0],"int64"),Tensor([2, 0],"int64"),Tensor([2, 0],"int64"),Tensor([2, 0],"int64"),Tensor([2, 0],"int64"),Tensor([2, 0],"int64"),Tensor([2, 0],"int64"),Tensor([2, 0],"int64"),Tensor([2, 0],"int64"),], axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107835 (unix time) try "date -d @1749107835" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fc93b6ec3c0) received by PID 49517 (TID 0x7fc93c2ca740) from PID 997114816 ***]


2025-06-05 15:16:51.107521 GPU 1 49490 test begin: paddle.concat(list[Tensor([2, 1, 0],"float32"),Tensor([2, 1, 0],"float32"),Tensor([2, 1, 0],"float32"),Tensor([2, 1, 0],"float32"),Tensor([2, 1, 0],"float32"),Tensor([2, 1, 0],"float32"),Tensor([2, 1, 0],"float32"),Tensor([2, 1, 0],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107836 (unix time) try "date -d @1749107836" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f2fb1744330) received by PID 49490 (TID 0x7f2fb2322740) from PID 18446744072391770928 ***]


2025-06-05 15:17:03.640597 GPU 1 49858 test begin: paddle.concat(list[Tensor([2, 3, 0, 240],"float32"),Tensor([2, 3, 0, 240],"float32"),Tensor([2, 3, 0, 240],"float32"),Tensor([2, 3, 0, 240],"float32"),], 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107844 (unix time) try "date -d @1749107844" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fb2e77021e0) received by PID 49858 (TID 0x7fb2e82e0740) from PID 18446744073297469920 ***]


2025-06-05 15:17:04.422960 GPU 0 49899 test begin: paddle.concat(list[Tensor([2, 3, 240, 0],"float32"),Tensor([2, 3, 240, 0],"float32"),Tensor([2, 3, 240, 0],"float32"),Tensor([2, 3, 240, 0],"float32"),], 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107846 (unix time) try "date -d @1749107846" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f4a0cf8a1c0) received by PID 49899 (TID 0x7f4a0db68740) from PID 217620928 ***]


2025-06-05 15:17:04.737777 GPU 0 49915 test begin: paddle.concat(list[Tensor([216, 0, 1, 1, 2, 1],"float32"),Tensor([216, 0, 1, 1, 2, 1],"float32"),Tensor([216, 0, 1, 1, 2, 1],"float32"),Tensor([216, 0, 1, 1, 2, 3],"float32"),Tensor([216, 0, 1, 1, 2, 1],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107847 (unix time) try "date -d @1749107847" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fe51e7c8250) received by PID 49915 (TID 0x7fe51f3a6740) from PID 511476304 ***]


2025-06-05 15:17:04.882211 GPU 1 49941 test begin: paddle.concat(list[Tensor([216, 248, 0, 1, 2, 1],"float32"),Tensor([216, 248, 0, 1, 2, 1],"float32"),Tensor([216, 248, 0, 1, 2, 1],"float32"),Tensor([216, 248, 0, 1, 2, 3],"float32"),Tensor([216, 248, 0, 1, 2, 1],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107847 (unix time) try "date -d @1749107847" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fe5fcabe2a0) received by PID 49941 (TID 0x7fe5fd69c740) from PID 18446744073653707424 ***]


2025-06-05 15:17:14.900095 GPU 0 50038 test begin: paddle.concat(list[Tensor([216, 248, 1, 0, 2, 1],"float32"),Tensor([216, 248, 1, 0, 2, 1],"float32"),Tensor([216, 248, 1, 0, 2, 1],"float32"),Tensor([216, 248, 1, 0, 2, 3],"float32"),Tensor([216, 248, 1, 0, 2, 1],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107862 (unix time) try "date -d @1749107862" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f1f079d5330) received by PID 50038 (TID 0x7f1f085b3740) from PID 127750960 ***]


2025-06-05 15:17:15.766748 GPU 1 50120 test begin: paddle.concat(list[Tensor([216, 248, 1, 1, 0, 1],"float32"),Tensor([216, 248, 1, 1, 0, 1],"float32"),Tensor([216, 248, 1, 1, 0, 1],"float32"),Tensor([216, 248, 1, 1, 0, 3],"float32"),Tensor([216, 248, 1, 1, 0, 1],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107860 (unix time) try "date -d @1749107860" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f6afc7952d0) received by PID 50120 (TID 0x7f6afd373740) from PID 18446744073650393808 ***]


2025-06-05 15:17:16.014350 GPU 0 50119 test begin: paddle.concat(list[Tensor([216, 248, 1, 1, 2, 0],"float32"),Tensor([216, 248, 1, 1, 2, 0],"float32"),Tensor([216, 248, 1, 1, 2, 0],"float32"),Tensor([216, 248, 1, 1, 2, 0],"float32"),Tensor([216, 248, 1, 1, 2, 0],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107865 (unix time) try "date -d @1749107865" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f3ee8568140) received by PID 50119 (TID 0x7f3ee9146740) from PID 18446744073312567616 ***]


2025-06-05 15:17:16.240633 GPU 0 50188 test begin: paddle.concat(list[Tensor([24, 0],"float32"),Tensor([24, 0],"float32"),], 1, )

2025-06-05 15:17:16.460761 GPU 1 50090 test begin: paddle.concat(list[Tensor([256, 0, 1],"float32"),Tensor([256, 0, 1],"float32"),], 2, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107862 (unix time) try "date -d @1749107862" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 50090 (TID 0x7fc3107a0740) from PID 24 ***]


2025-06-05 15:17:16.738481 GPU 0 50222 test begin: paddle.concat(list[Tensor([3, 0, 2, 5],"float64"),Tensor([3, 0, 2, 5],"float64"),Tensor([3, 0, 2, 5],"float64"),], axis=1, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107863 (unix time) try "date -d @1749107863" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7feeb98b2110) received by PID 50222 (TID 0x7feeba490740) from PID 18446744072527487248 ***]


2025-06-05 15:17:16.764791 GPU 0 50211 test begin: paddle.concat(list[Tensor([3, 0, 2, 5],"float64"),], axis=1, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107862 (unix time) try "date -d @1749107862" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fde01e81230) received by PID 50211 (TID 0x7fdfea544740) from PID 31986224 ***]


2025-06-05 15:17:16.955824 GPU 1 50232 test begin: paddle.concat(list[Tensor([3, 0, 2, 5],"float64"),], axis=2, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107865 (unix time) try "date -d @1749107865" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fdfec642f30) received by PID 50232 (TID 0x7fe1d4415740) from PID 18446744073380572976 ***]


2025-06-05 15:17:25.211332 GPU 0 50314 test begin: paddle.concat(list[Tensor([3, 0, 2],"float64"),Tensor([3, 0, 2],"float64"),Tensor([3, 0, 2],"float64"),], axis=1, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107868 (unix time) try "date -d @1749107868" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xa66c6b80) received by PID 50314 (TID 0x7f71e4c53740) from PID 18446744072206707584 ***]


2025-06-05 15:17:26.169390 GPU 1 50484 test begin: paddle.concat(list[Tensor([3, 0, 2],"float64"),], axis=1, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107870 (unix time) try "date -d @1749107870" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 50484 (TID 0x7f7b14573740) from PID 0 ***]


2025-06-05 15:17:26.434021 GPU 1 50377 test begin: paddle.concat(list[Tensor([3, 0],"float32"),Tensor([3, 0],"float32"),], -1, )

2025-06-05 15:17:27.274660 GPU 0 50442 test begin: paddle.concat(list[Tensor([3, 0],"float64"),Tensor([3, 0],"float64"),Tensor([3, 0],"float64"),Tensor([3, 0],"float64"),Tensor([3, 0],"float64"),Tensor([3, 0],"float64"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107873 (unix time) try "date -d @1749107873" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f152a449330) received by PID 50442 (TID 0x7f152b027740) from PID 709137200 ***]


2025-06-05 15:17:27.781323 GPU 1 50514 test begin: paddle.concat(list[Tensor([3, 4, 0, 5],"float64"),Tensor([3, 4, 0, 5],"float64"),Tensor([3, 4, 0, 5],"float64"),], axis=1, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107875 (unix time) try "date -d @1749107875" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fe249ed61d0) received by PID 50514 (TID 0x7fe24aab4740) from PID 1240293840 ***]


2025-06-05 15:17:28.213569 GPU 0 50420 test begin: paddle.concat(list[Tensor([3, 4, 0, 5],"float64"),], axis=1, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107872 (unix time) try "date -d @1749107872" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 50420 (TID 0x7f68ec5c2740) from PID 0 ***]


2025-06-05 15:17:28.550807 GPU 0 50536 test begin: paddle.concat(list[Tensor([3, 4, 0, 5],"float64"),], axis=2, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107877 (unix time) try "date -d @1749107877" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 50536 (TID 0x7f539b30c740) from PID 0 ***]


2025-06-05 15:17:28.630379 GPU 1 50540 test begin: paddle.concat(list[Tensor([3, 4, 0],"float64"),Tensor([3, 4, 0],"float64"),Tensor([3, 4, 0],"float64"),], axis=1, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107876 (unix time) try "date -d @1749107876" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f25caf31310) received by PID 50540 (TID 0x7f25cbb0f740) from PID 18446744072819512080 ***]


2025-06-05 15:17:28.779520 GPU 1 50666 test begin: paddle.concat(list[Tensor([3, 4, 0],"float64"),], axis=1, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107873 (unix time) try "date -d @1749107873" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 50666 (TID 0x7f0942617740) from PID 0 ***]


2025-06-05 15:17:28.822153 GPU 1 50603 test begin: paddle.concat(list[Tensor([3, 4, 2, 0],"float64"),Tensor([3, 4, 2, 0],"float64"),Tensor([3, 4, 2, 0],"float64"),], axis=1, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107875 (unix time) try "date -d @1749107875" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 50603 (TID 0x7f764563e740) from PID 24 ***]


2025-06-05 15:17:39.289653 GPU 1 50732 test begin: paddle.concat(list[Tensor([3, 4, 2, 0],"float64"),], axis=1, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107884 (unix time) try "date -d @1749107884" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 50732 (TID 0x7fbe728fd740) from PID 0 ***]


2025-06-05 15:17:41.387223 GPU 0 50881 test begin: paddle.concat(list[Tensor([3, 4, 2, 0],"float64"),], axis=2, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107884 (unix time) try "date -d @1749107884" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 50881 (TID 0x7f09f08b1740) from PID 0 ***]


2025-06-05 15:17:41.571004 GPU 0 50849 test begin: paddle.concat(list[Tensor([4, 0, 918],"float16"),Tensor([4, 0, 918],"float16"),Tensor([4, 0, 918],"float16"),Tensor([4, 0, 918],"float16"),Tensor([4, 0, 918],"float16"),Tensor([4, 0, 918],"float16"),Tensor([4, 0, 918],"float16"),Tensor([4, 0, 918],"float16"),Tensor([4, 0, 918],"float16"),Tensor([4, 0, 918],"float16"),Tensor([4, 0, 918],"float16"),Tensor([4, 0, 918],"float16"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107886 (unix time) try "date -d @1749107886" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7efd46297330) received by PID 50849 (TID 0x7efd46e75740) from PID 1177121584 ***]


2025-06-05 15:17:41.675810 GPU 1 50850 test begin: paddle.concat(list[Tensor([4, 0],"float32"),], 1, )

2025-06-05 15:17:52.715389 GPU 1 51154 test begin: paddle.concat(list[Tensor([4, 304, 0],"float16"),Tensor([4, 304, 0],"float16"),Tensor([4, 304, 0],"float16"),Tensor([4, 304, 0],"float16"),Tensor([4, 304, 0],"float16"),Tensor([4, 304, 0],"float16"),Tensor([4, 304, 0],"float16"),Tensor([4, 304, 0],"float16"),Tensor([4, 304, 0],"float16"),Tensor([4, 304, 0],"float16"),Tensor([4, 304, 0],"float16"),Tensor([4, 304, 0],"float16"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107900 (unix time) try "date -d @1749107900" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f0634c6a2d0) received by PID 51154 (TID 0x7f0635848740) from PID 885433040 ***]


2025-06-05 15:17:53.534984 GPU 0 51179 test begin: paddle.concat(list[Tensor([4, 346, 0],"float16"),Tensor([4, 346, 0],"float16"),Tensor([4, 346, 0],"float16"),Tensor([4, 346, 0],"float16"),Tensor([4, 346, 0],"float16"),Tensor([4, 346, 0],"float16"),Tensor([4, 346, 0],"float16"),Tensor([4, 346, 0],"float16"),Tensor([4, 346, 0],"float16"),Tensor([4, 346, 0],"float16"),Tensor([4, 346, 0],"float16"),Tensor([4, 346, 0],"float16"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107901 (unix time) try "date -d @1749107901" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f0ccf70a2d0) received by PID 51179 (TID 0x7f0cd02e8740) from PID 18446744072894849744 ***]


2025-06-05 15:17:53.548712 GPU 0 51191 test begin: paddle.concat(list[Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),Tensor([40, 0, 8],"float32"),], axis=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107902 (unix time) try "date -d @1749107902" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 51191 (TID 0x7fefdba3d740) from PID 0 ***]


2025-06-05 15:17:53.683896 GPU 0 51192 test begin: paddle.concat(list[Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),], 0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107900 (unix time) try "date -d @1749107900" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f14d76753c0) received by PID 51192 (TID 0x7f14d8253740) from PID 18446744073028457408 ***]


2025-06-05 15:17:53.917703 GPU 0 51211 test begin: paddle.concat(list[Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),Tensor([40, 0],"float32"),], 0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107899 (unix time) try "date -d @1749107899" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fa58d7712d0) received by PID 51211 (TID 0x7fa58e34f740) from PID 18446744071787975376 ***]


2025-06-05 15:17:54.019748 GPU 1 51216 test begin: paddle.concat(list[Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),Tensor([40, 1, 0],"float32"),], axis=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107901 (unix time) try "date -d @1749107901" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fed9904d3c0) received by PID 51216 (TID 0x7fed99c2b740) from PID 18446744071981814720 ***]


2025-06-05 15:17:54.920748 GPU 1 51281 test begin: paddle.concat(list[Tensor([5, 0, 1],"float32"),Tensor([5, 0, 1],"float32"),], 2, )

2025-06-05 15:17:54.983427 GPU 0 51282 test begin: paddle.concat(list[Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107901 (unix time) try "date -d @1749107901" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 51282 (TID 0x7f52b03da740) from PID 0 ***]


2025-06-05 15:18:04.969216 GPU 1 51401 test begin: paddle.concat(list[Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),Tensor([512, 0],"float32"),], axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107910 (unix time) try "date -d @1749107910" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f70e6d913a0) received by PID 51401 (TID 0x7f70e796f740) from PID 18446744073287570336 ***]


2025-06-05 15:18:05.190526 GPU 1 51428 test begin: paddle.concat(list[Tensor([52, 0, 3, 1],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107912 (unix time) try "date -d @1749107912" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 51428 (TID 0x7fa4c56c7740) from PID 0 ***]


2025-06-05 15:18:05.546569 GPU 0 51566 test begin: paddle.concat(list[Tensor([52, 1, 0, 1],"float32"),], axis=1, )

2025-06-05 15:18:05.625476 GPU 1 51605 test begin: paddle.concat(list[Tensor([52, 1, 3, 0],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107912 (unix time) try "date -d @1749107912" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 51605 (TID 0x7f14d5ede740) from PID 0 ***]


2025-06-05 15:18:05.646604 GPU 0 51597 test begin: paddle.concat(list[Tensor([52, 4, 0, 5, 1, 8],"float32"),Tensor([52, 4, 0, 5, 1, 8],"float32"),Tensor([52, 4, 0, 5, 1, 8],"float32"),], axis=2, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107913 (unix time) try "date -d @1749107913" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7faf07751040) received by PID 51597 (TID 0x7faf0832f740) from PID 125112384 ***]


2025-06-05 15:18:06.449622 GPU 1 51635 test begin: paddle.concat(list[Tensor([52, 4, 0, 8],"float32"),Tensor([52, 4, 0, 8],"float32"),Tensor([52, 4, 0, 8],"float32"),], axis=2, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107911 (unix time) try "date -d @1749107911" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f24b136f0c0) received by PID 51635 (TID 0x7f24b1f4d740) from PID 18446744072387752128 ***]


2025-06-05 15:18:06.625309 GPU 1 51658 test begin: paddle.concat(list[Tensor([52, 4, 1, 5, 0, 8],"float32"),Tensor([52, 4, 3, 5, 0, 8],"float32"),Tensor([52, 4, 1, 5, 0, 8],"float32"),], axis=2, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107915 (unix time) try "date -d @1749107915" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f557c4641c0) received by PID 51658 (TID 0x7f557d042740) from PID 2084979136 ***]


2025-06-05 15:18:07.114119 GPU 1 51715 test begin: paddle.concat(list[Tensor([52, 4, 5, 0, 5],"float32"),Tensor([52, 4, 5, 0, 2],"float32"),], axis=4, )

2025-06-05 15:18:07.447619 GPU 0 51725 test begin: paddle.concat(list[Tensor([52, 5, 0, 1],"float32"),Tensor([52, 5, 0, 3],"float32"),Tensor([52, 5, 0, 1],"float32"),], axis=3, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107914 (unix time) try "date -d @1749107914" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f7527bc31c0) received by PID 51725 (TID 0x7f75287a1740) from PID 666644928 ***]


2025-06-05 15:18:07.594640 GPU 0 51749 test begin: paddle.concat(list[Tensor([56, 0, 16, 16],"float32"),Tensor([56, 0, 16, 16],"float32"),Tensor([56, 0, 16, 16],"float32"),], 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107916 (unix time) try "date -d @1749107916" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xa5002b60) received by PID 51749 (TID 0x7f21824d8740) from PID 18446744072182836064 ***]


2025-06-05 15:18:18.548760 GPU 1 51885 test begin: paddle.concat(list[Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),Tensor([60000, 0],"bool"),], axis=1, )
element 0 of tensors does not require grad and does not have a grad_fn


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<bool, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, bool>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107924 (unix time) try "date -d @1749107924" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 51885 (TID 0x7f59db5b3740) from PID 24 ***]


2025-06-05 15:18:20.005333 GPU 0 52003 test begin: paddle.concat(list[Tensor([64, 0, 56, 56],"float32"),Tensor([64, 0, 56, 56],"float32"),Tensor([64, 0, 56, 56],"float32"),Tensor([64, 0, 56, 56],"float32"),Tensor([64, 0, 56, 56],"float32"),Tensor([64, 0, 56, 56],"float32"),Tensor([64, 0, 56, 56],"float32"),Tensor([64, 0, 56, 56],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107924 (unix time) try "date -d @1749107924" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f4fea59d2b0) received by PID 52003 (TID 0x7f4feb17b740) from PID 18446744073346339504 ***]


2025-06-05 15:18:20.087928 GPU 0 51940 test begin: paddle.concat(list[Tensor([64, 0, 7, 7],"float32"),Tensor([64, 0, 7, 7],"float32"),Tensor([64, 0, 7, 7],"float32"),Tensor([64, 0, 7, 7],"float32"),Tensor([64, 0, 7, 7],"float32"),Tensor([64, 0, 7, 7],"float32"),Tensor([64, 0, 7, 7],"float32"),Tensor([64, 0, 7, 7],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107925 (unix time) try "date -d @1749107925" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f51239202e0) received by PID 51940 (TID 0x7f51244fe740) from PID 596771552 ***]


2025-06-05 15:18:20.253970 GPU 1 51961 test begin: paddle.concat(list[Tensor([64, 1280, 0, 7],"float32"),Tensor([64, 288, 0, 7],"float32"),Tensor([64, 288, 0, 7],"float32"),Tensor([64, 288, 0, 7],"float32"),Tensor([64, 288, 0, 7],"float32"),Tensor([64, 288, 0, 7],"float32"),Tensor([64, 288, 0, 7],"float32"),Tensor([64, 288, 0, 7],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107926 (unix time) try "date -d @1749107926" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f83b9ad62b0) received by PID 51961 (TID 0x7f83ba6b4740) from PID 18446744072529732272 ***]


2025-06-05 15:18:29.301594 GPU 0 52517 test begin: paddle.concat(list[Tensor([64, 1280, 7, 0],"float32"),Tensor([64, 288, 7, 0],"float32"),Tensor([64, 288, 7, 0],"float32"),Tensor([64, 288, 7, 0],"float32"),Tensor([64, 288, 7, 0],"float32"),Tensor([64, 288, 7, 0],"float32"),Tensor([64, 288, 7, 0],"float32"),Tensor([64, 288, 7, 0],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107939 (unix time) try "date -d @1749107939" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fc0f34b31f0) received by PID 52517 (TID 0x7fc0f4091740) from PID 18446744073496375792 ***]


2025-06-05 15:18:29.542711 GPU 0 52546 test begin: paddle.concat(list[Tensor([64, 160, 0, 56],"float32"),Tensor([64, 192, 0, 56],"float32"),Tensor([64, 192, 0, 56],"float32"),Tensor([64, 192, 0, 56],"float32"),Tensor([64, 192, 0, 56],"float32"),Tensor([64, 192, 0, 56],"float32"),Tensor([64, 192, 0, 56],"float32"),Tensor([64, 192, 0, 56],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107939 (unix time) try "date -d @1749107939" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fb3757892b0) received by PID 52546 (TID 0x7fb376367740) from PID 1970836144 ***]


2025-06-05 15:18:30.522059 GPU 1 52584 test begin: paddle.concat(list[Tensor([64, 160, 56, 0],"float32"),Tensor([64, 192, 56, 0],"float32"),Tensor([64, 192, 56, 0],"float32"),Tensor([64, 192, 56, 0],"float32"),Tensor([64, 192, 56, 0],"float32"),Tensor([64, 192, 56, 0],"float32"),Tensor([64, 192, 56, 0],"float32"),Tensor([64, 192, 56, 0],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107943 (unix time) try "date -d @1749107943" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fa12c81e2c0) received by PID 52584 (TID 0x7fa12d3fc740) from PID 746709696 ***]


2025-06-05 15:18:30.677975 GPU 1 52560 test begin: paddle.concat(list[Tensor([8, 0, 128, 64],"float32"),Tensor([8, 0, 1, 64],"float32"),], axis=-2, )

2025-06-05 15:18:31.901820 GPU 1 52599 test begin: paddle.concat(list[Tensor([8, 16, 128, 0],"float32"),Tensor([8, 16, 1, 0],"float32"),], axis=-2, )

2025-06-05 15:18:32.078454 GPU 0 52615 test begin: paddle.concat(tuple(Tensor([0, 1, 192],"float32"),Tensor([0, 576, 192],"float32"),), axis=1, )

2025-06-05 15:18:32.099898 GPU 0 52611 test begin: paddle.concat(tuple(Tensor([0, 1, 32],"float32"),Tensor([0, 1, 32],"float32"),Tensor([0, 1, 32],"float32"),Tensor([0, 1, 32],"float32"),Tensor([0, 1, 32],"float32"),Tensor([0, 1, 32],"float32"),Tensor([0, 1, 32],"float32"),Tensor([0, 1, 32],"float32"),), axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107942 (unix time) try "date -d @1749107942" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f973bfe12f0) received by PID 52611 (TID 0x7f973cbbf740) from PID 1006506736 ***]


2025-06-05 15:18:32.129791 GPU 0 52639 test begin: paddle.concat(tuple(Tensor([0, 10],"bool"),Tensor([0, 1],"bool"),), axis=1, )
element 0 of tensors does not require grad and does not have a grad_fn


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<bool, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, bool>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107942 (unix time) try "date -d @1749107942" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 52639 (TID 0x7f3181108740) from PID 24 ***]


2025-06-05 15:18:43.877253 GPU 1 52872 test begin: paddle.concat(tuple(Tensor([0, 10],"int64"),Tensor([0, 1],"int64"),), axis=-1, )
element 0 of tensors does not require grad and does not have a grad_fn


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107950 (unix time) try "date -d @1749107950" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xa6889f50) received by PID 52872 (TID 0x7fef843fe740) from PID 18446744072208555856 ***]


2025-06-05 15:18:44.517460 GPU 1 52976 test begin: paddle.concat(tuple(Tensor([0, 120, 14, 14],"float16"),Tensor([0, 120, 14, 14],"float16"),Tensor([0, 120, 14, 14],"float16"),Tensor([0, 120, 14, 14],"float16"),), axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107953 (unix time) try "date -d @1749107953" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7ff980eb6310) received by PID 52976 (TID 0x7ff981a94740) from PID 18446744071577494288 ***]


2025-06-05 15:18:44.627720 GPU 0 53016 test begin: paddle.concat(tuple(Tensor([0, 12],"float64"),), 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107950 (unix time) try "date -d @1749107950" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 53016 (TID 0x7fe613cf2740) from PID 0 ***]


2025-06-05 15:18:44.973974 GPU 1 52957 test begin: paddle.concat(tuple(Tensor([0, 1],"bool"),Tensor([0, 1],"bool"),), axis=1, )
element 0 of tensors does not require grad and does not have a grad_fn


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<bool, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, bool>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107950 (unix time) try "date -d @1749107950" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 52957 (TID 0x7f8c29361740) from PID 24 ***]


2025-06-05 15:18:45.450508 GPU 1 53049 test begin: paddle.concat(tuple(Tensor([0, 1],"int64"),Tensor([0, 1],"int64"),), axis=-1, )
element 0 of tensors does not require grad and does not have a grad_fn


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<long, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, long>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107952 (unix time) try "date -d @1749107952" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 53049 (TID 0x7f11f0595740) from PID 24 ***]


2025-06-05 15:18:45.572864 GPU 1 53017 test begin: paddle.concat(tuple(Tensor([0, 2, 128, 128],"float32"),Tensor([0, 1, 128, 128],"float32"),Tensor([0, 3, 128, 128],"float32"),Tensor([0, 2, 128, 128],"float32"),Tensor([0, 2, 128, 128],"float32"),), axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107953 (unix time) try "date -d @1749107953" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f3185071160) received by PID 53017 (TID 0x7f3185c4f740) from PID 18446744071646417248 ***]


2025-06-05 15:18:46.177843 GPU 0 53006 test begin: paddle.concat(tuple(Tensor([0, 2, 248, 216],"float32"),Tensor([0, 1, 248, 216],"float32"),Tensor([0, 3, 248, 216],"float32"),Tensor([0, 2, 248, 216],"float32"),), axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107951 (unix time) try "date -d @1749107951" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f32d4bd70b0) received by PID 53006 (TID 0x7f32d57b5740) from PID 18446744072983769264 ***]


2025-06-05 15:18:46.401497 GPU 1 53096 test begin: paddle.concat(tuple(Tensor([0, 256, 28, 28],"float16"),Tensor([0, 256, 28, 28],"float16"),Tensor([0, 128, 28, 28],"float16"),Tensor([0, 256, 28, 28],"float16"),Tensor([0, 256, 28, 28],"float16"),), 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107954 (unix time) try "date -d @1749107954" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f2e38c6f2d0) received by PID 53096 (TID 0x7f2e3984d740) from PID 952562384 ***]


2025-06-05 15:18:46.414662 GPU 0 53082 test begin: paddle.concat(tuple(Tensor([0, 256, 28, 28],"float32"),Tensor([0, 256, 28, 28],"float32"),Tensor([0, 128, 28, 28],"float32"),Tensor([0, 256, 28, 28],"float32"),Tensor([0, 256, 28, 28],"float32"),), 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107953 (unix time) try "date -d @1749107953" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fd8475e22c0) received by PID 53082 (TID 0x7fd8481c0740) from PID 1197351616 ***]


2025-06-05 15:18:58.435026 GPU 0 53551 test begin: paddle.concat(tuple(Tensor([0, 3],"float64"),), 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107959 (unix time) try "date -d @1749107959" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f93233a33f0) received by PID 53551 (TID 0x7f950b137740) from PID 591016944 ***]


2025-06-05 15:18:58.842553 GPU 1 53713 test begin: paddle.concat(tuple(Tensor([0, 512, 14, 14],"float16"),Tensor([0, 512, 14, 14],"float16"),Tensor([0, 256, 14, 14],"float16"),Tensor([0, 512, 14, 14],"float16"),Tensor([0, 512, 14, 14],"float16"),Tensor([0, 512, 14, 14],"float16"),Tensor([0, 512, 14, 14],"float16"),), 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108138 (unix time) try "date -d @1749108138" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fc309d752a0) received by PID 53713 (TID 0x7fc30a953740) from PID 165106336 ***]


2025-06-05 15:18:58.933034 GPU 0 53725 test begin: paddle.concat(tuple(Tensor([0, 512, 14, 14],"float16"),Tensor([0, 512, 14, 14],"float16"),Tensor([0, 512, 14, 14],"float16"),Tensor([0, 512, 14, 14],"float16"),), 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107961 (unix time) try "date -d @1749107961" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f52f891b310) received by PID 53725 (TID 0x7f52f94f9740) from PID 18446744073584882448 ***]


2025-06-05 15:18:59.597458 GPU 1 53623 test begin: paddle.concat(tuple(Tensor([0, 512, 14, 14],"float32"),Tensor([0, 512, 14, 14],"float32"),Tensor([0, 256, 14, 14],"float32"),Tensor([0, 512, 14, 14],"float32"),Tensor([0, 512, 14, 14],"float32"),Tensor([0, 512, 14, 14],"float32"),Tensor([0, 512, 14, 14],"float32"),), 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108025 (unix time) try "date -d @1749108025" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f3083d18330) received by PID 53623 (TID 0x7f30848f6740) from PID 18446744071626130224 ***]


2025-06-05 15:18:59.806736 GPU 0 53642 test begin: paddle.concat(tuple(Tensor([0, 512, 14, 14],"float32"),Tensor([0, 512, 14, 14],"float32"),Tensor([0, 512, 14, 14],"float32"),Tensor([0, 512, 14, 14],"float32"),), 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107961 (unix time) try "date -d @1749107961" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fd3d35d0310) received by PID 53642 (TID 0x7fd3d41ae740) from PID 18446744072960672528 ***]


2025-06-05 15:19:10.151569 GPU 0 53896 test begin: paddle.concat(tuple(Tensor([1, 0, 1, 8],"float32"),Tensor([1, 0, 1, 8],"float32"),), axis=-2, )

2025-06-05 15:19:10.698816 GPU 0 53919 test begin: paddle.concat(tuple(Tensor([1, 0, 2, 4],"float32"),Tensor([1, 0, 2, 4],"float32"),), axis=-1, )

2025-06-05 15:19:11.468226 GPU 0 53972 test begin: paddle.concat(tuple(Tensor([1, 0, 256],"float32"),Tensor([1, 0, 256],"float32"),), axis=1, )

2025-06-05 15:19:11.678300 GPU 0 53962 test begin: paddle.concat(tuple(Tensor([1, 0, 9, 128],"float32"),Tensor([1, 0, 9, 128],"float32"),), axis=3, )

2025-06-05 15:19:12.814594 GPU 0 54019 test begin: paddle.concat(tuple(Tensor([1, 0],"int64"),Tensor([1, 0],"int64"),), axis=-1, )
element 0 of tensors does not require grad and does not have a grad_fn


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<long, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, long>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107988 (unix time) try "date -d @1749107988" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 54019 (TID 0x7fe6092f7740) from PID 24 ***]


2025-06-05 15:19:19.981801 GPU 0 54249 test begin: paddle.concat(tuple(Tensor([1, 1, 2, 0],"float32"),Tensor([1, 1, 2, 0],"float32"),), axis=-1, )

2025-06-05 15:19:20.540486 GPU 1 54263 test begin: paddle.concat(tuple(Tensor([1, 1, 20, 0],"float32"),Tensor([1, 1, 20, 0],"float32"),), axis=-1, )

2025-06-05 15:19:20.800578 GPU 1 54272 test begin: paddle.concat(tuple(Tensor([1, 1, 8, 0],"float32"),Tensor([1, 1, 8, 0],"float32"),), axis=1, )

2025-06-05 15:19:21.112852 GPU 0 54310 test begin: paddle.concat(tuple(Tensor([1, 10, 0, 128],"float32"),Tensor([1, 10, 0, 128],"float32"),), axis=3, )

2025-06-05 15:19:24.266844 GPU 0 54356 test begin: paddle.concat(tuple(Tensor([1, 12, 0, 128],"float32"),Tensor([1, 12, 0, 128],"float32"),), axis=3, )

2025-06-05 15:19:24.482981 GPU 1 54366 test begin: paddle.concat(tuple(Tensor([1, 2, 0, 4],"float32"),Tensor([1, 1, 0, 4],"float32"),), axis=1, )

2025-06-05 15:19:24.518097 GPU 1 54378 test begin: paddle.concat(tuple(Tensor([1, 20, 0],"float32"),Tensor([1, 20, 0],"float32"),), axis=-1, )

2025-06-05 15:19:24.530238 GPU 1 54406 test begin: paddle.concat(tuple(Tensor([1, 3, 0, 256],"float32"),Tensor([1, 3, 0, 256],"float32"),), 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749107998 (unix time) try "date -d @1749107998" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 54406 (TID 0x7f5559868740) from PID 24 ***]


2025-06-05 15:19:24.549551 GPU 1 54388 test begin: paddle.concat(tuple(Tensor([1, 4, 0, 8],"float32"),Tensor([1, 4, 0, 8],"float32"),), axis=-2, )

2025-06-05 15:19:39.941549 GPU 0 54535 test begin: paddle.concat(tuple(Tensor([1, 4, 1, 0],"float32"),Tensor([1, 4, 1, 0],"float32"),), axis=-2, )

2025-06-05 15:19:40.864415 GPU 0 54625 test begin: paddle.concat(tuple(Tensor([1, 4, 2, 0],"float32"),Tensor([1, 4, 1, 0],"float32"),), axis=-2, )

2025-06-05 15:19:41.027330 GPU 0 54622 test begin: paddle.concat(tuple(Tensor([13, 0, 16],"float32"),Tensor([13, 0, 16],"float32"),), 2, )

2025-06-05 15:19:57.013034 GPU 0 54915 test begin: paddle.concat(tuple(Tensor([13, 0, 32],"float32"),Tensor([13, 0, 32],"float32"),Tensor([13, 0, 32],"float32"),Tensor([13, 0, 32],"float32"),Tensor([13, 0, 32],"float32"),Tensor([13, 0, 32],"float32"),Tensor([13, 0, 32],"float32"),Tensor([13, 0, 32],"float32"),), axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108019 (unix time) try "date -d @1749108019" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7ffbb6c21300) received by PID 54915 (TID 0x7ffbb77ff740) from PID 18446744072480756480 ***]


2025-06-05 15:19:57.672320 GPU 0 54888 test begin: paddle.concat(tuple(Tensor([13, 0, 4],"float32"),Tensor([13, 0, 4],"float32"),), axis=2, )

2025-06-05 15:20:00.067724 GPU 0 54966 test begin: paddle.concat(tuple(Tensor([13, 1, 0],"float32"),Tensor([13, 1, 0],"float32"),Tensor([13, 1, 0],"float32"),Tensor([13, 1, 0],"float32"),Tensor([13, 1, 0],"float32"),Tensor([13, 1, 0],"float32"),Tensor([13, 1, 0],"float32"),Tensor([13, 1, 0],"float32"),), axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108023 (unix time) try "date -d @1749108023" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f0941c30330) received by PID 54966 (TID 0x7f094280e740) from PID 1103299376 ***]


2025-06-05 15:20:00.913132 GPU 0 54977 test begin: paddle.concat(tuple(Tensor([13, 7, 0],"float32"),Tensor([13, 7, 0],"float32"),), 2, )

2025-06-05 15:20:05.817265 GPU 0 55076 test begin: paddle.concat(tuple(Tensor([140, 0, 1, 1, 2, 6],"float32"),Tensor([140, 0, 1, 1, 2, 1],"float32"),), axis=-1, )

2025-06-05 15:20:07.982198 GPU 0 55087 test begin: paddle.concat(tuple(Tensor([140, 188, 1, 1, 2, 0],"float32"),Tensor([140, 188, 1, 1, 2, 0],"float32"),), axis=-1, )

2025-06-05 15:20:08.698139 GPU 0 55213 test begin: paddle.concat(tuple(Tensor([2, 0],"float64"),), 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108092 (unix time) try "date -d @1749108092" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 55213 (TID 0x7f2a479b5740) from PID 0 ***]


2025-06-05 15:20:08.713453 GPU 0 55231 test begin: paddle.concat(tuple(Tensor([2, 4, 0],"float32"),Tensor([2, 4, 0],"float32"),), axis=-1, )

2025-06-05 15:20:18.739006 GPU 0 55484 test begin: paddle.concat(tuple(Tensor([4, 0, 376, 25, 2],"float32"),Tensor([4, 0, 376, 25, 1],"float32"),), axis=-1, )

2025-06-05 15:20:21.637599 GPU 0 55564 test begin: paddle.concat(tuple(Tensor([4, 2, 0, 128],"float32"),Tensor([4, 1, 0, 128],"float32"),Tensor([4, 3, 0, 128],"float32"),Tensor([4, 2, 0, 128],"float32"),Tensor([4, 2, 0, 128],"float32"),), axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108043 (unix time) try "date -d @1749108043" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fc5648ab2d0) received by PID 55564 (TID 0x7fc565489740) from PID 1686811344 ***]


2025-06-05 15:20:27.630090 GPU 0 56064 test begin: paddle.concat(tuple(Tensor([4, 2, 0, 216],"float32"),Tensor([4, 1, 0, 216],"float32"),Tensor([4, 3, 0, 216],"float32"),Tensor([4, 2, 0, 216],"float32"),), axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108051 (unix time) try "date -d @1749108051" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f33e1d4f2a0) received by PID 56064 (TID 0x7f33e292d740) from PID 18446744073203413664 ***]


2025-06-05 15:20:29.521692 GPU 0 56099 test begin: paddle.concat(tuple(Tensor([4, 2, 128, 0],"float32"),Tensor([4, 1, 128, 0],"float32"),Tensor([4, 3, 128, 0],"float32"),Tensor([4, 2, 128, 0],"float32"),Tensor([4, 2, 128, 0],"float32"),), axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108052 (unix time) try "date -d @1749108052" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7ffa2fa5b330) received by PID 56099 (TID 0x7ffa30639740) from PID 799388464 ***]


2025-06-05 15:20:31.257685 GPU 0 56198 test begin: paddle.concat(tuple(Tensor([4, 2, 248, 0],"float32"),Tensor([4, 1, 248, 0],"float32"),Tensor([4, 3, 248, 0],"float32"),Tensor([4, 2, 248, 0],"float32"),), axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108057 (unix time) try "date -d @1749108057" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fc4a48c11a0) received by PID 56198 (TID 0x7fc4a549f740) from PID 18446744072175227296 ***]


2025-06-05 15:20:32.063763 GPU 0 56179 test begin: paddle.concat(tuple(Tensor([4, 280, 0, 25, 2],"float32"),Tensor([4, 280, 0, 25, 1],"float32"),), axis=-1, )

2025-06-05 15:20:36.835727 GPU 0 56257 test begin: paddle.concat(tuple(Tensor([64, 0, 14, 14],"float16"),Tensor([64, 0, 14, 14],"float16"),Tensor([64, 0, 14, 14],"float16"),Tensor([64, 0, 14, 14],"float16"),), 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108067 (unix time) try "date -d @1749108067" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7ff7897740e0) received by PID 56257 (TID 0x7ff78a352740) from PID 18446744071720878304 ***]


2025-06-05 15:20:54.209838 GPU 0 57143 test begin: paddle.concat(tuple(Tensor([64, 256, 0, 28],"float32"),Tensor([64, 256, 0, 28],"float32"),Tensor([64, 128, 0, 28],"float32"),Tensor([64, 256, 0, 28],"float32"),Tensor([64, 256, 0, 28],"float32"),), 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108085 (unix time) try "date -d @1749108085" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fa2df60e2a0) received by PID 57143 (TID 0x7fa2e01ec740) from PID 18446744073162252960 ***]


2025-06-05 15:20:55.533603 GPU 0 57202 test begin: paddle.concat(tuple(Tensor([64, 256, 28, 0],"float16"),Tensor([64, 256, 28, 0],"float16"),Tensor([64, 128, 28, 0],"float16"),Tensor([64, 256, 28, 0],"float16"),Tensor([64, 256, 28, 0],"float16"),), 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108088 (unix time) try "date -d @1749108088" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fcf8b2492d0) received by PID 57202 (TID 0x7fcf8be27740) from PID 18446744071749014224 ***]


2025-06-05 15:21:09.907048 GPU 0 57317 test begin: paddle.concat(tuple(Tensor([64, 256, 28, 0],"float32"),Tensor([64, 256, 28, 0],"float32"),Tensor([64, 128, 28, 0],"float32"),Tensor([64, 256, 28, 0],"float32"),Tensor([64, 256, 28, 0],"float32"),), 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108095 (unix time) try "date -d @1749108095" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f13863442a0) received by PID 57317 (TID 0x7f1386f22740) from PID 18446744071666156192 ***]


2025-06-05 15:21:09.959900 GPU 0 57307 test begin: paddle.concat(tuple(Tensor([64, 512, 0, 14],"float16"),Tensor([64, 512, 0, 14],"float16"),Tensor([64, 256, 0, 14],"float16"),Tensor([64, 512, 0, 14],"float16"),Tensor([64, 512, 0, 14],"float16"),Tensor([64, 512, 0, 14],"float16"),Tensor([64, 512, 0, 14],"float16"),), 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108095 (unix time) try "date -d @1749108095" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f1651ceb300) received by PID 57307 (TID 0x7f16528c9740) from PID 1372500736 ***]


2025-06-05 15:21:10.755847 GPU 0 57415 test begin: paddle.concat(tuple(Tensor([64, 512, 0, 14],"float16"),Tensor([64, 512, 0, 14],"float16"),Tensor([64, 512, 0, 14],"float16"),Tensor([64, 512, 0, 14],"float16"),), 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108095 (unix time) try "date -d @1749108095" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f8eed8a7310) received by PID 57415 (TID 0x7f8eee485740) from PID 18446744073399857936 ***]


2025-06-05 15:21:12.902631 GPU 0 57445 test begin: paddle.concat(tuple(Tensor([64, 512, 0, 14],"float32"),Tensor([64, 512, 0, 14],"float32"),Tensor([64, 256, 0, 14],"float32"),Tensor([64, 512, 0, 14],"float32"),Tensor([64, 512, 0, 14],"float32"),Tensor([64, 512, 0, 14],"float32"),Tensor([64, 512, 0, 14],"float32"),), 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108096 (unix time) try "date -d @1749108096" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fba25ab2330) received by PID 57445 (TID 0x7fba26690740) from PID 631972656 ***]


2025-06-05 15:21:16.191565 GPU 1 57502 test begin: paddle.concat(tuple(Tensor([64, 512, 0, 14],"float32"),Tensor([64, 512, 0, 14],"float32"),Tensor([64, 512, 0, 14],"float32"),Tensor([64, 512, 0, 14],"float32"),), 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108100 (unix time) try "date -d @1749108100" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f8d72a5a2f0) received by PID 57502 (TID 0x7f8d73638740) from PID 1923457776 ***]


2025-06-05 15:21:16.504296 GPU 1 57506 test begin: paddle.concat(tuple(Tensor([64, 512, 14, 0],"float16"),Tensor([64, 512, 14, 0],"float16"),Tensor([64, 256, 14, 0],"float16"),Tensor([64, 512, 14, 0],"float16"),Tensor([64, 512, 14, 0],"float16"),Tensor([64, 512, 14, 0],"float16"),Tensor([64, 512, 14, 0],"float16"),), 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108100 (unix time) try "date -d @1749108100" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f32e93dd2d0) received by PID 57506 (TID 0x7f32e9fbb740) from PID 18446744073327727312 ***]


2025-06-05 15:21:16.511635 GPU 1 57516 test begin: paddle.concat(tuple(Tensor([64, 512, 14, 0],"float16"),Tensor([64, 512, 14, 0],"float16"),Tensor([64, 512, 14, 0],"float16"),Tensor([64, 512, 14, 0],"float16"),), 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108100 (unix time) try "date -d @1749108100" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f3898d9f0a0) received by PID 57516 (TID 0x7f389997d740) from PID 18446744071979004064 ***]


2025-06-05 15:21:16.930172 GPU 1 57552 test begin: paddle.concat(tuple(Tensor([64, 512, 14, 0],"float32"),Tensor([64, 512, 14, 0],"float32"),Tensor([64, 256, 14, 0],"float32"),Tensor([64, 512, 14, 0],"float32"),Tensor([64, 512, 14, 0],"float32"),Tensor([64, 512, 14, 0],"float32"),Tensor([64, 512, 14, 0],"float32"),), 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108100 (unix time) try "date -d @1749108100" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f5c86baa2f0) received by PID 57552 (TID 0x7f5c87788740) from PID 18446744071674962672 ***]


2025-06-05 15:21:17.199038 GPU 1 57562 test begin: paddle.concat(tuple(Tensor([64, 512, 14, 0],"float32"),Tensor([64, 512, 14, 0],"float32"),Tensor([64, 512, 14, 0],"float32"),Tensor([64, 512, 14, 0],"float32"),), 1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108101 (unix time) try "date -d @1749108101" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fbfb9f692e0) received by PID 57562 (TID 0x7fbfbab47740) from PID 18446744072534528736 ***]


2025-06-05 15:21:17.389789 GPU 1 57525 test begin: paddle.concat(tuple(Tensor([8, 0, 128, 128],"float32"),Tensor([8, 0, 128, 128],"float32"),Tensor([8, 0, 128, 128],"float32"),Tensor([8, 0, 128, 128],"float32"),Tensor([8, 0, 128, 128],"float32"),), axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108100 (unix time) try "date -d @1749108100" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f1c003cd2a0) received by PID 57525 (TID 0x7f1c00fab740) from PID 3986080 ***]


2025-06-05 15:21:17.391280 GPU 1 57547 test begin: paddle.concat(tuple(Tensor([8, 2, 0, 128],"float32"),Tensor([8, 1, 0, 128],"float32"),Tensor([8, 3, 0, 128],"float32"),Tensor([8, 2, 0, 128],"float32"),Tensor([8, 2, 0, 128],"float32"),), axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108101 (unix time) try "date -d @1749108101" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f7849179310) received by PID 57547 (TID 0x7f7849d57740) from PID 1226281744 ***]


2025-06-05 15:21:17.405746 GPU 1 57571 test begin: paddle.concat(tuple(Tensor([8, 2, 128, 0],"float32"),Tensor([8, 1, 128, 0],"float32"),Tensor([8, 3, 128, 0],"float32"),Tensor([8, 2, 128, 0],"float32"),Tensor([8, 2, 128, 0],"float32"),), axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108100 (unix time) try "date -d @1749108100" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7ff3eff942d0) received by PID 57571 (TID 0x7ff3f0b72740) from PID 18446744073440674512 ***]


2025-06-05 15:21:17.677013 GPU 1 57599 test begin: paddle.concat(x=list[Tensor([0, 1024, 4, 14, 14],"float32"),Tensor([0, 256, 4, 14, 14],"float32"),], axis=1, name=None, )

2025-06-05 15:21:17.868490 GPU 1 57545 test begin: paddle.concat(x=list[Tensor([13, 0, 1],"float32"),Tensor([13, 0, 1],"float32"),Tensor([13, 0, 1],"float32"),], axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108101 (unix time) try "date -d @1749108101" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f14840790d0) received by PID 57545 (TID 0x7f1484c57740) from PID 18446744071629672656 ***]


2025-06-05 15:21:18.773200 GPU 0 57713 test begin: paddle.concat(x=list[Tensor([16, 0, 32],"float32"),Tensor([16, 0, 32],"float32"),], axis=2, )

2025-06-05 15:21:34.257675 GPU 0 58145 test begin: paddle.concat(x=list[Tensor([2048, 0],"float16"),Tensor([2048, 0],"float16"),], axis=-1, )

2025-06-05 15:21:37.689730 GPU 0 58186 test begin: paddle.concat(x=list[Tensor([8, 0, 4, 14, 14],"float32"),Tensor([8, 0, 4, 14, 14],"float32"),], axis=1, name=None, )

2025-06-05 15:21:43.201038 GPU 0 58294 test begin: paddle.concat(x=list[Tensor([8, 1024, 0, 14, 14],"float32"),Tensor([8, 256, 0, 14, 14],"float32"),], axis=1, name=None, )

2025-06-05 15:21:43.791556 GPU 0 58314 test begin: paddle.concat(x=tuple(Tensor([0, 1, 1024],"float32"),Tensor([0, 256, 1024],"float32"),), axis=1, )

2025-06-05 15:21:43.980016 GPU 0 58345 test begin: paddle.concat(x=tuple(Tensor([0, 96, 1],"float32"),Tensor([0, 384, 1],"float32"),Tensor([0, 384, 1],"float32"),), axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108127 (unix time) try "date -d @1749108127" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xa2196d80) received by PID 58345 (TID 0x7fb83b8a3740) from PID 18446744072134159744 ***]


2025-06-05 15:21:44.181975 GPU 0 58472 test begin: paddle.concat(x=tuple(Tensor([1, 1, 0],"float32"),Tensor([1, 256, 0],"float32"),), axis=1, )

2025-06-05 15:21:44.206238 GPU 0 58433 test begin: paddle.concat(x=tuple(Tensor([1, 16, 0, 64],"float32"),Tensor([1, 16, 0, 64],"float32"),), axis=-2, )

2025-06-05 15:21:44.211191 GPU 0 58429 test begin: paddle.concat(x=tuple(Tensor([1, 16, 1, 0],"float32"),Tensor([1, 16, 256, 0],"float32"),), axis=-2, )

2025-06-05 15:21:44.778395 GPU 0 58418 test begin: paddle.concat(x=tuple(Tensor([124, 0, 56, 56],"float32"),Tensor([124, 0, 56, 56],"float32"),), axis=1, )

2025-06-05 15:21:51.071699 GPU 1 58533 test begin: paddle.concat(x=tuple(Tensor([124, 10, 0, 56],"float32"),Tensor([124, 30, 0, 56],"float32"),), axis=1, )

2025-06-05 15:21:51.097521 GPU 1 58560 test begin: paddle.concat(x=tuple(Tensor([13, 0, 1],"float32"),Tensor([13, 0, 1],"float32"),Tensor([13, 0, 1],"float32"),), axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108132 (unix time) try "date -d @1749108132" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fae4f557fc0) received by PID 58560 (TID 0x7fae50136740) from PID 1331003328 ***]


2025-06-05 15:21:51.582681 GPU 1 58568 test begin: paddle.concat(x=tuple(Tensor([13, 0, 96, 32],"float32"),Tensor([13, 0, 96, 4],"float32"),), axis=3, )

2025-06-05 15:21:51.698468 GPU 1 58645 test begin: paddle.concat(x=tuple(Tensor([13, 96, 0],"float32"),Tensor([13, 384, 0],"float32"),Tensor([13, 384, 0],"float32"),), axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108133 (unix time) try "date -d @1749108133" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7ff7eca32050) received by PID 58645 (TID 0x7ff7ed610740) from PID 18446744073384697936 ***]


2025-06-05 15:21:51.722727 GPU 1 58589 test begin: paddle.diag(Tensor([0, 10],"float32"), offset=-1, )
Warning: The core code of paddle.diag is too complex.
[paddle error] paddle.diag(Tensor([0, 10],"float32"), offset=-1, ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-06-05 15:21:51.741294 GPU 1 58613 test begin: paddle.diag(Tensor([10, 0],"float32"), offset=1, )
Warning: The core code of paddle.diag is too complex.
[paddle error] paddle.diag(Tensor([10, 0],"float32"), offset=1, ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-06-05 15:21:51.765752 GPU 0 58711 test begin: paddle.diag(x=Tensor([0, 3],"float64"), offset=-1, )
Warning: The core code of paddle.diag is too complex.
[paddle error] paddle.diag(x=Tensor([0, 3],"float64"), offset=-1, ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-06-05 15:21:51.775449 GPU 0 58658 test begin: paddle.diag(x=Tensor([2, 0],"float64"), offset=2, )
Warning: The core code of paddle.diag is too complex.
[paddle error] paddle.diag(x=Tensor([2, 0],"float64"), offset=2, ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-06-05 15:21:51.804135 GPU 1 58625 test begin: paddle.diag(x=Tensor([3, 0],"float64"), offset=1, )
Warning: The core code of paddle.diag is too complex.
[paddle error] paddle.diag(x=Tensor([3, 0],"float64"), offset=1, ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-06-05 15:21:51.866437 GPU 1 58615 test begin: paddle.diff(Tensor([0, 4],"float32"), n=1, axis=-1, prepend=None, append=Tensor([0, 3],"float32"), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108133 (unix time) try "date -d @1749108133" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 58615 (TID 0x7f081a723740) from PID 24 ***]


2025-06-05 15:21:51.868140 GPU 1 58590 test begin: paddle.diff(Tensor([0, 4],"float32"), n=1, axis=-1, prepend=Tensor([0, 2],"float32"), append=Tensor([0, 3],"float32"), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108132 (unix time) try "date -d @1749108132" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xa41ad2f0) received by PID 58590 (TID 0x7ff357790740) from PID 18446744072167805680 ***]


2025-06-05 15:21:51.924121 GPU 1 58680 test begin: paddle.diff(Tensor([0, 4],"float32"), n=1, axis=-1, prepend=Tensor([0, 3],"float32"), append=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108134 (unix time) try "date -d @1749108134" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 58680 (TID 0x7fe5fbb41740) from PID 24 ***]


2025-06-05 15:22:04.110570 GPU 0 59125 test begin: paddle.diff(Tensor([0, 4],"float32"), n=2, axis=-1, prepend=None, append=Tensor([0, 4],"float32"), )

2025-06-05 15:22:08.270568 GPU 0 59196 test begin: paddle.diff(Tensor([0, 4],"float32"), n=2, axis=-1, prepend=Tensor([0, 4],"float32"), append=None, )

2025-06-05 15:22:13.357231 GPU 0 58711 test begin: paddle.diff(Tensor([0, 4],"float32"), n=2, axis=-1, prepend=Tensor([0, 4],"float32"), append=Tensor([0, 4],"float32"), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108133 (unix time) try "date -d @1749108133" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xa91d9600) received by PID 58711 (TID 0x7ff106bb4740) from PID 18446744072251872768 ***]


2025-06-05 15:22:13.744244 GPU 0 58658 test begin: paddle.diff(Tensor([2, 0],"float32"), n=1, axis=-1, prepend=None, append=Tensor([2, 0],"float32"), )

2025-06-05 15:22:14.337519 GPU 0 59337 test begin: paddle.diff(Tensor([2, 0],"float32"), n=1, axis=-1, prepend=Tensor([2, 0],"float32"), append=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108156 (unix time) try "date -d @1749108156" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xa459d000) received by PID 59337 (TID 0x7fade9c87740) from PID 18446744072171933696 ***]


2025-06-05 15:22:14.499551 GPU 1 58589 test begin: paddle.diff(Tensor([2, 0],"float32"), n=1, axis=-1, prepend=Tensor([2, 0],"float32"), append=Tensor([2, 0],"float32"), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108135 (unix time) try "date -d @1749108135" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xa7fa3b60) received by PID 58589 (TID 0x7f5fa3468740) from PID 18446744072232778592 ***]


2025-06-05 15:22:14.614726 GPU 1 58613 test begin: paddle.diff(Tensor([2, 0],"float32"), n=2, axis=-1, prepend=None, append=Tensor([2, 0],"float32"), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108134 (unix time) try "date -d @1749108134" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 58613 (TID 0x7ff68e728740) from PID 24 ***]


2025-06-05 15:22:14.751842 GPU 1 58625 test begin: paddle.diff(Tensor([2, 0],"float32"), n=2, axis=-1, prepend=Tensor([2, 0],"float32"), append=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108135 (unix time) try "date -d @1749108135" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 58625 (TID 0x7ffa95f78740) from PID 24 ***]


2025-06-05 15:22:15.108237 GPU 0 59336 test begin: paddle.diff(Tensor([2, 0],"float32"), n=2, axis=-1, prepend=Tensor([2, 0],"float32"), append=Tensor([2, 0],"float32"), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108154 (unix time) try "date -d @1749108154" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xa6ba8a80) received by PID 59336 (TID 0x7f2405f34740) from PID 18446744072211827328 ***]


2025-06-05 15:22:15.272765 GPU 0 59364 test begin: paddle.dist(Tensor([0, 2, 3, 2],"float32"), Tensor([0, 1, 3, 1],"float32"), 2, )
[paddle error] paddle.dist(Tensor([0, 2, 3, 2],"float32"), Tensor([0, 1, 3, 1],"float32"), 2, ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [0, 2, 3, 2].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-06-05 15:22:15.854929 GPU 0 59390 test begin: paddle.dist(Tensor([0, 2, 3, 2],"float32"), Tensor([1, 1, 3, 1],"float32"), 2, )
[paddle error] paddle.dist(Tensor([0, 2, 3, 2],"float32"), Tensor([1, 1, 3, 1],"float32"), 2, ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [0, 2, 3, 2].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-06-05 15:22:15.883850 GPU 0 59422 test begin: paddle.dist(Tensor([0, 2],"float32"), Tensor([0, 2],"float32"), 0, )
Expected a proper Tensor but got None (or an undefined Tensor in C++) for argument #0 'self'
[paddle error] paddle.dist(Tensor([0, 2],"float32"), Tensor([0, 2],"float32"), 0, ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [0, 2].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-06-05 15:22:16.028922 GPU 0 59418 test begin: paddle.dist(Tensor([2, 0, 3, 2],"float32"), Tensor([1, 0, 3, 1],"float32"), 2, )
[paddle error] paddle.dist(Tensor([2, 0, 3, 2],"float32"), Tensor([1, 0, 3, 1],"float32"), 2, ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [2, 0, 3, 2].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-06-05 15:22:16.110409 GPU 0 59384 test begin: paddle.dist(Tensor([2, 0, 3, 2],"float32"), Tensor([1, 1, 3, 1],"float32"), 2, )
[paddle error] paddle.dist(Tensor([2, 0, 3, 2],"float32"), Tensor([1, 1, 3, 1],"float32"), 2, ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [2, 0, 3, 2].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-06-05 15:22:23.379980 GPU 1 59589 test begin: paddle.dist(Tensor([2, 0],"float32"), Tensor([2, 0],"float32"), 0, )
Expected a proper Tensor but got None (or an undefined Tensor in C++) for argument #0 'self'
[paddle error] paddle.dist(Tensor([2, 0],"float32"), Tensor([2, 0],"float32"), 0, ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [2, 0].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-06-05 15:22:23.547971 GPU 1 59578 test begin: paddle.dist(Tensor([2, 2, 0, 2],"float32"), Tensor([1, 1, 0, 1],"float32"), 2, )
[paddle error] paddle.dist(Tensor([2, 2, 0, 2],"float32"), Tensor([1, 1, 0, 1],"float32"), 2, ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [2, 2, 0, 2].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-06-05 15:22:23.672325 GPU 1 59567 test begin: paddle.dist(Tensor([2, 2, 3, 0],"float32"), Tensor([1, 1, 3, 0],"float32"), 2, )
[paddle error] paddle.dist(Tensor([2, 2, 3, 0],"float32"), Tensor([1, 1, 3, 0],"float32"), 2, ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [2, 2, 3, 0].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-06-05 15:22:23.753684 GPU 1 59626 test begin: paddle.dist(Tensor([2, 2, 3, 0],"float32"), Tensor([1, 1, 3, 1],"float32"), 2, )
[paddle error] paddle.dist(Tensor([2, 2, 3, 0],"float32"), Tensor([1, 1, 3, 1],"float32"), 2, ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [2, 2, 3, 0].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-06-05 15:22:23.858071 GPU 1 59692 test begin: paddle.dist(x=Tensor([0, 1, 1, 4, 4],"float64"), y=Tensor([0, 8, 7, 1, 4],"float64"), )
[paddle error] paddle.dist(x=Tensor([0, 1, 1, 4, 4],"float64"), y=Tensor([0, 8, 7, 1, 4],"float64"), ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [0, 1, 1, 4, 4].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-06-05 15:22:23.999609 GPU 1 59756 test begin: paddle.dist(x=Tensor([0, 1, 4, 4],"float64"), y=Tensor([7, 1, 4],"float64"), )
[paddle error] paddle.dist(x=Tensor([0, 1, 4, 4],"float64"), y=Tensor([7, 1, 4],"float64"), ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [0, 1, 4, 4].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-06-05 15:22:24.106247 GPU 0 59681 test begin: paddle.dist(x=Tensor([0, 2],"float64"), y=Tensor([0, 2],"float64"), p=0, )
Expected a proper Tensor but got None (or an undefined Tensor in C++) for argument #0 'self'
[paddle error] paddle.dist(x=Tensor([0, 2],"float64"), y=Tensor([0, 2],"float64"), p=0, ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [0, 2].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-06-05 15:22:24.232107 GPU 1 59792 test begin: paddle.dist(x=Tensor([0, 4, 1, 3],"float64"), y=Tensor([4, 3, 1],"float64"), p=7, )
[paddle error] paddle.dist(x=Tensor([0, 4, 1, 3],"float64"), y=Tensor([4, 3, 1],"float64"), p=7, ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [0, 4, 1, 3].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-06-05 15:22:24.257277 GPU 1 59755 test begin: paddle.dist(x=Tensor([0, 4],"float32"), y=Tensor([0, 4],"float32"), )
[paddle error] paddle.dist(x=Tensor([0, 4],"float32"), y=Tensor([0, 4],"float32"), ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [0, 4].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-06-05 15:22:24.261329 GPU 1 59664 test begin: paddle.dist(x=Tensor([0, 4],"float64"), y=Tensor([0, 4],"float64"), p=1, )
[paddle error] paddle.dist(x=Tensor([0, 4],"float64"), y=Tensor([0, 4],"float64"), p=1, ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [0, 4].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-06-05 15:22:24.483290 GPU 0 59666 test begin: paddle.dist(x=Tensor([0],"float64"), y=Tensor([0],"float64"), )
[paddle error] paddle.dist(x=Tensor([0],"float64"), y=Tensor([0],"float64"), ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [0].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-06-05 15:22:25.708358 GPU 1 60218 test begin: paddle.dist(x=Tensor([10],"float64"), y=Tensor([0, 10],"float64"), )
[paddle error] paddle.dist(x=Tensor([10],"float64"), y=Tensor([0, 10],"float64"), ) 
 (InvalidArgument) The Input(Y) has not been initialized properly. The shape of Input(Y) = [0, 10].
  [Hint: Expected common::product(y_dims) != 0, but received common::product(y_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1377)


2025-06-05 15:22:25.917323 GPU 1 59818 test begin: paddle.dist(x=Tensor([10],"float64"), y=Tensor([0, 10],"float64"), p=4, )
[paddle error] paddle.dist(x=Tensor([10],"float64"), y=Tensor([0, 10],"float64"), p=4, ) 
 (InvalidArgument) The Input(Y) has not been initialized properly. The shape of Input(Y) = [0, 10].
  [Hint: Expected common::product(y_dims) != 0, but received common::product(y_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1377)


2025-06-05 15:22:34.334016 GPU 0 60441 test begin: paddle.dist(x=Tensor([2, 0, 1, 4, 4],"float64"), y=Tensor([2, 0, 7, 1, 4],"float64"), )
[paddle error] paddle.dist(x=Tensor([2, 0, 1, 4, 4],"float64"), y=Tensor([2, 0, 7, 1, 4],"float64"), ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [2, 0, 1, 4, 4].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-06-05 15:22:35.052951 GPU 0 59422 test begin: paddle.dist(x=Tensor([2, 0],"float64"), y=Tensor([2, 0],"float64"), p=0, )
Expected a proper Tensor but got None (or an undefined Tensor in C++) for argument #0 'self'
[paddle error] paddle.dist(x=Tensor([2, 0],"float64"), y=Tensor([2, 0],"float64"), p=0, ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [2, 0].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-06-05 15:22:35.440388 GPU 0 59422 test begin: paddle.dist(x=Tensor([2, 1, 0, 4, 4],"float64"), y=Tensor([2, 8, 0, 1, 4],"float64"), )
[paddle error] paddle.dist(x=Tensor([2, 1, 0, 4, 4],"float64"), y=Tensor([2, 8, 0, 1, 4],"float64"), ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [2, 1, 0, 4, 4].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-06-05 15:22:35.466901 GPU 0 59364 test begin: paddle.dist(x=Tensor([2, 1, 0, 4],"float64"), y=Tensor([7, 1, 4],"float64"), )
[paddle error] paddle.dist(x=Tensor([2, 1, 0, 4],"float64"), y=Tensor([7, 1, 4],"float64"), ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [2, 1, 0, 4].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-06-05 15:22:35.569116 GPU 0 59390 test begin: paddle.dist(x=Tensor([2, 1, 1, 0, 4],"float64"), y=Tensor([2, 8, 7, 0, 4],"float64"), )
[paddle error] paddle.dist(x=Tensor([2, 1, 1, 0, 4],"float64"), y=Tensor([2, 8, 7, 0, 4],"float64"), ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [2, 1, 1, 0, 4].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-06-05 15:22:35.697508 GPU 0 59422 test begin: paddle.dist(x=Tensor([2, 1, 1, 0, 4],"float64"), y=Tensor([2, 8, 7, 1, 4],"float64"), )
[paddle error] paddle.dist(x=Tensor([2, 1, 1, 0, 4],"float64"), y=Tensor([2, 8, 7, 1, 4],"float64"), ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [2, 1, 1, 0, 4].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-06-05 15:22:35.698943 GPU 0 59364 test begin: paddle.dist(x=Tensor([2, 1, 1, 4, 0],"float64"), y=Tensor([2, 8, 7, 1, 0],"float64"), )
[paddle error] paddle.dist(x=Tensor([2, 1, 1, 4, 0],"float64"), y=Tensor([2, 8, 7, 1, 0],"float64"), ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [2, 1, 1, 4, 0].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-06-05 15:22:35.930606 GPU 0 59390 test begin: paddle.dist(x=Tensor([2, 1, 1, 4, 4],"float64"), y=Tensor([2, 0, 7, 1, 4],"float64"), )
[paddle error] paddle.dist(x=Tensor([2, 1, 1, 4, 4],"float64"), y=Tensor([2, 0, 7, 1, 4],"float64"), ) 
 (InvalidArgument) The Input(Y) has not been initialized properly. The shape of Input(Y) = [2, 0, 7, 1, 4].
  [Hint: Expected common::product(y_dims) != 0, but received common::product(y_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1377)


2025-06-05 15:22:36.041510 GPU 0 59364 test begin: paddle.dist(x=Tensor([2, 1, 1, 4, 4],"float64"), y=Tensor([2, 8, 0, 1, 4],"float64"), )
[paddle error] paddle.dist(x=Tensor([2, 1, 1, 4, 4],"float64"), y=Tensor([2, 8, 0, 1, 4],"float64"), ) 
 (InvalidArgument) The Input(Y) has not been initialized properly. The shape of Input(Y) = [2, 8, 0, 1, 4].
  [Hint: Expected common::product(y_dims) != 0, but received common::product(y_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1377)


2025-06-05 15:22:36.153957 GPU 0 60504 test begin: paddle.dist(x=Tensor([2, 1, 4, 4],"float64"), y=Tensor([0, 1, 4],"float64"), )
[paddle error] paddle.dist(x=Tensor([2, 1, 4, 4],"float64"), y=Tensor([0, 1, 4],"float64"), ) 
 (InvalidArgument) The Input(Y) has not been initialized properly. The shape of Input(Y) = [0, 1, 4].
  [Hint: Expected common::product(y_dims) != 0, but received common::product(y_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1377)


2025-06-05 15:22:36.154083 GPU 0 59384 test begin: paddle.dist(x=Tensor([2, 4, 1, 0],"float64"), y=Tensor([4, 3, 1],"float64"), p=7, )
[paddle error] paddle.dist(x=Tensor([2, 4, 1, 0],"float64"), y=Tensor([4, 3, 1],"float64"), p=7, ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [2, 4, 1, 0].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-06-05 15:22:36.158893 GPU 0 59422 test begin: paddle.dist(x=Tensor([2, 4, 1, 3],"float64"), y=Tensor([4, 0, 1],"float64"), p=7, )
[paddle error] paddle.dist(x=Tensor([2, 4, 1, 3],"float64"), y=Tensor([4, 0, 1],"float64"), p=7, ) 
 (InvalidArgument) The Input(Y) has not been initialized properly. The shape of Input(Y) = [4, 0, 1].
  [Hint: Expected common::product(y_dims) != 0, but received common::product(y_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1377)


2025-06-05 15:22:36.316960 GPU 0 59418 test begin: paddle.dist(x=Tensor([4, 0],"float32"), y=Tensor([4, 0],"float32"), )
[paddle error] paddle.dist(x=Tensor([4, 0],"float32"), y=Tensor([4, 0],"float32"), ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [4, 0].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-06-05 15:22:36.349060 GPU 0 59390 test begin: paddle.dist(x=Tensor([4, 0],"float64"), y=Tensor([4, 0],"float64"), p=1, )
[paddle error] paddle.dist(x=Tensor([4, 0],"float64"), y=Tensor([4, 0],"float64"), p=1, ) 
 (InvalidArgument) The Input(X) has not been initialized properly. The shape of Input(X) = [4, 0].
  [Hint: Expected common::product(x_dims) != 0, but received common::product(x_dims):0 == 0:0.] (at ../paddle/phi/infermeta/binary.cc:1371)


2025-06-05 15:22:36.560191 GPU 0 59364 test begin: paddle.dstack(list[Tensor([0, 1, 1, 1],"float64"),Tensor([0, 1, 1, 1],"float64"),Tensor([0, 1, 1, 1],"float64"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108156 (unix time) try "date -d @1749108156" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xa49b1da0) received by PID 59364 (TID 0x7f91c0bec740) from PID 18446744072176213408 ***]


2025-06-05 15:22:36.609366 GPU 0 59390 test begin: paddle.dstack(list[Tensor([0, 1, 1, 1],"float64"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108156 (unix time) try "date -d @1749108156" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 59390 (TID 0x7fe377eba740) from PID 0 ***]


2025-06-05 15:22:36.633874 GPU 0 59384 test begin: paddle.dstack(list[Tensor([0, 1, 1],"float64"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108156 (unix time) try "date -d @1749108156" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 59384 (TID 0x7fe12af52740) from PID 0 ***]


2025-06-05 15:22:36.684211 GPU 0 59422 test begin: paddle.dstack(list[Tensor([0, 1],"float64"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108156 (unix time) try "date -d @1749108156" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 59422 (TID 0x7f55d0d67740) from PID 0 ***]


2025-06-05 15:22:36.732516 GPU 0 59418 test begin: paddle.dstack(list[Tensor([0],"float64"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108156 (unix time) try "date -d @1749108156" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 59418 (TID 0x7efc3b1b7740) from PID 0 ***]


2025-06-05 15:22:41.625467 GPU 1 59578 test begin: paddle.dstack(list[Tensor([1, 0, 1, 1],"float64"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108161 (unix time) try "date -d @1749108161" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 59578 (TID 0x7fc0e3058740) from PID 0 ***]


2025-06-05 15:22:42.270256 GPU 1 59626 test begin: paddle.dstack(list[Tensor([1, 0, 1],"float64"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108162 (unix time) try "date -d @1749108162" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x3740e7d) received by PID 59626 (TID 0x7ff2f5439740) from PID 57937533 ***]


2025-06-05 15:22:42.822915 GPU 1 59589 test begin: paddle.dstack(list[Tensor([1, 0],"float64"),], )

2025-06-05 15:22:42.944304 GPU 1 59567 test begin: paddle.dstack(list[Tensor([1, 1, 0, 1],"float64"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108163 (unix time) try "date -d @1749108163" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 59567 (TID 0x7f61fc14e740) from PID 0 ***]


2025-06-05 15:22:43.102321 GPU 1 59692 test begin: paddle.dstack(list[Tensor([1, 1, 0],"float64"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108163 (unix time) try "date -d @1749108163" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 59692 (TID 0x7fde9b840740) from PID 0 ***]


2025-06-05 15:22:43.383765 GPU 1 59664 test begin: paddle.dstack(list[Tensor([1, 1, 1, 0],"float64"),], )

2025-06-05 15:22:46.247002 GPU 0 59681 test begin: paddle.hstack(list[Tensor([0, 1, 1, 1],"float64"),Tensor([0, 1, 1, 1],"float64"),Tensor([0, 1, 1, 1],"float64"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108166 (unix time) try "date -d @1749108166" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f67255c6010) received by PID 59681 (TID 0x7f67261a4740) from PID 626810896 ***]


2025-06-05 15:22:46.374505 GPU 1 59756 test begin: paddle.hstack(list[Tensor([0, 1, 1, 1],"float64"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108166 (unix time) try "date -d @1749108166" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 59756 (TID 0x7f64f37c6740) from PID 0 ***]


2025-06-05 15:22:46.423357 GPU 1 59818 test begin: paddle.hstack(list[Tensor([0, 1, 1],"float64"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108166 (unix time) try "date -d @1749108166" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 59818 (TID 0x7f4c854a5740) from PID 0 ***]


2025-06-05 15:22:46.532006 GPU 0 59666 test begin: paddle.hstack(list[Tensor([0, 1],"float64"),], )

2025-06-05 15:22:46.567047 GPU 1 59755 test begin: paddle.hstack(list[Tensor([1, 0, 1, 1],"float64"),Tensor([1, 0, 1, 1],"float64"),Tensor([1, 0, 1, 1],"float64"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108166 (unix time) try "date -d @1749108166" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xa79dd7f0) received by PID 59755 (TID 0x7ff0f22fb740) from PID 18446744072226723824 ***]


2025-06-05 15:22:46.581501 GPU 1 60218 test begin: paddle.hstack(list[Tensor([1, 0, 1, 1],"float64"),], )

2025-06-05 15:22:46.597141 GPU 1 59792 test begin: paddle.hstack(list[Tensor([1, 0, 1],"float64"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108166 (unix time) try "date -d @1749108166" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 59792 (TID 0x7fbb4c6a0740) from PID 0 ***]


2025-06-05 15:22:52.283676 GPU 1 61305 test begin: paddle.hstack(list[Tensor([1, 0],"float64"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108190 (unix time) try "date -d @1749108190" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 61305 (TID 0x7fd5b952d740) from PID 0 ***]


2025-06-05 15:22:52.342676 GPU 1 61261 test begin: paddle.hstack(list[Tensor([1, 1, 0, 1],"float64"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108192 (unix time) try "date -d @1749108192" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f484e0e2a70) received by PID 61261 (TID 0x7f4a35e64740) from PID 1309551216 ***]


2025-06-05 15:22:52.534147 GPU 1 61206 test begin: paddle.hstack(list[Tensor([1, 1, 0],"float64"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108192 (unix time) try "date -d @1749108192" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 61206 (TID 0x7f365d2b8740) from PID 0 ***]


2025-06-05 15:22:53.063206 GPU 1 61324 test begin: paddle.hstack(list[Tensor([1, 1, 1, 0],"float64"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108193 (unix time) try "date -d @1749108193" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 61324 (TID 0x7fd67a9dd740) from PID 0 ***]


2025-06-05 15:22:53.974164 GPU 0 60441 test begin: paddle.inner(x=Tensor([0],"float64"), y=Tensor([0],"float64"), )
[paddle error] paddle.inner(x=Tensor([0],"float64"), y=Tensor([0],"float64"), ) 
 (InvalidArgument) can not reshape 0 to -1, 0, because the unspecified dimension 0 can be any number and is ambiguous
  [Hint: Expected unk_dim_idx == -1, but received unk_dim_idx:0 != -1:-1.] (at ../paddle/phi/infermeta/unary.cc:2209)


2025-06-05 15:22:54.030168 GPU 1 61245 test begin: paddle.inner(x=Tensor([2, 5, 3, 0],"float64"), y=Tensor([3, 2, 5, 0],"float64"), )
[paddle error] paddle.inner(x=Tensor([2, 5, 3, 0],"float64"), y=Tensor([3, 2, 5, 0],"float64"), ) 
 (InvalidArgument) can not reshape 2, 5, 3, 0 to -1, 0, because the unspecified dimension 0 can be any number and is ambiguous
  [Hint: Expected unk_dim_idx == -1, but received unk_dim_idx:0 != -1:-1.] (at ../paddle/phi/infermeta/unary.cc:2209)


2025-06-05 15:22:54.666063 GPU 1 61438 test begin: paddle.inner(x=Tensor([3, 0],"float64"), y=Tensor([5, 0],"float64"), )
[paddle error] paddle.inner(x=Tensor([3, 0],"float64"), y=Tensor([5, 0],"float64"), ) 
 (InvalidArgument) can not reshape 3, 0 to -1, 0, because the unspecified dimension 0 can be any number and is ambiguous
  [Hint: Expected unk_dim_idx == -1, but received unk_dim_idx:0 != -1:-1.] (at ../paddle/phi/infermeta/unary.cc:2209)


2025-06-05 15:22:55.554152 GPU 1 61490 test begin: paddle.inner(x=Tensor([4, 0],"float32"), y=Tensor([4, 0],"float32"), )
[paddle error] paddle.inner(x=Tensor([4, 0],"float32"), y=Tensor([4, 0],"float32"), ) 
 (InvalidArgument) can not reshape 4, 0 to -1, 0, because the unspecified dimension 0 can be any number and is ambiguous
  [Hint: Expected unk_dim_idx == -1, but received unk_dim_idx:0 != -1:-1.] (at ../paddle/phi/infermeta/unary.cc:2209)


2025-06-05 15:22:55.766937 GPU 0 61479 test begin: paddle.inner(x=Tensor([5, 3, 0],"float64"), y=Tensor([2, 5, 0],"float64"), )
[paddle error] paddle.inner(x=Tensor([5, 3, 0],"float64"), y=Tensor([2, 5, 0],"float64"), ) 
 (InvalidArgument) can not reshape 5, 3, 0 to -1, 0, because the unspecified dimension 0 can be any number and is ambiguous
  [Hint: Expected unk_dim_idx == -1, but received unk_dim_idx:0 != -1:-1.] (at ../paddle/phi/infermeta/unary.cc:2209)


2025-06-05 15:23:02.615162 GPU 0 60441 test begin: paddle.kron(Tensor([2, 2],"complex128"), Tensor([0, 2, 3],"float64"), )
[paddle error] paddle.kron(Tensor([2, 2],"complex128"), Tensor([0, 2, 3],"float64"), ) 
 (InvalidArgument) The type of data we are trying to retrieve (complex128) does not match the type of data (float64) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():11 != phi::CppTypeToDataType<T>::Type():13.] (at ../paddle/phi/core/dense_tensor.cc:153)


2025-06-05 15:23:02.913776 GPU 0 60654 test begin: paddle.kron(Tensor([2, 2],"complex128"), Tensor([2, 0, 3],"float64"), )
[paddle error] paddle.kron(Tensor([2, 2],"complex128"), Tensor([2, 0, 3],"float64"), ) 
 (InvalidArgument) The type of data we are trying to retrieve (complex128) does not match the type of data (float64) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():11 != phi::CppTypeToDataType<T>::Type():13.] (at ../paddle/phi/core/dense_tensor.cc:153)


2025-06-05 15:23:03.009554 GPU 0 60504 test begin: paddle.kron(Tensor([2, 2],"complex128"), Tensor([2, 2, 0],"float64"), )
[paddle error] paddle.kron(Tensor([2, 2],"complex128"), Tensor([2, 2, 0],"float64"), ) 
 (InvalidArgument) The type of data we are trying to retrieve (complex128) does not match the type of data (float64) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():11 != phi::CppTypeToDataType<T>::Type():13.] (at ../paddle/phi/core/dense_tensor.cc:153)


2025-06-05 15:23:03.280009 GPU 0 60441 test begin: paddle.lerp(Tensor([0, 1, 1, 1],"float32"), Tensor([0, 3, 8, 8],"float32"), 0.3, )
[paddle error] paddle.lerp(Tensor([0, 1, 1, 1],"float32"), Tensor([0, 3, 8, 8],"float32"), 0.3, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:03.497131 GPU 0 60504 test begin: paddle.lerp(Tensor([0, 1, 1],"float32"), Tensor([0, 28, 28],"float32"), 0.36, )
[paddle error] paddle.lerp(Tensor([0, 1, 1],"float32"), Tensor([0, 28, 28],"float32"), 0.36, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:03.711339 GPU 0 60654 test begin: paddle.lerp(Tensor([0, 1, 1],"float32"), Tensor([0, 8, 8],"float32"), 0.3, )
[paddle error] paddle.lerp(Tensor([0, 1, 1],"float32"), Tensor([0, 8, 8],"float32"), 0.3, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:03.815219 GPU 0 60441 test begin: paddle.lerp(Tensor([0, 1, 8, 8],"float32"), Tensor([0, 3, 8, 8],"float32"), 1.1, )
[paddle error] paddle.lerp(Tensor([0, 1, 8, 8],"float32"), Tensor([0, 3, 8, 8],"float32"), 1.1, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:03.890063 GPU 0 60773 test begin: paddle.lerp(Tensor([0, 1],"float32"), Tensor([0, 1],"float32"), Tensor([0, 1],"float32"), )
[paddle error] paddle.lerp(Tensor([0, 1],"float32"), Tensor([0, 1],"float32"), Tensor([0, 1],"float32"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:04.030588 GPU 0 60504 test begin: paddle.lerp(Tensor([0, 28, 28],"float32"), Tensor([0, 28, 28],"float32"), 1.0, )
[paddle error] paddle.lerp(Tensor([0, 28, 28],"float32"), Tensor([0, 28, 28],"float32"), 1.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:04.035263 GPU 0 60654 test begin: paddle.lerp(Tensor([0, 28, 28],"float32"), Tensor([0, 28, 28],"float32"), 1.2, )
[paddle error] paddle.lerp(Tensor([0, 28, 28],"float32"), Tensor([0, 28, 28],"float32"), 1.2, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:04.217786 GPU 0 60714 test begin: paddle.lerp(Tensor([0, 3, 3],"float32"), Tensor([0, 3, 3],"float32"), Tensor([0, 3, 3],"float32"), )
[paddle error] paddle.lerp(Tensor([0, 3, 3],"float32"), Tensor([0, 3, 3],"float32"), Tensor([0, 3, 3],"float32"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:04.417636 GPU 0 60654 test begin: paddle.lerp(Tensor([0, 3, 3],"float32"), Tensor([1, 3, 3],"float32"), Tensor([1, 3, 3],"float32"), )
[paddle error] paddle.lerp(Tensor([0, 3, 3],"float32"), Tensor([1, 3, 3],"float32"), Tensor([1, 3, 3],"float32"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:04.429754 GPU 0 60441 test begin: paddle.lerp(Tensor([0, 3, 3],"float64"), Tensor([0, 3, 3],"float64"), Tensor([0, 3, 3],"float64"), )
[paddle error] paddle.lerp(Tensor([0, 3, 3],"float64"), Tensor([0, 3, 3],"float64"), Tensor([0, 3, 3],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:04.513926 GPU 0 60760 test begin: paddle.lerp(Tensor([0, 3, 3],"float64"), Tensor([1, 3, 3],"float64"), Tensor([1, 3, 3],"float64"), )
[paddle error] paddle.lerp(Tensor([0, 3, 3],"float64"), Tensor([1, 3, 3],"float64"), Tensor([1, 3, 3],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:04.660519 GPU 0 60504 test begin: paddle.lerp(Tensor([0, 3, 8, 8],"float32"), Tensor([0, 3, 8, 8],"float32"), 2.1, )
[paddle error] paddle.lerp(Tensor([0, 3, 8, 8],"float32"), Tensor([0, 3, 8, 8],"float32"), 2.1, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:04.677183 GPU 0 60773 test begin: paddle.lerp(Tensor([0, 3],"float64"), Tensor([0, 3],"float64"), Tensor([0, 3],"float64"), )
[paddle error] paddle.lerp(Tensor([0, 3],"float64"), Tensor([0, 3],"float64"), Tensor([0, 3],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:04.713715 GPU 0 60749 test begin: paddle.lerp(Tensor([0, 3],"float64"), Tensor([1, 3],"float64"), Tensor([1, 3],"float64"), )
[paddle error] paddle.lerp(Tensor([0, 3],"float64"), Tensor([1, 3],"float64"), Tensor([1, 3],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:04.721981 GPU 0 60803 test begin: paddle.lerp(Tensor([0, 6, 3, 1, 2, 5],"float64"), Tensor([0, 6, 3, 1, 2, 5],"float64"), Tensor([0, 6, 3, 1, 2, 5],"float64"), )
[paddle error] paddle.lerp(Tensor([0, 6, 3, 1, 2, 5],"float64"), Tensor([0, 6, 3, 1, 2, 5],"float64"), Tensor([0, 6, 3, 1, 2, 5],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:04.735433 GPU 0 60654 test begin: paddle.lerp(Tensor([0, 6, 3, 4, 1, 5],"float64"), Tensor([0, 6, 3, 4, 1, 5],"float64"), Tensor([0, 6, 3, 4, 1, 5],"float64"), )
[paddle error] paddle.lerp(Tensor([0, 6, 3, 4, 1, 5],"float64"), Tensor([0, 6, 3, 4, 1, 5],"float64"), Tensor([0, 6, 3, 4, 1, 5],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:04.887664 GPU 0 60804 test begin: paddle.lerp(Tensor([0, 8, 8],"float32"), Tensor([0, 8, 8],"float32"), 1.1, )
[paddle error] paddle.lerp(Tensor([0, 8, 8],"float32"), Tensor([0, 8, 8],"float32"), 1.1, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:04.919769 GPU 0 60714 test begin: paddle.lerp(Tensor([0, 8, 8],"float32"), Tensor([0, 8, 8],"float32"), 2.1, )
[paddle error] paddle.lerp(Tensor([0, 8, 8],"float32"), Tensor([0, 8, 8],"float32"), 2.1, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:04.981723 GPU 0 60441 test begin: paddle.lerp(Tensor([0],"float32"), Tensor([0],"float32"), Tensor([0],"float32"), )
[paddle error] paddle.lerp(Tensor([0],"float32"), Tensor([0],"float32"), Tensor([0],"float32"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:05.006386 GPU 0 60773 test begin: paddle.lerp(Tensor([0],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), )
[paddle error] paddle.lerp(Tensor([0],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:05.008365 GPU 0 60654 test begin: paddle.lerp(Tensor([0],"float64"), Tensor([0],"float64"), Tensor([0],"float64"), )
[paddle error] paddle.lerp(Tensor([0],"float64"), Tensor([0],"float64"), Tensor([0],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:05.234381 GPU 0 60504 test begin: paddle.lerp(Tensor([0],"float64"), Tensor([1],"float64"), Tensor([1],"float64"), )
[paddle error] paddle.lerp(Tensor([0],"float64"), Tensor([1],"float64"), Tensor([1],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:05.402716 GPU 0 60654 test begin: paddle.lerp(Tensor([1, 0, 1],"float32"), Tensor([3, 0, 28],"float32"), 0.36, )
[paddle error] paddle.lerp(Tensor([1, 0, 1],"float32"), Tensor([3, 0, 28],"float32"), 0.36, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:05.414599 GPU 0 60803 test begin: paddle.lerp(Tensor([1, 0, 1],"float32"), Tensor([3, 0, 8],"float32"), 0.3, )
[paddle error] paddle.lerp(Tensor([1, 0, 1],"float32"), Tensor([3, 0, 8],"float32"), 0.3, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:05.679275 GPU 0 60773 test begin: paddle.lerp(Tensor([1, 0, 28],"float32"), Tensor([3, 0, 28],"float32"), 1.0, )
[paddle error] paddle.lerp(Tensor([1, 0, 28],"float32"), Tensor([3, 0, 28],"float32"), 1.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:05.686229 GPU 0 60760 test begin: paddle.lerp(Tensor([1, 0, 3],"float32"), Tensor([1, 0, 3],"float32"), Tensor([1, 0, 3],"float32"), )
[paddle error] paddle.lerp(Tensor([1, 0, 3],"float32"), Tensor([1, 0, 3],"float32"), Tensor([1, 0, 3],"float32"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:05.795941 GPU 0 60714 test begin: paddle.lerp(Tensor([1, 0, 3],"float64"), Tensor([1, 0, 3],"float64"), Tensor([1, 0, 3],"float64"), )
[paddle error] paddle.lerp(Tensor([1, 0, 3],"float64"), Tensor([1, 0, 3],"float64"), Tensor([1, 0, 3],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:05.798003 GPU 0 60441 test begin: paddle.lerp(Tensor([1, 0, 8],"float32"), Tensor([3, 0, 8],"float32"), 1.1, )
[paddle error] paddle.lerp(Tensor([1, 0, 8],"float32"), Tensor([3, 0, 8],"float32"), 1.1, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:05.981459 GPU 0 60654 test begin: paddle.lerp(Tensor([1, 0],"float64"), Tensor([1, 0],"float64"), Tensor([1, 0],"float64"), )
[paddle error] paddle.lerp(Tensor([1, 0],"float64"), Tensor([1, 0],"float64"), Tensor([1, 0],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:05.987926 GPU 0 60803 test begin: paddle.lerp(Tensor([1, 1, 0],"float32"), Tensor([3, 28, 0],"float32"), 0.36, )
[paddle error] paddle.lerp(Tensor([1, 1, 0],"float32"), Tensor([3, 28, 0],"float32"), 0.36, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:06.101335 GPU 0 60749 test begin: paddle.lerp(Tensor([1, 1, 0],"float32"), Tensor([3, 8, 0],"float32"), 0.3, )
[paddle error] paddle.lerp(Tensor([1, 1, 0],"float32"), Tensor([3, 8, 0],"float32"), 0.3, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:06.206778 GPU 0 60760 test begin: paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([0, 28, 28],"float32"), 0.36, )
[paddle error] paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([0, 28, 28],"float32"), 0.36, ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:91)


2025-06-05 15:23:06.213997 GPU 0 60504 test begin: paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([0, 8, 8],"float32"), 0.3, )
[paddle error] paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([0, 8, 8],"float32"), 0.3, ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:91)


2025-06-05 15:23:06.222354 GPU 0 60654 test begin: paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 0, 28],"float32"), 0.36, )
[paddle error] paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 0, 28],"float32"), 0.36, ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:91)


2025-06-05 15:23:06.235551 GPU 0 60714 test begin: paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 0, 8],"float32"), 0.3, )
[paddle error] paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 0, 8],"float32"), 0.3, ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:91)


2025-06-05 15:23:06.241058 GPU 0 60803 test begin: paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 28, 0],"float32"), 0.36, )
[paddle error] paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 28, 0],"float32"), 0.36, ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:91)


2025-06-05 15:23:06.243022 GPU 0 60773 test begin: paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 8, 0],"float32"), 0.3, )
[paddle error] paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 8, 0],"float32"), 0.3, ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:91)


2025-06-05 15:23:06.441177 GPU 0 60441 test begin: paddle.lerp(Tensor([1, 28, 0],"float32"), Tensor([3, 28, 0],"float32"), 1.0, )
[paddle error] paddle.lerp(Tensor([1, 28, 0],"float32"), Tensor([3, 28, 0],"float32"), 1.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:06.447325 GPU 0 60804 test begin: paddle.lerp(Tensor([1, 28, 28],"float32"), Tensor([0, 28, 28],"float32"), 1.0, )
[paddle error] paddle.lerp(Tensor([1, 28, 28],"float32"), Tensor([0, 28, 28],"float32"), 1.0, ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:91)


2025-06-05 15:23:06.666993 GPU 0 60749 test begin: paddle.lerp(Tensor([1, 3, 0],"float32"), Tensor([1, 3, 0],"float32"), Tensor([1, 3, 0],"float32"), )
[paddle error] paddle.lerp(Tensor([1, 3, 0],"float32"), Tensor([1, 3, 0],"float32"), Tensor([1, 3, 0],"float32"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:06.706808 GPU 0 60803 test begin: paddle.lerp(Tensor([1, 3, 0],"float64"), Tensor([1, 3, 0],"float64"), Tensor([1, 3, 0],"float64"), )
[paddle error] paddle.lerp(Tensor([1, 3, 0],"float64"), Tensor([1, 3, 0],"float64"), Tensor([1, 3, 0],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:06.724666 GPU 0 60654 test begin: paddle.lerp(Tensor([1, 3, 3],"float32"), Tensor([0, 3, 3],"float32"), Tensor([1, 3, 3],"float32"), )
[paddle error] paddle.lerp(Tensor([1, 3, 3],"float32"), Tensor([0, 3, 3],"float32"), Tensor([1, 3, 3],"float32"), ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:91)


2025-06-05 15:23:06.744906 GPU 0 60760 test begin: paddle.lerp(Tensor([1, 3, 3],"float32"), Tensor([1, 3, 3],"float32"), Tensor([0, 3, 3],"float32"), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_lerp(_object*, _object*, _object*)
1   lerp_ad_func(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&)
2   paddle::experimental::lerp(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&)
3   Eigen::TensorEvaluator<Eigen::TensorBroadcastingOp<Eigen::DSizes<int, 3> const, Eigen::TensorMap<Eigen::Tensor<float const, 3, 1, long>, 0, Eigen::MakePointer> const> const, Eigen::DefaultDevice>::BroadcastBlock(Eigen::DSizes<long, 3> const&, Eigen::DSizes<long, 3> const&, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 6> const&, long, long, Eigen::internal::TensorBlockScratchAllocator<Eigen::DefaultDevice>&, float*, float**, unsigned long*) const

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108186 (unix time) try "date -d @1749108186" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f74b20d9f38) received by PID 60760 (TID 0x7f75b8a7e740) from PID 18446744072401821496 ***]


2025-06-05 15:23:06.797270 GPU 0 60714 test begin: paddle.lerp(Tensor([1, 3, 3],"float64"), Tensor([0, 3, 3],"float64"), Tensor([1, 3, 3],"float64"), )
[paddle error] paddle.lerp(Tensor([1, 3, 3],"float64"), Tensor([0, 3, 3],"float64"), Tensor([1, 3, 3],"float64"), ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:91)


2025-06-05 15:23:06.832892 GPU 0 60804 test begin: paddle.lerp(Tensor([1, 3, 3],"float64"), Tensor([1, 3, 3],"float64"), Tensor([0, 3, 3],"float64"), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_lerp(_object*, _object*, _object*)
1   lerp_ad_func(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&)
2   paddle::experimental::lerp(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&)
3   Eigen::TensorEvaluator<Eigen::TensorBroadcastingOp<Eigen::DSizes<int, 3> const, Eigen::TensorMap<Eigen::Tensor<double const, 3, 1, long>, 0, Eigen::MakePointer> const> const, Eigen::DefaultDevice>::BroadcastBlock(Eigen::DSizes<long, 3> const&, Eigen::DSizes<long, 3> const&, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 6> const&, long, long, Eigen::internal::TensorBlockScratchAllocator<Eigen::DefaultDevice>&, double*, double**, unsigned long*) const

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108186 (unix time) try "date -d @1749108186" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f9e4a311194) received by PID 60804 (TID 0x7f9f50c9b740) from PID 1244729748 ***]


2025-06-05 15:23:06.909952 GPU 0 60504 test begin: paddle.lerp(Tensor([1, 3],"float64"), Tensor([0, 3],"float64"), Tensor([1, 3],"float64"), )
[paddle error] paddle.lerp(Tensor([1, 3],"float64"), Tensor([0, 3],"float64"), Tensor([1, 3],"float64"), ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:91)


2025-06-05 15:23:06.930080 GPU 0 60773 test begin: paddle.lerp(Tensor([1, 3],"float64"), Tensor([1, 3],"float64"), Tensor([0, 3],"float64"), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_lerp(_object*, _object*, _object*)
1   lerp_ad_func(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&)
2   paddle::experimental::lerp(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&)
3   Eigen::TensorEvaluator<Eigen::TensorBroadcastingOp<Eigen::DSizes<int, 2> const, Eigen::TensorMap<Eigen::Tensor<double const, 2, 1, long>, 0, Eigen::MakePointer> const> const, Eigen::DefaultDevice>::BroadcastBlock(Eigen::DSizes<long, 2> const&, Eigen::DSizes<long, 2> const&, Eigen::DSizes<long, 4> const&, Eigen::DSizes<long, 4> const&, Eigen::DSizes<long, 4> const&, long, long, Eigen::internal::TensorBlockScratchAllocator<Eigen::DefaultDevice>&, double*, double**, unsigned long*) const

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108187 (unix time) try "date -d @1749108187" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f67accf64ad) received by PID 60773 (TID 0x7f68b4317740) from PID 18446744072313857197 ***]


2025-06-05 15:23:06.970866 GPU 0 60749 test begin: paddle.lerp(Tensor([1, 8, 0],"float32"), Tensor([3, 8, 0],"float32"), 1.1, )
[paddle error] paddle.lerp(Tensor([1, 8, 0],"float32"), Tensor([3, 8, 0],"float32"), 1.1, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:07.017147 GPU 0 60441 test begin: paddle.lerp(Tensor([1, 8, 8],"float32"), Tensor([0, 8, 8],"float32"), 1.1, )
[paddle error] paddle.lerp(Tensor([1, 8, 8],"float32"), Tensor([0, 8, 8],"float32"), 1.1, ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:91)


2025-06-05 15:23:07.022487 GPU 0 60654 test begin: paddle.lerp(Tensor([10, 1, 0, 5, 5],"float32"), Tensor([10, 5, 1, 5, 5],"float32"), Tensor([1],"float32"), )
[paddle error] paddle.lerp(Tensor([10, 1, 0, 5, 5],"float32"), Tensor([10, 5, 1, 5, 5],"float32"), Tensor([1],"float32"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:07.129008 GPU 0 60803 test begin: paddle.lerp(Tensor([10, 1, 10, 5, 5],"float32"), Tensor([10, 0, 1, 5, 5],"float32"), Tensor([1],"float32"), )
[paddle error] paddle.lerp(Tensor([10, 1, 10, 5, 5],"float32"), Tensor([10, 0, 1, 5, 5],"float32"), Tensor([1],"float32"), ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:91)


2025-06-05 15:23:07.141906 GPU 0 60714 test begin: paddle.lerp(Tensor([10, 5, 10, 1, 0],"float32"), Tensor([10, 5, 10, 5, 1],"float32"), Tensor([1],"float32"), )
[paddle error] paddle.lerp(Tensor([10, 5, 10, 1, 0],"float32"), Tensor([10, 5, 10, 5, 1],"float32"), Tensor([1],"float32"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:07.253011 GPU 0 60654 test begin: paddle.lerp(Tensor([10, 5, 10, 1, 5],"float32"), Tensor([10, 5, 10, 0, 1],"float32"), Tensor([1],"float32"), )
[paddle error] paddle.lerp(Tensor([10, 5, 10, 1, 5],"float32"), Tensor([10, 5, 10, 0, 1],"float32"), Tensor([1],"float32"), ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:91)


2025-06-05 15:23:07.264616 GPU 0 60749 test begin: paddle.lerp(Tensor([1],"float32"), Tensor([0],"float32"), Tensor([1],"float32"), )
[paddle error] paddle.lerp(Tensor([1],"float32"), Tensor([0],"float32"), Tensor([1],"float32"), ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:91)


2025-06-05 15:23:07.389217 GPU 0 60803 test begin: paddle.lerp(Tensor([1],"float32"), Tensor([1],"float32"), Tensor([0],"float32"), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_lerp(_object*, _object*, _object*)
1   lerp_ad_func(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&)
2   paddle::experimental::lerp(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&)
3   void phi::LerpKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor*)
4   Eigen::TensorEvaluator<Eigen::TensorBroadcastingOp<Eigen::DSizes<int, 1> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer> const> const, Eigen::DefaultDevice>::BroadcastBlock(Eigen::DSizes<long, 1> const&, Eigen::DSizes<long, 1> const&, Eigen::DSizes<long, 2> const&, Eigen::DSizes<long, 2> const&, Eigen::DSizes<long, 2> const&, long, long, Eigen::internal::TensorBlockScratchAllocator<Eigen::DefaultDevice>&, float*, float**, unsigned long*) const

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108187 (unix time) try "date -d @1749108187" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fec16bc38eb) received by PID 60803 (TID 0x7fed1e3ca740) from PID 381434091 ***]


2025-06-05 15:23:07.390368 GPU 0 60441 test begin: paddle.lerp(Tensor([1],"float64"), Tensor([0],"float64"), Tensor([1],"float64"), )
[paddle error] paddle.lerp(Tensor([1],"float64"), Tensor([0],"float64"), Tensor([1],"float64"), ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:91)


2025-06-05 15:23:07.409076 GPU 0 60504 test begin: paddle.lerp(Tensor([1],"float64"), Tensor([1],"float64"), Tensor([0],"float64"), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_lerp(_object*, _object*, _object*)
1   lerp_ad_func(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&)
2   paddle::experimental::lerp(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&)
3   void phi::LerpKernel<double, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor*)
4   Eigen::TensorEvaluator<Eigen::TensorBroadcastingOp<Eigen::DSizes<int, 1> const, Eigen::TensorMap<Eigen::Tensor<double const, 1, 1, long>, 0, Eigen::MakePointer> const> const, Eigen::DefaultDevice>::BroadcastBlock(Eigen::DSizes<long, 1> const&, Eigen::DSizes<long, 1> const&, Eigen::DSizes<long, 2> const&, Eigen::DSizes<long, 2> const&, Eigen::DSizes<long, 2> const&, long, long, Eigen::internal::TensorBlockScratchAllocator<Eigen::DefaultDevice>&, double*, double**, unsigned long*) const

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108187 (unix time) try "date -d @1749108187" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7efb25549e22) received by PID 60504 (TID 0x7efc2cd4e740) from PID 626302498 ***]


2025-06-05 15:23:07.409845 GPU 0 60714 test begin: paddle.lerp(Tensor([2, 0, 1, 1],"float32"), Tensor([2, 0, 8, 8],"float32"), 0.3, )
[paddle error] paddle.lerp(Tensor([2, 0, 1, 1],"float32"), Tensor([2, 0, 8, 8],"float32"), 0.3, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:07.491790 GPU 0 60654 test begin: paddle.lerp(Tensor([2, 0, 5],"float32"), Tensor([3, 2, 1, 5],"float32"), 0.5, )
[paddle error] paddle.lerp(Tensor([2, 0, 5],"float32"), Tensor([3, 2, 1, 5],"float32"), 0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:07.601568 GPU 0 60749 test begin: paddle.lerp(Tensor([2, 0, 8, 8],"float32"), Tensor([2, 0, 8, 8],"float32"), 1.1, )
[paddle error] paddle.lerp(Tensor([2, 0, 8, 8],"float32"), Tensor([2, 0, 8, 8],"float32"), 1.1, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:07.678755 GPU 0 60714 test begin: paddle.lerp(Tensor([2, 0, 8, 8],"float32"), Tensor([2, 0, 8, 8],"float32"), 2.1, )
[paddle error] paddle.lerp(Tensor([2, 0, 8, 8],"float32"), Tensor([2, 0, 8, 8],"float32"), 2.1, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:07.722990 GPU 0 60441 test begin: paddle.lerp(Tensor([2, 0],"float32"), Tensor([2, 0],"float32"), Tensor([2, 0],"float32"), )
[paddle error] paddle.lerp(Tensor([2, 0],"float32"), Tensor([2, 0],"float32"), Tensor([2, 0],"float32"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:07.849583 GPU 0 60654 test begin: paddle.lerp(Tensor([2, 0],"float32"), Tensor([2, 1],"float32"), Tensor([2, 1],"float32"), )
[paddle error] paddle.lerp(Tensor([2, 0],"float32"), Tensor([2, 1],"float32"), Tensor([2, 1],"float32"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:07.852481 GPU 0 60749 test begin: paddle.lerp(Tensor([2, 1, 0, 1],"float32"), Tensor([2, 3, 0, 8],"float32"), 0.3, )
[paddle error] paddle.lerp(Tensor([2, 1, 0, 1],"float32"), Tensor([2, 3, 0, 8],"float32"), 0.3, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:07.965897 GPU 0 60441 test begin: paddle.lerp(Tensor([2, 1, 0, 8],"float32"), Tensor([2, 3, 0, 8],"float32"), 1.1, )
[paddle error] paddle.lerp(Tensor([2, 1, 0, 8],"float32"), Tensor([2, 3, 0, 8],"float32"), 1.1, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:07.978161 GPU 0 60714 test begin: paddle.lerp(Tensor([2, 1, 1, 0],"float32"), Tensor([2, 3, 8, 0],"float32"), 0.3, )
[paddle error] paddle.lerp(Tensor([2, 1, 1, 0],"float32"), Tensor([2, 3, 8, 0],"float32"), 0.3, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:08.350574 GPU 0 60749 test begin: paddle.lerp(Tensor([2, 1, 1, 1],"float32"), Tensor([2, 0, 8, 8],"float32"), 0.3, )
[paddle error] paddle.lerp(Tensor([2, 1, 1, 1],"float32"), Tensor([2, 0, 8, 8],"float32"), 0.3, ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:91)


2025-06-05 15:23:08.365345 GPU 0 60441 test begin: paddle.lerp(Tensor([2, 1, 1, 1],"float32"), Tensor([2, 3, 0, 8],"float32"), 0.3, )
[paddle error] paddle.lerp(Tensor([2, 1, 1, 1],"float32"), Tensor([2, 3, 0, 8],"float32"), 0.3, ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:91)


2025-06-05 15:23:08.401817 GPU 0 60654 test begin: paddle.lerp(Tensor([2, 1, 1, 1],"float32"), Tensor([2, 3, 8, 0],"float32"), 0.3, )
[paddle error] paddle.lerp(Tensor([2, 1, 1, 1],"float32"), Tensor([2, 3, 8, 0],"float32"), 0.3, ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:91)


2025-06-05 15:23:08.721634 GPU 0 60714 test begin: paddle.lerp(Tensor([2, 1, 8, 0],"float32"), Tensor([2, 3, 8, 0],"float32"), 1.1, )
[paddle error] paddle.lerp(Tensor([2, 1, 8, 0],"float32"), Tensor([2, 3, 8, 0],"float32"), 1.1, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:08.758014 GPU 0 60441 test begin: paddle.lerp(Tensor([2, 1, 8, 8],"float32"), Tensor([2, 0, 8, 8],"float32"), 1.1, )
[paddle error] paddle.lerp(Tensor([2, 1, 8, 8],"float32"), Tensor([2, 0, 8, 8],"float32"), 1.1, ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:91)


2025-06-05 15:23:08.768122 GPU 0 60654 test begin: paddle.lerp(Tensor([2, 1],"float32"), Tensor([2, 0],"float32"), Tensor([2, 1],"float32"), )
[paddle error] paddle.lerp(Tensor([2, 1],"float32"), Tensor([2, 0],"float32"), Tensor([2, 1],"float32"), ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:91)


2025-06-05 15:23:08.780731 GPU 0 60749 test begin: paddle.lerp(Tensor([2, 1],"float32"), Tensor([2, 1],"float32"), Tensor([2, 0],"float32"), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_lerp(_object*, _object*, _object*)
1   lerp_ad_func(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&)
2   paddle::experimental::lerp(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&)
3   Eigen::TensorEvaluator<Eigen::TensorBroadcastingOp<Eigen::DSizes<int, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 0, Eigen::MakePointer> const> const, Eigen::DefaultDevice>::BroadcastBlock(Eigen::DSizes<long, 2> const&, Eigen::DSizes<long, 2> const&, Eigen::DSizes<long, 4> const&, Eigen::DSizes<long, 4> const&, Eigen::DSizes<long, 4> const&, long, long, Eigen::internal::TensorBlockScratchAllocator<Eigen::DefaultDevice>&, float*, float**, unsigned long*) const

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108188 (unix time) try "date -d @1749108188" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f9aea4250b5) received by PID 60749 (TID 0x7f9bf1948740) from PID 18446744073344798901 ***]


2025-06-05 15:23:09.064369 GPU 0 60714 test begin: paddle.lerp(Tensor([2, 2, 5],"float32"), Tensor([0, 2, 1, 5],"float32"), 0.5, )
[paddle error] paddle.lerp(Tensor([2, 2, 5],"float32"), Tensor([0, 2, 1, 5],"float32"), 0.5, ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:91)


2025-06-05 15:23:09.087550 GPU 0 60441 test begin: paddle.lerp(Tensor([2, 3, 0, 8],"float32"), Tensor([2, 3, 0, 8],"float32"), 2.1, )
[paddle error] paddle.lerp(Tensor([2, 3, 0, 8],"float32"), Tensor([2, 3, 0, 8],"float32"), 2.1, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:09.094218 GPU 0 60654 test begin: paddle.lerp(Tensor([2, 3, 8, 0],"float32"), Tensor([2, 3, 8, 0],"float32"), 2.1, )
[paddle error] paddle.lerp(Tensor([2, 3, 8, 0],"float32"), Tensor([2, 3, 8, 0],"float32"), 2.1, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:09.325362 GPU 0 60714 test begin: paddle.lerp(Tensor([2, 5],"float32"), Tensor([2, 2, 5],"float32"), Tensor([0, 2, 2, 5],"float32"), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_lerp(_object*, _object*, _object*)
1   lerp_ad_func(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&)
2   paddle::experimental::lerp(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&)
3   Eigen::TensorEvaluator<Eigen::TensorBroadcastingOp<Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 0, Eigen::MakePointer> const> const, Eigen::DefaultDevice>::BroadcastBlock(Eigen::DSizes<long, 4> const&, Eigen::DSizes<long, 4> const&, Eigen::DSizes<long, 8> const&, Eigen::DSizes<long, 8> const&, Eigen::DSizes<long, 8> const&, long, long, Eigen::internal::TensorBlockScratchAllocator<Eigen::DefaultDevice>&, float*, float**, unsigned long*) const

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108189 (unix time) try "date -d @1749108189" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f6cb80e5f4d) received by PID 60714 (TID 0x7f6dbea85740) from PID 18446744072502533965 ***]


2025-06-05 15:23:09.358101 GPU 0 60654 test begin: paddle.lerp(Tensor([3, 0, 28],"float32"), Tensor([3, 0, 28],"float32"), 1.2, )
[paddle error] paddle.lerp(Tensor([3, 0, 28],"float32"), Tensor([3, 0, 28],"float32"), 1.2, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:09.385280 GPU 0 60441 test begin: paddle.lerp(Tensor([3, 0, 3, 1, 2, 5],"float64"), Tensor([3, 0, 3, 1, 2, 5],"float64"), Tensor([3, 0, 3, 1, 2, 5],"float64"), )
[paddle error] paddle.lerp(Tensor([3, 0, 3, 1, 2, 5],"float64"), Tensor([3, 0, 3, 1, 2, 5],"float64"), Tensor([3, 0, 3, 1, 2, 5],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:09.582776 GPU 0 60654 test begin: paddle.lerp(Tensor([3, 0, 3, 4, 1, 5],"float64"), Tensor([3, 0, 3, 4, 1, 5],"float64"), Tensor([3, 0, 3, 4, 1, 5],"float64"), )
[paddle error] paddle.lerp(Tensor([3, 0, 3, 4, 1, 5],"float64"), Tensor([3, 0, 3, 4, 1, 5],"float64"), Tensor([3, 0, 3, 4, 1, 5],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:09.662403 GPU 0 60441 test begin: paddle.lerp(Tensor([3, 0, 8],"float32"), Tensor([3, 0, 8],"float32"), 2.1, )
[paddle error] paddle.lerp(Tensor([3, 0, 8],"float32"), Tensor([3, 0, 8],"float32"), 2.1, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:09.910367 GPU 0 60654 test begin: paddle.lerp(Tensor([3, 28, 0],"float32"), Tensor([3, 28, 0],"float32"), 1.2, )
[paddle error] paddle.lerp(Tensor([3, 28, 0],"float32"), Tensor([3, 28, 0],"float32"), 1.2, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:09.969901 GPU 0 60441 test begin: paddle.lerp(Tensor([3, 6, 0, 1, 2, 5],"float64"), Tensor([3, 6, 0, 1, 2, 5],"float64"), Tensor([3, 6, 0, 1, 2, 5],"float64"), )
[paddle error] paddle.lerp(Tensor([3, 6, 0, 1, 2, 5],"float64"), Tensor([3, 6, 0, 1, 2, 5],"float64"), Tensor([3, 6, 0, 1, 2, 5],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:10.627213 GPU 0 60441 test begin: paddle.lerp(Tensor([3, 6, 0, 4, 1, 5],"float64"), Tensor([3, 6, 0, 4, 1, 5],"float64"), Tensor([3, 6, 0, 4, 1, 5],"float64"), )
[paddle error] paddle.lerp(Tensor([3, 6, 0, 4, 1, 5],"float64"), Tensor([3, 6, 0, 4, 1, 5],"float64"), Tensor([3, 6, 0, 4, 1, 5],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:10.640989 GPU 0 60654 test begin: paddle.lerp(Tensor([3, 6, 3, 0, 1, 5],"float64"), Tensor([3, 6, 3, 0, 1, 5],"float64"), Tensor([3, 6, 3, 0, 1, 5],"float64"), )
[paddle error] paddle.lerp(Tensor([3, 6, 3, 0, 1, 5],"float64"), Tensor([3, 6, 3, 0, 1, 5],"float64"), Tensor([3, 6, 3, 0, 1, 5],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:11.011346 GPU 0 60441 test begin: paddle.lerp(Tensor([3, 6, 3, 0, 2, 5],"float64"), Tensor([3, 6, 3, 0, 2, 5],"float64"), Tensor([3, 6, 3, 0, 2, 5],"float64"), )
[paddle error] paddle.lerp(Tensor([3, 6, 3, 0, 2, 5],"float64"), Tensor([3, 6, 3, 0, 2, 5],"float64"), Tensor([3, 6, 3, 0, 2, 5],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:11.178082 GPU 0 60654 test begin: paddle.lerp(Tensor([3, 6, 3, 0, 2, 5],"float64"), Tensor([3, 6, 3, 1, 2, 5],"float64"), Tensor([3, 6, 3, 1, 2, 5],"float64"), )
[paddle error] paddle.lerp(Tensor([3, 6, 3, 0, 2, 5],"float64"), Tensor([3, 6, 3, 1, 2, 5],"float64"), Tensor([3, 6, 3, 1, 2, 5],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:11.577506 GPU 0 60441 test begin: paddle.lerp(Tensor([3, 6, 3, 1, 0, 5],"float64"), Tensor([3, 6, 3, 1, 0, 5],"float64"), Tensor([3, 6, 3, 1, 0, 5],"float64"), )
[paddle error] paddle.lerp(Tensor([3, 6, 3, 1, 0, 5],"float64"), Tensor([3, 6, 3, 1, 0, 5],"float64"), Tensor([3, 6, 3, 1, 0, 5],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:11.604138 GPU 0 60654 test begin: paddle.lerp(Tensor([3, 6, 3, 1, 2, 0],"float64"), Tensor([3, 6, 3, 1, 2, 0],"float64"), Tensor([3, 6, 3, 1, 2, 0],"float64"), )
[paddle error] paddle.lerp(Tensor([3, 6, 3, 1, 2, 0],"float64"), Tensor([3, 6, 3, 1, 2, 0],"float64"), Tensor([3, 6, 3, 1, 2, 0],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:11.849031 GPU 0 60654 test begin: paddle.lerp(Tensor([3, 6, 3, 1, 2, 5],"float64"), Tensor([3, 6, 3, 0, 2, 5],"float64"), Tensor([3, 6, 3, 1, 2, 5],"float64"), )
[paddle error] paddle.lerp(Tensor([3, 6, 3, 1, 2, 5],"float64"), Tensor([3, 6, 3, 0, 2, 5],"float64"), Tensor([3, 6, 3, 1, 2, 5],"float64"), ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:91)


2025-06-05 15:23:11.868698 GPU 0 60441 test begin: paddle.lerp(Tensor([3, 6, 3, 1, 2, 5],"float64"), Tensor([3, 6, 3, 1, 2, 5],"float64"), Tensor([3, 6, 3, 0, 2, 5],"float64"), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_lerp(_object*, _object*, _object*)
1   lerp_ad_func(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&)
2   paddle::experimental::lerp(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&)
3   Eigen::internal::TensorExecutor<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<double, 6, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<double const, double const>, Eigen::TensorBroadcastingOp<Eigen::DSizes<int, 6> const, Eigen::TensorMap<Eigen::Tensor<double const, 6, 1, long>, 0, Eigen::MakePointer> const> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<double const, double const>, Eigen::TensorBroadcastingOp<Eigen::DSizes<int, 6> const, Eigen::TensorMap<Eigen::Tensor<double const, 6, 1, long>, 0, Eigen::MakePointer> const> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<double const, double const>, Eigen::TensorBroadcastingOp<Eigen::DSizes<int, 6> const, Eigen::TensorMap<Eigen::Tensor<double const, 6, 1, long>, 0, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::DSizes<int, 6> const, Eigen::TensorMap<Eigen::Tensor<double const, 6, 1, long>, 0, Eigen::MakePointer> const> const> const> const> const> const, Eigen::DefaultDevice, true, (Eigen::internal::TiledEvaluation)1>::run(Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<double, 6, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<double const, double const>, Eigen::TensorBroadcastingOp<Eigen::DSizes<int, 6> const, Eigen::TensorMap<Eigen::Tensor<double const, 6, 1, long>, 0, Eigen::MakePointer> const> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<double const, double const>, Eigen::TensorBroadcastingOp<Eigen::DSizes<int, 6> const, Eigen::TensorMap<Eigen::Tensor<double const, 6, 1, long>, 0, Eigen::MakePointer> const> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<double const, double const>, Eigen::TensorBroadcastingOp<Eigen::DSizes<int, 6> const, Eigen::TensorMap<Eigen::Tensor<double const, 6, 1, long>, 0, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::DSizes<int, 6> const, Eigen::TensorMap<Eigen::Tensor<double const, 6, 1, long>, 0, Eigen::MakePointer> const> const> const> const> const> const&, Eigen::DefaultDevice const&)
4   Eigen::TensorEvaluator<Eigen::TensorBroadcastingOp<Eigen::DSizes<int, 6> const, Eigen::TensorMap<Eigen::Tensor<double const, 6, 1, long>, 0, Eigen::MakePointer> const> const, Eigen::DefaultDevice>::BroadcastBlock(Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 12> const&, Eigen::DSizes<long, 12> const&, Eigen::DSizes<long, 12> const&, long, long, Eigen::internal::TensorBlockScratchAllocator<Eigen::DefaultDevice>&, double*, double**, unsigned long*) const

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108192 (unix time) try "date -d @1749108192" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fe7037d0112) received by PID 60441 (TID 0x7fe80a14b740) from PID 58523922 ***]


2025-06-05 15:23:12.134649 GPU 0 60654 test begin: paddle.lerp(Tensor([3, 6, 3, 4, 0, 5],"float64"), Tensor([3, 6, 3, 4, 0, 5],"float64"), Tensor([3, 6, 3, 4, 0, 5],"float64"), )
[paddle error] paddle.lerp(Tensor([3, 6, 3, 4, 0, 5],"float64"), Tensor([3, 6, 3, 4, 0, 5],"float64"), Tensor([3, 6, 3, 4, 0, 5],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:12.380170 GPU 0 60654 test begin: paddle.lerp(Tensor([3, 6, 3, 4, 0, 5],"float64"), Tensor([3, 6, 3, 4, 1, 5],"float64"), Tensor([3, 6, 3, 4, 1, 5],"float64"), )
[paddle error] paddle.lerp(Tensor([3, 6, 3, 4, 0, 5],"float64"), Tensor([3, 6, 3, 4, 1, 5],"float64"), Tensor([3, 6, 3, 4, 1, 5],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:12.616381 GPU 0 60654 test begin: paddle.lerp(Tensor([3, 6, 3, 4, 1, 0],"float64"), Tensor([3, 6, 3, 4, 1, 0],"float64"), Tensor([3, 6, 3, 4, 1, 0],"float64"), )
[paddle error] paddle.lerp(Tensor([3, 6, 3, 4, 1, 0],"float64"), Tensor([3, 6, 3, 4, 1, 0],"float64"), Tensor([3, 6, 3, 4, 1, 0],"float64"), ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:12.958884 GPU 0 60654 test begin: paddle.lerp(Tensor([3, 6, 3, 4, 1, 5],"float64"), Tensor([3, 6, 3, 4, 0, 5],"float64"), Tensor([3, 6, 3, 4, 1, 5],"float64"), )
[paddle error] paddle.lerp(Tensor([3, 6, 3, 4, 1, 5],"float64"), Tensor([3, 6, 3, 4, 0, 5],"float64"), Tensor([3, 6, 3, 4, 1, 5],"float64"), ) 
 (InvalidArgument) LerpKernel's input y must not empty.
  [Hint: Expected y.numel() > 0, but received y.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:91)


2025-06-05 15:23:13.465433 GPU 0 60654 test begin: paddle.lerp(Tensor([3, 6, 3, 4, 1, 5],"float64"), Tensor([3, 6, 3, 4, 1, 5],"float64"), Tensor([3, 6, 3, 4, 0, 5],"float64"), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_lerp(_object*, _object*, _object*)
1   lerp_ad_func(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&)
2   paddle::experimental::lerp(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&)
3   Eigen::internal::TensorExecutor<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<double, 6, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<double const, double const>, Eigen::TensorBroadcastingOp<Eigen::DSizes<int, 6> const, Eigen::TensorMap<Eigen::Tensor<double const, 6, 1, long>, 0, Eigen::MakePointer> const> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<double const, double const>, Eigen::TensorBroadcastingOp<Eigen::DSizes<int, 6> const, Eigen::TensorMap<Eigen::Tensor<double const, 6, 1, long>, 0, Eigen::MakePointer> const> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<double const, double const>, Eigen::TensorBroadcastingOp<Eigen::DSizes<int, 6> const, Eigen::TensorMap<Eigen::Tensor<double const, 6, 1, long>, 0, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::DSizes<int, 6> const, Eigen::TensorMap<Eigen::Tensor<double const, 6, 1, long>, 0, Eigen::MakePointer> const> const> const> const> const> const, Eigen::DefaultDevice, true, (Eigen::internal::TiledEvaluation)1>::run(Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<double, 6, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<double const, double const>, Eigen::TensorBroadcastingOp<Eigen::DSizes<int, 6> const, Eigen::TensorMap<Eigen::Tensor<double const, 6, 1, long>, 0, Eigen::MakePointer> const> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<double const, double const>, Eigen::TensorBroadcastingOp<Eigen::DSizes<int, 6> const, Eigen::TensorMap<Eigen::Tensor<double const, 6, 1, long>, 0, Eigen::MakePointer> const> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<double const, double const>, Eigen::TensorBroadcastingOp<Eigen::DSizes<int, 6> const, Eigen::TensorMap<Eigen::Tensor<double const, 6, 1, long>, 0, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::DSizes<int, 6> const, Eigen::TensorMap<Eigen::Tensor<double const, 6, 1, long>, 0, Eigen::MakePointer> const> const> const> const> const> const&, Eigen::DefaultDevice const&)
4   Eigen::TensorEvaluator<Eigen::TensorBroadcastingOp<Eigen::DSizes<int, 6> const, Eigen::TensorMap<Eigen::Tensor<double const, 6, 1, long>, 0, Eigen::MakePointer> const> const, Eigen::DefaultDevice>::BroadcastBlock(Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 12> const&, Eigen::DSizes<long, 12> const&, Eigen::DSizes<long, 12> const&, long, long, Eigen::internal::TensorBlockScratchAllocator<Eigen::DefaultDevice>&, double*, double**, unsigned long*) const

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108193 (unix time) try "date -d @1749108193" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7effe28f9112) received by PID 60654 (TID 0x7f00e9174740) from PID 18446744073215643922 ***]


2025-06-05 15:23:14.385226 GPU 0 61995 test begin: paddle.lerp(Tensor([3, 8, 0],"float32"), Tensor([3, 8, 0],"float32"), 2.1, )
[paddle error] paddle.lerp(Tensor([3, 8, 0],"float32"), Tensor([3, 8, 0],"float32"), 2.1, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:14.483942 GPU 1 61385 test begin: paddle.lerp(x=Tensor([0, 5, 4, 3],"float64"), y=Tensor([0, 5, 4, 3],"float64"), weight=0.0, )
[paddle error] paddle.lerp(x=Tensor([0, 5, 4, 3],"float64"), y=Tensor([0, 5, 4, 3],"float64"), weight=0.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:14.984024 GPU 1 61385 test begin: paddle.lerp(x=Tensor([0, 5, 4, 3],"float64"), y=Tensor([0, 5, 4, 3],"float64"), weight=0.5, )
[paddle error] paddle.lerp(x=Tensor([0, 5, 4, 3],"float64"), y=Tensor([0, 5, 4, 3],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:15.080967 GPU 1 61245 test begin: paddle.lerp(x=Tensor([0, 5, 4, 3],"float64"), y=Tensor([0, 5, 4, 3],"float64"), weight=1.0, )
[paddle error] paddle.lerp(x=Tensor([0, 5, 4, 3],"float64"), y=Tensor([0, 5, 4, 3],"float64"), weight=1.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:15.345395 GPU 1 61245 test begin: paddle.lerp(x=Tensor([0, 5, 4],"float64"), y=Tensor([0, 5, 4],"float64"), weight=0.5, )
[paddle error] paddle.lerp(x=Tensor([0, 5, 4],"float64"), y=Tensor([0, 5, 4],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:15.346682 GPU 1 61385 test begin: paddle.lerp(x=Tensor([0, 5],"float64"), y=Tensor([0, 5],"float64"), weight=0.5, )
[paddle error] paddle.lerp(x=Tensor([0, 5],"float64"), y=Tensor([0, 5],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:15.360104 GPU 1 61428 test begin: paddle.lerp(x=Tensor([0, 5],"float64"), y=Tensor([1],"float64"), weight=0.2, )
[paddle error] paddle.lerp(x=Tensor([0, 5],"float64"), y=Tensor([1],"float64"), weight=0.2, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:15.592310 GPU 1 61245 test begin: paddle.lerp(x=Tensor([0],"float32"), y=Tensor([0],"float32"), weight=0.5, )
[paddle error] paddle.lerp(x=Tensor([0],"float32"), y=Tensor([0],"float32"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:15.602173 GPU 1 61385 test begin: paddle.lerp(x=Tensor([0],"float64"), y=Tensor([0],"float64"), weight=0.5, )
[paddle error] paddle.lerp(x=Tensor([0],"float64"), y=Tensor([0],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:15.608815 GPU 1 61458 test begin: paddle.lerp(x=Tensor([4, 0, 4, 3],"float64"), y=Tensor([4, 0, 4, 3],"float64"), weight=0.0, )
[paddle error] paddle.lerp(x=Tensor([4, 0, 4, 3],"float64"), y=Tensor([4, 0, 4, 3],"float64"), weight=0.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:15.674643 GPU 1 61428 test begin: paddle.lerp(x=Tensor([4, 0, 4, 3],"float64"), y=Tensor([4, 0, 4, 3],"float64"), weight=0.5, )
[paddle error] paddle.lerp(x=Tensor([4, 0, 4, 3],"float64"), y=Tensor([4, 0, 4, 3],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:15.875708 GPU 1 61385 test begin: paddle.lerp(x=Tensor([4, 0, 4, 3],"float64"), y=Tensor([4, 0, 4, 3],"float64"), weight=1.0, )
[paddle error] paddle.lerp(x=Tensor([4, 0, 4, 3],"float64"), y=Tensor([4, 0, 4, 3],"float64"), weight=1.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:15.926578 GPU 1 61428 test begin: paddle.lerp(x=Tensor([4, 0, 4],"float64"), y=Tensor([4, 0, 4],"float64"), weight=0.5, )
[paddle error] paddle.lerp(x=Tensor([4, 0, 4],"float64"), y=Tensor([4, 0, 4],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:15.955330 GPU 1 61245 test begin: paddle.lerp(x=Tensor([4, 0],"float64"), y=Tensor([1],"float64"), weight=0.2, )
[paddle error] paddle.lerp(x=Tensor([4, 0],"float64"), y=Tensor([1],"float64"), weight=0.2, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:15.962958 GPU 1 61458 test begin: paddle.lerp(x=Tensor([4, 0],"float64"), y=Tensor([4, 0],"float64"), weight=0.5, )
[paddle error] paddle.lerp(x=Tensor([4, 0],"float64"), y=Tensor([4, 0],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:16.231609 GPU 1 61438 test begin: paddle.lerp(x=Tensor([4, 5, 0, 3],"float64"), y=Tensor([4, 5, 0, 3],"float64"), weight=0.0, )
[paddle error] paddle.lerp(x=Tensor([4, 5, 0, 3],"float64"), y=Tensor([4, 5, 0, 3],"float64"), weight=0.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:16.311115 GPU 1 61428 test begin: paddle.lerp(x=Tensor([4, 5, 0, 3],"float64"), y=Tensor([4, 5, 0, 3],"float64"), weight=0.5, )
[paddle error] paddle.lerp(x=Tensor([4, 5, 0, 3],"float64"), y=Tensor([4, 5, 0, 3],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:16.458242 GPU 1 61458 test begin: paddle.lerp(x=Tensor([4, 5, 0, 3],"float64"), y=Tensor([4, 5, 0, 3],"float64"), weight=1.0, )
[paddle error] paddle.lerp(x=Tensor([4, 5, 0, 3],"float64"), y=Tensor([4, 5, 0, 3],"float64"), weight=1.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:16.461332 GPU 1 61385 test begin: paddle.lerp(x=Tensor([4, 5, 0],"float64"), y=Tensor([4, 5, 0],"float64"), weight=0.5, )
[paddle error] paddle.lerp(x=Tensor([4, 5, 0],"float64"), y=Tensor([4, 5, 0],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:16.549362 GPU 1 61245 test begin: paddle.lerp(x=Tensor([4, 5, 4, 0],"float64"), y=Tensor([4, 5, 4, 0],"float64"), weight=0.0, )
[paddle error] paddle.lerp(x=Tensor([4, 5, 4, 0],"float64"), y=Tensor([4, 5, 4, 0],"float64"), weight=0.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:16.591546 GPU 0 62010 test begin: paddle.lerp(x=Tensor([4, 5, 4, 0],"float64"), y=Tensor([4, 5, 4, 0],"float64"), weight=0.5, )
[paddle error] paddle.lerp(x=Tensor([4, 5, 4, 0],"float64"), y=Tensor([4, 5, 4, 0],"float64"), weight=0.5, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:16.640919 GPU 1 61438 test begin: paddle.lerp(x=Tensor([4, 5, 4, 0],"float64"), y=Tensor([4, 5, 4, 0],"float64"), weight=1.0, )
[paddle error] paddle.lerp(x=Tensor([4, 5, 4, 0],"float64"), y=Tensor([4, 5, 4, 0],"float64"), weight=1.0, ) 
 (InvalidArgument) LerpKernel's input x must not empty.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/impl/lerp_kernel_impl.h:86)


2025-06-05 15:23:16.847096 GPU 0 62021 test begin: paddle.linalg.cholesky_solve(Tensor([0, 30, 2],"float64"), Tensor([0, 30, 30],"float64"), upper=True, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/autograd/graph.py:823: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:180.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[paddle error] paddle.linalg.cholesky_solve(Tensor([0, 30, 2],"float64"), Tensor([0, 30, 30],"float64"), upper=True, ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:16.873941 GPU 1 61428 test begin: paddle.linalg.cholesky_solve(Tensor([1, 30, 0],"float64"), Tensor([2, 30, 30],"float64"), upper=True, )
[paddle error] paddle.linalg.cholesky_solve(Tensor([1, 30, 0],"float64"), Tensor([2, 30, 30],"float64"), upper=True, ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:16.982407 GPU 1 61490 test begin: paddle.linalg.cholesky_solve(Tensor([1, 30, 2],"float64"), Tensor([0, 30, 30],"float64"), upper=True, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/autograd/graph.py:823: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:180.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[paddle error] paddle.linalg.cholesky_solve(Tensor([1, 30, 2],"float64"), Tensor([0, 30, 30],"float64"), upper=True, ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:16.999218 GPU 0 61448 test begin: paddle.linalg.cholesky_solve(Tensor([20, 0],"float64"), Tensor([20, 20],"float64"), upper=True, )
[paddle error] paddle.linalg.cholesky_solve(Tensor([20, 0],"float64"), Tensor([20, 20],"float64"), upper=True, ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:17.004577 GPU 1 61458 test begin: paddle.linalg.cholesky_solve(x=Tensor([0, 2, 4, 3],"float64"), y=Tensor([0, 2, 4, 4],"float64"), )
[paddle error] paddle.linalg.cholesky_solve(x=Tensor([0, 2, 4, 3],"float64"), y=Tensor([0, 2, 4, 4],"float64"), ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:17.029422 GPU 0 62020 test begin: paddle.linalg.cholesky_solve(x=Tensor([0, 2, 4, 3],"float64"), y=Tensor([0, 2, 4, 4],"float64"), upper=True, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/autograd/graph.py:823: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:180.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[paddle error] paddle.linalg.cholesky_solve(x=Tensor([0, 2, 4, 3],"float64"), y=Tensor([0, 2, 4, 4],"float64"), upper=True, ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:17.057607 GPU 1 61385 test begin: paddle.linalg.cholesky_solve(x=Tensor([0, 4, 3],"float64"), y=Tensor([0, 4, 4],"float64"), )
[paddle error] paddle.linalg.cholesky_solve(x=Tensor([0, 4, 3],"float64"), y=Tensor([0, 4, 4],"float64"), ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:17.094401 GPU 0 62044 test begin: paddle.linalg.cholesky_solve(x=Tensor([4, 0],"float32"), y=Tensor([4, 4],"float32"), )
[paddle error] paddle.linalg.cholesky_solve(x=Tensor([4, 0],"float32"), y=Tensor([4, 4],"float32"), ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:17.158076 GPU 0 62077 test begin: paddle.linalg.cholesky_solve(x=Tensor([4, 0],"float64"), y=Tensor([4, 4],"float64"), )
[paddle error] paddle.linalg.cholesky_solve(x=Tensor([4, 0],"float64"), y=Tensor([4, 4],"float64"), ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:17.183498 GPU 1 61245 test begin: paddle.linalg.cholesky_solve(x=Tensor([5, 0, 4, 3],"float64"), y=Tensor([5, 0, 4, 4],"float64"), )
[paddle error] paddle.linalg.cholesky_solve(x=Tensor([5, 0, 4, 3],"float64"), y=Tensor([5, 0, 4, 4],"float64"), ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:17.461570 GPU 1 61438 test begin: paddle.linalg.cholesky_solve(x=Tensor([5, 0, 4, 3],"float64"), y=Tensor([5, 0, 4, 4],"float64"), upper=True, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/autograd/graph.py:823: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:180.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[paddle error] paddle.linalg.cholesky_solve(x=Tensor([5, 0, 4, 3],"float64"), y=Tensor([5, 0, 4, 4],"float64"), upper=True, ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:17.672539 GPU 1 62154 test begin: paddle.linalg.cholesky_solve(x=Tensor([5, 2, 4, 0],"float64"), y=Tensor([5, 2, 4, 4],"float64"), )
[paddle error] paddle.linalg.cholesky_solve(x=Tensor([5, 2, 4, 0],"float64"), y=Tensor([5, 2, 4, 4],"float64"), ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:17.779327 GPU 0 62121 test begin: paddle.linalg.cholesky_solve(x=Tensor([5, 2, 4, 0],"float64"), y=Tensor([5, 2, 4, 4],"float64"), upper=True, )
[paddle error] paddle.linalg.cholesky_solve(x=Tensor([5, 2, 4, 0],"float64"), y=Tensor([5, 2, 4, 4],"float64"), upper=True, ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:17.989337 GPU 1 61478 test begin: paddle.linalg.cholesky_solve(x=Tensor([5, 4, 0],"float64"), y=Tensor([5, 4, 4],"float64"), )
[paddle error] paddle.linalg.cholesky_solve(x=Tensor([5, 4, 0],"float64"), y=Tensor([5, 4, 4],"float64"), ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:18.430892 GPU 0 61479 test begin: paddle.linalg.cond(Tensor([0, 3],"float32"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([0, 3],"float32"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [0, 3], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-06-05 15:23:18.728751 GPU 1 62200 test begin: paddle.linalg.cond(Tensor([0, 3],"float32"), p=-1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([0, 3],"float32"), p=-1, ) 
 only support p is -1 when input is a square matrix or batches of square matrices

2025-06-05 15:23:18.962499 GPU 0 61479 test begin: paddle.linalg.cond(Tensor([0, 3],"float32"), p=1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([0, 3],"float32"), p=1, ) 
 only support p is 1 when input is a square matrix or batches of square matrices

2025-06-05 15:23:19.331640 GPU 0 61479 test begin: paddle.linalg.cond(Tensor([0, 3],"float32"), p=2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([0, 3],"float32"), p=2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [0, 3], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-06-05 15:23:19.615038 GPU 0 61479 test begin: paddle.linalg.cond(Tensor([0, 3],"float32"), p=math.inf, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([0, 3],"float32"), p=math.inf, ) 
 only support p is inf when input is a square matrix or batches of square matrices

2025-06-05 15:23:19.912913 GPU 0 62210 test begin: paddle.linalg.cond(Tensor([0, 5],"float32"), -1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([0, 5],"float32"), -1, ) 
 only support p is -1 when input is a square matrix or batches of square matrices

2025-06-05 15:23:20.136734 GPU 0 61479 test begin: paddle.linalg.cond(Tensor([0, 5],"float32"), -2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([0, 5],"float32"), -2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [0, 5], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-06-05 15:23:20.378537 GPU 0 61479 test begin: paddle.linalg.cond(Tensor([0, 5],"float32"), -math.inf, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([0, 5],"float32"), -math.inf, ) 
 only support p is -inf when input is a square matrix or batches of square matrices

2025-06-05 15:23:20.549153 GPU 1 62233 test begin: paddle.linalg.cond(Tensor([0, 5],"float32"), 1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([0, 5],"float32"), 1, ) 
 only support p is 1 when input is a square matrix or batches of square matrices

2025-06-05 15:23:20.665219 GPU 0 61479 test begin: paddle.linalg.cond(Tensor([0, 5],"float32"), 2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([0, 5],"float32"), 2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [0, 5], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-06-05 15:23:21.104580 GPU 0 61479 test begin: paddle.linalg.cond(Tensor([0, 5],"float32"), None, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([0, 5],"float32"), None, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [0, 5], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-06-05 15:23:21.356630 GPU 0 61479 test begin: paddle.linalg.cond(Tensor([0, 5],"float32"), math.inf, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([0, 5],"float32"), math.inf, ) 
 only support p is inf when input is a square matrix or batches of square matrices

2025-06-05 15:23:21.453643 GPU 1 62236 test begin: paddle.linalg.cond(Tensor([0, 7],"float64"), -2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([0, 7],"float64"), -2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [0, 7], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-06-05 15:23:21.621136 GPU 0 61479 test begin: paddle.linalg.cond(Tensor([0, 7],"float64"), 2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([0, 7],"float64"), 2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [0, 7], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-06-05 15:23:21.890605 GPU 0 61479 test begin: paddle.linalg.cond(Tensor([0, 7],"float64"), None, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([0, 7],"float64"), None, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [0, 7], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-06-05 15:23:22.265843 GPU 0 61479 test begin: paddle.linalg.cond(Tensor([2, 4, 0, 3],"float32"), -1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([2, 4, 0, 3],"float32"), -1, ) 
 only support p is -1 when input is a square matrix or batches of square matrices

2025-06-05 15:23:22.539315 GPU 0 61479 test begin: paddle.linalg.cond(Tensor([2, 4, 0, 3],"float32"), -2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([2, 4, 0, 3],"float32"), -2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [2, 4, 0, 3], X's size = 0, 'shape' is [2, 4], the capacity of 'shape' is 8.
  [Hint: Expected capacity == in_size, but received capacity:8 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-06-05 15:23:22.861000 GPU 0 61479 test begin: paddle.linalg.cond(Tensor([2, 4, 0, 3],"float32"), -math.inf, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([2, 4, 0, 3],"float32"), -math.inf, ) 
 only support p is -inf when input is a square matrix or batches of square matrices

2025-06-05 15:23:22.875512 GPU 0 62275 test begin: paddle.linalg.cond(Tensor([2, 4, 0, 3],"float32"), 1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([2, 4, 0, 3],"float32"), 1, ) 
 only support p is 1 when input is a square matrix or batches of square matrices

2025-06-05 15:23:23.310808 GPU 0 61479 test begin: paddle.linalg.cond(Tensor([2, 4, 0, 3],"float32"), 2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([2, 4, 0, 3],"float32"), 2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [2, 4, 0, 3], X's size = 0, 'shape' is [2, 4], the capacity of 'shape' is 8.
  [Hint: Expected capacity == in_size, but received capacity:8 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-06-05 15:23:23.676218 GPU 0 61479 test begin: paddle.linalg.cond(Tensor([2, 4, 0, 3],"float32"), None, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([2, 4, 0, 3],"float32"), None, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [2, 4, 0, 3], X's size = 0, 'shape' is [2, 4], the capacity of 'shape' is 8.
  [Hint: Expected capacity == in_size, but received capacity:8 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-06-05 15:23:23.963039 GPU 0 61448 test begin: paddle.linalg.cond(Tensor([2, 4, 0, 3],"float32"), math.inf, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([2, 4, 0, 3],"float32"), math.inf, ) 
 only support p is inf when input is a square matrix or batches of square matrices

2025-06-05 15:23:23.998751 GPU 0 61479 test begin: paddle.linalg.cond(Tensor([2, 4, 3, 0],"float32"), -1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([2, 4, 3, 0],"float32"), -1, ) 
 only support p is -1 when input is a square matrix or batches of square matrices

2025-06-05 15:23:24.017464 GPU 1 61458 test begin: paddle.linalg.cond(Tensor([2, 4, 3, 0],"float32"), -2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([2, 4, 3, 0],"float32"), -2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [2, 4, 3, 0], X's size = 0, 'shape' is [2, 4], the capacity of 'shape' is 8.
  [Hint: Expected capacity == in_size, but received capacity:8 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-06-05 15:23:24.020004 GPU 1 61428 test begin: paddle.linalg.cond(Tensor([2, 4, 3, 0],"float32"), -math.inf, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([2, 4, 3, 0],"float32"), -math.inf, ) 
 only support p is -inf when input is a square matrix or batches of square matrices

2025-06-05 15:23:24.216025 GPU 1 61245 test begin: paddle.linalg.cond(Tensor([2, 4, 3, 0],"float32"), 1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([2, 4, 3, 0],"float32"), 1, ) 
 only support p is 1 when input is a square matrix or batches of square matrices

2025-06-05 15:23:24.612449 GPU 0 61448 test begin: paddle.linalg.cond(Tensor([2, 4, 3, 0],"float32"), 2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([2, 4, 3, 0],"float32"), 2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [2, 4, 3, 0], X's size = 0, 'shape' is [2, 4], the capacity of 'shape' is 8.
  [Hint: Expected capacity == in_size, but received capacity:8 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-06-05 15:23:24.621954 GPU 1 61458 test begin: paddle.linalg.cond(Tensor([2, 4, 3, 0],"float32"), None, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([2, 4, 3, 0],"float32"), None, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [2, 4, 3, 0], X's size = 0, 'shape' is [2, 4], the capacity of 'shape' is 8.
  [Hint: Expected capacity == in_size, but received capacity:8 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-06-05 15:23:24.627849 GPU 0 61479 test begin: paddle.linalg.cond(Tensor([2, 4, 3, 0],"float32"), math.inf, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([2, 4, 3, 0],"float32"), math.inf, ) 
 only support p is inf when input is a square matrix or batches of square matrices

2025-06-05 15:23:24.785255 GPU 1 61428 test begin: paddle.linalg.cond(Tensor([3, 0],"float32"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([3, 0],"float32"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [3, 0], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-06-05 15:23:25.289021 GPU 1 61458 test begin: paddle.linalg.cond(Tensor([3, 0],"float32"), p=-1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([3, 0],"float32"), p=-1, ) 
 only support p is -1 when input is a square matrix or batches of square matrices

2025-06-05 15:23:25.344053 GPU 0 61448 test begin: paddle.linalg.cond(Tensor([3, 0],"float32"), p=1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([3, 0],"float32"), p=1, ) 
 only support p is 1 when input is a square matrix or batches of square matrices

2025-06-05 15:23:25.344569 GPU 1 61245 test begin: paddle.linalg.cond(Tensor([3, 0],"float32"), p=2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([3, 0],"float32"), p=2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [3, 0], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-06-05 15:23:25.346021 GPU 1 61428 test begin: paddle.linalg.cond(Tensor([3, 0],"float32"), p=math.inf, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([3, 0],"float32"), p=math.inf, ) 
 only support p is inf when input is a square matrix or batches of square matrices

2025-06-05 15:23:25.516708 GPU 0 61479 test begin: paddle.linalg.cond(Tensor([5, 0],"float32"), -1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([5, 0],"float32"), -1, ) 
 only support p is -1 when input is a square matrix or batches of square matrices

2025-06-05 15:23:25.725922 GPU 1 61458 test begin: paddle.linalg.cond(Tensor([5, 0],"float32"), -2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([5, 0],"float32"), -2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [5, 0], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-06-05 15:23:25.734204 GPU 1 61428 test begin: paddle.linalg.cond(Tensor([5, 0],"float32"), -math.inf, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([5, 0],"float32"), -math.inf, ) 
 only support p is -inf when input is a square matrix or batches of square matrices

2025-06-05 15:23:25.811975 GPU 1 61385 test begin: paddle.linalg.cond(Tensor([5, 0],"float32"), 1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([5, 0],"float32"), 1, ) 
 only support p is 1 when input is a square matrix or batches of square matrices

2025-06-05 15:23:25.886663 GPU 0 61448 test begin: paddle.linalg.cond(Tensor([5, 0],"float32"), 2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([5, 0],"float32"), 2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [5, 0], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-06-05 15:23:26.012037 GPU 0 61479 test begin: paddle.linalg.cond(Tensor([5, 0],"float32"), None, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([5, 0],"float32"), None, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [5, 0], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-06-05 15:23:26.078126 GPU 1 61245 test begin: paddle.linalg.cond(Tensor([5, 0],"float32"), math.inf, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([5, 0],"float32"), math.inf, ) 
 only support p is inf when input is a square matrix or batches of square matrices

2025-06-05 15:23:26.174535 GPU 1 61428 test begin: paddle.linalg.cond(Tensor([9, 0],"float64"), -2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([9, 0],"float64"), -2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [9, 0], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-06-05 15:23:26.185575 GPU 1 61438 test begin: paddle.linalg.cond(Tensor([9, 0],"float64"), 2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([9, 0],"float64"), 2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [9, 0], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-06-05 15:23:26.209207 GPU 1 61385 test begin: paddle.linalg.cond(Tensor([9, 0],"float64"), None, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(Tensor([9, 0],"float64"), None, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [9, 0], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-06-05 15:23:26.226771 GPU 1 61490 test begin: paddle.linalg.cond(x=Tensor([0, 3],"float32"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([0, 3],"float32"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [0, 3], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-06-05 15:23:26.244319 GPU 1 61478 test begin: paddle.linalg.cond(x=Tensor([0, 3],"float64"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([0, 3],"float64"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [0, 3], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-06-05 15:23:26.321918 GPU 1 61458 test begin: paddle.linalg.cond(x=Tensor([0, 4],"float64"), p=-2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([0, 4],"float64"), p=-2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [0, 4], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-06-05 15:23:26.376203 GPU 0 61479 test begin: paddle.linalg.cond(x=Tensor([0, 4],"float64"), p=1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([0, 4],"float64"), p=1, ) 
 only support p is 1 when input is a square matrix or batches of square matrices

2025-06-05 15:23:26.386735 GPU 0 61448 test begin: paddle.linalg.cond(x=Tensor([3, 0],"float32"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([3, 0],"float32"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [3, 0], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-06-05 15:23:26.504283 GPU 1 61245 test begin: paddle.linalg.cond(x=Tensor([3, 0],"float64"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([3, 0],"float64"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [3, 0], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-06-05 15:23:26.637904 GPU 1 61438 test begin: paddle.linalg.cond(x=Tensor([4, 0],"float64"), p=-2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([4, 0],"float64"), p=-2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [4, 0], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-06-05 15:23:26.658060 GPU 1 61385 test begin: paddle.linalg.cond(x=Tensor([4, 0],"float64"), p=1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([4, 0],"float64"), p=1, ) 
 only support p is 1 when input is a square matrix or batches of square matrices

2025-06-05 15:23:26.659300 GPU 1 61478 test begin: paddle.linalg.cond(x=Tensor([4, 2, 0, 4],"float64"), p=-1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([4, 2, 0, 4],"float64"), p=-1, ) 
 only support p is -1 when input is a square matrix or batches of square matrices

2025-06-05 15:23:26.662917 GPU 1 61490 test begin: paddle.linalg.cond(x=Tensor([4, 2, 0, 4],"float64"), p=-math.inf, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([4, 2, 0, 4],"float64"), p=-math.inf, ) 
 only support p is -inf when input is a square matrix or batches of square matrices

2025-06-05 15:23:26.663637 GPU 0 61479 test begin: paddle.linalg.cond(x=Tensor([4, 2, 0, 4],"float64"), p=math.inf, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([4, 2, 0, 4],"float64"), p=math.inf, ) 
 only support p is inf when input is a square matrix or batches of square matrices

2025-06-05 15:23:26.664116 GPU 1 61428 test begin: paddle.linalg.cond(x=Tensor([4, 2, 4, 0],"float64"), p=-1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([4, 2, 4, 0],"float64"), p=-1, ) 
 only support p is -1 when input is a square matrix or batches of square matrices

2025-06-05 15:23:26.667252 GPU 1 61458 test begin: paddle.linalg.cond(x=Tensor([4, 2, 4, 0],"float64"), p=-math.inf, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([4, 2, 4, 0],"float64"), p=-math.inf, ) 
 only support p is -inf when input is a square matrix or batches of square matrices

2025-06-05 15:23:26.828451 GPU 0 61448 test begin: paddle.linalg.cond(x=Tensor([4, 2, 4, 0],"float64"), p=math.inf, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([4, 2, 4, 0],"float64"), p=math.inf, ) 
 only support p is inf when input is a square matrix or batches of square matrices

2025-06-05 15:23:26.937746 GPU 1 61478 test begin: paddle.linalg.cond(x=Tensor([6, 0],"float64"), p=-2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([6, 0],"float64"), p=-2, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [6, 0], X's size = 0, 'shape' is [], the capacity of 'shape' is 1.
  [Hint: Expected capacity == in_size, but received capacity:1 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-06-05 15:23:26.951057 GPU 1 61438 test begin: paddle.linalg.cond(x=Tensor([6, 2, 4, 0, 4],"float64"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([6, 2, 4, 0, 4],"float64"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [6, 2, 4, 0, 4], X's size = 0, 'shape' is [6, 2, 4], the capacity of 'shape' is 48.
  [Hint: Expected capacity == in_size, but received capacity:48 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-06-05 15:23:26.954266 GPU 0 61479 test begin: paddle.linalg.cond(x=Tensor([6, 2, 4, 3, 0],"float64"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.linalg.cond(x=Tensor([6, 2, 4, 3, 0],"float64"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [6, 2, 4, 3, 0], X's size = 0, 'shape' is [6, 2, 4], the capacity of 'shape' is 48.
  [Hint: Expected capacity == in_size, but received capacity:48 != in_size:0.] (at ../paddle/phi/infermeta/unary.cc:2245)


2025-06-05 15:23:26.956163 GPU 1 61385 test begin: paddle.linalg.cov(Tensor([3, 0],"float32"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: cov(): degrees of freedom is <= 0. Correction should be strictly less than the number of observations. (Triggered internally at /pytorch/aten/src/ATen/native/Correlation.cpp:116.)
  return func(*args, **kwargs)
[accuracy error] paddle.linalg.cov(Tensor([3, 0],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 2 / 9 (22.2%)
Greatest absolute difference: nan at index (2, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (2, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 3]), dtype=torch.float32)
tensor([[nan, nan, nan],
        [nan, nan, nan],
        [inf, nan, -inf]])
DESIRED: (shape=torch.Size([3, 3]), dtype=torch.float32)
tensor([[nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan]])

2025-06-05 15:23:26.958483 GPU 1 61458 test begin: paddle.linalg.cov(x=Tensor([4, 0],"float32"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: cov(): degrees of freedom is <= 0. Correction should be strictly less than the number of observations. (Triggered internally at /pytorch/aten/src/ATen/native/Correlation.cpp:116.)
  return func(*args, **kwargs)
[accuracy error] paddle.linalg.cov(x=Tensor([4, 0],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 5 / 16 (31.2%)
Greatest absolute difference: nan at index (0, 2) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 4]), dtype=torch.float32)
tensor([[nan, nan, inf, inf],
        [nan, nan, inf, nan],
        [-inf, nan, -inf, nan],
        [nan, nan, nan, nan]])
DESIRED: (shape=torch.Size([4, 4]), dtype=torch.float32)
tensor([[nan, nan, nan, nan],
        [nan, nan, nan, nan],
        [nan, nan, nan, nan],
        [nan, nan, nan, nan]])

2025-06-05 15:23:27.234392 GPU 1 61478 test begin: paddle.linalg.lstsq(Tensor([0, 10],"float64"), Tensor([0, 8],"float64"), rcond=1e-15, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([0, 10],"float64"), Tensor([0, 8],"float64"), rcond=1e-15, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:27.275296 GPU 1 61385 test begin: paddle.linalg.lstsq(Tensor([0, 2, 8],"float32"), Tensor([0, 2, 15],"float32"), rcond=None, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([0, 2, 8],"float32"), Tensor([0, 2, 15],"float32"), rcond=None, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:27.321313 GPU 1 61458 test begin: paddle.linalg.lstsq(Tensor([0, 5],"float32"), Tensor([0, 8],"float32"), rcond=None, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([0, 5],"float32"), Tensor([0, 8],"float32"), rcond=None, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:27.429918 GPU 1 61490 test begin: paddle.linalg.lstsq(Tensor([0, 7, 3],"float64"), Tensor([0, 7, 6],"float64"), rcond=1e-15, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([0, 7, 3],"float64"), Tensor([0, 7, 6],"float64"), rcond=1e-15, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:27.478393 GPU 0 61448 test begin: paddle.linalg.lstsq(Tensor([0, 8, 6],"float64"), Tensor([0, 8, 10],"float64"), rcond=1e-15, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([0, 8, 6],"float64"), Tensor([0, 8, 10],"float64"), rcond=1e-15, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:27.482822 GPU 1 61438 test begin: paddle.linalg.lstsq(Tensor([0, 9],"float32"), Tensor([0, 5],"float32"), rcond=1e-15, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([0, 9],"float32"), Tensor([0, 5],"float32"), rcond=1e-15, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:27.483213 GPU 1 61245 test begin: paddle.linalg.lstsq(Tensor([10, 0, 3],"float64"), Tensor([10, 0, 6],"float64"), rcond=1e-15, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([10, 0, 3],"float64"), Tensor([10, 0, 6],"float64"), rcond=1e-15, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:27.689203 GPU 0 61479 test begin: paddle.linalg.lstsq(Tensor([10, 0, 6],"float64"), Tensor([10, 0, 10],"float64"), rcond=1e-15, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([10, 0, 6],"float64"), Tensor([10, 0, 10],"float64"), rcond=1e-15, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:27.691152 GPU 1 61428 test begin: paddle.linalg.lstsq(Tensor([10, 0],"float32"), Tensor([10, 0],"float32"), rcond=None, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([10, 0],"float32"), Tensor([10, 0],"float32"), rcond=None, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:27.937057 GPU 1 61385 test begin: paddle.linalg.lstsq(Tensor([10, 0],"float32"), Tensor([10, 8],"float32"), rcond=None, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([10, 0],"float32"), Tensor([10, 8],"float32"), rcond=None, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:27.976039 GPU 0 61448 test begin: paddle.linalg.lstsq(Tensor([10, 5],"float32"), Tensor([10, 0],"float32"), rcond=None, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([10, 5],"float32"), Tensor([10, 0],"float32"), rcond=None, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:27.999863 GPU 1 61478 test begin: paddle.linalg.lstsq(Tensor([10, 7, 0],"float64"), Tensor([10, 7, 0],"float64"), rcond=1e-15, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([10, 7, 0],"float64"), Tensor([10, 7, 0],"float64"), rcond=1e-15, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:28.071036 GPU 1 61458 test begin: paddle.linalg.lstsq(Tensor([10, 7, 0],"float64"), Tensor([10, 7, 6],"float64"), rcond=1e-15, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([10, 7, 0],"float64"), Tensor([10, 7, 6],"float64"), rcond=1e-15, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:28.282252 GPU 1 61438 test begin: paddle.linalg.lstsq(Tensor([10, 7, 3],"float64"), Tensor([10, 7, 0],"float64"), rcond=1e-15, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([10, 7, 3],"float64"), Tensor([10, 7, 0],"float64"), rcond=1e-15, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:28.320790 GPU 1 61490 test begin: paddle.linalg.lstsq(Tensor([10, 8, 0],"float64"), Tensor([10, 8, 0],"float64"), rcond=1e-15, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([10, 8, 0],"float64"), Tensor([10, 8, 0],"float64"), rcond=1e-15, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:28.433211 GPU 1 61385 test begin: paddle.linalg.lstsq(Tensor([10, 8, 0],"float64"), Tensor([10, 8, 10],"float64"), rcond=1e-15, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([10, 8, 0],"float64"), Tensor([10, 8, 10],"float64"), rcond=1e-15, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:28.456117 GPU 1 61245 test begin: paddle.linalg.lstsq(Tensor([10, 8, 6],"float64"), Tensor([10, 8, 0],"float64"), rcond=1e-15, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([10, 8, 6],"float64"), Tensor([10, 8, 0],"float64"), rcond=1e-15, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:28.614054 GPU 1 61478 test begin: paddle.linalg.lstsq(Tensor([3, 0, 8],"float32"), Tensor([3, 0, 15],"float32"), rcond=None, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([3, 0, 8],"float32"), Tensor([3, 0, 15],"float32"), rcond=None, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:28.664132 GPU 0 61448 test begin: paddle.linalg.lstsq(Tensor([3, 2, 0],"float32"), Tensor([3, 2, 0],"float32"), rcond=None, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([3, 2, 0],"float32"), Tensor([3, 2, 0],"float32"), rcond=None, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:28.683185 GPU 1 61428 test begin: paddle.linalg.lstsq(Tensor([3, 2, 0],"float32"), Tensor([3, 2, 15],"float32"), rcond=None, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([3, 2, 0],"float32"), Tensor([3, 2, 15],"float32"), rcond=None, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:28.795800 GPU 1 61490 test begin: paddle.linalg.lstsq(Tensor([3, 2, 8],"float32"), Tensor([3, 2, 0],"float32"), rcond=None, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([3, 2, 8],"float32"), Tensor([3, 2, 0],"float32"), rcond=None, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:28.830196 GPU 1 61458 test begin: paddle.linalg.lstsq(Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), rcond=1e-15, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), rcond=1e-15, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:28.947147 GPU 1 61438 test begin: paddle.linalg.lstsq(Tensor([5, 0],"float64"), Tensor([5, 8],"float64"), rcond=1e-15, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([5, 0],"float64"), Tensor([5, 8],"float64"), rcond=1e-15, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:29.204841 GPU 1 61478 test begin: paddle.linalg.lstsq(Tensor([5, 10],"float64"), Tensor([5, 0],"float64"), rcond=1e-15, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([5, 10],"float64"), Tensor([5, 0],"float64"), rcond=1e-15, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:29.229754 GPU 1 61458 test begin: paddle.linalg.lstsq(Tensor([9, 0],"float32"), Tensor([9, 0],"float32"), rcond=1e-15, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([9, 0],"float32"), Tensor([9, 0],"float32"), rcond=1e-15, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:29.254337 GPU 1 61385 test begin: paddle.linalg.lstsq(Tensor([9, 0],"float32"), Tensor([9, 5],"float32"), rcond=1e-15, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([9, 0],"float32"), Tensor([9, 5],"float32"), rcond=1e-15, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:29.296038 GPU 1 61245 test begin: paddle.linalg.lstsq(Tensor([9, 9],"float32"), Tensor([9, 0],"float32"), rcond=1e-15, driver="gels", )
[paddle error] paddle.linalg.lstsq(Tensor([9, 9],"float32"), Tensor([9, 0],"float32"), rcond=1e-15, driver="gels", ) 
 (PreconditionNotMet) Tensor holds no memory. Call Tensor::mutable_data firstly.
  [Hint: holder_ should not be null.] (at ../paddle/phi/core/dense_tensor_impl.cc:43)


2025-06-05 15:23:29.330369 GPU 0 61448 test begin: paddle.linalg.matrix_norm(x=Tensor([0, 3, 4, 5],"float64"), p=-2, axis=list[1,2,], keepdim=False, )
[paddle error] paddle.linalg.matrix_norm(x=Tensor([0, 3, 4, 5],"float64"), p=-2, axis=list[1,2,], keepdim=False, ) 
 (InvalidArgument) Zero-size tensor to reduction operation minimum which has no identity.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/reduce_min_kernel.cc:30)


2025-06-05 15:23:29.519226 GPU 1 61438 test begin: paddle.linalg.matrix_norm(x=Tensor([0, 3, 4, 5],"float64"), p=-2, axis=list[1,2,], keepdim=True, )
[paddle error] paddle.linalg.matrix_norm(x=Tensor([0, 3, 4, 5],"float64"), p=-2, axis=list[1,2,], keepdim=True, ) 
 (InvalidArgument) Zero-size tensor to reduction operation minimum which has no identity.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/reduce_min_kernel.cc:30)


2025-06-05 15:23:29.812498 GPU 1 61428 test begin: paddle.linalg.matrix_norm(x=Tensor([0, 3, 4],"float64"), p="nuc", axis=list[0,1,], keepdim=False, )
[accuracy error] backward  paddle.linalg.matrix_norm(x=Tensor([0, 3, 4],"float64"), p="nuc", axis=list[0,1,], keepdim=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'shape' do not match: torch.Size([0, 0, 4, 3]) != torch.Size([0, 3, 4]).
ACTUAL: (shape=torch.Size([0, 0, 4, 3]), dtype=torch.float64)
tensor([], size=(0, 0, 4, 3), dtype=torch.float64)
DESIRED: (shape=torch.Size([0, 3, 4]), dtype=torch.float64)
tensor([], size=(0, 3, 4), dtype=torch.float64)

2025-06-05 15:23:29.826281 GPU 1 61245 test begin: paddle.linalg.matrix_norm(x=Tensor([0, 3, 4],"float64"), p="nuc", axis=list[0,1,], keepdim=True, )
[accuracy error] backward  paddle.linalg.matrix_norm(x=Tensor([0, 3, 4],"float64"), p="nuc", axis=list[0,1,], keepdim=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'shape' do not match: torch.Size([0, 0, 4, 3]) != torch.Size([0, 3, 4]).
ACTUAL: (shape=torch.Size([0, 0, 4, 3]), dtype=torch.float64)
tensor([], size=(0, 0, 4, 3), dtype=torch.float64)
DESIRED: (shape=torch.Size([0, 3, 4]), dtype=torch.float64)
tensor([], size=(0, 3, 4), dtype=torch.float64)

2025-06-05 15:23:29.857214 GPU 1 61458 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 0, 4],"float64"), p="nuc", axis=list[0,1,], keepdim=False, )
[accuracy error] backward  paddle.linalg.matrix_norm(x=Tensor([2, 0, 4],"float64"), p="nuc", axis=list[0,1,], keepdim=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'shape' do not match: torch.Size([2, 0, 4, 0]) != torch.Size([2, 0, 4]).
ACTUAL: (shape=torch.Size([2, 0, 4, 0]), dtype=torch.float64)
tensor([], size=(2, 0, 4, 0), dtype=torch.float64)
DESIRED: (shape=torch.Size([2, 0, 4]), dtype=torch.float64)
tensor([], size=(2, 0, 4), dtype=torch.float64)

2025-06-05 15:23:30.011829 GPU 0 61448 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 0, 4],"float64"), p="nuc", axis=list[0,1,], keepdim=True, )
[accuracy error] backward  paddle.linalg.matrix_norm(x=Tensor([2, 0, 4],"float64"), p="nuc", axis=list[0,1,], keepdim=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'shape' do not match: torch.Size([2, 0, 4, 0]) != torch.Size([2, 0, 4]).
ACTUAL: (shape=torch.Size([2, 0, 4, 0]), dtype=torch.float64)
tensor([], size=(2, 0, 4, 0), dtype=torch.float64)
DESIRED: (shape=torch.Size([2, 0, 4]), dtype=torch.float64)
tensor([], size=(2, 0, 4), dtype=torch.float64)

2025-06-05 15:23:30.257466 GPU 1 61385 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 3, 0],"float64"), p="nuc", axis=list[0,1,], keepdim=False, )
[accuracy error] backward  paddle.linalg.matrix_norm(x=Tensor([2, 3, 0],"float64"), p="nuc", axis=list[0,1,], keepdim=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'shape' do not match: torch.Size([2, 2, 0, 3]) != torch.Size([2, 3, 0]).
ACTUAL: (shape=torch.Size([2, 2, 0, 3]), dtype=torch.float64)
tensor([], size=(2, 2, 0, 3), dtype=torch.float64)
DESIRED: (shape=torch.Size([2, 3, 0]), dtype=torch.float64)
tensor([], size=(2, 3, 0), dtype=torch.float64)

2025-06-05 15:23:30.336538 GPU 1 61458 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 3, 0],"float64"), p="nuc", axis=list[0,1,], keepdim=True, )
[accuracy error] backward  paddle.linalg.matrix_norm(x=Tensor([2, 3, 0],"float64"), p="nuc", axis=list[0,1,], keepdim=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'shape' do not match: torch.Size([2, 2, 0, 3]) != torch.Size([2, 3, 0]).
ACTUAL: (shape=torch.Size([2, 2, 0, 3]), dtype=torch.float64)
tensor([], size=(2, 2, 0, 3), dtype=torch.float64)
DESIRED: (shape=torch.Size([2, 3, 0]), dtype=torch.float64)
tensor([], size=(2, 3, 0), dtype=torch.float64)

2025-06-05 15:23:30.339720 GPU 0 61448 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 3, 0],"float64"), p=-math.inf, axis=list[0,1,], keepdim=False, )
[paddle error] paddle.linalg.matrix_norm(x=Tensor([2, 3, 0],"float64"), p=-math.inf, axis=list[0,1,], keepdim=False, ) 
 (InvalidArgument) Zero-size tensor to reduction operation minimum which has no identity.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/reduce_min_kernel.cc:30)


2025-06-05 15:23:30.368231 GPU 1 61490 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 3, 0],"float64"), p=-math.inf, axis=list[0,1,], keepdim=True, )
[paddle error] paddle.linalg.matrix_norm(x=Tensor([2, 3, 0],"float64"), p=-math.inf, axis=list[0,1,], keepdim=True, ) 
 (InvalidArgument) Zero-size tensor to reduction operation minimum which has no identity.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/reduce_min_kernel.cc:30)


2025-06-05 15:23:30.429095 GPU 1 61438 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 3, 4, 0],"float64"), p=-2, axis=list[1,2,], keepdim=False, )
[paddle error] paddle.linalg.matrix_norm(x=Tensor([2, 3, 4, 0],"float64"), p=-2, axis=list[1,2,], keepdim=False, ) 
 (InvalidArgument) Zero-size tensor to reduction operation minimum which has no identity.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/reduce_min_kernel.cc:30)


2025-06-05 15:23:30.441739 GPU 1 61428 test begin: paddle.linalg.matrix_norm(x=Tensor([2, 3, 4, 0],"float64"), p=-2, axis=list[1,2,], keepdim=True, )
[paddle error] paddle.linalg.matrix_norm(x=Tensor([2, 3, 4, 0],"float64"), p=-2, axis=list[1,2,], keepdim=True, ) 
 (InvalidArgument) Zero-size tensor to reduction operation minimum which has no identity.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/reduce_min_kernel.cc:30)


2025-06-05 15:23:32.331555 GPU 1 61438 test begin: paddle.linalg.matrix_rank(Tensor([0, 10],"float32"), hermitian=True, )
Warning: The core code of paddle.linalg.matrix_rank is too complex.
[paddle error] paddle.linalg.matrix_rank(Tensor([0, 10],"float32"), hermitian=True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:0 != cols:10.] (at ../paddle/phi/infermeta/unary.cc:2510)


2025-06-05 15:23:32.337745 GPU 1 61478 test begin: paddle.linalg.matrix_rank(Tensor([0, 10],"float32"), hermitian=True, atol=0.015, rtol=None, )
Warning: The core code of paddle.linalg.matrix_rank is too complex.
[paddle error] paddle.linalg.matrix_rank(Tensor([0, 10],"float32"), hermitian=True, atol=0.015, rtol=None, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:0 != cols:10.] (at ../paddle/phi/infermeta/binary.cc:3154)


2025-06-05 15:23:32.549031 GPU 0 61448 test begin: paddle.linalg.matrix_rank(Tensor([0, 10],"float32"), hermitian=True, atol=0.2, rtol=0.05, )
Warning: The core code of paddle.linalg.matrix_rank is too complex.
[paddle error] paddle.linalg.matrix_rank(Tensor([0, 10],"float32"), hermitian=True, atol=0.2, rtol=0.05, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:0 != cols:10.] (at ../paddle/phi/infermeta/binary.cc:3154)


2025-06-05 15:23:32.600761 GPU 1 61428 test begin: paddle.linalg.matrix_rank(Tensor([0, 10],"float32"), hermitian=True, atol=None, rtol=1.1, )
Warning: The core code of paddle.linalg.matrix_rank is too complex.
[paddle error] paddle.linalg.matrix_rank(Tensor([0, 10],"float32"), hermitian=True, atol=None, rtol=1.1, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:0 != cols:10.] (at ../paddle/phi/infermeta/binary.cc:3154)


2025-06-05 15:23:32.686107 GPU 1 61490 test begin: paddle.linalg.matrix_rank(Tensor([0, 10],"float32"), tol=Tensor([2],"float32"), )
Warning: The core code of paddle.linalg.matrix_rank is too complex.
[accuracy error] paddle.linalg.matrix_rank(Tensor([0, 10],"float32"), tol=Tensor([2],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'shape' do not match: torch.Size([2]) != torch.Size([]).
ACTUAL: (shape=torch.Size([2]), dtype=torch.int64)
tensor([0, 0])
DESIRED: (shape=torch.Size([]), dtype=torch.int64)
0

2025-06-05 15:23:32.743582 GPU 1 61478 test begin: paddle.linalg.matrix_rank(Tensor([0, 1],"float64"), Tensor([0, 4],"float64"), False, )
[accuracy error] paddle.linalg.matrix_rank(Tensor([0, 1],"float64"), Tensor([0, 4],"float64"), False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'shape' do not match: torch.Size([0, 4]) != torch.Size([]).
ACTUAL: (shape=torch.Size([0, 4]), dtype=torch.int64)
tensor([], size=(0, 4), dtype=torch.int64)
DESIRED: (shape=torch.Size([]), dtype=torch.int64)
0

2025-06-05 15:23:32.778044 GPU 1 61245 test begin: paddle.linalg.matrix_rank(Tensor([0, 1],"float64"), Tensor([1, 4],"float64"), False, )
Warning: The core code of paddle.linalg.matrix_rank is too complex.
[accuracy error] paddle.linalg.matrix_rank(Tensor([0, 1],"float64"), Tensor([1, 4],"float64"), False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'shape' do not match: torch.Size([1, 4]) != torch.Size([]).
ACTUAL: (shape=torch.Size([1, 4]), dtype=torch.int64)
tensor([[0, 0, 0, 0]])
DESIRED: (shape=torch.Size([]), dtype=torch.int64)
0

2025-06-05 15:23:32.801572 GPU 1 61458 test begin: paddle.linalg.matrix_rank(Tensor([0, 200],"float64"), Tensor([0, 200],"float64"), True, )
[paddle error] paddle.linalg.matrix_rank(Tensor([0, 200],"float64"), Tensor([0, 200],"float64"), True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:0 != cols:200.] (at ../paddle/phi/infermeta/binary.cc:3154)


2025-06-05 15:23:33.035500 GPU 0 61448 test begin: paddle.linalg.matrix_rank(Tensor([0, 200],"float64"), Tensor([200, 200],"float64"), True, )
[paddle error] paddle.linalg.matrix_rank(Tensor([0, 200],"float64"), Tensor([200, 200],"float64"), True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:0 != cols:200.] (at ../paddle/phi/infermeta/binary.cc:3154)


2025-06-05 15:23:33.053123 GPU 1 61385 test begin: paddle.linalg.matrix_rank(Tensor([0, 3],"float32"), 0.1, True, )
[paddle error] paddle.linalg.matrix_rank(Tensor([0, 3],"float32"), 0.1, True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:0 != cols:3.] (at ../paddle/phi/infermeta/unary.cc:2510)


2025-06-05 15:23:33.070918 GPU 1 61458 test begin: paddle.linalg.matrix_rank(Tensor([0, 4, 5, 5],"float64"), hermitian=False, atol=Tensor([3, 4],"float64"), rtol=None, )
[paddle error] paddle.linalg.matrix_rank(Tensor([0, 4, 5, 5],"float64"), hermitian=False, atol=Tensor([3, 4],"float64"), rtol=None, ) 
 (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [0, 4] and the shape of Y = [3, 4]. Received [0] in X is not equal to [3] in Y at i:0.
  [Hint: Expected x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0) == true, but received x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0):0 != true:1.] (at ../paddle/phi/kernels/funcs/common_shape.h:72)


2025-06-05 15:23:33.071270 GPU 1 61478 test begin: paddle.linalg.matrix_rank(Tensor([0, 4, 5, 6],"float32"), Tensor([3, 4],"float32"), False, )
[paddle error] paddle.linalg.matrix_rank(Tensor([0, 4, 5, 6],"float32"), Tensor([3, 4],"float32"), False, ) 
 (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [0, 4] and the shape of Y = [3, 4]. Received [0] in X is not equal to [3] in Y at i:0.
  [Hint: Expected x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0) == true, but received x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0):0 != true:1.] (at ../paddle/phi/kernels/funcs/common_shape.h:72)


2025-06-05 15:23:33.080020 GPU 1 61438 test begin: paddle.linalg.matrix_rank(Tensor([0, 4, 7, 8],"float64"), Tensor([3, 4],"float32"), hermitian=False, )
[paddle error] paddle.linalg.matrix_rank(Tensor([0, 4, 7, 8],"float64"), Tensor([3, 4],"float32"), hermitian=False, ) 
 (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [0, 4] and the shape of Y = [3, 4]. Received [0] in X is not equal to [3] in Y at i:0.
  [Hint: Expected x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0) == true, but received x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0):0 != true:1.] (at ../paddle/phi/kernels/funcs/common_shape.h:72)


2025-06-05 15:23:33.175421 GPU 1 61428 test begin: paddle.linalg.matrix_rank(Tensor([0, 4, 7, 8],"float64"), hermitian=False, atol=Tensor([3, 1],"float32"), rtol=Tensor([3, 1],"float32"), )
[paddle error] paddle.linalg.matrix_rank(Tensor([0, 4, 7, 8],"float64"), hermitian=False, atol=Tensor([3, 1],"float32"), rtol=Tensor([3, 1],"float32"), ) 
 (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [0, 4] and the shape of Y = [3, 1]. Received [0] in X is not equal to [3] in Y at i:0.
  [Hint: Expected x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0) == true, but received x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0):0 != true:1.] (at ../paddle/phi/kernels/funcs/common_shape.h:72)


2025-06-05 15:23:33.182758 GPU 1 61490 test begin: paddle.linalg.matrix_rank(Tensor([0, 4, 7, 8],"float64"), hermitian=False, atol=Tensor([3, 4],"float32"), rtol=Tensor([3, 4],"float32"), )
[paddle error] paddle.linalg.matrix_rank(Tensor([0, 4, 7, 8],"float64"), hermitian=False, atol=Tensor([3, 4],"float32"), rtol=Tensor([3, 4],"float32"), ) 
 (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [0, 4] and the shape of Y = [3, 4]. Received [0] in X is not equal to [3] in Y at i:0.
  [Hint: Expected x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0) == true, but received x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0):0 != true:1.] (at ../paddle/phi/kernels/funcs/common_shape.h:72)


2025-06-05 15:23:33.409686 GPU 1 61245 test begin: paddle.linalg.matrix_rank(Tensor([10, 0],"float32"), hermitian=True, )
[paddle error] paddle.linalg.matrix_rank(Tensor([10, 0],"float32"), hermitian=True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:10 != cols:0.] (at ../paddle/phi/infermeta/unary.cc:2510)


2025-06-05 15:23:33.509380 GPU 1 61490 test begin: paddle.linalg.matrix_rank(Tensor([10, 0],"float32"), hermitian=True, atol=0.015, rtol=None, )
[paddle error] paddle.linalg.matrix_rank(Tensor([10, 0],"float32"), hermitian=True, atol=0.015, rtol=None, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:10 != cols:0.] (at ../paddle/phi/infermeta/binary.cc:3154)


2025-06-05 15:23:33.514075 GPU 0 61448 test begin: paddle.linalg.matrix_rank(Tensor([10, 0],"float32"), hermitian=True, atol=0.2, rtol=0.05, )
[paddle error] paddle.linalg.matrix_rank(Tensor([10, 0],"float32"), hermitian=True, atol=0.2, rtol=0.05, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:10 != cols:0.] (at ../paddle/phi/infermeta/binary.cc:3154)


2025-06-05 15:23:33.580907 GPU 1 61385 test begin: paddle.linalg.matrix_rank(Tensor([10, 0],"float32"), hermitian=True, atol=None, rtol=1.1, )
[paddle error] paddle.linalg.matrix_rank(Tensor([10, 0],"float32"), hermitian=True, atol=None, rtol=1.1, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:10 != cols:0.] (at ../paddle/phi/infermeta/binary.cc:3154)


2025-06-05 15:23:33.616777 GPU 1 61438 test begin: paddle.linalg.matrix_rank(Tensor([10, 0],"float32"), tol=Tensor([2],"float32"), )
[accuracy error] paddle.linalg.matrix_rank(Tensor([10, 0],"float32"), tol=Tensor([2],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'shape' do not match: torch.Size([2]) != torch.Size([]).
ACTUAL: (shape=torch.Size([2]), dtype=torch.int64)
tensor([0, 0])
DESIRED: (shape=torch.Size([]), dtype=torch.int64)
0

2025-06-05 15:23:33.726108 GPU 1 61428 test begin: paddle.linalg.matrix_rank(Tensor([200, 0],"float64"), Tensor([200, 0],"float64"), True, )
[paddle error] paddle.linalg.matrix_rank(Tensor([200, 0],"float64"), Tensor([200, 0],"float64"), True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:200 != cols:0.] (at ../paddle/phi/infermeta/binary.cc:3154)


2025-06-05 15:23:33.842093 GPU 1 61490 test begin: paddle.linalg.matrix_rank(Tensor([200, 0],"float64"), Tensor([200, 200],"float64"), True, )
[paddle error] paddle.linalg.matrix_rank(Tensor([200, 0],"float64"), Tensor([200, 200],"float64"), True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:200 != cols:0.] (at ../paddle/phi/infermeta/binary.cc:3154)


2025-06-05 15:23:33.990833 GPU 1 61438 test begin: paddle.linalg.matrix_rank(Tensor([3, 0, 5, 5],"float64"), hermitian=False, atol=Tensor([3, 4],"float64"), rtol=None, )
[paddle error] paddle.linalg.matrix_rank(Tensor([3, 0, 5, 5],"float64"), hermitian=False, atol=Tensor([3, 4],"float64"), rtol=None, ) 
 (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [3, 0] and the shape of Y = [3, 4]. Received [0] in X is not equal to [4] in Y at i:1.
  [Hint: Expected x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0) == true, but received x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0):0 != true:1.] (at ../paddle/phi/kernels/funcs/common_shape.h:72)


2025-06-05 15:23:33.995890 GPU 0 61448 test begin: paddle.linalg.matrix_rank(Tensor([3, 0, 5, 6],"float32"), Tensor([3, 4],"float32"), False, )
[paddle error] paddle.linalg.matrix_rank(Tensor([3, 0, 5, 6],"float32"), Tensor([3, 4],"float32"), False, ) 
 (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [3, 0] and the shape of Y = [3, 4]. Received [0] in X is not equal to [4] in Y at i:1.
  [Hint: Expected x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0) == true, but received x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0):0 != true:1.] (at ../paddle/phi/kernels/funcs/common_shape.h:72)


2025-06-05 15:23:34.175596 GPU 1 61428 test begin: paddle.linalg.matrix_rank(Tensor([3, 0, 7, 8],"float64"), Tensor([3, 4],"float32"), hermitian=False, )
[paddle error] paddle.linalg.matrix_rank(Tensor([3, 0, 7, 8],"float64"), Tensor([3, 4],"float32"), hermitian=False, ) 
 (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [3, 0] and the shape of Y = [3, 4]. Received [0] in X is not equal to [4] in Y at i:1.
  [Hint: Expected x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0) == true, but received x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0):0 != true:1.] (at ../paddle/phi/kernels/funcs/common_shape.h:72)


2025-06-05 15:23:34.215697 GPU 1 61245 test begin: paddle.linalg.matrix_rank(Tensor([3, 0, 7, 8],"float64"), hermitian=False, atol=Tensor([3, 4],"float32"), rtol=Tensor([3, 4],"float32"), )
[paddle error] paddle.linalg.matrix_rank(Tensor([3, 0, 7, 8],"float64"), hermitian=False, atol=Tensor([3, 4],"float32"), rtol=Tensor([3, 4],"float32"), ) 
 (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [3, 0] and the shape of Y = [3, 4]. Received [0] in X is not equal to [4] in Y at i:1.
  [Hint: Expected x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0) == true, but received x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0):0 != true:1.] (at ../paddle/phi/kernels/funcs/common_shape.h:72)


2025-06-05 15:23:34.222130 GPU 1 61385 test begin: paddle.linalg.matrix_rank(Tensor([3, 0],"float32"), 0.1, True, )
[paddle error] paddle.linalg.matrix_rank(Tensor([3, 0],"float32"), 0.1, True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:3 != cols:0.] (at ../paddle/phi/infermeta/unary.cc:2510)


2025-06-05 15:23:34.392580 GPU 1 61478 test begin: paddle.linalg.matrix_rank(Tensor([3, 4, 0, 5],"float64"), hermitian=True, atol=0.5, rtol=None, )
[paddle error] paddle.linalg.matrix_rank(Tensor([3, 4, 0, 5],"float64"), hermitian=True, atol=0.5, rtol=None, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:0 != cols:5.] (at ../paddle/phi/infermeta/binary.cc:3154)


2025-06-05 15:23:34.726052 GPU 1 61385 test begin: paddle.linalg.matrix_rank(Tensor([3, 4, 5, 0],"float64"), hermitian=True, atol=0.5, rtol=None, )
[paddle error] paddle.linalg.matrix_rank(Tensor([3, 4, 5, 0],"float64"), hermitian=True, atol=0.5, rtol=None, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:5 != cols:0.] (at ../paddle/phi/infermeta/binary.cc:3154)


2025-06-05 15:23:34.919814 GPU 1 61478 test begin: paddle.linalg.matrix_rank(Tensor([5, 0],"float64"), Tensor([1, 0],"float64"), False, )
[accuracy error] paddle.linalg.matrix_rank(Tensor([5, 0],"float64"), Tensor([1, 0],"float64"), False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'shape' do not match: torch.Size([1, 0]) != torch.Size([]).
ACTUAL: (shape=torch.Size([1, 0]), dtype=torch.int64)
tensor([], size=(1, 0), dtype=torch.int64)
DESIRED: (shape=torch.Size([]), dtype=torch.int64)
0

2025-06-05 15:23:34.926053 GPU 1 61490 test begin: paddle.linalg.matrix_rank(Tensor([5, 0],"float64"), Tensor([1, 4],"float64"), False, )
[accuracy error] paddle.linalg.matrix_rank(Tensor([5, 0],"float64"), Tensor([1, 4],"float64"), False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'shape' do not match: torch.Size([1, 4]) != torch.Size([]).
ACTUAL: (shape=torch.Size([1, 4]), dtype=torch.int64)
tensor([[0, 0, 0, 0]])
DESIRED: (shape=torch.Size([]), dtype=torch.int64)
0

2025-06-05 15:23:34.961132 GPU 1 61458 test begin: paddle.linalg.matrix_rank(x=Tensor([0, 3, 4, 4],"float64"), tol=Tensor([2, 3],"float64"), hermitian=True, )
[paddle error] paddle.linalg.matrix_rank(x=Tensor([0, 3, 4, 4],"float64"), tol=Tensor([2, 3],"float64"), hermitian=True, ) 
 (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [0, 3] and the shape of Y = [2, 3]. Received [0] in X is not equal to [2] in Y at i:0.
  [Hint: Expected x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0) == true, but received x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0):0 != true:1.] (at ../paddle/phi/kernels/funcs/common_shape.h:72)


2025-06-05 15:23:34.992206 GPU 0 61448 test begin: paddle.linalg.matrix_rank(x=Tensor([0, 4, 4, 5],"float64"), tol=Tensor([2, 1],"float64"), hermitian=False, )
[paddle error] paddle.linalg.matrix_rank(x=Tensor([0, 4, 4, 5],"float64"), tol=Tensor([2, 1],"float64"), hermitian=False, ) 
 (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [0, 4] and the shape of Y = [2, 1]. Received [0] in X is not equal to [2] in Y at i:0.
  [Hint: Expected x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0) == true, but received x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0):0 != true:1.] (at ../paddle/phi/kernels/funcs/common_shape.h:72)


2025-06-05 15:23:34.993392 GPU 1 61428 test begin: paddle.linalg.matrix_rank(x=Tensor([0, 4],"float64"), tol=4.4, hermitian=True, )
[paddle error] paddle.linalg.matrix_rank(x=Tensor([0, 4],"float64"), tol=4.4, hermitian=True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:0 != cols:4.] (at ../paddle/phi/infermeta/unary.cc:2510)


2025-06-05 15:23:35.012392 GPU 1 61245 test begin: paddle.linalg.matrix_rank(x=Tensor([0, 4],"float64"), tol=Tensor([1],"float64"), hermitian=True, )
[paddle error] paddle.linalg.matrix_rank(x=Tensor([0, 4],"float64"), tol=Tensor([1],"float64"), hermitian=True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:0 != cols:4.] (at ../paddle/phi/infermeta/binary.cc:3154)


2025-06-05 15:23:35.140308 GPU 0 61479 test begin: paddle.linalg.matrix_rank(x=Tensor([2, 0, 4, 4],"float64"), tol=Tensor([2, 3],"float64"), hermitian=True, )
Warning: The core code of paddle.linalg.matrix_rank is too complex.
[paddle error] paddle.linalg.matrix_rank(x=Tensor([2, 0, 4, 4],"float64"), tol=Tensor([2, 3],"float64"), hermitian=True, ) 
 (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [2, 0] and the shape of Y = [2, 3]. Received [0] in X is not equal to [3] in Y at i:1.
  [Hint: Expected x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0) == true, but received x_dims_array[i] == y_dims_array[i] || (x_dims_array[i] <= 1 && x_dims_array[i] != 0) || (y_dims_array[i] <= 1 && y_dims_array[i] != 0):0 != true:1.] (at ../paddle/phi/kernels/funcs/common_shape.h:72)


2025-06-05 15:23:35.152430 GPU 1 61490 test begin: paddle.linalg.matrix_rank(x=Tensor([2, 2, 0, 4],"float64"), tol=Tensor([1, 1],"float64"), hermitian=True, )
[paddle error] paddle.linalg.matrix_rank(x=Tensor([2, 2, 0, 4],"float64"), tol=Tensor([1, 1],"float64"), hermitian=True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:0 != cols:4.] (at ../paddle/phi/infermeta/binary.cc:3154)


2025-06-05 15:23:35.169691 GPU 0 61995 test begin: paddle.linalg.matrix_rank(x=Tensor([2, 2, 4, 0],"float64"), tol=Tensor([1, 1],"float64"), hermitian=True, )
Warning: The core code of paddle.linalg.matrix_rank is too complex.
[paddle error] paddle.linalg.matrix_rank(x=Tensor([2, 2, 4, 0],"float64"), tol=Tensor([1, 1],"float64"), hermitian=True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:4 != cols:0.] (at ../paddle/phi/infermeta/binary.cc:3154)


2025-06-05 15:23:35.187180 GPU 1 61478 test begin: paddle.linalg.matrix_rank(x=Tensor([2, 3, 0, 4],"float64"), tol=Tensor([1],"float64"), hermitian=True, )
[paddle error] paddle.linalg.matrix_rank(x=Tensor([2, 3, 0, 4],"float64"), tol=Tensor([1],"float64"), hermitian=True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:0 != cols:4.] (at ../paddle/phi/infermeta/binary.cc:3154)


2025-06-05 15:23:35.212235 GPU 1 61458 test begin: paddle.linalg.matrix_rank(x=Tensor([2, 3, 0, 4],"float64"), tol=Tensor([2, 3],"float64"), hermitian=True, )
[paddle error] paddle.linalg.matrix_rank(x=Tensor([2, 3, 0, 4],"float64"), tol=Tensor([2, 3],"float64"), hermitian=True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:0 != cols:4.] (at ../paddle/phi/infermeta/binary.cc:3154)


2025-06-05 15:23:35.244000 GPU 0 61448 test begin: paddle.linalg.matrix_rank(x=Tensor([2, 3, 4, 0],"float64"), tol=Tensor([1],"float64"), hermitian=True, )
[paddle error] paddle.linalg.matrix_rank(x=Tensor([2, 3, 4, 0],"float64"), tol=Tensor([1],"float64"), hermitian=True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:4 != cols:0.] (at ../paddle/phi/infermeta/binary.cc:3154)


2025-06-05 15:23:35.254900 GPU 1 61245 test begin: paddle.linalg.matrix_rank(x=Tensor([2, 3, 4, 0],"float64"), tol=Tensor([2, 3],"float64"), hermitian=True, )
[paddle error] paddle.linalg.matrix_rank(x=Tensor([2, 3, 4, 0],"float64"), tol=Tensor([2, 3],"float64"), hermitian=True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:4 != cols:0.] (at ../paddle/phi/infermeta/binary.cc:3154)


2025-06-05 15:23:35.372435 GPU 1 61490 test begin: paddle.linalg.matrix_rank(x=Tensor([4, 0],"float64"), tol=4.4, hermitian=True, )
[paddle error] paddle.linalg.matrix_rank(x=Tensor([4, 0],"float64"), tol=4.4, hermitian=True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:4 != cols:0.] (at ../paddle/phi/infermeta/unary.cc:2510)


2025-06-05 15:23:35.404058 GPU 1 61428 test begin: paddle.linalg.matrix_rank(x=Tensor([4, 0],"float64"), tol=Tensor([1],"float64"), hermitian=True, )
[paddle error] paddle.linalg.matrix_rank(x=Tensor([4, 0],"float64"), tol=Tensor([1],"float64"), hermitian=True, ) 
 (InvalidArgument) if hermitian == true, matrix should be n*n
  [Hint: Expected rows == cols, but received rows:4 != cols:0.] (at ../paddle/phi/infermeta/binary.cc:3154)


2025-06-05 15:23:35.507799 GPU 0 61448 test begin: paddle.linalg.multi_dot(list[Tensor([4],"float64"),Tensor([4, 3],"float64"),Tensor([3, 0],"float64"),], )

Intel MKL ERROR: Parameter 11 was incorrect on entry to cblas_dgemm.

Intel MKL ERROR: Parameter 11 was incorrect on entry to cblas_dgemm.

Intel MKL ERROR: Parameter 11 was incorrect on entry to cblas_dgemm.

Intel MKL ERROR: Parameter 11 was incorrect on entry to cblas_dgemm.

Intel MKL ERROR: Parameter 9 was incorrect on entry to cblas_dgemm.

Intel MKL ERROR: Parameter 11 was incorrect on entry to cblas_dgemm.

Intel MKL ERROR: Parameter 9 was incorrect on entry to cblas_dgemm.
[accuracy error] backward  paddle.linalg.multi_dot(list[Tensor([4],"float64"),Tensor([4, 3],"float64"),Tensor([3, 0],"float64"),], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 4 / 12 (33.3%)
Greatest absolute difference: 0.4046155174175975 at index (2, 0) (up to 0.01 allowed)
Greatest relative difference: inf at index (1, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 3]), dtype=torch.float64)
tensor([[ 0.0000e+00, 4.8806e-313, 6.5782e-313],
        [ 3.3589e-01, 4.8507e-317,  1.2369e-03],
        [ 4.0462e-01, 4.8806e-313, 6.1538e-313],
        [-3.2796e-01, 1.9118e-314,  3.4728e-01]], dtype=torch.float64)
DESIRED: (shape=torch.Size([4, 3]), dtype=torch.float64)
tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], dtype=torch.float64)

2025-06-05 15:23:35.742032 GPU 1 61245 test begin: paddle.linalg.norm(x=Tensor([0, 3, 3],"float64"), axis=list[1,2,], p=1, )
[paddle error] paddle.linalg.norm(x=Tensor([0, 3, 3],"float64"), axis=list[1,2,], p=1, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:35.760156 GPU 1 61428 test begin: paddle.linalg.norm(x=Tensor([0, 3, 3],"float64"), axis=list[1,2,], p=math.inf, )
[paddle error] paddle.linalg.norm(x=Tensor([0, 3, 3],"float64"), axis=list[1,2,], p=math.inf, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:35.778617 GPU 0 61448 test begin: paddle.linalg.norm(x=Tensor([2, 3, 0],"float64"), p=-math.inf, axis=list[0,1,], keepdim=False, )
[paddle error] paddle.linalg.norm(x=Tensor([2, 3, 0],"float64"), p=-math.inf, axis=list[0,1,], keepdim=False, ) 
 (InvalidArgument) Zero-size tensor to reduction operation minimum which has no identity.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/reduce_min_kernel.cc:30)


2025-06-05 15:23:35.800595 GPU 1 61490 test begin: paddle.linalg.norm(x=Tensor([2, 3, 0],"float64"), p=-math.inf, axis=list[0,1,], keepdim=True, )
[paddle error] paddle.linalg.norm(x=Tensor([2, 3, 0],"float64"), p=-math.inf, axis=list[0,1,], keepdim=True, ) 
 (InvalidArgument) Zero-size tensor to reduction operation minimum which has no identity.
  [Hint: Expected x.numel() > 0, but received x.numel():0 <= 0:0.] (at ../paddle/phi/kernels/reduce_min_kernel.cc:30)


2025-06-05 15:23:35.911947 GPU 1 61385 test begin: paddle.linalg.norm(x=Tensor([2, 3, 0],"float64"), p=1, axis=list[0,1,], keepdim=False, )
[paddle error] paddle.linalg.norm(x=Tensor([2, 3, 0],"float64"), p=1, axis=list[0,1,], keepdim=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:35.916295 GPU 0 61479 test begin: paddle.linalg.norm(x=Tensor([2, 3, 0],"float64"), p=1, axis=list[0,1,], keepdim=True, )
[paddle error] paddle.linalg.norm(x=Tensor([2, 3, 0],"float64"), p=1, axis=list[0,1,], keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:35.920654 GPU 1 61478 test begin: paddle.linalg.norm(x=Tensor([2, 3, 0],"float64"), p=2, axis=list[0,1,], keepdim=False, )
[paddle error] paddle.linalg.norm(x=Tensor([2, 3, 0],"float64"), p=2, axis=list[0,1,], keepdim=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:36.018223 GPU 1 61490 test begin: paddle.linalg.norm(x=Tensor([2, 3, 0],"float64"), p=2, axis=list[0,1,], keepdim=True, )
[paddle error] paddle.linalg.norm(x=Tensor([2, 3, 0],"float64"), p=2, axis=list[0,1,], keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:36.090354 GPU 0 61448 test begin: paddle.linalg.norm(x=Tensor([2, 3, 0],"float64"), p=math.inf, axis=list[0,1,], keepdim=False, )
[paddle error] paddle.linalg.norm(x=Tensor([2, 3, 0],"float64"), p=math.inf, axis=list[0,1,], keepdim=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:36.090333 GPU 1 61458 test begin: paddle.linalg.norm(x=Tensor([2, 3, 0],"float64"), p=math.inf, axis=list[0,1,], keepdim=True, )
[paddle error] paddle.linalg.norm(x=Tensor([2, 3, 0],"float64"), p=math.inf, axis=list[0,1,], keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:36.124172 GPU 1 61438 test begin: paddle.linalg.norm(x=Tensor([3, 0, 3],"float64"), axis=list[0,2,], p=1, )
[paddle error] paddle.linalg.norm(x=Tensor([3, 0, 3],"float64"), axis=list[0,2,], p=1, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:36.159446 GPU 1 61385 test begin: paddle.linalg.norm(x=Tensor([3, 0, 3],"float64"), axis=list[0,2,], p=2, )
[paddle error] paddle.linalg.norm(x=Tensor([3, 0, 3],"float64"), axis=list[0,2,], p=2, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:36.139226 GPU 0 61479 test begin: paddle.linalg.pinv(Tensor([0, 200, 300],"float64"), rcond=1e-15, hermitian=False, )
[paddle error] paddle.linalg.pinv(Tensor([0, 200, 300],"float64"), rcond=1e-15, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:36.143255 GPU 1 61428 test begin: paddle.linalg.pinv(Tensor([0, 4, 5],"float64"), rcond=1e-15, hermitian=False, )
[paddle error] paddle.linalg.pinv(Tensor([0, 4, 5],"float64"), rcond=1e-15, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:36.203592 GPU 1 61478 test begin: paddle.linalg.pinv(Tensor([0, 4],"float64"), rcond=1e-15, hermitian=False, )
[paddle error] paddle.linalg.pinv(Tensor([0, 4],"float64"), rcond=1e-15, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:36.206957 GPU 1 61245 test begin: paddle.linalg.pinv(Tensor([0, 5, 5],"float64"), rcond=1e-10, hermitian=False, )
[paddle error] paddle.linalg.pinv(Tensor([0, 5, 5],"float64"), rcond=1e-10, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:36.261508 GPU 0 61995 test begin: paddle.linalg.pinv(Tensor([0, 5],"float64"), rcond=1e-15, hermitian=False, )
[paddle error] paddle.linalg.pinv(Tensor([0, 5],"float64"), rcond=1e-15, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:36.279856 GPU 1 61490 test begin: paddle.linalg.pinv(Tensor([0, 6, 5, 4],"float64"), rcond=1e-15, hermitian=False, )
[paddle error] paddle.linalg.pinv(Tensor([0, 6, 5, 4],"float64"), rcond=1e-15, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:36.331412 GPU 1 61458 test begin: paddle.linalg.pinv(Tensor([2, 0, 300],"float64"), rcond=1e-15, hermitian=False, )
[paddle error] paddle.linalg.pinv(Tensor([2, 0, 300],"float64"), rcond=1e-15, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:36.340770 GPU 0 61448 test begin: paddle.linalg.pinv(Tensor([2, 200, 0],"float64"), rcond=1e-15, hermitian=False, )
[paddle error] paddle.linalg.pinv(Tensor([2, 200, 0],"float64"), rcond=1e-15, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:36.446336 GPU 1 61385 test begin: paddle.linalg.pinv(Tensor([3, 0, 5, 4],"float64"), rcond=1e-15, hermitian=False, )
[paddle error] paddle.linalg.pinv(Tensor([3, 0, 5, 4],"float64"), rcond=1e-15, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:36.466051 GPU 1 61478 test begin: paddle.linalg.pinv(Tensor([3, 0, 5],"float64"), rcond=1e-10, hermitian=False, )
[paddle error] paddle.linalg.pinv(Tensor([3, 0, 5],"float64"), rcond=1e-10, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:36.516652 GPU 1 61438 test begin: paddle.linalg.pinv(Tensor([3, 0, 5],"float64"), rcond=1e-15, hermitian=False, )
[paddle error] paddle.linalg.pinv(Tensor([3, 0, 5],"float64"), rcond=1e-15, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:36.582527 GPU 1 61490 test begin: paddle.linalg.pinv(Tensor([3, 4, 0],"float64"), rcond=1e-15, hermitian=False, )
[paddle error] paddle.linalg.pinv(Tensor([3, 4, 0],"float64"), rcond=1e-15, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:36.587595 GPU 0 61479 test begin: paddle.linalg.pinv(Tensor([3, 5, 0],"float64"), rcond=1e-10, hermitian=False, )
[paddle error] paddle.linalg.pinv(Tensor([3, 5, 0],"float64"), rcond=1e-10, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:36.587781 GPU 1 61458 test begin: paddle.linalg.pinv(Tensor([3, 6, 0, 4],"float64"), rcond=1e-15, hermitian=False, )
[paddle error] paddle.linalg.pinv(Tensor([3, 6, 0, 4],"float64"), rcond=1e-15, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:36.606829 GPU 0 61448 test begin: paddle.linalg.pinv(Tensor([3, 6, 5, 0],"float64"), rcond=1e-15, hermitian=False, )
[paddle error] paddle.linalg.pinv(Tensor([3, 6, 5, 0],"float64"), rcond=1e-15, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:36.622412 GPU 0 61995 test begin: paddle.linalg.pinv(Tensor([4, 0],"float64"), rcond=1e-15, hermitian=False, )
[paddle error] paddle.linalg.pinv(Tensor([4, 0],"float64"), rcond=1e-15, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:36.681530 GPU 0 62010 test begin: paddle.linalg.pinv(Tensor([5, 0],"float64"), rcond=1e-15, hermitian=False, )
[paddle error] paddle.linalg.pinv(Tensor([5, 0],"float64"), rcond=1e-15, hermitian=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:36.684932 GPU 1 61428 test begin: paddle.linalg.pinv(x=Tensor([0, 2, 2],"float64"), rcond=5, hermitian=True, )
[paddle error] paddle.linalg.pinv(x=Tensor([0, 2, 2],"float64"), rcond=5, hermitian=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:36.694591 GPU 1 61385 test begin: paddle.linalg.pinv(x=Tensor([0, 4, 40],"float64"), )
[paddle error] paddle.linalg.pinv(x=Tensor([0, 4, 40],"float64"), ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:36.725170 GPU 1 61478 test begin: paddle.linalg.pinv(x=Tensor([0, 4, 40],"float64"), rcond=0.5, )
[paddle error] paddle.linalg.pinv(x=Tensor([0, 4, 40],"float64"), rcond=0.5, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:36.755901 GPU 1 61245 test begin: paddle.linalg.pinv(x=Tensor([0, 40],"float64"), )
[paddle error] paddle.linalg.pinv(x=Tensor([0, 40],"float64"), ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:36.876596 GPU 1 61490 test begin: paddle.linalg.pinv(x=Tensor([0, 4],"float32"), )
[paddle error] paddle.linalg.pinv(x=Tensor([0, 4],"float32"), ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:36.889705 GPU 1 61458 test begin: paddle.linalg.pinv(x=Tensor([2, 0, 40],"float64"), )
[paddle error] paddle.linalg.pinv(x=Tensor([2, 0, 40],"float64"), ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:36.948722 GPU 0 61479 test begin: paddle.linalg.pinv(x=Tensor([2, 0, 40],"float64"), rcond=0.5, )
[paddle error] paddle.linalg.pinv(x=Tensor([2, 0, 40],"float64"), rcond=0.5, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:36.955606 GPU 1 61438 test begin: paddle.linalg.pinv(x=Tensor([2, 0],"float64"), )
[paddle error] paddle.linalg.pinv(x=Tensor([2, 0],"float64"), ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:36.959971 GPU 1 61385 test begin: paddle.linalg.pinv(x=Tensor([2, 4, 0],"float64"), )
[paddle error] paddle.linalg.pinv(x=Tensor([2, 4, 0],"float64"), ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:36.975242 GPU 0 61448 test begin: paddle.linalg.pinv(x=Tensor([2, 4, 0],"float64"), rcond=0.5, )
[paddle error] paddle.linalg.pinv(x=Tensor([2, 4, 0],"float64"), rcond=0.5, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:37.125498 GPU 1 61478 test begin: paddle.linalg.pinv(x=Tensor([3, 0],"float32"), )
[paddle error] paddle.linalg.pinv(x=Tensor([3, 0],"float32"), ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:37.132219 GPU 0 62010 test begin: paddle.linalg.pinv(x=Tensor([4, 0, 2],"float64"), rcond=5, hermitian=True, )
[paddle error] paddle.linalg.pinv(x=Tensor([4, 0, 2],"float64"), rcond=5, hermitian=True, ) 
 (InvalidArgument) Eigh op is designed for square matrix, consequentlyinner-most 2 dimensions of Input(X) should be symmetric.But received X's shape[-2] = 0 and shape[-1] = 2.
  [Hint: Expected input_dim[rank - 2] == input_dim[rank - 1], but received input_dim[rank - 2]:0 != input_dim[rank - 1]:2.] (at ../paddle/phi/infermeta/unary.cc:1151)


2025-06-05 15:23:37.167186 GPU 1 61245 test begin: paddle.linalg.pinv(x=Tensor([4, 2, 0],"float64"), rcond=5, hermitian=True, )
[paddle error] paddle.linalg.pinv(x=Tensor([4, 2, 0],"float64"), rcond=5, hermitian=True, ) 
 (InvalidArgument) Eigh op is designed for square matrix, consequentlyinner-most 2 dimensions of Input(X) should be symmetric.But received X's shape[-2] = 2 and shape[-1] = 0.
  [Hint: Expected input_dim[rank - 2] == input_dim[rank - 1], but received input_dim[rank - 2]:2 != input_dim[rank - 1]:0.] (at ../paddle/phi/infermeta/unary.cc:1151)


2025-06-05 15:23:37.715204 GPU 1 61385 test begin: paddle.linalg.svd_lowrank(Tensor([0, 17],"float64"), q=4, )
[paddle error] paddle.linalg.svd_lowrank(Tensor([0, 17],"float64"), q=4, ) 
 q(=4) must be non-negative integer and not greater than min(m, n)=0

2025-06-05 15:23:37.732617 GPU 0 61479 test begin: paddle.linalg.svd_lowrank(Tensor([0, 4, 17],"float64"), q=4, )
[paddle error] paddle.linalg.svd_lowrank(Tensor([0, 4, 17],"float64"), q=4, ) 
 ([0, 4, 17, 4, 17, 4, 17, 4], 4)

2025-06-05 15:23:37.897959 GPU 1 61458 test begin: paddle.linalg.svd_lowrank(Tensor([1, 0, 17],"float64"), q=4, )
[paddle error] paddle.linalg.svd_lowrank(Tensor([1, 0, 17],"float64"), q=4, ) 
 q(=4) must be non-negative integer and not greater than min(m, n)=0

2025-06-05 15:23:37.905629 GPU 0 61995 test begin: paddle.linalg.svd_lowrank(Tensor([1, 4, 0],"float64"), q=4, )
[paddle error] paddle.linalg.svd_lowrank(Tensor([1, 4, 0],"float64"), q=4, ) 
 q(=4) must be non-negative integer and not greater than min(m, n)=0

2025-06-05 15:23:37.927308 GPU 1 61428 test begin: paddle.linalg.svd_lowrank(Tensor([4, 0],"float64"), q=4, )
[paddle error] paddle.linalg.svd_lowrank(Tensor([4, 0],"float64"), q=4, ) 
 q(=4) must be non-negative integer and not greater than min(m, n)=0

2025-06-05 15:23:38.141235 GPU 0 62010 test begin: paddle.linalg.vector_norm(x=Tensor([2, 3, 0],"float64"), p=math.inf, axis=list[0,1,], keepdim=False, )
[paddle error] paddle.linalg.vector_norm(x=Tensor([2, 3, 0],"float64"), p=math.inf, axis=list[0,1,], keepdim=False, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:38.367915 GPU 1 61438 test begin: paddle.linalg.vector_norm(x=Tensor([2, 3, 0],"float64"), p=math.inf, axis=list[0,1,], keepdim=True, )
[paddle error] paddle.linalg.vector_norm(x=Tensor([2, 3, 0],"float64"), p=math.inf, axis=list[0,1,], keepdim=True, ) 
 (InvalidArgument) Tensor need be reduced must not empty.
  [Hint: Expected input.numel() > 0, but received input.numel():0 <= 0:0.] (at ../paddle/phi/kernels/funcs/reduce_function.h:1463)


2025-06-05 15:23:39.766151 GPU 1 61478 test begin: paddle.logsumexp(Tensor([0, 16, 4, 8],"float32"), axis=3, keepdim=True, )
[paddle error] paddle.logsumexp(Tensor([0, 16, 4, 8],"float32"), axis=3, keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:39.778181 GPU 1 61438 test begin: paddle.logsumexp(Tensor([0, 200, 40],"float32"), axis=-1, keepdim=False, )
[paddle error] paddle.logsumexp(Tensor([0, 200, 40],"float32"), axis=-1, keepdim=False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:39.862060 GPU 0 61448 test begin: paddle.logsumexp(Tensor([0, 200, 40],"float32"), axis=list[0,2,], keepdim=False, )
[paddle error] paddle.logsumexp(Tensor([0, 200, 40],"float32"), axis=list[0,2,], keepdim=False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:39.869672 GPU 1 61458 test begin: paddle.logsumexp(Tensor([0, 3, 4, 5],"float32"), 2, False, )
[paddle error] paddle.logsumexp(Tensor([0, 3, 4, 5],"float32"), 2, False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:39.874791 GPU 1 61385 test begin: paddle.logsumexp(Tensor([0, 3, 4, 5],"float32"), list[-1,], False, )
[paddle error] paddle.logsumexp(Tensor([0, 3, 4, 5],"float32"), list[-1,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:39.937800 GPU 1 61428 test begin: paddle.logsumexp(Tensor([0, 3, 4, 5],"float32"), list[2,-3,], False, )
[paddle error] paddle.logsumexp(Tensor([0, 3, 4, 5],"float32"), list[2,-3,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:39.938290 GPU 0 62010 test begin: paddle.logsumexp(Tensor([0, 3, 4, 5],"float32"), tuple(0,1,-1,), False, )
[paddle error] paddle.logsumexp(Tensor([0, 3, 4, 5],"float32"), tuple(0,1,-1,), False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:39.977961 GPU 0 61479 test begin: paddle.logsumexp(Tensor([0, 3, 4, 5],"float64"), list[-1,], True, )
[paddle error] paddle.logsumexp(Tensor([0, 3, 4, 5],"float64"), list[-1,], True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:39.985750 GPU 1 61478 test begin: paddle.logsumexp(Tensor([0, 3, 4, 5],"float64"), list[0,-1,], False, )
[paddle error] paddle.logsumexp(Tensor([0, 3, 4, 5],"float64"), list[0,-1,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.010353 GPU 1 61245 test begin: paddle.logsumexp(Tensor([0, 3, 4, 5],"float64"), list[0,1,2,3,], False, )
[paddle error] paddle.logsumexp(Tensor([0, 3, 4, 5],"float64"), list[0,1,2,3,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.012027 GPU 1 62233 test begin: paddle.logsumexp(Tensor([0, 4, 16, 1],"float32"), axis=1, keepdim=True, )
[paddle error] paddle.logsumexp(Tensor([0, 4, 16, 1],"float32"), axis=1, keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.034663 GPU 1 62236 test begin: paddle.logsumexp(Tensor([0, 5, 6],"float64"), list[-1,], False, )
[paddle error] paddle.logsumexp(Tensor([0, 5, 6],"float64"), list[-1,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.038470 GPU 1 61490 test begin: paddle.logsumexp(Tensor([0, 60],"float32"), axis=1, )
[paddle error] paddle.logsumexp(Tensor([0, 60],"float32"), axis=1, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.092397 GPU 1 61458 test begin: paddle.logsumexp(Tensor([0, 8, 4, 8],"float32"), axis=3, keepdim=True, )
[paddle error] paddle.logsumexp(Tensor([0, 8, 4, 8],"float32"), axis=3, keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.094280 GPU 1 61385 test begin: paddle.logsumexp(Tensor([0],"float32"), axis=0, )
[paddle error] paddle.logsumexp(Tensor([0],"float32"), axis=0, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.106974 GPU 0 62210 test begin: paddle.logsumexp(Tensor([10, 0],"float32"), axis=1, )
[paddle error] paddle.logsumexp(Tensor([10, 0],"float32"), axis=1, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.132519 GPU 1 61438 test begin: paddle.logsumexp(Tensor([2, 0, 4, 5],"float32"), 2, False, )
[paddle error] paddle.logsumexp(Tensor([2, 0, 4, 5],"float32"), 2, False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.258717 GPU 0 61448 test begin: paddle.logsumexp(Tensor([2, 0, 4, 5],"float32"), list[-1,], False, )
[paddle error] paddle.logsumexp(Tensor([2, 0, 4, 5],"float32"), list[-1,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.278463 GPU 1 61490 test begin: paddle.logsumexp(Tensor([2, 0, 4, 5],"float32"), list[2,-3,], False, )
[paddle error] paddle.logsumexp(Tensor([2, 0, 4, 5],"float32"), list[2,-3,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.306599 GPU 0 61479 test begin: paddle.logsumexp(Tensor([2, 0, 4, 5],"float32"), tuple(0,1,-1,), False, )
[paddle error] paddle.logsumexp(Tensor([2, 0, 4, 5],"float32"), tuple(0,1,-1,), False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.322840 GPU 1 61458 test begin: paddle.logsumexp(Tensor([2, 0, 4, 5],"float64"), list[-1,], True, )
[paddle error] paddle.logsumexp(Tensor([2, 0, 4, 5],"float64"), list[-1,], True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.327206 GPU 1 61385 test begin: paddle.logsumexp(Tensor([2, 0, 4, 5],"float64"), list[0,-1,], False, )
[paddle error] paddle.logsumexp(Tensor([2, 0, 4, 5],"float64"), list[0,-1,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.330053 GPU 1 61478 test begin: paddle.logsumexp(Tensor([2, 0, 4, 5],"float64"), list[0,1,2,3,], False, )
[paddle error] paddle.logsumexp(Tensor([2, 0, 4, 5],"float64"), list[0,1,2,3,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.369882 GPU 1 61428 test begin: paddle.logsumexp(Tensor([2, 0],"float32"), axis=1, )
[paddle error] paddle.logsumexp(Tensor([2, 0],"float32"), axis=1, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.384652 GPU 1 62236 test begin: paddle.logsumexp(Tensor([2, 3, 0, 5],"float32"), 2, False, )
[paddle error] paddle.logsumexp(Tensor([2, 3, 0, 5],"float32"), 2, False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.451884 GPU 1 62233 test begin: paddle.logsumexp(Tensor([2, 3, 0, 5],"float32"), list[-1,], False, )
[paddle error] paddle.logsumexp(Tensor([2, 3, 0, 5],"float32"), list[-1,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.469527 GPU 0 62010 test begin: paddle.logsumexp(Tensor([2, 3, 0, 5],"float32"), list[2,-3,], False, )
[paddle error] paddle.logsumexp(Tensor([2, 3, 0, 5],"float32"), list[2,-3,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.477960 GPU 0 61448 test begin: paddle.logsumexp(Tensor([2, 3, 0, 5],"float32"), tuple(0,1,-1,), False, )
[paddle error] paddle.logsumexp(Tensor([2, 3, 0, 5],"float32"), tuple(0,1,-1,), False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.479347 GPU 0 62210 test begin: paddle.logsumexp(Tensor([2, 3, 0, 5],"float64"), list[-1,], True, )
[paddle error] paddle.logsumexp(Tensor([2, 3, 0, 5],"float64"), list[-1,], True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.496273 GPU 1 61438 test begin: paddle.logsumexp(Tensor([2, 3, 0, 5],"float64"), list[0,-1,], False, )
[paddle error] paddle.logsumexp(Tensor([2, 3, 0, 5],"float64"), list[0,-1,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.533124 GPU 1 61245 test begin: paddle.logsumexp(Tensor([2, 3, 0, 5],"float64"), list[0,1,2,3,], False, )
[paddle error] paddle.logsumexp(Tensor([2, 3, 0, 5],"float64"), list[0,1,2,3,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.539247 GPU 1 61458 test begin: paddle.logsumexp(Tensor([2, 3, 4, 0],"float32"), 2, False, )
[paddle error] paddle.logsumexp(Tensor([2, 3, 4, 0],"float32"), 2, False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.541008 GPU 1 61385 test begin: paddle.logsumexp(Tensor([2, 3, 4, 0],"float32"), list[-1,], False, )
[paddle error] paddle.logsumexp(Tensor([2, 3, 4, 0],"float32"), list[-1,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.634541 GPU 1 61478 test begin: paddle.logsumexp(Tensor([2, 3, 4, 0],"float32"), list[2,-3,], False, )
[paddle error] paddle.logsumexp(Tensor([2, 3, 4, 0],"float32"), list[2,-3,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.645898 GPU 0 61479 test begin: paddle.logsumexp(Tensor([2, 3, 4, 0],"float32"), tuple(0,1,-1,), False, )
[paddle error] paddle.logsumexp(Tensor([2, 3, 4, 0],"float32"), tuple(0,1,-1,), False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.696315 GPU 1 61490 test begin: paddle.logsumexp(Tensor([2, 3, 4, 0],"float64"), list[-1,], True, )
[paddle error] paddle.logsumexp(Tensor([2, 3, 4, 0],"float64"), list[-1,], True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.722419 GPU 0 61448 test begin: paddle.logsumexp(Tensor([2, 3, 4, 0],"float64"), list[0,-1,], False, )
[paddle error] paddle.logsumexp(Tensor([2, 3, 4, 0],"float64"), list[0,-1,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.740241 GPU 0 62210 test begin: paddle.logsumexp(Tensor([2, 3, 4, 0],"float64"), list[0,1,2,3,], False, )
[paddle error] paddle.logsumexp(Tensor([2, 3, 4, 0],"float64"), list[0,1,2,3,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.757186 GPU 1 62233 test begin: paddle.logsumexp(Tensor([26, 0, 16, 1],"float32"), axis=1, keepdim=True, )
[paddle error] paddle.logsumexp(Tensor([26, 0, 16, 1],"float32"), axis=1, keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.768248 GPU 1 61428 test begin: paddle.logsumexp(Tensor([26, 0, 4, 8],"float32"), axis=3, keepdim=True, )
[paddle error] paddle.logsumexp(Tensor([26, 0, 4, 8],"float32"), axis=3, keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.809239 GPU 0 62010 test begin: paddle.logsumexp(Tensor([26, 16, 0, 8],"float32"), axis=3, keepdim=True, )
[paddle error] paddle.logsumexp(Tensor([26, 16, 0, 8],"float32"), axis=3, keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.836234 GPU 1 61438 test begin: paddle.logsumexp(Tensor([26, 16, 4, 0],"float32"), axis=3, keepdim=True, )
[paddle error] paddle.logsumexp(Tensor([26, 16, 4, 0],"float32"), axis=3, keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.866027 GPU 1 61478 test begin: paddle.logsumexp(Tensor([26, 4, 0, 1],"float32"), axis=1, keepdim=True, )
[paddle error] paddle.logsumexp(Tensor([26, 4, 0, 1],"float32"), axis=1, keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.876930 GPU 1 62236 test begin: paddle.logsumexp(Tensor([26, 4, 16, 0],"float32"), axis=1, keepdim=True, )
[paddle error] paddle.logsumexp(Tensor([26, 4, 16, 0],"float32"), axis=1, keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.889116 GPU 1 61458 test begin: paddle.logsumexp(Tensor([26, 8, 0, 8],"float32"), axis=3, keepdim=True, )
[paddle error] paddle.logsumexp(Tensor([26, 8, 0, 8],"float32"), axis=3, keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:40.954613 GPU 1 61385 test begin: paddle.logsumexp(Tensor([26, 8, 4, 0],"float32"), axis=3, keepdim=True, )
[paddle error] paddle.logsumexp(Tensor([26, 8, 4, 0],"float32"), axis=3, keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:41.087591 GPU 1 61478 test begin: paddle.logsumexp(Tensor([30, 0, 40],"float32"), axis=-1, keepdim=False, )
[paddle error] paddle.logsumexp(Tensor([30, 0, 40],"float32"), axis=-1, keepdim=False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:41.109430 GPU 1 61458 test begin: paddle.logsumexp(Tensor([30, 0, 40],"float32"), axis=list[0,2,], keepdim=False, )
[paddle error] paddle.logsumexp(Tensor([30, 0, 40],"float32"), axis=list[0,2,], keepdim=False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:41.109900 GPU 1 61245 test begin: paddle.logsumexp(Tensor([30, 200, 0],"float32"), axis=-1, keepdim=False, )
[paddle error] paddle.logsumexp(Tensor([30, 200, 0],"float32"), axis=-1, keepdim=False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:41.119806 GPU 1 61490 test begin: paddle.logsumexp(Tensor([30, 200, 0],"float32"), axis=list[0,2,], keepdim=False, )
[paddle error] paddle.logsumexp(Tensor([30, 200, 0],"float32"), axis=list[0,2,], keepdim=False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:41.131388 GPU 0 61448 test begin: paddle.logsumexp(Tensor([4, 0, 6],"float64"), list[-1,], False, )
[paddle error] paddle.logsumexp(Tensor([4, 0, 6],"float64"), list[-1,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:41.144575 GPU 1 61438 test begin: paddle.logsumexp(Tensor([4, 5, 0],"float64"), list[-1,], False, )
[paddle error] paddle.logsumexp(Tensor([4, 5, 0],"float64"), list[-1,], False, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:41.187616 GPU 1 62236 test begin: paddle.logsumexp(x=Tensor([0, 3, 2],"float32"), axis=2, )
[paddle error] paddle.logsumexp(x=Tensor([0, 3, 2],"float32"), axis=2, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:41.188592 GPU 1 61428 test begin: paddle.logsumexp(x=Tensor([0, 3, 2],"float64"), axis=0, keepdim=True, )
[paddle error] paddle.logsumexp(x=Tensor([0, 3, 2],"float64"), axis=0, keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:41.198194 GPU 1 62233 test begin: paddle.logsumexp(x=Tensor([0, 3, 2],"float64"), axis=2, )
[paddle error] paddle.logsumexp(x=Tensor([0, 3, 2],"float64"), axis=2, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:41.199388 GPU 0 61479 test begin: paddle.logsumexp(x=Tensor([0, 3, 2],"float64"), axis=list[0,1,], )
[paddle error] paddle.logsumexp(x=Tensor([0, 3, 2],"float64"), axis=list[0,1,], ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:41.201002 GPU 1 61385 test begin: paddle.logsumexp(x=Tensor([0, 3, 2],"float64"), axis=list[0,1,], keepdim=True, )
[paddle error] paddle.logsumexp(x=Tensor([0, 3, 2],"float64"), axis=list[0,1,], keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:41.201946 GPU 0 62210 test begin: paddle.logsumexp(x=Tensor([2, 0, 2],"float32"), axis=2, )
[paddle error] paddle.logsumexp(x=Tensor([2, 0, 2],"float32"), axis=2, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:41.216234 GPU 0 62010 test begin: paddle.logsumexp(x=Tensor([2, 0, 2],"float64"), axis=0, keepdim=True, )
[paddle error] paddle.logsumexp(x=Tensor([2, 0, 2],"float64"), axis=0, keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:41.310547 GPU 1 61478 test begin: paddle.logsumexp(x=Tensor([2, 0, 2],"float64"), axis=2, )
[paddle error] paddle.logsumexp(x=Tensor([2, 0, 2],"float64"), axis=2, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:41.327135 GPU 1 61458 test begin: paddle.logsumexp(x=Tensor([2, 0, 2],"float64"), axis=list[0,1,], )
[paddle error] paddle.logsumexp(x=Tensor([2, 0, 2],"float64"), axis=list[0,1,], ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:41.365026 GPU 0 61448 test begin: paddle.logsumexp(x=Tensor([2, 0, 2],"float64"), axis=list[0,1,], keepdim=True, )
[paddle error] paddle.logsumexp(x=Tensor([2, 0, 2],"float64"), axis=list[0,1,], keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:41.435790 GPU 1 61245 test begin: paddle.logsumexp(x=Tensor([2, 3, 0],"float32"), axis=2, )
[paddle error] paddle.logsumexp(x=Tensor([2, 3, 0],"float32"), axis=2, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:41.474052 GPU 1 61490 test begin: paddle.logsumexp(x=Tensor([2, 3, 0],"float64"), axis=0, keepdim=True, )
[paddle error] paddle.logsumexp(x=Tensor([2, 3, 0],"float64"), axis=0, keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:41.489507 GPU 0 62210 test begin: paddle.logsumexp(x=Tensor([2, 3, 0],"float64"), axis=2, )
[paddle error] paddle.logsumexp(x=Tensor([2, 3, 0],"float64"), axis=2, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:41.495813 GPU 1 61438 test begin: paddle.logsumexp(x=Tensor([2, 3, 0],"float64"), axis=list[0,1,], )
[paddle error] paddle.logsumexp(x=Tensor([2, 3, 0],"float64"), axis=list[0,1,], ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:41.505700 GPU 1 61385 test begin: paddle.logsumexp(x=Tensor([2, 3, 0],"float64"), axis=list[0,1,], keepdim=True, )
[paddle error] paddle.logsumexp(x=Tensor([2, 3, 0],"float64"), axis=list[0,1,], keepdim=True, ) 
 (InvalidArgument) The dims of Input(X) should be greater than 0.
  [Hint: Expected 0 < x_dim[i], but received 0:0 >= x_dim[i]:0.] (at ../paddle/phi/kernels/impl/logsumexp_kernel_impl.h:81)


2025-06-05 15:23:41.528538 GPU 1 61478 test begin: paddle.mv(Tensor([0, 12],"float32"), Tensor([12],"float32"), )
[accuracy error] backward  paddle.mv(Tensor([0, 12],"float32"), Tensor([12],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 2 / 12 (16.7%)
Greatest absolute difference: 4.9860362409492547e+33 at index (0,) (up to 0.01 allowed)
Greatest relative difference: inf at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([12]), dtype=torch.float32)
tensor([-4.9860e+33,  0.0000e+00,  4.7644e-44,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  1.5793e-42,  0.0000e+00, -4.9860e+33,  0.0000e+00,
         4.7644e-44,  0.0000e+00])
DESIRED: (shape=torch.Size([12]), dtype=torch.float32)
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])

2025-06-05 15:23:41.535539 GPU 1 62236 test begin: paddle.mv(Tensor([0, 18],"float32"), Tensor([18],"float32"), )
[accuracy error] backward  paddle.mv(Tensor([0, 18],"float32"), Tensor([18],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 8 / 18 (44.4%)
Greatest absolute difference: 4922168.0 at index (0,) (up to 0.01 allowed)
Greatest relative difference: inf at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([18]), dtype=torch.float32)
tensor([-4.9222e+06,  4.5832e-41,  1.2883e-38,  0.0000e+00, -4.0865e+06,
         4.5832e-41, -4.0976e+06,  4.5832e-41, -4.1263e+06,  4.5832e-41,
        -4.1027e+06,  4.5832e-41, -4.0997e+06,  4.5832e-41, -4.0827e+06,
         4.5832e-41, -4.1138e+06,  4.5832e-41])
DESIRED: (shape=torch.Size([18]), dtype=torch.float32)
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])

2025-06-05 15:23:41.554953 GPU 0 61479 test begin: paddle.nn.functional.cosine_similarity(x1=Tensor([2, 0, 4],"float64"), x2=Tensor([2, 0, 4],"float64"), axis=1, eps=0, )
[accuracy error] paddle.nn.functional.cosine_similarity(x1=Tensor([2, 0, 4],"float64"), x2=Tensor([2, 0, 4],"float64"), axis=1, eps=0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 8 / 8 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 4]), dtype=torch.float64)
tensor([[nan, nan, nan, nan],
        [nan, nan, nan, nan]], dtype=torch.float64)
DESIRED: (shape=torch.Size([2, 4]), dtype=torch.float64)
tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.]], dtype=torch.float64)

2025-06-05 15:23:41.605625 GPU 1 61428 test begin: paddle.nn.functional.glu(Tensor([0, 1, 512],"float32"), -1, None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108221 (unix time) try "date -d @1749108221" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 61428 (TID 0x7f92607c5740) from PID 0 ***]


2025-06-05 15:23:41.639175 GPU 1 61458 test begin: paddle.nn.functional.glu(Tensor([0, 10, 512],"float32"), -1, None, )

2025-06-05 15:23:41.717879 GPU 0 61448 test begin: paddle.nn.functional.glu(Tensor([0, 20],"float64"), -1, )

2025-06-05 15:23:41.725275 GPU 1 61385 test begin: paddle.nn.functional.glu(Tensor([0, 20],"float64"), -1, None, )

2025-06-05 15:23:41.756176 GPU 0 62210 test begin: paddle.nn.functional.glu(Tensor([1, 0, 512],"float32"), -1, None, )

2025-06-05 15:23:41.785488 GPU 1 61245 test begin: paddle.nn.functional.glu(Tensor([1, 1, 0],"float32"), -1, None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108221 (unix time) try "date -d @1749108221" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 61245 (TID 0x7fd80c9c4740) from PID 0 ***]


2025-06-05 15:23:41.791845 GPU 0 62010 test begin: paddle.nn.functional.glu(Tensor([1, 10, 0],"float32"), -1, None, )

2025-06-05 15:23:41.799167 GPU 1 61478 test begin: paddle.nn.functional.glu(Tensor([5, 0],"float64"), -1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108221 (unix time) try "date -d @1749108221" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 61478 (TID 0x7f7cf8856740) from PID 0 ***]


2025-06-05 15:23:41.853586 GPU 1 61438 test begin: paddle.nn.functional.glu(Tensor([6, 0],"float64"), -1, None, )

2025-06-05 15:23:41.873449 GPU 1 61490 test begin: paddle.nn.functional.glu(x=Tensor([0, 2, 8],"float32"), )

2025-06-05 15:23:41.984795 GPU 0 61479 test begin: paddle.nn.functional.glu(x=Tensor([0, 2, 8],"float64"), )

2025-06-05 15:23:42.054393 GPU 1 62236 test begin: paddle.nn.functional.glu(x=Tensor([0, 4],"float32"), )

2025-06-05 15:23:42.125300 GPU 1 62233 test begin: paddle.nn.functional.glu(x=Tensor([0, 4],"float64"), )

2025-06-05 15:23:42.330146 GPU 0 62275 test begin: paddle.nn.functional.glu(x=Tensor([0, 6, 2, 8],"float32"), )

2025-06-05 15:23:43.101628 GPU 0 62020 test begin: paddle.nn.functional.glu(x=Tensor([0, 6, 2, 8],"float32"), axis=2, )

2025-06-05 15:23:43.129139 GPU 0 62077 test begin: paddle.nn.functional.glu(x=Tensor([0, 6, 2, 8],"float64"), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108223 (unix time) try "date -d @1749108223" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 62077 (TID 0x7f2fa12c9740) from PID 24 ***]


2025-06-05 15:23:43.159757 GPU 1 62200 test begin: paddle.nn.functional.glu(x=Tensor([0, 6, 2, 8],"float64"), axis=2, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108223 (unix time) try "date -d @1749108223" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 62200 (TID 0x7f784ff68740) from PID 0 ***]


2025-06-05 15:23:43.883103 GPU 1 62154 test begin: paddle.nn.functional.glu(x=Tensor([10, 0, 8],"float32"), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108224 (unix time) try "date -d @1749108224" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 62154 (TID 0x7f61df99f740) from PID 24 ***]


2025-06-05 15:23:43.890908 GPU 0 62044 test begin: paddle.nn.functional.glu(x=Tensor([10, 0, 8],"float64"), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108224 (unix time) try "date -d @1749108224" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 62044 (TID 0x7f40103bd740) from PID 24 ***]


2025-06-05 15:23:44.914291 GPU 0 61995 test begin: paddle.nn.functional.glu(x=Tensor([10, 2, 0],"float32"), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108225 (unix time) try "date -d @1749108225" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fbd00000002) received by PID 61995 (TID 0x7fbd617ca740) from PID 2 ***]


2025-06-05 15:23:45.556661 GPU 0 62021 test begin: paddle.nn.functional.glu(x=Tensor([10, 2, 0],"float64"), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108225 (unix time) try "date -d @1749108225" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 62021 (TID 0x7fe4104a4740) from PID 24 ***]


2025-06-05 15:23:47.204160 GPU 0 62121 test begin: paddle.nn.functional.glu(x=Tensor([2, 0],"float32"), )

2025-06-05 15:23:51.617758 GPU 0 62873 test begin: paddle.nn.functional.glu(x=Tensor([2, 0],"float64"), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108257 (unix time) try "date -d @1749108257" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7feaee60b3a0) received by PID 62873 (TID 0x7feaef1e9740) from PID 18446744073413899168 ***]


2025-06-05 15:23:51.913178 GPU 0 62889 test begin: paddle.nn.functional.glu(x=Tensor([4, 0, 2, 8],"float32"), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<float, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108258 (unix time) try "date -d @1749108258" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 62889 (TID 0x7f2e40b2f740) from PID 24 ***]


2025-06-05 15:23:52.434249 GPU 0 62909 test begin: paddle.nn.functional.glu(x=Tensor([4, 0, 2, 8],"float64"), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SplitWithNumGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
4   void phi::ConcatKernel<double, phi::CPUContext>(phi::CPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108258 (unix time) try "date -d @1749108258" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x18) received by PID 62909 (TID 0x7f856ce4d740) from PID 24 ***]


2025-06-05 15:23:52.523510 GPU 0 63011 test begin: paddle.nn.functional.glu(x=Tensor([4, 6, 0, 8],"float32"), axis=2, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108257 (unix time) try "date -d @1749108257" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f21d527a440) received by PID 63011 (TID 0x7f23f7d7c740) from PID 18446744072990729280 ***]


2025-06-05 15:23:52.711971 GPU 0 62962 test begin: paddle.nn.functional.glu(x=Tensor([4, 6, 2, 0],"float64"), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108260 (unix time) try "date -d @1749108260" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7fee4145e3e0) received by PID 62962 (TID 0x7ff066d7d740) from PID 1095099360 ***]


2025-06-05 15:23:52.917905 GPU 0 62990 test begin: paddle.nn.functional.layer_norm(Tensor([0, 64, 64],"float32"), list[64,], Tensor([64],"float32"), Tensor([64],"float32"), )
[accuracy error] backward  paddle.nn.functional.layer_norm(Tensor([0, 64, 64],"float32"), list[64,], Tensor([64],"float32"), Tensor([64],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 30 / 64 (46.9%)
Greatest absolute difference: 1.258386847326249e+34 at index (42,) (up to 0.01 allowed)
Greatest relative difference: inf at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([64]), dtype=torch.float32)
tensor([ 1.0303e+34,  4.5629e-41,  1.0323e+34,  4.5629e-41,  1.0325e+34,
         4.5629e-41,  1.0338e+34,  4.5629e-41,  1.0312e+34,  4.5629e-41,
         1.0329e+34,  4.5629e-41,  1.0358e+34,  4.5629e-41,  1.0333e+34,
         4.5629e-41,  1.0321e+34,  4.5629e-41,  1.0344e+34,  4.5629e-41,
         1.0311e+34,  4.5629e-41,  1.0349e+34,  4.5629e-41,  1.0313e+34,
         4.5629e-41,  1.0344e+34,  4.5629e-41,  1.0333e+34,  4.5629e-41,
        -1.2404e-23,  4.5626e-41,  1.0362e+34,  4.5629e-41,  1.0303e+34,
         4.5629e-41,  1.0361e+34,  4.5629e-41,  1.0344e+34,  4.5629e-41,
         1.0279e+34,  4.5629e-41,  1.2584e+34,  4.5629e-41,  1.0346e+34,
         4.5629e-41,  1.0303e+34,  4.5629e-41,  1.0311e+34,  4.5629e-41,
         1.0338e+34,  4.5629e-41,  1.0312e+34,  4.5629e-41,  1.0311e+34,
         4.5629e-41,  7.9780e-10,  4.5628e-41,  1.2534e+34,  4.5629e-41,
         1.2534e+34,  4.5629e-41,  1.0309e+34,  4.5629e-41])
DESIRED: (shape=torch.Size([64]), dtype=torch.float32)
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])

2025-06-05 15:23:53.457588 GPU 0 63191 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), margin=0.3, swap=False, reduction="mean", name=None, )
[paddle error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), margin=0.3, swap=False, reduction="mean", name=None, ) 
 The positive distance or negative distance should be greater than 0, The distance functions should be checked.

2025-06-05 15:23:53.963325 GPU 0 63192 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), margin=0.3, swap=False, reduction="none", name=None, )
[paddle error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), margin=0.3, swap=False, reduction="none", name=None, ) 
 The positive distance or negative distance should be greater than 0, The distance functions should be checked.

2025-06-05 15:23:54.817678 GPU 0 63213 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), margin=0.3, swap=False, reduction="sum", name=None, )
[paddle error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), margin=0.3, swap=False, reduction="sum", name=None, ) 
 The positive distance or negative distance should be greater than 0, The distance functions should be checked.

2025-06-05 15:23:57.234365 GPU 0 63242 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), margin=0.3, swap=True, reduction="mean", name=None, )
[paddle error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), margin=0.3, swap=True, reduction="mean", name=None, ) 
 The positive distance or negative distance should be greater than 0, The distance functions should be checked.

2025-06-05 15:24:06.739269 GPU 0 63610 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 0],"float64"), positive=Tensor([5, 0],"float64"), negative=Tensor([5, 0],"float64"), distance_function=None, margin=0.3, swap=False, reduction="mean", )
[paddle error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 0],"float64"), positive=Tensor([5, 0],"float64"), negative=Tensor([5, 0],"float64"), distance_function=None, margin=0.3, swap=False, reduction="mean", ) 
 The positive distance or negative distance should be greater than 0, The distance functions should be checked.

2025-06-05 15:24:18.158621 GPU 0 62990 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 0],"float64"), positive=Tensor([5, 0],"float64"), negative=Tensor([5, 0],"float64"), distance_function=None, margin=0.3, swap=False, reduction="none", )
[paddle error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 0],"float64"), positive=Tensor([5, 0],"float64"), negative=Tensor([5, 0],"float64"), distance_function=None, margin=0.3, swap=False, reduction="none", ) 
 The positive distance or negative distance should be greater than 0, The distance functions should be checked.

2025-06-05 15:24:18.414630 GPU 0 62990 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 0],"float64"), positive=Tensor([5, 0],"float64"), negative=Tensor([5, 0],"float64"), distance_function=None, margin=0.3, swap=False, reduction="sum", )
[paddle error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 0],"float64"), positive=Tensor([5, 0],"float64"), negative=Tensor([5, 0],"float64"), distance_function=None, margin=0.3, swap=False, reduction="sum", ) 
 The positive distance or negative distance should be greater than 0, The distance functions should be checked.

2025-06-05 15:24:18.467735 GPU 0 63191 test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 0],"float64"), positive=Tensor([5, 0],"float64"), negative=Tensor([5, 0],"float64"), distance_function=None, margin=0.3, swap=True, reduction="mean", )
[paddle error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 0],"float64"), positive=Tensor([5, 0],"float64"), negative=Tensor([5, 0],"float64"), distance_function=None, margin=0.3, swap=True, reduction="mean", ) 
 The positive distance or negative distance should be greater than 0, The distance functions should be checked.

2025-06-05 15:24:18.668157 GPU 0 62990 test begin: paddle.nn.utils.vector_to_parameters(Tensor([165],"float32"), list[Tensor([0, 15],"float32"),Tensor([15],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([165],"float32"), list[Tensor([0, 15],"float32"),Tensor([15],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 15], input(X)'s shape = [165], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:15 != input_axis_dim:165.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:24:18.756931 GPU 0 63191 test begin: paddle.nn.utils.vector_to_parameters(Tensor([165],"float32"), list[Tensor([10, 0],"float32"),Tensor([15],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([165],"float32"), list[Tensor([10, 0],"float32"),Tensor([15],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 15], input(X)'s shape = [165], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:15 != input_axis_dim:165.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:24:19.153856 GPU 0 62990 test begin: paddle.nn.utils.vector_to_parameters(Tensor([165],"float32"), list[Tensor([10, 15],"float32"),Tensor([0],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([165],"float32"), list[Tensor([10, 15],"float32"),Tensor([0],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [150, 0], input(X)'s shape = [165], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:150 != input_axis_dim:165.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:24:19.359562 GPU 0 63191 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:20.310940 GPU 0 63192 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:20.327651 GPU 0 62990 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:20.373439 GPU 0 63213 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:20.878983 GPU 0 63192 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:20.924676 GPU 0 63191 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:20.958990 GPU 0 62990 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:22.470228 GPU 0 63242 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:22.530568 GPU 0 63213 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:22.568610 GPU 0 63191 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([0],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([0],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:22.600161 GPU 0 63192 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:22.875102 GPU 0 62990 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:22.962473 GPU 0 63242 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:23.000317 GPU 0 63192 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:23.152827 GPU 0 63213 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:23.203537 GPU 0 63191 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:23.479818 GPU 0 63242 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:23.489008 GPU 0 62990 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:23.561825 GPU 0 63192 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:23.570703 GPU 0 63213 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:23.801794 GPU 0 63191 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:24.032398 GPU 0 63213 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:24.069831 GPU 0 63192 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:24.177792 GPU 0 62990 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:24.216296 GPU 0 63242 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:24.336232 GPU 0 63191 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:24.710580 GPU 0 63192 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:24.823708 GPU 0 62990 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:24.834600 GPU 0 63191 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:24.851163 GPU 0 63213 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:25.026455 GPU 0 63242 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:25.213018 GPU 0 63192 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:25.454267 GPU 0 63213 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:25.493513 GPU 0 62990 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:25.642702 GPU 0 63191 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:25.720051 GPU 0 63192 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:26.006969 GPU 0 63242 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:26.053279 GPU 0 62990 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:26.397609 GPU 0 63192 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:26.457947 GPU 0 63242 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:26.503533 GPU 0 63213 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:26.560680 GPU 0 63191 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:26.571454 GPU 0 62990 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:26.832503 GPU 0 64424 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:26.898915 GPU 0 63192 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:27.023781 GPU 0 62990 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:27.255411 GPU 0 63213 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:27.352250 GPU 0 63191 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([0],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([0],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:27.372580 GPU 0 63242 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:27.649333 GPU 0 63192 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:27.713213 GPU 0 62990 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:27.942778 GPU 0 63213 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:28.000168 GPU 0 63191 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:28.108773 GPU 0 63242 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:28.146040 GPU 0 62990 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:28.399474 GPU 0 63192 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:28.417885 GPU 0 63610 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:28.597187 GPU 0 62990 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:28.642441 GPU 0 63242 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:28.647271 GPU 0 63191 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:28.647908 GPU 0 63213 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:28.845294 GPU 0 63192 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:28.932940 GPU 0 62990 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:29.186966 GPU 0 64482 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:29.212365 GPU 0 64442 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:29.288706 GPU 0 63610 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:29.306097 GPU 0 63242 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:29.365557 GPU 0 63213 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:29.527431 GPU 0 63191 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:29.535023 GPU 0 62990 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([0],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([0],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:29.575139 GPU 0 63192 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:29.882145 GPU 0 64462 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:30.825070 GPU 0 62990 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:30.828716 GPU 0 63213 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:30.877938 GPU 0 63191 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:30.942619 GPU 0 63192 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:31.029130 GPU 0 63242 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:31.062808 GPU 0 63610 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:31.186893 GPU 0 62990 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:31.322855 GPU 0 63213 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:31.402479 GPU 0 63191 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:31.600422 GPU 0 63242 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:31.609061 GPU 0 63192 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:31.890108 GPU 0 62990 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:31.951464 GPU 0 63191 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:31.958814 GPU 0 63610 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:31.988253 GPU 0 63213 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:32.083670 GPU 0 63192 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:32.106668 GPU 0 63242 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:32.468381 GPU 0 63191 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:32.546786 GPU 0 63213 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:32.576506 GPU 0 62990 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:32.662396 GPU 0 63192 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:32.706355 GPU 0 63242 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:32.750699 GPU 0 63610 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:32.882154 GPU 0 63191 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:32.975890 GPU 0 63213 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:33.196045 GPU 0 63192 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:33.201589 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:33.283591 GPU 0 62990 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:33.286786 GPU 0 63242 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:33.330336 GPU 0 63191 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:33.381085 GPU 0 63213 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:33.614443 GPU 0 63610 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:33.880035 GPU 0 63242 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:33.976992 GPU 0 63192 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([0],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([0],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:34.231020 GPU 0 63191 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:34.381188 GPU 0 62990 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:34.875261 GPU 0 63213 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:35.297256 GPU 0 63610 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:35.424137 GPU 0 63213 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:35.427426 GPU 0 63191 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:35.495404 GPU 0 63242 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:35.562801 GPU 0 63192 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:35.658818 GPU 0 62990 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:35.897288 GPU 0 63213 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:36.022748 GPU 0 63191 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:36.058742 GPU 0 63242 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:36.135432 GPU 0 63192 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:36.225046 GPU 0 63610 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:36.502667 GPU 0 63213 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:36.690460 GPU 0 62990 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:36.777102 GPU 0 63610 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:36.882251 GPU 0 63242 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:36.922165 GPU 0 63191 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:37.115786 GPU 0 63192 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:37.124295 GPU 0 63213 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:37.316977 GPU 0 63610 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:37.572137 GPU 0 62990 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:37.678402 GPU 0 63191 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:37.744440 GPU 0 63192 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:37.746549 GPU 0 63242 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:37.950160 GPU 0 63213 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:38.001964 GPU 0 63191 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:38.200176 GPU 0 63610 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:38.291204 GPU 0 63242 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:38.337540 GPU 0 63192 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:39.000200 GPU 0 63213 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:39.069744 GPU 0 62990 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:39.298675 GPU 0 63191 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:39.339834 GPU 0 63610 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:39.405174 GPU 0 63192 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([0],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([0],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:39.477714 GPU 0 63213 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:39.645838 GPU 0 63242 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:39.666548 GPU 0 62990 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:39.693850 GPU 0 63191 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:39.934457 GPU 0 63610 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:40.365376 GPU 0 63192 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:40.365803 GPU 0 63213 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:42.036230 GPU 0 63191 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:42.198639 GPU 0 63213 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:42.200311 GPU 0 63242 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:42.269067 GPU 0 63610 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:42.276805 GPU 0 62990 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:42.364949 GPU 0 63192 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:42.393556 GPU 0 63191 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:42.530609 GPU 0 63213 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:42.595605 GPU 0 63242 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:42.781921 GPU 0 63610 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:42.835642 GPU 0 62990 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:42.845319 GPU 0 63191 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:42.890285 GPU 0 63213 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:42.938796 GPU 0 63242 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:42.979838 GPU 0 63192 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:43.338278 GPU 0 63610 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:43.453886 GPU 0 62990 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:43.484281 GPU 0 63213 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:43.513472 GPU 0 63191 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:43.673270 GPU 0 63242 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:43.801631 GPU 0 63192 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:43.844107 GPU 0 63610 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:48.801573 GPU 0 64424 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:50.961555 GPU 0 64462 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:51.190035 GPU 0 64442 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:51.929861 GPU 0 64482 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:57.827499 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:58.219471 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:24:59.618171 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:25:00.046673 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:25:00.470974 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:25:00.771139 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:25:01.741786 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:25:02.118317 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:25:03.456385 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:25:03.948168 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:25:04.484691 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:25:05.070261 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:25:05.509880 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([0],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:25:06.239514 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:25:07.071664 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 0],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:25:07.927654 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:25:08.286100 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:25:08.688428 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([0, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:25:09.233939 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:25:09.715319 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:25:10.423866 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:25:11.041847 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:25:11.646267 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:25:12.440572 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:25:12.873754 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:25:13.527849 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:25:14.703750 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),Tensor([128],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:25:14.976981 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([1851904],"float32"), list[Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 128],"float32"),Tensor([128],"float32"),Tensor([128, 512],"float32"),Tensor([512],"float32"),Tensor([512, 128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),Tensor([0],"float32"),], ) 
 Unimplemented error. Invalid dimension to be accessed. Now only supports access to dimension 0 to 9, but received dimension is 172.
  [../paddle/common/ddim.h:61]

2025-06-05 15:25:15.347849 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([27],"float32"), list[Tensor([0, 2, 4],"float32"),Tensor([3],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([27],"float32"), list[Tensor([0, 2, 4],"float32"),Tensor([3],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 3], input(X)'s shape = [27], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:3 != input_axis_dim:27.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:15.543209 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([27],"float32"), list[Tensor([3, 0, 4],"float32"),Tensor([3],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([27],"float32"), list[Tensor([3, 0, 4],"float32"),Tensor([3],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 3], input(X)'s shape = [27], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:3 != input_axis_dim:27.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:15.745389 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([27],"float32"), list[Tensor([3, 2, 0],"float32"),Tensor([3],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([27],"float32"), list[Tensor([3, 2, 0],"float32"),Tensor([3],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 3], input(X)'s shape = [27], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:3 != input_axis_dim:27.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:15.894434 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([27],"float32"), list[Tensor([3, 2, 4],"float32"),Tensor([0],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([27],"float32"), list[Tensor([3, 2, 4],"float32"),Tensor([0],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [24, 0], input(X)'s shape = [27], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:24 != input_axis_dim:27.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:16.022333 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([0, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([0, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 768, 48, 48, 768, 768, 48, 48], input(X)'s shape = [2880], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2496 != input_axis_dim:2880.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:16.655825 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 0],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 0],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 768, 48, 48, 768, 768, 48, 48], input(X)'s shape = [2880], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2496 != input_axis_dim:2880.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:17.551274 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([0, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([0, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [384, 0, 48, 48, 768, 768, 48, 48], input(X)'s shape = [2880], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2112 != input_axis_dim:2880.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:17.972389 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 0],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 0],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [384, 0, 48, 48, 768, 768, 48, 48], input(X)'s shape = [2880], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2112 != input_axis_dim:2880.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:18.375734 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([0],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([0],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [384, 768, 0, 48, 768, 768, 48, 48], input(X)'s shape = [2880], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2832 != input_axis_dim:2880.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:18.771476 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([0],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([0],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [384, 768, 48, 0, 768, 768, 48, 48], input(X)'s shape = [2880], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2832 != input_axis_dim:2880.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:19.294275 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([0, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([0, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [384, 768, 48, 48, 0, 768, 48, 48], input(X)'s shape = [2880], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2112 != input_axis_dim:2880.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:19.725642 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 0],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 0],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [384, 768, 48, 48, 0, 768, 48, 48], input(X)'s shape = [2880], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2112 != input_axis_dim:2880.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:20.598250 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([0, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([0, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [384, 768, 48, 48, 768, 0, 48, 48], input(X)'s shape = [2880], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2112 != input_axis_dim:2880.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:22.746038 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 0],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 0],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [384, 768, 48, 48, 768, 0, 48, 48], input(X)'s shape = [2880], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2112 != input_axis_dim:2880.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:23.148490 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([0],"float32"),Tensor([48],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([0],"float32"),Tensor([48],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [384, 768, 48, 48, 768, 768, 0, 48], input(X)'s shape = [2880], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2832 != input_axis_dim:2880.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:23.344945 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([0],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2880],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([0],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [384, 768, 48, 48, 768, 768, 48, 0], input(X)'s shape = [2880], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2832 != input_axis_dim:2880.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:23.522482 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([30],"float32"), list[Tensor([0, 3],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([30],"float32"), list[Tensor([0, 3],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 0], input(X)'s shape = [30], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:0 != input_axis_dim:30.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:23.752988 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([30],"float32"), list[Tensor([10, 0],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([30],"float32"), list[Tensor([10, 0],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 0], input(X)'s shape = [30], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:0 != input_axis_dim:30.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:23.980911 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([0, 8],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([64, 16],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([0, 8],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([64, 16],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 1024, 64, 64, 1024, 1024, 64, 64], input(X)'s shape = [3840], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:3328 != input_axis_dim:3840.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:24.161991 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 0],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([64, 16],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 0],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([64, 16],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 1024, 64, 64, 1024, 1024, 64, 64], input(X)'s shape = [3840], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:3328 != input_axis_dim:3840.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:24.374887 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([0, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([64, 16],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([0, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([64, 16],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [512, 0, 64, 64, 1024, 1024, 64, 64], input(X)'s shape = [3840], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2816 != input_axis_dim:3840.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:24.630309 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([64, 0],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([64, 16],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([64, 0],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([64, 16],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [512, 0, 64, 64, 1024, 1024, 64, 64], input(X)'s shape = [3840], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2816 != input_axis_dim:3840.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:24.855874 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([64, 16],"float32"),Tensor([0],"float32"),Tensor([64],"float32"),Tensor([64, 16],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([64, 16],"float32"),Tensor([0],"float32"),Tensor([64],"float32"),Tensor([64, 16],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [512, 1024, 0, 64, 1024, 1024, 64, 64], input(X)'s shape = [3840], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:3776 != input_axis_dim:3840.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:25.061595 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([0],"float32"),Tensor([64, 16],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([0],"float32"),Tensor([64, 16],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [512, 1024, 64, 0, 1024, 1024, 64, 64], input(X)'s shape = [3840], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:3776 != input_axis_dim:3840.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:26.328661 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([0, 16],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([0, 16],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [512, 1024, 64, 64, 0, 1024, 64, 64], input(X)'s shape = [3840], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2816 != input_axis_dim:3840.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:26.590560 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([64, 0],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([64, 0],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [512, 1024, 64, 64, 0, 1024, 64, 64], input(X)'s shape = [3840], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2816 != input_axis_dim:3840.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:26.765921 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([64, 16],"float32"),Tensor([64, 0],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([3840],"float32"), list[Tensor([64, 8],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([64, 16],"float32"),Tensor([64, 0],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [512, 1024, 64, 64, 1024, 0, 64, 64], input(X)'s shape = [3840], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2816 != input_axis_dim:3840.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:26.941139 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([387],"float32"), list[Tensor([3, 2, 0, 4, 4],"float32"),Tensor([3],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([387],"float32"), list[Tensor([3, 2, 0, 4, 4],"float32"),Tensor([3],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 3], input(X)'s shape = [387], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:3 != input_axis_dim:387.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:27.193115 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([387],"float32"), list[Tensor([3, 2, 4, 4, 4],"float32"),Tensor([0],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([387],"float32"), list[Tensor([3, 2, 4, 4, 4],"float32"),Tensor([0],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [384, 0], input(X)'s shape = [387], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:384 != input_axis_dim:387.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:27.358220 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([6],"float32"), list[Tensor([0, 2],"float32"),Tensor([2],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([6],"float32"), list[Tensor([0, 2],"float32"),Tensor([2],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 2], input(X)'s shape = [6], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2 != input_axis_dim:6.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:27.576642 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([6],"float32"), list[Tensor([2, 0],"float32"),Tensor([2],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([6],"float32"), list[Tensor([2, 0],"float32"),Tensor([2],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 2], input(X)'s shape = [6], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2 != input_axis_dim:6.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:27.890694 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([6],"float32"), list[Tensor([2, 2],"float32"),Tensor([0],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([6],"float32"), list[Tensor([2, 2],"float32"),Tensor([0],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [4, 0], input(X)'s shape = [6], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:4 != input_axis_dim:6.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:28.212002 GPU 0 64602 test begin: paddle.nn.utils.vector_to_parameters(Tensor([99],"float32"), list[Tensor([3, 0, 4, 4],"float32"),Tensor([3],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([99],"float32"), list[Tensor([3, 0, 4, 4],"float32"),Tensor([3],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [0, 3], input(X)'s shape = [99], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:3 != input_axis_dim:99.] (at ../paddle/phi/infermeta/unary.cc:4453)


2025-06-05 15:25:28.621180 GPU 0 64602 test begin: paddle.outer(Tensor([10],"float32"), Tensor([0],"float32"), )

Intel MKL ERROR: Parameter 9 was incorrect on entry to cblas_sgemm.

Intel MKL ERROR: Parameter 11 was incorrect on entry to cblas_sgemm.
[accuracy error] backward  paddle.outer(Tensor([10],"float32"), Tensor([0],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 5 / 10 (50.0%)
Greatest absolute difference: 4.06137055312085e+17 at index (6,) (up to 0.01 allowed)
Greatest relative difference: inf at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([10]), dtype=torch.float32)
tensor([3.5031e+17, 4.5761e-41, 3.4839e+17, 4.5761e-41, 3.5028e+17, 4.5761e-41,
        4.0614e+17, 4.5761e-41, 3.4788e+17, 4.5761e-41])
DESIRED: (shape=torch.Size([10]), dtype=torch.float32)
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])

2025-06-05 15:25:30.646645 GPU 0 64602 test begin: paddle.sgn(Tensor([0, 4],"complex128"), )
[paddle error] paddle.sgn(Tensor([0, 4],"complex128"), ) 
 (InvalidArgument) Expected the stride of last dimension of input(X) to be 1.But received 2. This means that the last dimension of theTensor(x) is not continuous and cannot be as_complex directly.You can call x.contiguous() to make the Tensor(x) contiguous first.
  [Hint: Expected x.strides()[x.strides().size() - 1] == 1, but received x.strides()[x.strides().size() - 1]:2 != 1:1.] (at ../paddle/phi/kernels/stride/as_complex_kernel.cc:35)


2025-06-05 15:25:30.861523 GPU 0 64602 test begin: paddle.sgn(Tensor([0, 4],"complex64"), )
[paddle error] paddle.sgn(Tensor([0, 4],"complex64"), ) 
 (InvalidArgument) Expected the stride of last dimension of input(X) to be 1.But received 2. This means that the last dimension of theTensor(x) is not continuous and cannot be as_complex directly.You can call x.contiguous() to make the Tensor(x) contiguous first.
  [Hint: Expected x.strides()[x.strides().size() - 1] == 1, but received x.strides()[x.strides().size() - 1]:2 != 1:1.] (at ../paddle/phi/kernels/stride/as_complex_kernel.cc:35)


2025-06-05 15:25:31.164837 GPU 0 64602 test begin: paddle.sgn(Tensor([2, 0],"complex128"), )
[paddle error] paddle.sgn(Tensor([2, 0],"complex128"), ) 
 (InvalidArgument) Expected the stride of last dimension of input(X) to be 1.But received 2. This means that the last dimension of theTensor(x) is not continuous and cannot be as_complex directly.You can call x.contiguous() to make the Tensor(x) contiguous first.
  [Hint: Expected x.strides()[x.strides().size() - 1] == 1, but received x.strides()[x.strides().size() - 1]:2 != 1:1.] (at ../paddle/phi/kernels/stride/as_complex_kernel.cc:35)


2025-06-05 15:25:31.477762 GPU 0 64602 test begin: paddle.sgn(Tensor([2, 0],"complex64"), )
[paddle error] paddle.sgn(Tensor([2, 0],"complex64"), ) 
 (InvalidArgument) Expected the stride of last dimension of input(X) to be 1.But received 2. This means that the last dimension of theTensor(x) is not continuous and cannot be as_complex directly.You can call x.contiguous() to make the Tensor(x) contiguous first.
  [Hint: Expected x.strides()[x.strides().size() - 1] == 1, but received x.strides()[x.strides().size() - 1]:2 != 1:1.] (at ../paddle/phi/kernels/stride/as_complex_kernel.cc:35)


2025-06-05 15:25:31.681769 GPU 0 64602 test begin: paddle.std(Tensor([0, 32],"float32"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0605 15:25:31.992159 64602 dygraph_functions.cc:85403] got different data type, run type promotion automatically, this may cause data type been changed.
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/paddle/tensor/stat.py:277: UserWarning: Degrees of freedom is <= 0.
  out = var(**locals())
[accuracy error] paddle.std(Tensor([0, 32],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected nan but got -0.0.
Absolute difference: nan (up to 0.01 allowed)
Relative difference: nan (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
-0.0
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
nan

2025-06-05 15:25:32.145756 GPU 0 64602 test begin: paddle.std(Tensor([0, 5],"float32"), )
[accuracy error] paddle.std(Tensor([0, 5],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected nan but got -0.0.
Absolute difference: nan (up to 0.01 allowed)
Relative difference: nan (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
-0.0
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
nan

2025-06-05 15:25:32.438688 GPU 0 64602 test begin: paddle.std(Tensor([0],"float32"), )
[accuracy error] paddle.std(Tensor([0],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected nan but got -0.0.
Absolute difference: nan (up to 0.01 allowed)
Relative difference: nan (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
-0.0
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
nan

2025-06-05 15:25:32.711768 GPU 0 64602 test begin: paddle.std(Tensor([1, 0, 4, 10],"float32"), list[1,3,], True, False, )
[accuracy error] paddle.std(Tensor([1, 0, 4, 10],"float32"), list[1,3,], True, False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 4]), dtype=torch.float32)
tensor([[-0., -0., -0., -0.]])
DESIRED: (shape=torch.Size([1, 4]), dtype=torch.float32)
tensor([[nan, nan, nan, nan]])

2025-06-05 15:25:33.482914 GPU 0 64602 test begin: paddle.std(Tensor([1, 0, 4, 10],"float64"), list[1,2,], True, False, )
[accuracy error] paddle.std(Tensor([1, 0, 4, 10],"float64"), list[1,2,], True, False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 10 / 10 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 10]), dtype=torch.float64)
tensor([[-0., -0., -0., -0., -0., -0., -0., -0., -0., -0.]],
       dtype=torch.float64)
DESIRED: (shape=torch.Size([1, 10]), dtype=torch.float64)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       dtype=torch.float64)

2025-06-05 15:25:34.278096 GPU 0 64602 test begin: paddle.std(Tensor([1, 0, 4, 10],"float64"), list[1,3,], True, False, )
[accuracy error] paddle.std(Tensor([1, 0, 4, 10],"float64"), list[1,3,], True, False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 4]), dtype=torch.float64)
tensor([[-0., -0., -0., -0.]], dtype=torch.float64)
DESIRED: (shape=torch.Size([1, 4]), dtype=torch.float64)
tensor([[nan, nan, nan, nan]], dtype=torch.float64)

2025-06-05 15:25:34.582702 GPU 0 64602 test begin: paddle.std(Tensor([1, 0, 4, 10],"float64"), tuple(1,3,), True, False, )
[accuracy error] paddle.std(Tensor([1, 0, 4, 10],"float64"), tuple(1,3,), True, False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 4]), dtype=torch.float64)
tensor([[-0., -0., -0., -0.]], dtype=torch.float64)
DESIRED: (shape=torch.Size([1, 4]), dtype=torch.float64)
tensor([[nan, nan, nan, nan]], dtype=torch.float64)

2025-06-05 15:25:34.843403 GPU 0 64602 test begin: paddle.std(Tensor([1, 3, 0, 10],"float64"), 2, True, False, )
[accuracy error] paddle.std(Tensor([1, 3, 0, 10],"float64"), 2, True, False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 30 / 30 (100.0%)
Greatest absolute difference: nan at index (0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 3, 10]), dtype=torch.float64)
tensor([[[-0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
         [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
         [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0.]]],
       dtype=torch.float64)
DESIRED: (shape=torch.Size([1, 3, 10]), dtype=torch.float64)
tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],
       dtype=torch.float64)

2025-06-05 15:25:35.140165 GPU 0 64602 test begin: paddle.std(Tensor([1, 3, 0, 10],"float64"), list[1,2,], True, False, )
[accuracy error] paddle.std(Tensor([1, 3, 0, 10],"float64"), list[1,2,], True, False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 10 / 10 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 10]), dtype=torch.float64)
tensor([[-0., -0., -0., -0., -0., -0., -0., -0., -0., -0.]],
       dtype=torch.float64)
DESIRED: (shape=torch.Size([1, 10]), dtype=torch.float64)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       dtype=torch.float64)

2025-06-05 15:25:35.437389 GPU 0 64602 test begin: paddle.std(Tensor([1, 3, 4, 0],"float32"), list[1,3,], True, False, )
[accuracy error] paddle.std(Tensor([1, 3, 4, 0],"float32"), list[1,3,], True, False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 4]), dtype=torch.float32)
tensor([[-0., -0., -0., -0.]])
DESIRED: (shape=torch.Size([1, 4]), dtype=torch.float32)
tensor([[nan, nan, nan, nan]])

2025-06-05 15:25:35.667530 GPU 0 64602 test begin: paddle.std(Tensor([1, 3, 4, 0],"float64"), list[1,3,], True, False, )
[accuracy error] paddle.std(Tensor([1, 3, 4, 0],"float64"), list[1,3,], True, False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 4]), dtype=torch.float64)
tensor([[-0., -0., -0., -0.]], dtype=torch.float64)
DESIRED: (shape=torch.Size([1, 4]), dtype=torch.float64)
tensor([[nan, nan, nan, nan]], dtype=torch.float64)

2025-06-05 15:25:36.081752 GPU 0 64602 test begin: paddle.std(Tensor([1, 3, 4, 0],"float64"), tuple(1,3,), True, False, )
[accuracy error] paddle.std(Tensor([1, 3, 4, 0],"float64"), tuple(1,3,), True, False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 4]), dtype=torch.float64)
tensor([[-0., -0., -0., -0.]], dtype=torch.float64)
DESIRED: (shape=torch.Size([1, 4]), dtype=torch.float64)
tensor([[nan, nan, nan, nan]], dtype=torch.float64)

2025-06-05 15:25:36.335999 GPU 0 64602 test begin: paddle.std(Tensor([3, 0],"float32"), )
[accuracy error] paddle.std(Tensor([3, 0],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected nan but got -0.0.
Absolute difference: nan (up to 0.01 allowed)
Relative difference: nan (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
-0.0
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
nan

2025-06-05 15:25:37.191973 GPU 0 64602 test begin: paddle.std(Tensor([32, 0],"float32"), )
[accuracy error] paddle.std(Tensor([32, 0],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected nan but got -0.0.
Absolute difference: nan (up to 0.01 allowed)
Relative difference: nan (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
-0.0
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
nan

2025-06-05 15:25:37.789233 GPU 0 64602 test begin: paddle.std(Tensor([6, 0],"float32"), axis=1, )
[accuracy error] paddle.std(Tensor([6, 0],"float32"), axis=1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 6 / 6 (100.0%)
Greatest absolute difference: nan at index (0,) (up to 0.01 allowed)
Greatest relative difference: nan at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([6]), dtype=torch.float32)
tensor([-0., -0., -0., -0., -0., -0.])
DESIRED: (shape=torch.Size([6]), dtype=torch.float32)
tensor([nan, nan, nan, nan, nan, nan])

2025-06-05 15:25:38.305307 GPU 0 64602 test begin: paddle.std(x=Tensor([0, 3, 3],"float64"), )
[accuracy error] paddle.std(x=Tensor([0, 3, 3],"float64"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected nan but got -0.0.
Absolute difference: nan (up to 0.01 allowed)
Relative difference: nan (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float64)
-0.0
DESIRED: (shape=torch.Size([]), dtype=torch.float64)
nan

2025-06-05 15:25:38.622167 GPU 0 64602 test begin: paddle.std(x=Tensor([0, 3, 3],"float64"), axis=0, )
[accuracy error] paddle.std(x=Tensor([0, 3, 3],"float64"), axis=0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 9 / 9 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 3]), dtype=torch.float64)
tensor([[-0., -0., -0.],
        [-0., -0., -0.],
        [-0., -0., -0.]], dtype=torch.float64)
DESIRED: (shape=torch.Size([3, 3]), dtype=torch.float64)
tensor([[nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan]], dtype=torch.float64)

2025-06-05 15:25:38.868611 GPU 0 64602 test begin: paddle.std(x=Tensor([0, 3, 3],"float64"), axis=list[0,1,], )
[accuracy error] paddle.std(x=Tensor([0, 3, 3],"float64"), axis=list[0,1,], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 3 / 3 (100.0%)
Greatest absolute difference: nan at index (0,) (up to 0.01 allowed)
Greatest relative difference: nan at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3]), dtype=torch.float64)
tensor([-0., -0., -0.], dtype=torch.float64)
DESIRED: (shape=torch.Size([3]), dtype=torch.float64)
tensor([nan, nan, nan], dtype=torch.float64)

2025-06-05 15:25:39.124861 GPU 0 64602 test begin: paddle.std(x=Tensor([0, 3, 3],"float64"), axis=tuple(0,1,), )
[accuracy error] paddle.std(x=Tensor([0, 3, 3],"float64"), axis=tuple(0,1,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 3 / 3 (100.0%)
Greatest absolute difference: nan at index (0,) (up to 0.01 allowed)
Greatest relative difference: nan at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3]), dtype=torch.float64)
tensor([-0., -0., -0.], dtype=torch.float64)
DESIRED: (shape=torch.Size([3]), dtype=torch.float64)
tensor([nan, nan, nan], dtype=torch.float64)

2025-06-05 15:25:39.380923 GPU 0 64602 test begin: paddle.std(x=Tensor([0, 3, 3],"float64"), axis=tuple(0,1,), keepdim=True, )
[accuracy error] paddle.std(x=Tensor([0, 3, 3],"float64"), axis=tuple(0,1,), keepdim=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 3 / 3 (100.0%)
Greatest absolute difference: nan at index (0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1, 3]), dtype=torch.float64)
tensor([[[-0., -0., -0.]]], dtype=torch.float64)
DESIRED: (shape=torch.Size([1, 1, 3]), dtype=torch.float64)
tensor([[[nan, nan, nan]]], dtype=torch.float64)

2025-06-05 15:25:39.615964 GPU 0 64602 test begin: paddle.std(x=Tensor([0, 3],"float32"), )
[accuracy error] paddle.std(x=Tensor([0, 3],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected nan but got -0.0.
Absolute difference: nan (up to 0.01 allowed)
Relative difference: nan (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
-0.0
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
nan

2025-06-05 15:25:40.133151 GPU 0 64602 test begin: paddle.std(x=Tensor([0, 3],"float64"), )
[accuracy error] paddle.std(x=Tensor([0, 3],"float64"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected nan but got -0.0.
Absolute difference: nan (up to 0.01 allowed)
Relative difference: nan (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float64)
-0.0
DESIRED: (shape=torch.Size([]), dtype=torch.float64)
nan

2025-06-05 15:25:40.488303 GPU 0 64602 test begin: paddle.std(x=Tensor([2, 0],"float32"), )
[accuracy error] paddle.std(x=Tensor([2, 0],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected nan but got -0.0.
Absolute difference: nan (up to 0.01 allowed)
Relative difference: nan (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
-0.0
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
nan

2025-06-05 15:25:41.039787 GPU 0 64602 test begin: paddle.std(x=Tensor([2, 0],"float64"), )
[accuracy error] paddle.std(x=Tensor([2, 0],"float64"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected nan but got -0.0.
Absolute difference: nan (up to 0.01 allowed)
Relative difference: nan (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float64)
-0.0
DESIRED: (shape=torch.Size([]), dtype=torch.float64)
nan

2025-06-05 15:25:41.795469 GPU 0 64602 test begin: paddle.std(x=Tensor([3, 0, 3],"float64"), )
[accuracy error] paddle.std(x=Tensor([3, 0, 3],"float64"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected nan but got -0.0.
Absolute difference: nan (up to 0.01 allowed)
Relative difference: nan (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float64)
-0.0
DESIRED: (shape=torch.Size([]), dtype=torch.float64)
nan

2025-06-05 15:25:42.806107 GPU 0 64602 test begin: paddle.std(x=Tensor([3, 0, 3],"float64"), axis=list[0,1,], )
[accuracy error] paddle.std(x=Tensor([3, 0, 3],"float64"), axis=list[0,1,], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 3 / 3 (100.0%)
Greatest absolute difference: nan at index (0,) (up to 0.01 allowed)
Greatest relative difference: nan at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3]), dtype=torch.float64)
tensor([-0., -0., -0.], dtype=torch.float64)
DESIRED: (shape=torch.Size([3]), dtype=torch.float64)
tensor([nan, nan, nan], dtype=torch.float64)

2025-06-05 15:25:43.159741 GPU 0 64602 test begin: paddle.std(x=Tensor([3, 0, 3],"float64"), axis=tuple(0,1,), )
[accuracy error] paddle.std(x=Tensor([3, 0, 3],"float64"), axis=tuple(0,1,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 3 / 3 (100.0%)
Greatest absolute difference: nan at index (0,) (up to 0.01 allowed)
Greatest relative difference: nan at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3]), dtype=torch.float64)
tensor([-0., -0., -0.], dtype=torch.float64)
DESIRED: (shape=torch.Size([3]), dtype=torch.float64)
tensor([nan, nan, nan], dtype=torch.float64)

2025-06-05 15:25:43.510207 GPU 0 64602 test begin: paddle.std(x=Tensor([3, 0, 3],"float64"), axis=tuple(0,1,), keepdim=True, )
[accuracy error] paddle.std(x=Tensor([3, 0, 3],"float64"), axis=tuple(0,1,), keepdim=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 3 / 3 (100.0%)
Greatest absolute difference: nan at index (0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1, 3]), dtype=torch.float64)
tensor([[[-0., -0., -0.]]], dtype=torch.float64)
DESIRED: (shape=torch.Size([1, 1, 3]), dtype=torch.float64)
tensor([[[nan, nan, nan]]], dtype=torch.float64)

2025-06-05 15:25:43.898593 GPU 0 64602 test begin: paddle.std(x=Tensor([3, 3, 0],"float64"), )
[accuracy error] paddle.std(x=Tensor([3, 3, 0],"float64"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected nan but got -0.0.
Absolute difference: nan (up to 0.01 allowed)
Relative difference: nan (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float64)
-0.0
DESIRED: (shape=torch.Size([]), dtype=torch.float64)
nan

2025-06-05 15:25:44.266292 GPU 0 63191 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,1,0,],list[3,2,1,],], )

Intel MKL ERROR: Parameter 9 was incorrect on entry to cblas_dgemm.

Intel MKL ERROR: Parameter 11 was incorrect on entry to cblas_dgemm.
[accuracy error] backward  paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([0, 5, 1, 5],"float64"), list[list[3,1,0,],list[3,2,1,],], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 12 / 25 (48.0%)
Greatest absolute difference: 3.6024319539774895e+252 at index (0, 0, 1, 2) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 0, 0, 4) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1, 5, 5]), dtype=torch.float64)
tensor([[[[6.9449e-310, 1.3658e-314,  0.0000e+00,  0.0000e+00, 5.4937e+222],
          [5.4937e+222,  6.2490e-85, 3.6024e+252, 3.8099e+180, 6.1678e+223],
          [ 2.5258e-52, 9.6525e+183, 1.5132e-110,  2.3457e+98,  6.1484e-71],
          [1.1526e+141,  7.9268e-61, 1.0626e+248, 1.1526e+141,  7.9268e-61],
          [1.0626e+248,  1.1328e-95, 9.6525e+183, 1.5132e-110, 7.4861e-114]]]],
       dtype=torch.float64)
DESIRED: (shape=torch.Size([1, 1, 5, 5]), dtype=torch.float64)
tensor([[[[0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.]]]], dtype=torch.float64)

2025-06-05 15:25:44.524997 GPU 0 63192 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[2,3,0,],list[3,1,0,],], )

Intel MKL ERROR: Parameter 9 was incorrect on entry to cblas_dgemm.

Intel MKL ERROR: Parameter 11 was incorrect on entry to cblas_dgemm.
[accuracy error] backward  paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[2,3,0,],list[3,1,0,],], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 17 / 25 (68.0%)
Greatest absolute difference: nan at index (0, 0, 0, 2) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 0, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1, 5, 5]), dtype=torch.float64)
tensor([[[[1.3350e-307, 5.5627e-307,         nan, 1.6132e-307, 2.7816e-309],
          [        nan,         nan,         nan,         nan,         nan],
          [2.1138e-307,         nan,         nan, 5.5627e-308,         nan],
          [        nan, 6.6752e-308,         nan,         nan,         nan],
          [        nan,         nan,         nan,         nan, 2.6423e-308]]]],
       dtype=torch.float64)
DESIRED: (shape=torch.Size([1, 1, 5, 5]), dtype=torch.float64)
tensor([[[[0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.]]]], dtype=torch.float64)

2025-06-05 15:25:45.012492 GPU 0 63213 test begin: paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[3,2,],list[3,1,],], )

Intel MKL ERROR: Parameter 9 was incorrect on entry to cblas_dgemm.

Intel MKL ERROR: Parameter 11 was incorrect on entry to cblas_dgemm.
[accuracy error] backward  paddle.tensordot(Tensor([1, 1, 5, 5],"float64"), Tensor([5, 5, 0, 5],"float64"), list[list[3,2,],list[3,1,],], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 16 / 25 (64.0%)
Greatest absolute difference: nan at index (0, 0, 0, 1) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 0, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1, 5, 5]), dtype=torch.float64)
tensor([[[[6.9191e-310,         nan, 2.7816e-309,         nan,         nan],
          [1.3778e-314,         nan,         nan, 1.8913e-307,         nan],
          [1.3778e-314,         nan,         nan, 4.7283e-308, 2.8927e-307],
          [1.3778e-314,         nan,         nan,         nan,         nan],
          [1.1682e-307,         nan,         nan,         nan,         nan]]]],
       dtype=torch.float64)
DESIRED: (shape=torch.Size([1, 1, 5, 5]), dtype=torch.float64)
tensor([[[[0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.],
          [0., 0., 0., 0., 0.]]]], dtype=torch.float64)

2025-06-05 15:25:45.014902 GPU 0 62990 test begin: paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([0, 4, 5],"float32"), 0, )

Intel MKL ERROR: Parameter 9 was incorrect on entry to cblas_sgemm.

Intel MKL ERROR: Parameter 11 was incorrect on entry to cblas_sgemm.
[accuracy error] backward  paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([0, 4, 5],"float32"), 0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 1 / 48 (2.1%)
Greatest absolute difference: 0.47386282682418823 at index (0, 0, 1) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 0, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 4, 4]), dtype=torch.float32)
tensor([[[-4.9202e-03, -4.7386e-01,  7.1887e-43,  0.0000e+00],
         [-2.1473e-15,  0.0000e+00, -6.2343e-16,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])
DESIRED: (shape=torch.Size([3, 4, 4]), dtype=torch.float32)
tensor([[[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]],

        [[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]],

        [[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]]])

2025-06-05 15:25:45.088581 GPU 0 63191 test begin: paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 4, 0],"float32"), 0, )

Intel MKL ERROR: Parameter 9 was incorrect on entry to cblas_sgemm.

Intel MKL ERROR: Parameter 11 was incorrect on entry to cblas_sgemm.
[accuracy error] backward  paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 4, 0],"float32"), 0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 17 / 48 (35.4%)
Greatest absolute difference: 7.1443279863152655e+31 at index (2, 3, 0) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 4, 4]), dtype=torch.float32)
tensor([[[ 9.1835e+20,  4.5862e-41, -9.3675e-17,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
         [ 1.2208e+06,  0.0000e+00, -9.8608e-32,  1.0581e+21],
         [ 5.2165e-11,  1.1578e+27,  7.5031e+28,  1.9284e+31]],

        [[ 8.9718e+00,  7.3787e+28,  1.6928e+22,  7.0067e+22],
         [-3.7475e-27, -1.3042e-26, -1.2987e-31,  4.7431e+30],
         [-1.2238e-26, -3.8032e-31,  1.7862e+31, -6.1864e-34],
         [ 5.1490e-11,  8.2954e+17,  6.3016e-42,  0.0000e+00]],

        [[-6.4319e-17,  0.0000e+00, -5.5443e-17,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
         [ 4.7414e+16,  2.6176e-12,  4.2484e-05,  1.9146e+23],
         [ 7.1443e+31,  3.6015e-14,  1.7743e+28,  1.3458e-14]]])
DESIRED: (shape=torch.Size([3, 4, 4]), dtype=torch.float32)
tensor([[[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]],

        [[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]],

        [[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]]])

2025-06-05 15:25:45.251796 GPU 0 63192 test begin: paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 4, 0],"float32"), 1, )

Intel MKL ERROR: Parameter 9 was incorrect on entry to cblas_sgemm.

Intel MKL ERROR: Parameter 11 was incorrect on entry to cblas_sgemm.
[accuracy error] backward  paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 4, 0],"float32"), 1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 24 / 48 (50.0%)
Greatest absolute difference: nan at index (0, 2, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 2, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 4, 4]), dtype=torch.float32)
tensor([[[ 5.0742e-27,  4.5653e-41, -1.3257e-17,  0.0000e+00],
         [-1.4715e-17,  0.0000e+00, -1.3257e-17,  0.0000e+00],
         [        nan,  4.8673e-39,         nan,  2.2959e-39],
         [ 6.7958e-39,  5.1428e-39,         nan,  8.1734e-39]],

        [[        nan,         nan,         nan,  5.6020e-39],
         [        nan,  1.8369e-40,  2.8469e-39,         nan],
         [        nan,         nan,         nan,         nan],
         [ 3.0306e-39,         nan,         nan,         nan]],

        [[        nan,  6.1530e-39,  6.2448e-39,         nan],
         [ 7.1632e-39,         nan,         nan,  3.3061e-39],
         [        nan,         nan,  6.6122e-39,         nan],
         [ 3.4898e-39,  3.6734e-39,         nan,         nan]]])
DESIRED: (shape=torch.Size([3, 4, 4]), dtype=torch.float32)
tensor([[[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]],

        [[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]],

        [[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]]])

2025-06-05 15:25:45.252725 GPU 0 63242 test begin: paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 4, 0],"float32"), 2, )

Intel MKL ERROR: Parameter 9 was incorrect on entry to cblas_sgemm.

Intel MKL ERROR: Parameter 11 was incorrect on entry to cblas_sgemm.
[accuracy error] backward  paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 4, 0],"float32"), 2, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 18 / 48 (37.5%)
Greatest absolute difference: nan at index (0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 4, 4]), dtype=torch.float32)
tensor([[[        nan,  4.5699e-41,         nan,  4.5699e-41],
         [-1.8201e-14,  0.0000e+00, -1.8201e-14,  0.0000e+00],
         [ 1.2208e+06,  0.0000e+00, -9.8608e-32,  1.0581e+21],
         [ 5.2165e-11,  1.1578e+27,  7.5031e+28,  1.9284e+31]],

        [[ 8.9718e+00,  7.3787e+28,  1.6928e+22,  7.0067e+22],
         [-3.7475e-27, -1.3042e-26, -1.2987e-31,  4.7431e+30],
         [-1.2238e-26, -3.8063e-31,  1.7862e+31, -2.5948e-27],
         [ 5.1490e-11,  1.8525e+28,  6.3016e-42,  0.0000e+00]],

        [[-1.6831e-14,  0.0000e+00, -2.1757e-14,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
         [ 1.0498e+12,  3.0979e+32, -1.4902e-26, -1.3430e-26],
         [ 1.3220e-35,  2.9965e+32,  2.6187e+32,  5.1491e-11]]])
DESIRED: (shape=torch.Size([3, 4, 4]), dtype=torch.float32)
tensor([[[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]],

        [[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]],

        [[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]]])

2025-06-05 15:25:45.417030 GPU 0 63610 test begin: paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 4, 0],"float32"), list[list[1,2,],list[0,1,],], )

Intel MKL ERROR: Parameter 9 was incorrect on entry to cblas_sgemm.

Intel MKL ERROR: Parameter 11 was incorrect on entry to cblas_sgemm.
[accuracy error] backward  paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 4, 0],"float32"), list[list[1,2,],list[0,1,],], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 7 / 48 (14.6%)
Greatest absolute difference: 1.9769226104286898e+20 at index (0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 4, 4]), dtype=torch.float32)
tensor([[[1.9769e+20, 4.5807e-41, 1.6918e-38, 0.0000e+00],
         [5.0639e-32, 0.0000e+00, 1.9769e+20, 4.5807e-41],
         [1.6918e-38, 0.0000e+00, 5.0651e-32, 0.0000e+00],
         [1.9769e+20, 4.5807e-41, 1.6939e-38, 0.0000e+00]],

        [[5.2084e-32, 0.0000e+00, 1.9769e+20, 4.5807e-41],
         [1.6963e-38, 0.0000e+00, 5.3661e-32, 0.0000e+00],
         [1.9769e+20, 4.5807e-41, 1.6952e-38, 0.0000e+00],
         [5.2959e-32, 0.0000e+00, 1.9769e+20, 4.5807e-41]],

        [[1.7098e-38, 0.0000e+00, 6.2752e-32, 0.0000e+00],
         [1.9769e+20, 4.5807e-41, 0.0000e+00, 0.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]])
DESIRED: (shape=torch.Size([3, 4, 4]), dtype=torch.float32)
tensor([[[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]],

        [[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]],

        [[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]]])

2025-06-05 15:25:45.525500 GPU 0 63191 test begin: paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 4, 0],"float32"), tuple(list[1,2,],list[0,1,],), )

Intel MKL ERROR: Parameter 9 was incorrect on entry to cblas_sgemm.

Intel MKL ERROR: Parameter 11 was incorrect on entry to cblas_sgemm.
[accuracy error] backward  paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 4, 0],"float32"), tuple(list[1,2,],list[0,1,],), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 17 / 48 (35.4%)
Greatest absolute difference: 7.1443279863152655e+31 at index (2, 3, 0) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 4, 4]), dtype=torch.float32)
tensor([[[ 9.1835e+20,  4.5862e-41, -9.3675e-17,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
         [ 1.2208e+06,  0.0000e+00, -9.8608e-32,  1.0581e+21],
         [ 5.2165e-11,  1.1578e+27,  7.5031e+28,  1.9284e+31]],

        [[ 8.9718e+00,  7.3787e+28,  1.6928e+22,  7.0067e+22],
         [-3.7475e-27, -1.3042e-26, -1.2987e-31,  4.7431e+30],
         [-1.2238e-26, -3.8032e-31,  1.7862e+31, -6.1864e-34],
         [ 5.1490e-11,  8.2954e+17,  6.3016e-42,  0.0000e+00]],

        [[-6.4319e-17,  0.0000e+00, -5.5443e-17,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
         [ 4.7414e+16,  2.6176e-12,  4.2484e-05,  1.9146e+23],
         [ 7.1443e+31,  3.6015e-14,  1.7743e+28,  1.3458e-14]]])
DESIRED: (shape=torch.Size([3, 4, 4]), dtype=torch.float32)
tensor([[[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]],

        [[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]],

        [[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]]])

2025-06-05 15:25:46.201067 GPU 1 67094 test begin: paddle.tile(Tensor([1, 0, 1, 1, 1, 1],"float32"), list[1,3,4,4,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 6>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 12> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108365 (unix time) try "date -d @1749108365" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fd067a000ef) received by PID 67094 (TID 0x7fd17acd7740) from PID 1738539247 ***]


2025-06-05 15:25:46.234086 GPU 0 63242 test begin: paddle.tile(Tensor([1, 0, 1, 1, 1, 3],"float32"), list[216,248,1,1,2,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 6>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 12> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108346 (unix time) try "date -d @1749108346" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f63ed2930ef) received by PID 63242 (TID 0x7f650056a740) from PID 18446744073393484015 ***]


2025-06-05 15:25:46.291246 GPU 1 67059 test begin: paddle.tile(Tensor([1, 0, 1, 1],"float32"), list[3,1,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 4>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 4> const&, Eigen::DSizes<long, 8> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108366 (unix time) try "date -d @1749108366" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f42bbba00ef) received by PID 67059 (TID 0x7f43cee77740) from PID 18446744072564113647 ***]


2025-06-05 15:25:46.319353 GPU 0 63192 test begin: paddle.tile(Tensor([1, 0, 1, 64, 16],"float32"), list[1,1,4,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 5>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108346 (unix time) try "date -d @1749108346" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f42015970ef) received by PID 63192 (TID 0x7f431486e740) from PID 22638831 ***]


2025-06-05 15:25:46.369512 GPU 0 63610 test begin: paddle.tile(Tensor([1, 0, 13, 13],"float32"), list[3,1,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 4>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 4> const&, Eigen::DSizes<long, 8> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108346 (unix time) try "date -d @1749108346" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fb19ffdd0ef) received by PID 63610 (TID 0x7fb2b31b4740) from PID 18446744072098795759 ***]


2025-06-05 15:25:46.383879 GPU 0 63191 test begin: paddle.tile(Tensor([1, 0, 2, 2],"float32"), list[1,10,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 4>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 4> const&, Eigen::DSizes<long, 8> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108346 (unix time) try "date -d @1749108346" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fd74fe790ef) received by PID 63191 (TID 0x7fd863050740) from PID 1340575983 ***]


2025-06-05 15:25:46.572029 GPU 0 63213 test begin: paddle.tile(Tensor([1, 0, 64, 64, 2],"float32"), tuple(16,1,1,1,1,), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 5>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108346 (unix time) try "date -d @1749108346" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f5daf3860ef) received by PID 63213 (TID 0x7f5ec265d740) from PID 18446744072354291951 ***]


2025-06-05 15:25:46.584923 GPU 0 62990 test begin: paddle.tile(Tensor([1, 1, 0, 1, 1, 3],"float32"), list[216,248,1,1,2,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 6>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 12> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108346 (unix time) try "date -d @1749108346" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f31672060ef) received by PID 62990 (TID 0x7f327a4dd740) from PID 1730175215 ***]


2025-06-05 15:25:46.677498 GPU 0 64602 test begin: paddle.tile(Tensor([1, 1, 0, 13],"float32"), list[3,1,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 4>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 4> const&, Eigen::DSizes<long, 8> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108346 (unix time) try "date -d @1749108346" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f8f4bbcc0ef) received by PID 64602 (TID 0x7f905eea3740) from PID 1270661359 ***]


2025-06-05 15:25:49.385695 GPU 0 64424 test begin: paddle.tile(Tensor([1, 1, 0, 1],"float32"), list[3,1,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 4>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 4> const&, Eigen::DSizes<long, 8> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108350 (unix time) try "date -d @1749108350" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fa25f65c0ef) received by PID 64424 (TID 0x7fa372933740) from PID 1600504047 ***]


2025-06-05 15:25:51.294991 GPU 0 64462 test begin: paddle.tile(Tensor([1, 1, 0, 2],"float32"), list[1,10,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 4>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 4> const&, Eigen::DSizes<long, 8> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108352 (unix time) try "date -d @1749108352" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fde9090a0ef) received by PID 64462 (TID 0x7fdfa3be1740) from PID 18446744071839981807 ***]


2025-06-05 15:25:51.669612 GPU 0 64442 test begin: paddle.tile(Tensor([1, 1, 0, 64, 2],"float32"), tuple(16,1,1,1,1,), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 5>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108352 (unix time) try "date -d @1749108352" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f431bb650ef) received by PID 64442 (TID 0x7f442ed3c740) from PID 464933103 ***]


2025-06-05 15:25:53.571396 GPU 0 64482 test begin: paddle.tile(Tensor([1, 1, 1, 0, 1, 3],"float32"), list[216,248,1,1,2,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 6>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 12> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108354 (unix time) try "date -d @1749108354" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f461a7780ef) received by PID 64482 (TID 0x7f472da4f740) from PID 444039407 ***]


2025-06-05 15:25:54.340046 GPU 0 67465 test begin: paddle.tile(Tensor([1, 1, 1, 0],"float32"), list[3,1,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 4>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 4> const&, Eigen::DSizes<long, 8> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108371 (unix time) try "date -d @1749108371" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f760cf170ef) received by PID 67465 (TID 0x7f77201ee740) from PID 217149679 ***]


2025-06-05 15:25:54.550353 GPU 0 67488 test begin: paddle.tile(Tensor([1, 1, 1, 1, 0, 3],"float32"), list[216,248,1,1,2,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 6>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 12> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108374 (unix time) try "date -d @1749108374" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fbd8461f0ef) received by PID 67488 (TID 0x7fbe978f6740) from PID 18446744071635595503 ***]


2025-06-05 15:25:55.531341 GPU 0 67486 test begin: paddle.tile(Tensor([1, 1, 1, 1, 1, 0],"float32"), list[216,248,1,1,2,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 6>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 12> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108375 (unix time) try "date -d @1749108375" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f9baee240ef) received by PID 67486 (TID 0x7f9cc20fb740) from PID 18446744072348647663 ***]


2025-06-05 15:25:55.669099 GPU 0 67534 test begin: paddle.tile(Tensor([1, 1, 13, 0],"float32"), list[3,1,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 4>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 4> const&, Eigen::DSizes<long, 8> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108375 (unix time) try "date -d @1749108375" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f3787e1d0ef) received by PID 67534 (TID 0x7f389aff4740) from PID 18446744071694307567 ***]


2025-06-05 15:25:55.738282 GPU 0 67574 test begin: paddle.tile(Tensor([1, 1, 2, 0],"float32"), list[1,10,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 4>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 4> const&, Eigen::DSizes<long, 8> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108376 (unix time) try "date -d @1749108376" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fbd157f90ef) received by PID 67574 (TID 0x7fbe289d0740) from PID 360681711 ***]


2025-06-05 15:25:55.769225 GPU 0 67519 test begin: paddle.tile(Tensor([1, 1, 64, 0, 2],"float32"), tuple(16,1,1,1,1,), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 5>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108376 (unix time) try "date -d @1749108376" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fdfff5c60ef) received by PID 67519 (TID 0x7fe11289d740) from PID 18446744073698828527 ***]


2025-06-05 15:25:55.814170 GPU 0 67556 test begin: paddle.tile(Tensor([1, 1, 64, 64, 0],"float32"), tuple(16,1,1,1,1,), )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 5>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108377 (unix time) try "date -d @1749108377" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f618b0700ef) received by PID 67556 (TID 0x7f629e347740) from PID 18446744071747076335 ***]


2025-06-05 15:25:57.830484 GPU 0 67613 test begin: paddle.tile(Tensor([1, 2, 0, 64, 16],"float32"), list[1,1,4,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 5>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108378 (unix time) try "date -d @1749108378" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f3595f2b0ef) received by PID 67613 (TID 0x7f36a9202740) from PID 18446744071930294511 ***]


2025-06-05 15:26:02.185654 GPU 0 67705 test begin: paddle.tile(Tensor([1, 2, 1, 0, 16],"float32"), list[1,1,4,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 5>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108382 (unix time) try "date -d @1749108382" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f78c62c10ef) received by PID 67705 (TID 0x7f79d9498740) from PID 18446744072739361007 ***]


2025-06-05 15:26:03.252541 GPU 1 67025 test begin: paddle.tile(Tensor([1, 2, 1, 64, 0],"float32"), list[1,1,4,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 5>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108363 (unix time) try "date -d @1749108363" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f581017f0ef) received by PID 67025 (TID 0x7f5923456740) from PID 270004463 ***]


2025-06-05 15:26:03.491230 GPU 0 67771 test begin: paddle.tile(Tensor([1, 3, 0, 1, 1, 1],"float32"), list[1,3,4,4,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 6>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 12> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108384 (unix time) try "date -d @1749108384" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fa17cd180ef) received by PID 67771 (TID 0x7fa28ffef740) from PID 2094104815 ***]


2025-06-05 15:26:04.573837 GPU 1 67139 test begin: paddle.tile(Tensor([1, 3, 1, 0, 1, 1],"float32"), list[1,3,4,4,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 6>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 12> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108364 (unix time) try "date -d @1749108364" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f214a2ca0ef) received by PID 67139 (TID 0x7f225d5a1740) from PID 1244438767 ***]


2025-06-05 15:26:04.593703 GPU 1 67061 test begin: paddle.tile(Tensor([1, 3, 1, 1, 0, 1],"float32"), list[1,3,4,4,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 6>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 12> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108364 (unix time) try "date -d @1749108364" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fb199b500ef) received by PID 67061 (TID 0x7fb2ace27740) from PID 18446744071993360623 ***]


2025-06-05 15:26:04.674536 GPU 1 67048 test begin: paddle.tile(Tensor([1, 3, 1, 1, 1, 0],"float32"), list[1,3,4,4,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 6>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 12> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108364 (unix time) try "date -d @1749108364" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fc3763650ef) received by PID 67048 (TID 0x7fc48953c740) from PID 1983271151 ***]


2025-06-05 15:26:04.693691 GPU 1 67128 test begin: paddle.tile(Tensor([13, 0, 16, 16],"float32"), repeat_times=list[1,1,4,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 4>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 4> const&, Eigen::DSizes<long, 8> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108364 (unix time) try "date -d @1749108364" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fa371bb50ef) received by PID 67128 (TID 0x7fa484d8c740) from PID 1908101359 ***]


2025-06-05 15:26:04.895896 GPU 1 67076 test begin: paddle.tile(Tensor([13, 2, 0, 16],"float32"), repeat_times=list[1,1,4,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 4>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 4> const&, Eigen::DSizes<long, 8> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108365 (unix time) try "date -d @1749108365" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fb0078c10ef) received by PID 67076 (TID 0x7fb11aa98740) from PID 126619887 ***]


2025-06-05 15:26:06.515163 GPU 1 67114 test begin: paddle.tile(Tensor([13, 2, 16, 0],"float32"), repeat_times=list[1,1,4,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 4>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 4> const&, Eigen::DSizes<long, 8> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108367 (unix time) try "date -d @1749108367" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7efddd2610ef) received by PID 67114 (TID 0x7efef0438740) from PID 18446744073124843759 ***]


2025-06-05 15:26:07.195742 GPU 1 67174 test begin: paddle.tile(Tensor([16, 0, 1, 1, 4],"float32"), list[1,1,64,64,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 5>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108367 (unix time) try "date -d @1749108367" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7ff96e3150ef) received by PID 67174 (TID 0x7ffa814ec740) from PID 1848725743 ***]


2025-06-05 15:26:07.430461 GPU 1 67075 test begin: paddle.tile(Tensor([16, 0, 1, 3, 64, 64],"float32"), list[1,11,1,1,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 6>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 12> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108367 (unix time) try "date -d @1749108367" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7ff6fc0300ef) received by PID 67075 (TID 0x7ff80f307740) from PID 18446744073642639599 ***]


2025-06-05 15:26:11.966559 GPU 0 67980 test begin: paddle.tile(Tensor([16, 0, 1, 58, 58],"float32"), list[1,1,4,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 5>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108413 (unix time) try "date -d @1749108413" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f56f9f830ef) received by PID 67980 (TID 0x7f580d25a740) from PID 18446744073608376559 ***]


2025-06-05 15:26:12.333579 GPU 1 68036 test begin: paddle.tile(Tensor([16, 1, 0, 3, 64, 64],"float32"), list[1,11,1,1,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 6>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 12> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108411 (unix time) try "date -d @1749108411" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f5662f730ef) received by PID 68036 (TID 0x7f577624a740) from PID 1660367087 ***]


2025-06-05 15:26:13.012097 GPU 1 68006 test begin: paddle.tile(Tensor([16, 1, 1, 0, 64, 64],"float32"), list[1,11,1,1,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 6>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 12> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108413 (unix time) try "date -d @1749108413" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f92564060ef) received by PID 68006 (TID 0x7f93696dd740) from PID 1447059695 ***]


2025-06-05 15:26:13.121040 GPU 1 68049 test begin: paddle.tile(Tensor([16, 1, 1, 3, 0, 64],"float32"), list[1,11,1,1,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 6>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 12> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108415 (unix time) try "date -d @1749108415" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fc1699c90ef) received by PID 68049 (TID 0x7fc27cba0740) from PID 1771868399 ***]


2025-06-05 15:26:13.640124 GPU 1 68073 test begin: paddle.tile(Tensor([16, 1, 1, 3, 64, 0],"float32"), list[1,11,1,1,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 6>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 6> const&, Eigen::DSizes<long, 12> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108414 (unix time) try "date -d @1749108414" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f3b08ec30ef) received by PID 68073 (TID 0x7f3c1c19a740) from PID 149696751 ***]


2025-06-05 15:26:13.975483 GPU 1 68094 test begin: paddle.tile(Tensor([16, 10, 0, 1, 4],"float32"), list[1,1,64,64,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 5>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108416 (unix time) try "date -d @1749108416" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f1aa255f0ef) received by PID 68094 (TID 0x7f1bb5836740) from PID 18446744072138125551 ***]


2025-06-05 15:26:14.370623 GPU 1 68093 test begin: paddle.tile(Tensor([16, 10, 0, 58, 58],"float32"), list[1,1,4,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 5>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108415 (unix time) try "date -d @1749108415" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f6b45a190ef) received by PID 68093 (TID 0x7f6c58bf0740) from PID 1168216303 ***]


2025-06-05 15:26:16.437520 GPU 1 68074 test begin: paddle.tile(Tensor([16, 10, 1, 0, 4],"float32"), list[1,1,64,64,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 5>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108424 (unix time) try "date -d @1749108424" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f79225630ef) received by PID 68074 (TID 0x7f7a3583a740) from PID 576073967 ***]


2025-06-05 15:26:16.633087 GPU 1 68114 test begin: paddle.tile(Tensor([16, 10, 1, 0, 58],"float32"), list[1,1,4,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 5>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108415 (unix time) try "date -d @1749108415" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f6e8b76e0ef) received by PID 68114 (TID 0x7f6f9ea45740) from PID 18446744071754408175 ***]


2025-06-05 15:26:16.731528 GPU 1 68148 test begin: paddle.tile(Tensor([16, 10, 1, 1, 0],"float32"), list[1,1,64,64,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 5>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108419 (unix time) try "date -d @1749108419" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f8763a920ef) received by PID 68148 (TID 0x7f8876d69740) from PID 1672028399 ***]


2025-06-05 15:26:18.325119 GPU 1 68177 test begin: paddle.tile(Tensor([16, 10, 1, 58, 0],"float32"), list[1,1,4,1,1,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   TileGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::tile_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::TileGradKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
5   phi::funcs::EigenBroadcastGrad<Eigen::DefaultDevice, float, 5>::Eval(Eigen::DefaultDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 0, Eigen::MakePointer>, Eigen::DSizes<long, 5> const&, Eigen::DSizes<long, 10> const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108421 (unix time) try "date -d @1749108421" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f451b9520ef) received by PID 68177 (TID 0x7f462ec29740) from PID 462758127 ***]


2025-06-05 15:26:20.413960 GPU 1 68189 test begin: paddle.unflatten(x=Tensor([0, 6, 16],"float32"), axis=-1, shape=list[-1,2,], )
[paddle error] paddle.unflatten(x=Tensor([0, 6, 16],"float32"), axis=-1, shape=list[-1,2,], ) 
 (InvalidArgument) can not reshape 0, 6, 16 to 0, 6, -1, 2, because the unspecified dimension 2 can be any number and is ambiguous
  [Hint: Expected unk_dim_idx == -1, but received unk_dim_idx:2 != -1:-1.] (at ../paddle/phi/infermeta/unary.cc:2209)


2025-06-05 15:26:25.495600 GPU 0 68383 test begin: paddle.unflatten(x=Tensor([4, 0, 16],"float32"), axis=-1, shape=list[-1,2,], )
[paddle error] paddle.unflatten(x=Tensor([4, 0, 16],"float32"), axis=-1, shape=list[-1,2,], ) 
 (InvalidArgument) can not reshape 4, 0, 16 to 4, 0, -1, 2, because the unspecified dimension 2 can be any number and is ambiguous
  [Hint: Expected unk_dim_idx == -1, but received unk_dim_idx:2 != -1:-1.] (at ../paddle/phi/infermeta/unary.cc:2209)


2025-06-05 15:26:26.978426 GPU 0 68482 test begin: paddle.unflatten(x=Tensor([4, 0, 16],"float32"), axis=0, shape=list[-1,], )
[paddle error] paddle.unflatten(x=Tensor([4, 0, 16],"float32"), axis=0, shape=list[-1,], ) 
 (InvalidArgument) can not reshape 4, 0, 16 to -1, 0, 16, because the unspecified dimension 0 can be any number and is ambiguous
  [Hint: Expected unk_dim_idx == -1, but received unk_dim_idx:0 != -1:-1.] (at ../paddle/phi/infermeta/unary.cc:2209)


2025-06-05 15:26:27.039147 GPU 0 68450 test begin: paddle.unflatten(x=Tensor([4, 0, 16],"float32"), axis=0, shape=tuple(-1,), )
[paddle error] paddle.unflatten(x=Tensor([4, 0, 16],"float32"), axis=0, shape=tuple(-1,), ) 
 (InvalidArgument) can not reshape 4, 0, 16 to -1, 0, 16, because the unspecified dimension 0 can be any number and is ambiguous
  [Hint: Expected unk_dim_idx == -1, but received unk_dim_idx:0 != -1:-1.] (at ../paddle/phi/infermeta/unary.cc:2209)


2025-06-05 15:26:27.450132 GPU 0 68492 test begin: paddle.unflatten(x=Tensor([4, 0, 16],"float32"), axis=0, shape=tuple(-1,2,), )
[paddle error] paddle.unflatten(x=Tensor([4, 0, 16],"float32"), axis=0, shape=tuple(-1,2,), ) 
 (InvalidArgument) can not reshape 4, 0, 16 to -1, 2, 0, 16, because the unspecified dimension 0 can be any number and is ambiguous
  [Hint: Expected unk_dim_idx == -1, but received unk_dim_idx:0 != -1:-1.] (at ../paddle/phi/infermeta/unary.cc:2209)


2025-06-05 15:26:27.454529 GPU 0 68513 test begin: paddle.unflatten(x=Tensor([4, 6, 0],"float32"), axis=0, shape=list[-1,], )
[paddle error] paddle.unflatten(x=Tensor([4, 6, 0],"float32"), axis=0, shape=list[-1,], ) 
 (InvalidArgument) can not reshape 4, 6, 0 to -1, 6, 0, because the unspecified dimension 0 can be any number and is ambiguous
  [Hint: Expected unk_dim_idx == -1, but received unk_dim_idx:0 != -1:-1.] (at ../paddle/phi/infermeta/unary.cc:2209)


2025-06-05 15:26:27.739650 GPU 0 68899 test begin: paddle.unflatten(x=Tensor([4, 6, 0],"float32"), axis=0, shape=tuple(-1,), )
[paddle error] paddle.unflatten(x=Tensor([4, 6, 0],"float32"), axis=0, shape=tuple(-1,), ) 
 (InvalidArgument) can not reshape 4, 6, 0 to -1, 6, 0, because the unspecified dimension 0 can be any number and is ambiguous
  [Hint: Expected unk_dim_idx == -1, but received unk_dim_idx:0 != -1:-1.] (at ../paddle/phi/infermeta/unary.cc:2209)


2025-06-05 15:26:27.907633 GPU 0 68917 test begin: paddle.unflatten(x=Tensor([4, 6, 0],"float32"), axis=0, shape=tuple(-1,2,), )
[paddle error] paddle.unflatten(x=Tensor([4, 6, 0],"float32"), axis=0, shape=tuple(-1,2,), ) 
 (InvalidArgument) can not reshape 4, 6, 0 to -1, 2, 6, 0, because the unspecified dimension 0 can be any number and is ambiguous
  [Hint: Expected unk_dim_idx == -1, but received unk_dim_idx:0 != -1:-1.] (at ../paddle/phi/infermeta/unary.cc:2209)


2025-06-05 15:26:30.184458 GPU 0 68958 test begin: paddle.unique(x=Tensor([0, 2],"int32"), axis=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_unique(_object*, _object*, _object*)
1   unique_ad_func(paddle::Tensor const&, bool, bool, bool, std::vector<int, std::allocator<int> >, phi::DataType)
2   paddle::experimental::unique(paddle::Tensor const&, bool, bool, bool, std::vector<int, std::allocator<int> > const&, phi::DataType)
3   void phi::UniqueKernel<int, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, bool, bool, bool, std::vector<int, std::allocator<int> > const&, phi::DataType, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)
4   void phi::UniqueRawKernel<int, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, bool, bool, bool, std::vector<int, std::allocator<int> > const&, phi::DataType, bool, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, int>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108448 (unix time) try "date -d @1749108448" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 68958 (TID 0x7f80801ea740) from PID 0 ***]


2025-06-05 15:26:40.821108 GPU 0 69049 test begin: paddle.unique(x=Tensor([0, 2],"int64"), axis=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_unique(_object*, _object*, _object*)
1   unique_ad_func(paddle::Tensor const&, bool, bool, bool, std::vector<int, std::allocator<int> >, phi::DataType)
2   paddle::experimental::unique(paddle::Tensor const&, bool, bool, bool, std::vector<int, std::allocator<int> > const&, phi::DataType)
3   void phi::UniqueKernel<long, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, bool, bool, bool, std::vector<int, std::allocator<int> > const&, phi::DataType, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)
4   void phi::UniqueRawKernel<long, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, bool, bool, bool, std::vector<int, std::allocator<int> > const&, phi::DataType, bool, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, long>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108454 (unix time) try "date -d @1749108454" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 69049 (TID 0x7f23a0b92740) from PID 0 ***]


2025-06-05 15:26:41.606056 GPU 0 69098 test begin: paddle.unique(x=Tensor([2, 0],"float32"), axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_unique(_object*, _object*, _object*)
1   unique_ad_func(paddle::Tensor const&, bool, bool, bool, std::vector<int, std::allocator<int> >, phi::DataType)
2   paddle::experimental::unique(paddle::Tensor const&, bool, bool, bool, std::vector<int, std::allocator<int> > const&, phi::DataType)
3   void phi::UniqueKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, bool, bool, bool, std::vector<int, std::allocator<int> > const&, phi::DataType, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)
4   void phi::UniqueRawKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, bool, bool, bool, std::vector<int, std::allocator<int> > const&, phi::DataType, bool, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108458 (unix time) try "date -d @1749108458" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 69098 (TID 0x7f7eb31ed740) from PID 0 ***]


2025-06-05 15:27:12.887340 GPU 1 68189 test begin: paddle.unique(x=Tensor([2, 0],"float64"), axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_unique(_object*, _object*, _object*)
1   unique_ad_func(paddle::Tensor const&, bool, bool, bool, std::vector<int, std::allocator<int> >, phi::DataType)
2   paddle::experimental::unique(paddle::Tensor const&, bool, bool, bool, std::vector<int, std::allocator<int> > const&, phi::DataType)
3   void phi::UniqueKernel<double, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, bool, bool, bool, std::vector<int, std::allocator<int> > const&, phi::DataType, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)
4   void phi::UniqueRawKernel<double, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, bool, bool, bool, std::vector<int, std::allocator<int> > const&, phi::DataType, bool, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)
5   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108433 (unix time) try "date -d @1749108433" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 68189 (TID 0x7fe50681e740) from PID 0 ***]


2025-06-05 15:27:13.419647 GPU 1 69724 test begin: paddle.unique_consecutive(Tensor([0],"float64"), return_inverse=True, return_counts=True, axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_unique_consecutive(_object*, _object*, _object*)
1   unique_consecutive_ad_func(paddle::Tensor const&, bool, bool, std::vector<int, std::allocator<int> >, phi::DataType)
2   paddle::experimental::unique_consecutive(paddle::Tensor const&, bool, bool, std::vector<int, std::allocator<int> > const&, phi::DataType)
3   void phi::UniqueConsecutiveKernel<double, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, bool, bool, std::vector<int, std::allocator<int> > const&, phi::DataType, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108477 (unix time) try "date -d @1749108477" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 69724 (TID 0x7fd3c932d740) from PID 0 ***]


2025-06-05 15:27:14.715341 GPU 0 69742 test begin: paddle.unique_consecutive(x=Tensor([0, 4],"float32"), return_inverse=True, return_counts=True, axis=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_unique_consecutive(_object*, _object*, _object*)
1   unique_consecutive_ad_func(paddle::Tensor const&, bool, bool, std::vector<int, std::allocator<int> >, phi::DataType)
2   paddle::experimental::unique_consecutive(paddle::Tensor const&, bool, bool, std::vector<int, std::allocator<int> > const&, phi::DataType)
3   void phi::UniqueConsecutiveKernel<float, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, bool, bool, std::vector<int, std::allocator<int> > const&, phi::DataType, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, float>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108478 (unix time) try "date -d @1749108478" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 69742 (TID 0x7fe6c9461740) from PID 0 ***]


2025-06-05 15:27:16.121448 GPU 1 69804 test begin: paddle.unique_consecutive(x=Tensor([3, 0],"float64"), axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_unique_consecutive(_object*, _object*, _object*)
1   unique_consecutive_ad_func(paddle::Tensor const&, bool, bool, std::vector<int, std::allocator<int> >, phi::DataType)
2   paddle::experimental::unique_consecutive(paddle::Tensor const&, bool, bool, std::vector<int, std::allocator<int> > const&, phi::DataType)
3   void phi::UniqueConsecutiveKernel<double, phi::CPUContext>(phi::CPUContext const&, phi::DenseTensor const&, bool, bool, std::vector<int, std::allocator<int> > const&, phi::DataType, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)
4   phi::funcs::ConcatFunctor<phi::CPUContext, double>::operator()(phi::CPUContext const&, std::vector<phi::DenseTensor, std::allocator<phi::DenseTensor> > const&, int, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749108485 (unix time) try "date -d @1749108485" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 69804 (TID 0x7f10eb6bd740) from PID 0 ***]


2025-06-05 15:27:16.739686 GPU 1 69764 test begin: paddle.var(Tensor([0],"float32"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0605 15:28:08.345448 69764 dygraph_functions.cc:85403] got different data type, run type promotion automatically, this may cause data type been changed.
/root/paddlejob/PaddleAPITest-dev/tester/accuracy.py:203: UserWarning: Degrees of freedom is <= 0.
  paddle_output = self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
[accuracy error] paddle.var(Tensor([0],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected nan but got -0.0.
Absolute difference: nan (up to 0.01 allowed)
Relative difference: nan (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
-0.0
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
nan

2025-06-05 15:27:16.936686 GPU 1 69780 test begin: paddle.var(Tensor([1, 0, 4, 10],"float32"), list[1,3,], True, False, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0605 15:28:01.814333 69780 dygraph_functions.cc:85403] got different data type, run type promotion automatically, this may cause data type been changed.
/root/paddlejob/PaddleAPITest-dev/tester/accuracy.py:203: UserWarning: Degrees of freedom is <= 0.
  paddle_output = self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
[accuracy error] paddle.var(Tensor([1, 0, 4, 10],"float32"), list[1,3,], True, False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 4]), dtype=torch.float32)
tensor([[-0., -0., -0., -0.]])
DESIRED: (shape=torch.Size([1, 4]), dtype=torch.float32)
tensor([[nan, nan, nan, nan]])

2025-06-05 15:27:17.100618 GPU 1 69782 test begin: paddle.var(Tensor([1, 0, 4, 10],"float64"), list[1,2,], True, False, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0605 15:28:08.173261 69782 dygraph_functions.cc:85403] got different data type, run type promotion automatically, this may cause data type been changed.
/root/paddlejob/PaddleAPITest-dev/tester/accuracy.py:203: UserWarning: Degrees of freedom is <= 0.
  paddle_output = self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
[accuracy error] paddle.var(Tensor([1, 0, 4, 10],"float64"), list[1,2,], True, False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 10 / 10 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 10]), dtype=torch.float64)
tensor([[-0., -0., -0., -0., -0., -0., -0., -0., -0., -0.]],
       dtype=torch.float64)
DESIRED: (shape=torch.Size([1, 10]), dtype=torch.float64)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       dtype=torch.float64)

2025-06-05 15:27:17.204782 GPU 1 69817 test begin: paddle.var(Tensor([1, 0, 4, 10],"float64"), list[1,3,], True, False, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0605 15:28:07.122481 69817 dygraph_functions.cc:85403] got different data type, run type promotion automatically, this may cause data type been changed.
/root/paddlejob/PaddleAPITest-dev/tester/accuracy.py:203: UserWarning: Degrees of freedom is <= 0.
  paddle_output = self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
[accuracy error] paddle.var(Tensor([1, 0, 4, 10],"float64"), list[1,3,], True, False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 4]), dtype=torch.float64)
tensor([[-0., -0., -0., -0.]], dtype=torch.float64)
DESIRED: (shape=torch.Size([1, 4]), dtype=torch.float64)
tensor([[nan, nan, nan, nan]], dtype=torch.float64)

2025-06-05 15:27:17.718800 GPU 1 69876 test begin: paddle.var(Tensor([1, 0, 4, 10],"float64"), tuple(1,3,), True, False, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0605 15:28:03.789960 69876 dygraph_functions.cc:85403] got different data type, run type promotion automatically, this may cause data type been changed.
/root/paddlejob/PaddleAPITest-dev/tester/accuracy.py:203: UserWarning: Degrees of freedom is <= 0.
  paddle_output = self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
[accuracy error] paddle.var(Tensor([1, 0, 4, 10],"float64"), tuple(1,3,), True, False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 4]), dtype=torch.float64)
tensor([[-0., -0., -0., -0.]], dtype=torch.float64)
DESIRED: (shape=torch.Size([1, 4]), dtype=torch.float64)
tensor([[nan, nan, nan, nan]], dtype=torch.float64)

2025-06-05 15:27:18.311713 GPU 1 69745 test begin: paddle.var(Tensor([1, 3, 0, 10],"float64"), 2, True, False, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0605 15:28:08.600186 69745 dygraph_functions.cc:85403] got different data type, run type promotion automatically, this may cause data type been changed.
/root/paddlejob/PaddleAPITest-dev/tester/accuracy.py:203: UserWarning: Degrees of freedom is <= 0.
  paddle_output = self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
[accuracy error] paddle.var(Tensor([1, 3, 0, 10],"float64"), 2, True, False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 30 / 30 (100.0%)
Greatest absolute difference: nan at index (0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 3, 10]), dtype=torch.float64)
tensor([[[-0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
         [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
         [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0.]]],
       dtype=torch.float64)
DESIRED: (shape=torch.Size([1, 3, 10]), dtype=torch.float64)
tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],
       dtype=torch.float64)

2025-06-05 15:27:20.965122 GPU 1 69928 test begin: paddle.var(Tensor([1, 3, 0, 10],"float64"), list[1,2,], True, False, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0605 15:28:08.012971 69928 dygraph_functions.cc:85403] got different data type, run type promotion automatically, this may cause data type been changed.
/root/paddlejob/PaddleAPITest-dev/tester/accuracy.py:203: UserWarning: Degrees of freedom is <= 0.
  paddle_output = self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
[accuracy error] paddle.var(Tensor([1, 3, 0, 10],"float64"), list[1,2,], True, False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 10 / 10 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 10]), dtype=torch.float64)
tensor([[-0., -0., -0., -0., -0., -0., -0., -0., -0., -0.]],
       dtype=torch.float64)
DESIRED: (shape=torch.Size([1, 10]), dtype=torch.float64)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       dtype=torch.float64)

2025-06-05 15:27:22.325131 GPU 0 68383 test begin: paddle.var(Tensor([1, 3, 4, 0],"float32"), list[1,3,], True, False, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0605 15:27:22.810068 68383 dygraph_functions.cc:85403] got different data type, run type promotion automatically, this may cause data type been changed.
/root/paddlejob/PaddleAPITest-dev/tester/accuracy.py:203: UserWarning: Degrees of freedom is <= 0.
  paddle_output = self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
[accuracy error] paddle.var(Tensor([1, 3, 4, 0],"float32"), list[1,3,], True, False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 4]), dtype=torch.float32)
tensor([[-0., -0., -0., -0.]])
DESIRED: (shape=torch.Size([1, 4]), dtype=torch.float32)
tensor([[nan, nan, nan, nan]])

2025-06-05 15:27:22.555571 GPU 0 68450 test begin: paddle.var(Tensor([1, 3, 4, 0],"float64"), list[1,3,], True, False, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0605 15:27:23.619241 68450 dygraph_functions.cc:85403] got different data type, run type promotion automatically, this may cause data type been changed.
/root/paddlejob/PaddleAPITest-dev/tester/accuracy.py:203: UserWarning: Degrees of freedom is <= 0.
  paddle_output = self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
[accuracy error] paddle.var(Tensor([1, 3, 4, 0],"float64"), list[1,3,], True, False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 4]), dtype=torch.float64)
tensor([[-0., -0., -0., -0.]], dtype=torch.float64)
DESIRED: (shape=torch.Size([1, 4]), dtype=torch.float64)
tensor([[nan, nan, nan, nan]], dtype=torch.float64)

2025-06-05 15:27:22.577649 GPU 0 68482 test begin: paddle.var(Tensor([1, 3, 4, 0],"float64"), tuple(1,3,), True, False, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0605 15:27:23.389560 68482 dygraph_functions.cc:85403] got different data type, run type promotion automatically, this may cause data type been changed.
/root/paddlejob/PaddleAPITest-dev/tester/accuracy.py:203: UserWarning: Degrees of freedom is <= 0.
  paddle_output = self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
[accuracy error] paddle.var(Tensor([1, 3, 4, 0],"float64"), tuple(1,3,), True, False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 4]), dtype=torch.float64)
tensor([[-0., -0., -0., -0.]], dtype=torch.float64)
DESIRED: (shape=torch.Size([1, 4]), dtype=torch.float64)
tensor([[nan, nan, nan, nan]], dtype=torch.float64)

2025-06-05 15:27:23.506345 GPU 1 69948 test begin: paddle.var(Tensor([16, 0],"float32"), axis=-1, keepdim=True, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0605 15:28:09.560514 69948 dygraph_functions.cc:85403] got different data type, run type promotion automatically, this may cause data type been changed.
/root/paddlejob/PaddleAPITest-dev/tester/accuracy.py:203: UserWarning: Degrees of freedom is <= 0.
  paddle_output = self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
[accuracy error] paddle.var(Tensor([16, 0],"float32"), axis=-1, keepdim=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 16 / 16 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([16, 1]), dtype=torch.float32)
tensor([[-0.],
        [-0.],
        [-0.],
        [-0.],
        [-0.],
        [-0.],
        [-0.],
        [-0.],
        [-0.],
        [-0.],
        [-0.],
        [-0.],
        [-0.],
        [-0.],
        [-0.],
        [-0.]])
DESIRED: (shape=torch.Size([16, 1]), dtype=torch.float32)
tensor([[nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan]])

2025-06-05 15:27:23.571119 GPU 0 68383 test begin: paddle.var(Tensor([16, 0],"float64"), axis=-1, keepdim=True, )
[accuracy error] paddle.var(Tensor([16, 0],"float64"), axis=-1, keepdim=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 16 / 16 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([16, 1]), dtype=torch.float64)
tensor([[-0.],
        [-0.],
        [-0.],
        [-0.],
        [-0.],
        [-0.],
        [-0.],
        [-0.],
        [-0.],
        [-0.],
        [-0.],
        [-0.],
        [-0.],
        [-0.],
        [-0.],
        [-0.]], dtype=torch.float64)
DESIRED: (shape=torch.Size([16, 1]), dtype=torch.float64)
tensor([[nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan]], dtype=torch.float64)

2025-06-05 15:27:23.674277 GPU 0 68482 test begin: paddle.var(x=Tensor([0, 3, 3],"float64"), )
[accuracy error] paddle.var(x=Tensor([0, 3, 3],"float64"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected nan but got -0.0.
Absolute difference: nan (up to 0.01 allowed)
Relative difference: nan (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float64)
-0.0
DESIRED: (shape=torch.Size([]), dtype=torch.float64)
nan

2025-06-05 15:27:24.178588 GPU 0 68450 test begin: paddle.var(x=Tensor([0, 3, 3],"float64"), axis=0, )
[accuracy error] paddle.var(x=Tensor([0, 3, 3],"float64"), axis=0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 9 / 9 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 3]), dtype=torch.float64)
tensor([[-0., -0., -0.],
        [-0., -0., -0.],
        [-0., -0., -0.]], dtype=torch.float64)
DESIRED: (shape=torch.Size([3, 3]), dtype=torch.float64)
tensor([[nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan]], dtype=torch.float64)

2025-06-05 15:27:24.396958 GPU 0 68383 test begin: paddle.var(x=Tensor([0, 3, 3],"float64"), axis=list[0,1,], )
[accuracy error] paddle.var(x=Tensor([0, 3, 3],"float64"), axis=list[0,1,], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 3 / 3 (100.0%)
Greatest absolute difference: nan at index (0,) (up to 0.01 allowed)
Greatest relative difference: nan at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3]), dtype=torch.float64)
tensor([-0., -0., -0.], dtype=torch.float64)
DESIRED: (shape=torch.Size([3]), dtype=torch.float64)
tensor([nan, nan, nan], dtype=torch.float64)

2025-06-05 15:27:24.534354 GPU 0 68482 test begin: paddle.var(x=Tensor([0, 3, 3],"float64"), axis=tuple(0,1,), )
[accuracy error] paddle.var(x=Tensor([0, 3, 3],"float64"), axis=tuple(0,1,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 3 / 3 (100.0%)
Greatest absolute difference: nan at index (0,) (up to 0.01 allowed)
Greatest relative difference: nan at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3]), dtype=torch.float64)
tensor([-0., -0., -0.], dtype=torch.float64)
DESIRED: (shape=torch.Size([3]), dtype=torch.float64)
tensor([nan, nan, nan], dtype=torch.float64)

2025-06-05 15:27:25.096867 GPU 0 68482 test begin: paddle.var(x=Tensor([0, 3, 3],"float64"), axis=tuple(0,1,), keepdim=True, )
[accuracy error] paddle.var(x=Tensor([0, 3, 3],"float64"), axis=tuple(0,1,), keepdim=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 3 / 3 (100.0%)
Greatest absolute difference: nan at index (0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1, 3]), dtype=torch.float64)
tensor([[[-0., -0., -0.]]], dtype=torch.float64)
DESIRED: (shape=torch.Size([1, 1, 3]), dtype=torch.float64)
tensor([[[nan, nan, nan]]], dtype=torch.float64)

2025-06-05 15:27:25.116987 GPU 0 68513 test begin: paddle.var(x=Tensor([0, 3],"float32"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0605 15:27:25.411352 68513 dygraph_functions.cc:85403] got different data type, run type promotion automatically, this may cause data type been changed.
/root/paddlejob/PaddleAPITest-dev/tester/accuracy.py:203: UserWarning: Degrees of freedom is <= 0.
  paddle_output = self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
[accuracy error] paddle.var(x=Tensor([0, 3],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected nan but got -0.0.
Absolute difference: nan (up to 0.01 allowed)
Relative difference: nan (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
-0.0
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
nan

2025-06-05 15:27:25.146487 GPU 0 68492 test begin: paddle.var(x=Tensor([0, 3],"float64"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0605 15:27:26.066817 68492 dygraph_functions.cc:85403] got different data type, run type promotion automatically, this may cause data type been changed.
/root/paddlejob/PaddleAPITest-dev/tester/accuracy.py:203: UserWarning: Degrees of freedom is <= 0.
  paddle_output = self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
[accuracy error] paddle.var(x=Tensor([0, 3],"float64"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected nan but got -0.0.
Absolute difference: nan (up to 0.01 allowed)
Relative difference: nan (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float64)
-0.0
DESIRED: (shape=torch.Size([]), dtype=torch.float64)
nan

2025-06-05 15:27:25.246050 GPU 0 68899 test begin: paddle.var(x=Tensor([2, 0],"float32"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)
  return func(*args, **kwargs)
W0605 15:27:26.207953 68899 dygraph_functions.cc:85403] got different data type, run type promotion automatically, this may cause data type been changed.
/root/paddlejob/PaddleAPITest-dev/tester/accuracy.py:203: UserWarning: Degrees of freedom is <= 0.
  paddle_output = self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
[accuracy error] paddle.var(x=Tensor([2, 0],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected nan but got -0.0.
Absolute difference: nan (up to 0.01 allowed)
Relative difference: nan (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
-0.0
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
nan

2025-06-05 15:27:25.295892 GPU 0 68383 test begin: paddle.var(x=Tensor([2, 0],"float64"), )
[accuracy error] paddle.var(x=Tensor([2, 0],"float64"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected nan but got -0.0.
Absolute difference: nan (up to 0.01 allowed)
Relative difference: nan (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float64)
-0.0
DESIRED: (shape=torch.Size([]), dtype=torch.float64)
nan

2025-06-05 15:27:25.404949 GPU 0 68450 test begin: paddle.var(x=Tensor([3, 0, 3],"float64"), )
[accuracy error] paddle.var(x=Tensor([3, 0, 3],"float64"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected nan but got -0.0.
Absolute difference: nan (up to 0.01 allowed)
Relative difference: nan (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float64)
-0.0
DESIRED: (shape=torch.Size([]), dtype=torch.float64)
nan

2025-06-05 15:27:25.617230 GPU 0 68482 test begin: paddle.var(x=Tensor([3, 0, 3],"float64"), axis=list[0,1,], )
[accuracy error] paddle.var(x=Tensor([3, 0, 3],"float64"), axis=list[0,1,], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 3 / 3 (100.0%)
Greatest absolute difference: nan at index (0,) (up to 0.01 allowed)
Greatest relative difference: nan at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3]), dtype=torch.float64)
tensor([-0., -0., -0.], dtype=torch.float64)
DESIRED: (shape=torch.Size([3]), dtype=torch.float64)
tensor([nan, nan, nan], dtype=torch.float64)

2025-06-05 15:27:25.774286 GPU 0 68513 test begin: paddle.var(x=Tensor([3, 0, 3],"float64"), axis=tuple(0,1,), )
[accuracy error] paddle.var(x=Tensor([3, 0, 3],"float64"), axis=tuple(0,1,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 3 / 3 (100.0%)
Greatest absolute difference: nan at index (0,) (up to 0.01 allowed)
Greatest relative difference: nan at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3]), dtype=torch.float64)
tensor([-0., -0., -0.], dtype=torch.float64)
DESIRED: (shape=torch.Size([3]), dtype=torch.float64)
tensor([nan, nan, nan], dtype=torch.float64)

2025-06-05 15:27:26.162317 GPU 0 68450 test begin: paddle.var(x=Tensor([3, 0, 3],"float64"), axis=tuple(0,1,), keepdim=True, )
[accuracy error] paddle.var(x=Tensor([3, 0, 3],"float64"), axis=tuple(0,1,), keepdim=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 3 / 3 (100.0%)
Greatest absolute difference: nan at index (0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1, 3]), dtype=torch.float64)
tensor([[[-0., -0., -0.]]], dtype=torch.float64)
DESIRED: (shape=torch.Size([1, 1, 3]), dtype=torch.float64)
tensor([[[nan, nan, nan]]], dtype=torch.float64)

2025-06-05 15:27:26.536268 GPU 0 68383 test begin: paddle.var(x=Tensor([3, 3, 0],"float64"), )
[accuracy error] paddle.var(x=Tensor([3, 3, 0],"float64"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected nan but got -0.0.
Absolute difference: nan (up to 0.01 allowed)
Relative difference: nan (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float64)
-0.0
DESIRED: (shape=torch.Size([]), dtype=torch.float64)
nan

