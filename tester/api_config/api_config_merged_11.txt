paddle.diag(x=Tensor([2],"float64"), name="test name", )
paddle.cumsum(Tensor([5, 6],"float64"), axis=Tensor([1],"int32"), )
paddle.cumsum(Tensor([9, 10, 11],"float32"), axis=Tensor([1],"int64"), )
paddle.clip(x=Tensor([2],"float64"), min=Tensor([1],"float64"), max=Tensor([1],"float64"), name="test name", )
paddle.clip(x=Tensor([3, 3],"float64"), min=1, max=Tensor([1],"float64"), )
paddle.clip(Tensor([107136],"float32"), max=Tensor([],"int64"), )
paddle.clip(Tensor([],"float32"), Tensor([],"float32"), Tensor([],"float32"), )
paddle.clip(x=Tensor([1, 2],"float64"), min=Tensor([1],"float64"), max=Tensor([1],"float64"), )
paddle.clip(x=Tensor([2, 2],"float64"), min=Tensor([1],"float64"), max=Tensor([1],"float64"), )
paddle.clip(x=Tensor([3, 3],"float64"), min=Tensor([1],"float64"), max=None, )
paddle.clip(x=Tensor([3, 3],"float64"), min=Tensor([1],"float64"), max=Tensor([1],"float64"), )
paddle.clip(x=Tensor([3],"float64"), min=Tensor([1],"float64"), max=Tensor([1],"float64"), )
paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float32"), Tensor([1, 3, 8],"int64"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
paddle.nn.functional.max_unpool1d(Tensor([1, 3, 8],"float64"), Tensor([1, 3, 8],"int32"), kernel_size=2, stride=2, )
paddle.nn.functional.max_unpool2d(Tensor([2, 4, 11, 11],"float32"), Tensor([2, 4, 11, 11],"int32"), kernel_size=4, stride=None, padding=2, data_format="NCHW", output_size=None, name=None, )
paddle.nn.functional.max_unpool2d(Tensor([2, 4, 11, 11],"float64"), Tensor([2, 4, 11, 11],"int32"), kernel_size=4, stride=None, padding=2, data_format="NCHW", output_size=None, name=None, )
paddle.nn.functional.max_unpool2d(Tensor([2, 4, 20, 10],"float32"), Tensor([2, 4, 20, 10],"int32"), kernel_size=tuple(2,4,), stride=None, padding=0, data_format="NCHW", output_size=None, name=None, )
paddle.nn.functional.max_unpool2d(Tensor([2, 4, 20, 10],"float64"), Tensor([2, 4, 20, 10],"int32"), kernel_size=tuple(2,4,), stride=None, padding=0, data_format="NCHW", output_size=None, name=None, )
paddle.nn.functional.max_unpool2d(Tensor([2, 4, 20, 20],"float32"), Tensor([2, 4, 20, 20],"int32"), kernel_size=2, stride=None, padding=0, data_format="NCHW", output_size=None, name=None, )
paddle.nn.functional.max_unpool2d(Tensor([2, 4, 20, 20],"float32"), Tensor([2, 4, 20, 20],"int32"), kernel_size=2, stride=None, padding=0, data_format="NCHW", output_size=tuple(2,4,40,40,), name=None, )
paddle.nn.functional.max_unpool2d(Tensor([2, 4, 20, 20],"float64"), Tensor([2, 4, 20, 20],"int32"), kernel_size=2, stride=None, padding=0, data_format="NCHW", output_size=None, name=None, )
paddle.nn.functional.max_unpool2d(Tensor([2, 4, 20, 20],"float64"), Tensor([2, 4, 20, 20],"int32"), kernel_size=2, stride=None, padding=0, data_format="NCHW", output_size=tuple(2,4,40,40,), name=None, )
paddle.nn.functional.max_unpool2d(Tensor([2, 4, 21, 21],"float32"), Tensor([2, 4, 21, 21],"int32"), kernel_size=4, stride=2, padding=2, data_format="NCHW", output_size=None, name=None, )
paddle.nn.functional.max_unpool2d(Tensor([2, 4, 21, 21],"float64"), Tensor([2, 4, 21, 21],"int32"), kernel_size=4, stride=2, padding=2, data_format="NCHW", output_size=None, name=None, )
paddle.nn.functional.max_unpool2d(Tensor([2, 4, 7, 8],"float64"), Tensor([2, 4, 7, 8],"int64"), list[2,2,], stride=list[2,2,], padding=list[0,0,], data_format="NCHW", output_size=list[14,16,], name=None, )
paddle.nn.functional.max_unpool2d(Tensor([3, 2, 5, 5],"float64"), Tensor([3, 2, 5, 5],"int32"), list[4,4,], stride=list[2,2,], padding=list[0,0,], data_format="NCHW", output_size=list[12,12,], name=None, )
paddle.nn.functional.max_unpool2d(Tensor([3, 2, 5, 5],"float64"), Tensor([3, 2, 5, 5],"int64"), list[4,4,], stride=list[2,2,], padding=list[0,0,], data_format="NCHW", output_size=list[12,12,], name=None, )
paddle.nn.functional.max_unpool3d(Tensor([1, 1, 4, 5, 6],"float64"), Tensor([1, 1, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int32"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[7,9,11,], name=None, )
paddle.nn.functional.max_unpool3d(Tensor([1, 3, 4, 5, 6],"float64"), Tensor([1, 3, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
paddle.nn.functional.zeropad2d(Tensor([4, 3, 224, 224],"int32"), list[2,2,2,2,], )
paddle.nn.functional.zeropad2d(Tensor([4, 3, 224, 224],"int64"), list[1,2,3,4,], )
paddle.nn.functional.zeropad2d(Tensor([4, 3, 224, 224],"int64"), list[2,2,2,2,], )
paddle.nn.functional.zeropad2d(Tensor([4, 3, 224, 224],"int64"), list[2,2,4,1,], )
paddle.nn.functional.zeropad2d(Tensor([4, 3, 224, 224],"int64"), Tensor([4],"int32"), )
paddle.nn.functional.zeropad2d(Tensor([4, 3, 224, 224],"int64"), tuple(1,2,3,4,), )
paddle.nn.functional.softmax(Tensor([2, 2],"float32"), axis=Tensor([],"int64"), )
paddle.autograd.hessian(Tensor([5, 1],"float32"), list[Tensor([5, 2],"float32"),Tensor([5, 2],"float32"),], batch_axis=0, )
paddle.autograd.jacobian(Tensor([],"float64"), list[Tensor([4],"float64"),Tensor([4],"float64"),], batch_axis=None, )
paddle.cartesian_prod(list[Tensor([2],"complex128"),Tensor([1],"complex128"),Tensor([3],"complex128"),Tensor([0],"complex128"),], )
paddle.cartesian_prod(list[Tensor([2],"float16"),Tensor([2],"float16"),Tensor([1],"float16"),Tensor([0],"float16"),], )
paddle.cartesian_prod(list[Tensor([2],"float64"),Tensor([4],"float64"),Tensor([3],"float64"),Tensor([0],"float64"),], )
paddle.cartesian_prod(list[Tensor([2],"int64"),Tensor([2],"int64"),Tensor([1],"int64"),Tensor([0],"int64"),], )
paddle.cartesian_prod(list[Tensor([3],"complex128"),Tensor([5],"complex128"),Tensor([5],"complex128"),Tensor([0],"complex128"),], )
paddle.cartesian_prod(list[Tensor([3],"float64"),Tensor([5],"float64"),Tensor([3],"float64"),Tensor([0],"float64"),], )
paddle.cartesian_prod(list[Tensor([3],"int32"),Tensor([5],"int32"),Tensor([3],"int32"),Tensor([0],"int32"),], )
paddle.cartesian_prod(list[Tensor([4],"float16"),Tensor([3],"float16"),Tensor([5],"float16"),Tensor([0],"float16"),], )
paddle.cartesian_prod(list[Tensor([4],"float32"),Tensor([2],"float32"),Tensor([1],"float32"),Tensor([0],"float32"),], )
paddle.cartesian_prod(list[Tensor([4],"int32"),Tensor([4],"int32"),Tensor([5],"int32"),Tensor([0],"int32"),], )
paddle.cartesian_prod(list[Tensor([5],"complex64"),Tensor([2],"complex64"),Tensor([5],"complex64"),Tensor([0],"complex64"),], )
paddle.cartesian_prod(list[Tensor([5],"complex64"),Tensor([4],"complex64"),Tensor([3],"complex64"),Tensor([0],"complex64"),], )
paddle.cartesian_prod(list[Tensor([5],"int64"),Tensor([4],"int64"),Tensor([4],"int64"),Tensor([0],"int64"),], )
paddle.nn.functional.pad(Tensor([1, 1, 1, 1],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 1, 1],"int64"), pad=list[0,0,0,1,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 1, 10, 10],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 100, 100],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 100, 100],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 101, 101],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 101, 101],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 102, 102],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 102, 102],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 103, 103],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 103, 103],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 104, 104],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 104, 104],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 105, 105],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 106, 106],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 106, 106],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 107, 107],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 108, 108],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 108, 108],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 109, 109],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 109, 109],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 11, 11],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 110, 110],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 110, 110],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 111, 111],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 111, 111],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 112, 112],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 112, 112],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 113, 113],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 113, 113],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 114, 114],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 114, 114],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 115, 115],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 115, 115],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 116, 116],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 116, 116],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 117, 117],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 117, 117],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 118, 118],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 118, 118],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 119, 119],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 119, 119],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 12, 12],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 120, 120],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 120, 120],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 121, 121],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 121, 121],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 122, 122],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 123, 123],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 123, 123],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 124, 124],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 124, 124],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 125, 125],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 125, 125],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 126, 126],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 126, 126],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 127, 127],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 127, 127],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 128, 128],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 128, 128],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 128, 224],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 1, 129, 129],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 129, 129],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 13, 13],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 130, 130],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 130, 130],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 131, 131],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 132, 132],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 133, 133],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 133, 133],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 134, 134],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 134, 134],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 135, 135],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 135, 135],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 136, 136],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 137, 137],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 138, 138],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 138, 138],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 139, 139],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 139, 139],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 14, 14],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 140, 140],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 140, 140],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 141, 141],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 141, 141],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 142, 142],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 142, 142],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 143, 143],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 144, 144],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 144, 144],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 145, 145],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 146, 146],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 147, 147],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 147, 147],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 148, 148],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 149, 149],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 149, 149],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 15, 15],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 150, 150],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 150, 150],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 151, 151],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 151, 151],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 152, 152],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 153, 153],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 154, 154],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 154, 154],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 155, 155],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 155, 155],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 156, 156],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 157, 157],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 158, 158],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 158, 158],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 159, 159],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 16, 16],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 160, 160],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 160, 416],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 1, 161, 161],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 162, 162],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 162, 162],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 163, 163],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 163, 163],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 164, 164],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 164, 164],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 165, 165],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 165, 165],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 166, 166],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 167, 167],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 168, 168],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 169, 169],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 169, 169],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 17, 17],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 17, 17],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 170, 170],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 170, 170],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 171, 171],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 171, 171],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 172, 172],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 172, 172],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 173, 173],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 173, 173],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 174, 174],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 175, 175],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 175, 175],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 176, 176],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 176, 176],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 177, 177],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 178, 178],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 179, 179],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 18, 18],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 180, 180],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 181, 181],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 181, 181],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 182, 182],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 183, 183],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 183, 183],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 184, 184],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 185, 185],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 186, 186],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 187, 187],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 187, 187],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 188, 188],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 189, 189],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 189, 189],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 19, 19],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 19, 19],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 190, 190],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 190, 190],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 191, 191],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 191, 191],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 192, 192],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 192, 192],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 192, 512],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 1, 193, 193],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 193, 193],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 194, 194],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 194, 194],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 195, 195],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 196, 196],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 197, 197],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 197, 197],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 198, 198],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 198, 198],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 199, 199],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 2, 1],"int64"), pad=list[0,1,0,0,], mode="constant", value=-1000000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 1, 2, 2, 2],"int32"), pad=list[2,2,2,2,2,2,], mode="replicate", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 1, 2, 2, 2],"int64"), pad=list[2,2,2,2,2,2,], mode="replicate", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 1, 2, 2],"int32"), pad=list[2,2,2,2,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 1, 2, 2],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 2, 2],"int64"), pad=list[0,0,0,1,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 1, 2, 2],"int64"), pad=list[2,2,2,2,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 1, 20, 20],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 20, 20],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 200, 200],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 200, 200],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 201, 201],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 202, 202],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 203, 203],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 203, 203],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 204, 204],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 205, 205],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 206, 206],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 207, 207],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 207, 207],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 208, 208],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 209, 209],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 209, 209],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 21, 21],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 21, 21],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 210, 210],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 210, 210],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 211, 211],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 211, 211],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 212, 212],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 212, 212],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 213, 213],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 214, 214],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 215, 215],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 216, 216],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 217, 217],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 218, 218],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 219, 219],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 22, 22],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 220, 220],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 220, 220],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 221, 221],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 222, 222],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 222, 222],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 223, 223],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 224, 224],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 225, 225],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 226, 226],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 226, 226],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 227, 227],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 227, 227],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 228, 228],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 229, 229],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 23, 23],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 23, 23],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 230, 230],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 231, 231],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 232, 232],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 233, 233],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 234, 234],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 235, 235],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 236, 236],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 237, 237],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 238, 238],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 239, 239],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 24, 24],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 24, 24],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 240, 240],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 240, 240],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 241, 241],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 241, 241],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 242, 242],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 243, 243],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 243, 243],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 244, 244],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 245, 245],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 246, 246],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 247, 247],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 248, 248],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 249, 249],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 249, 249],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 25, 25],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 250, 250],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 251, 251],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 252, 252],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 253, 253],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 253, 253],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 254, 254],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 255, 255],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 256, 256],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 257, 257],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 258, 258],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 259, 259],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 26, 26],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 26, 26],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 260, 260],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 261, 261],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 262, 262],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 263, 263],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 264, 264],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 264, 264],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 265, 265],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 266, 266],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 267, 267],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 268, 268],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 268, 268],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 269, 269],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 27, 27],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 270, 270],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 270, 270],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 271, 271],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 272, 272],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 273, 273],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 274, 274],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 274, 274],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 275, 275],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 276, 276],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 276, 276],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 277, 277],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 277, 277],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 278, 278],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 279, 279],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 28, 28],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 28, 28],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 280, 280],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 281, 281],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 282, 282],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 283, 283],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 284, 284],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 285, 285],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 286, 286],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 287, 287],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 288, 288],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 289, 289],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 29, 29],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 29, 29],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 290, 290],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 291, 291],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 292, 292],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 293, 293],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 293, 293],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 298, 298],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 3, 2],"int64"), pad=list[0,1,0,0,], mode="constant", value=-1000000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 1, 3, 3],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 30, 30],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 30, 30],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 302, 302],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 307, 307],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 31, 31],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 31, 31],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 32, 32],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 32, 32],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 32, 512],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 1, 32, 544],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 1, 32, 576],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 1, 32, 672],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 1, 33, 33],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 33, 33],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 336, 336],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 339, 339],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 34, 34],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 34, 34],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 35, 35],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 35, 35],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 355, 355],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 36, 36],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 36, 36],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 369, 369],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 37, 37],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 38, 38],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 39, 39],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 39, 39],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 4, 4],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 40, 40],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 41, 41],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 42, 42],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 42, 42],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 43, 43],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 43, 43],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 44, 44],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 44, 44],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 45, 45],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 457, 457],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 46, 46],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 46, 46],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 47, 47],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 47, 47],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 477, 477],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 48, 48],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 48, 48],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 49, 49],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 49, 49],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 498, 498],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 5, 5],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 50, 50],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 50, 50],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 51, 51],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 52, 52],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 52, 52],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 53, 53],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 53, 53],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 54, 54],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 54, 54],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 55, 55],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 55, 55],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 56, 56],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 56, 56],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 57, 57],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 57, 57],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 58, 58],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 59, 59],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 59, 59],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 6, 6],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 60, 60],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 61, 61],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 61, 61],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 62, 62],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 62, 62],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 63, 63],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 63, 63],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 64, 64],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 64, 64],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 65, 65],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 66, 66],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 66, 66],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 67, 67],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 67, 67],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 68, 68],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 68, 68],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 69, 69],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 69, 69],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 7, 7],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 70, 70],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 70, 70],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 71, 71],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 71, 71],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 72, 72],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 72, 72],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 73, 73],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 73, 73],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 74, 74],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 74, 74],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 75, 75],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 75, 75],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 76, 76],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 76, 76],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 77, 77],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 77, 77],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 78, 78],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 78, 78],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 79, 79],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 79, 79],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 8, 8],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 80, 80],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 80, 80],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 81, 81],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 81, 81],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 82, 82],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 82, 82],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 83, 83],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 83, 83],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 84, 84],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 84, 84],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 85, 85],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 85, 85],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 86, 86],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 86, 86],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 87, 87],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 87, 87],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 88, 88],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 88, 88],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 89, 89],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 9, 9],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 90, 90],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 90, 90],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 91, 91],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 91, 91],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 92, 92],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 92, 92],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 93, 93],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 93, 93],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 94, 94],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 94, 94],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 95, 95],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 95, 95],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 96, 160],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 1, 96, 256],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 1, 96, 288],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 1, 96, 384],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 1, 96, 416],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 1, 96, 448],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 1, 96, 576],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 1, 96, 608],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 1, 96, 640],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 1, 96, 96],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 96, 96],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 97, 97],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 97, 97],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 98, 98],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 98, 98],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 99, 99],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 99, 99],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 128, 24, 104],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 128, 24, 112],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 128, 24, 144],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 128, 24, 152],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 128, 24, 160],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 128, 24, 40],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 128, 24, 64],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 128, 24, 72],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 128, 24, 96],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 128, 32, 56],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 128, 40, 104],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 128, 48, 128],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 128, 8, 128],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 128, 8, 136],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 128, 8, 144],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 128, 8, 168],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 2, 3],"int32"), pad=list[1,2,], mode="constant", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([1, 2, 3],"int32"), pad=list[1,2,], mode="reflect", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([1, 2, 3],"int32"), pad=list[1,2,], mode="replicate", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([1, 2, 3],"int32"), pad=list[2,2,], mode="replicate", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([1, 2, 3],"int64"), pad=list[1,2,], mode="constant", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([1, 2, 3],"int64"), pad=list[1,2,], mode="reflect", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([1, 2, 3],"int64"), pad=list[1,2,], mode="replicate", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([1, 2, 3],"int64"), pad=list[2,2,], mode="replicate", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([1, 256, 12, 20],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 256, 12, 32],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 256, 12, 36],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 256, 12, 48],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 256, 12, 52],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 256, 12, 56],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 256, 12, 72],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 256, 12, 76],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 256, 12, 80],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 256, 16, 28],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 256, 20, 52],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 256, 24, 64],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 256, 4, 64],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 256, 4, 68],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 256, 4, 72],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 256, 4, 84],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 6, 6, 3],"float32"), Tensor([4],"int32"), data_format="NHWC", )
paddle.nn.functional.pad(Tensor([1, 64, 16, 256],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([1, 64, 16, 272],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([1, 64, 16, 288],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([1, 64, 16, 336],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([1, 64, 48, 128],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([1, 64, 48, 144],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([1, 64, 48, 192],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([1, 64, 48, 208],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([1, 64, 48, 224],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([1, 64, 48, 288],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([1, 64, 48, 304],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([1, 64, 48, 320],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([1, 64, 48, 80],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([1, 64, 64, 112],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([1, 64, 80, 208],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([1, 64, 96, 256],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([10, 1, 32, 128],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 32, 160],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 32, 192],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 32, 224],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 32, 256],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 32, 288],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 32, 320],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 32, 384],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 32, 64],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 32, 96],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 64, 128],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 64, 160],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 64, 192],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 64, 224],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 64, 256],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 64, 288],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 64, 320],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 64, 352],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 64, 384],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 64, 416],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 64, 512],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 64, 544],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([14, 1, 10, 7],"int64"), pad=list[0,3,0,0,], mode="constant", value=0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([14, 1, 7, 7],"int64"), pad=list[0,0,0,1,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([14, 1, 7, 7],"int64"), pad=list[0,0,0,3,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([14, 1, 8, 7],"int64"), pad=list[0,1,0,0,], mode="constant", value=0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([2, 1, 3, 3],"int64"), pad=list[0,0,0,1,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([2, 1, 32, 128],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 1, 32, 64],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 1, 32, 640],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 1, 4, 3],"int64"), pad=list[0,1,0,0,], mode="constant", value=-10000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([2, 1, 4, 3],"int64"), pad=list[0,1,0,0,], mode="constant", value=-1000000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([2, 1, 4, 4],"int64"), pad=list[0,0,0,1,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([2, 1, 5, 4],"int64"), pad=list[0,1,0,0,], mode="constant", value=-10000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([2, 1, 5, 4],"int64"), pad=list[0,1,0,0,], mode="constant", value=-1000000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([2, 1, 64, 160],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 1, 64, 224],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 1, 64, 320],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 1, 64, 512],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 1, 64, 64],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 1, 64, 640],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 1, 96, 224],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 1, 96, 320],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 1, 96, 480],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 128, 16, 128],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 128, 16, 160],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 128, 16, 40],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 128, 16, 56],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 128, 16, 80],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 128, 24, 120],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 128, 24, 56],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 128, 24, 80],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 128, 8, 160],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 128, 8, 32],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 3, 4, 5],"complex128"), pad=Tensor([4],"int32"), mode="constant", value=100, )
paddle.nn.functional.pad(Tensor([2, 3, 4, 5],"complex128"), pad=Tensor([4],"int32"), mode="constant", value=100, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([2, 3, 4, 5],"complex128"), pad=Tensor([4],"int32"), mode="constant", value=100, data_format="NHWC", )
paddle.nn.functional.pad(Tensor([2, 3, 4, 5],"complex64"), pad=Tensor([4],"int32"), mode="constant", value=100, )
paddle.nn.functional.pad(Tensor([2, 3, 4, 5],"complex64"), pad=Tensor([4],"int32"), mode="constant", value=100, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([2, 3, 4, 5],"complex64"), pad=Tensor([4],"int32"), mode="constant", value=100, data_format="NHWC", )
paddle.nn.functional.pad(Tensor([2, 3, 4, 5],"float32"), pad=Tensor([4],"int32"), mode="constant", value=100, )
paddle.nn.functional.pad(Tensor([2, 3, 4, 5],"float32"), pad=Tensor([4],"int32"), mode="constant", value=100, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([2, 3, 4, 5],"float32"), pad=Tensor([4],"int32"), mode="constant", value=100, data_format="NHWC", )
paddle.nn.functional.pad(Tensor([2, 64, 16, 32],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([2, 64, 16, 320],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([2, 64, 16, 64],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([2, 64, 32, 112],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([2, 64, 32, 160],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([2, 64, 32, 256],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([2, 64, 32, 32],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([2, 64, 32, 320],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([2, 64, 32, 80],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([2, 64, 48, 112],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([2, 64, 48, 160],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([2, 64, 48, 240],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([3, 1, 32, 160],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([3, 1, 64, 32],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([3, 1, 64, 416],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([3, 1, 64, 672],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([3, 4, 5, 6, 7],"complex128"), pad=Tensor([6],"int64"), mode="reflect", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 5, 6, 7],"complex128"), pad=Tensor([6],"int64"), mode="reflect", value=0.0, data_format="NDHWC", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 5, 6, 7],"complex64"), pad=Tensor([6],"int64"), mode="reflect", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 5, 6, 7],"complex64"), pad=Tensor([6],"int64"), mode="reflect", value=0.0, data_format="NDHWC", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 5, 6, 7],"float32"), pad=Tensor([6],"int64"), mode="reflect", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 5, 6, 7],"float32"), pad=Tensor([6],"int64"), mode="reflect", value=0.0, data_format="NDHWC", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 5],"complex128"), pad=Tensor([2],"int32"), mode="constant", value=100, )
paddle.nn.functional.pad(Tensor([3, 4, 5],"complex128"), pad=Tensor([2],"int32"), mode="constant", value=100, data_format="NCL", )
paddle.nn.functional.pad(Tensor([3, 4, 5],"complex128"), pad=Tensor([2],"int32"), mode="constant", value=100, data_format="NLC", )
paddle.nn.functional.pad(Tensor([3, 4, 5],"complex64"), pad=Tensor([2],"int32"), mode="constant", value=100, )
paddle.nn.functional.pad(Tensor([3, 4, 5],"complex64"), pad=Tensor([2],"int32"), mode="constant", value=100, data_format="NCL", )
paddle.nn.functional.pad(Tensor([3, 4, 5],"complex64"), pad=Tensor([2],"int32"), mode="constant", value=100, data_format="NLC", )
paddle.nn.functional.pad(Tensor([3, 4, 5],"float32"), pad=Tensor([2],"int32"), mode="constant", value=100, )
paddle.nn.functional.pad(Tensor([3, 4, 5],"float32"), pad=Tensor([2],"int32"), mode="constant", value=100, data_format="NCL", )
paddle.nn.functional.pad(Tensor([3, 4, 5],"float32"), pad=Tensor([2],"int32"), mode="constant", value=100, data_format="NLC", )
paddle.nn.functional.pad(Tensor([3, 64, 16, 80],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([3, 64, 32, 16],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([3, 64, 32, 208],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([3, 64, 32, 336],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([4, 1, 3, 3],"int64"), pad=list[0,0,0,1,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 1, 32, 288],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([4, 1, 32, 32],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([4, 1, 32, 480],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([4, 1, 32, 608],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([4, 1, 32, 96],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([4, 1, 4, 3],"int64"), pad=list[0,1,0,0,], mode="constant", value=-10000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 1, 4, 3],"int64"), pad=list[0,1,0,0,], mode="constant", value=-1000000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 1, 4, 4],"int64"), pad=list[0,0,0,1,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 1, 5, 4],"int64"), pad=list[0,1,0,0,], mode="constant", value=-10000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 1, 5, 4],"int64"), pad=list[0,1,0,0,], mode="constant", value=-1000000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 1, 64, 96],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([4, 3, 224, 224],"int64"), pad=list[2,2,4,1,], mode="constant", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 3, 6, 6, 6],"int32"), pad=list[2,2,2,2,2,2,], mode="constant", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 3, 6, 6, 6],"int64"), pad=list[1,2,3,4,5,6,], mode="constant", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 3, 6, 6, 6],"int64"), pad=list[2,2,2,2,2,2,], mode="constant", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 3, 6, 6, 6],"int64"), pad=Tensor([6],"int32"), mode="constant", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 3, 6, 6, 6],"int64"), pad=tuple(1,2,3,4,5,6,), mode="constant", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 6, 6],"int32"), pad=list[2,2,], mode="constant", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([4, 6, 6],"int64"), pad=list[1,2,], mode="constant", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([4, 6, 6],"int64"), pad=list[2,2,], mode="constant", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([4, 6, 6],"int64"), pad=Tensor([2],"int32"), mode="constant", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([4, 6, 6],"int64"), pad=tuple(1,2,), mode="constant", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([4, 64, 16, 144],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([4, 64, 16, 240],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([4, 64, 16, 304],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([4, 64, 16, 48],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([4, 64, 32, 48],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([5, 1, 64, 128],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([5, 1, 64, 256],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([5, 1, 64, 576],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([6, 1, 3, 3],"int64"), pad=list[0,0,0,1,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([6, 1, 32, 192],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([6, 1, 32, 352],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([6, 1, 32, 448],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([6, 1, 4, 3],"int64"), pad=list[0,1,0,0,], mode="constant", value=-10000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([6, 1, 4, 3],"int64"), pad=list[0,1,0,0,], mode="constant", value=-1000000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([6, 1, 4, 4],"int64"), pad=list[0,0,0,1,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([6, 1, 5, 4],"int64"), pad=list[0,1,0,0,], mode="constant", value=-10000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([6, 1, 5, 4],"int64"), pad=list[0,1,0,0,], mode="constant", value=-1000000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([6, 1, 64, 384],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([7, 1, 64, 192],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([7, 1, 64, 608],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([8, 1, 32, 256],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([8, 1, 64, 448],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([8, 1, 64, 480],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([9, 1, 32, 416],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([9, 1, 64, 352],"float32"), Tensor([4],"int32"), value=0, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([1, 8, 64, 16],"float32"), Tensor([1, 2, 64, 16],"float32"), Tensor([1, 2, 64, 16],"float32"), Tensor([1],"int32"), Tensor([1],"int32"), Tensor([1, 1, 64, 64],"float32"), 0.25, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 232, 64],"float16"), Tensor([2, 1, 232, 64],"float16"), Tensor([2, 1, 232, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 35, 64],"float16"), Tensor([2, 1, 35, 64],"float16"), Tensor([2, 1, 35, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 36, 64],"float16"), Tensor([2, 1, 36, 64],"float16"), Tensor([2, 1, 36, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 37, 64],"float16"), Tensor([2, 1, 37, 64],"float16"), Tensor([2, 1, 37, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 38, 64],"float16"), Tensor([2, 1, 38, 64],"float16"), Tensor([2, 1, 38, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 39, 64],"float16"), Tensor([2, 1, 39, 64],"float16"), Tensor([2, 1, 39, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 45, 64],"float16"), Tensor([2, 1, 45, 64],"float16"), Tensor([2, 1, 45, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 47, 64],"float16"), Tensor([2, 1, 47, 64],"float16"), Tensor([2, 1, 47, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 50, 64],"float16"), Tensor([2, 1, 50, 64],"float16"), Tensor([2, 1, 50, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 51, 64],"float16"), Tensor([2, 1, 51, 64],"float16"), Tensor([2, 1, 51, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 52, 64],"float16"), Tensor([2, 1, 52, 64],"float16"), Tensor([2, 1, 52, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 57, 64],"float16"), Tensor([2, 1, 57, 64],"float16"), Tensor([2, 1, 57, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 59, 64],"float16"), Tensor([2, 1, 59, 64],"float16"), Tensor([2, 1, 59, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 38, 128],"float16"), Tensor([2, 2, 38, 128],"float16"), Tensor([2, 2, 38, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 39, 128],"float16"), Tensor([2, 2, 39, 128],"float16"), Tensor([2, 2, 39, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 40, 128],"float16"), Tensor([2, 2, 40, 128],"float16"), Tensor([2, 2, 40, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 41, 128],"float16"), Tensor([2, 2, 41, 128],"float16"), Tensor([2, 2, 41, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 47, 128],"float16"), Tensor([2, 2, 47, 128],"float16"), Tensor([2, 2, 47, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 51, 128],"float16"), Tensor([2, 2, 51, 128],"float16"), Tensor([2, 2, 51, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 53, 128],"float16"), Tensor([2, 2, 53, 128],"float16"), Tensor([2, 2, 53, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 54, 128],"float16"), Tensor([2, 2, 54, 128],"float16"), Tensor([2, 2, 54, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 57, 128],"float16"), Tensor([2, 2, 57, 128],"float16"), Tensor([2, 2, 57, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 107, 96],"float16"), Tensor([2, 8, 107, 96],"float16"), Tensor([2, 8, 107, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 107, 96],"float16"), Tensor([2, 8, 235, 96],"float16"), Tensor([2, 8, 235, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 109, 96],"float16"), Tensor([2, 8, 109, 96],"float16"), Tensor([2, 8, 109, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 109, 96],"float16"), Tensor([2, 8, 237, 96],"float16"), Tensor([2, 8, 237, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 110, 96],"float16"), Tensor([2, 8, 110, 96],"float16"), Tensor([2, 8, 110, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 110, 96],"float16"), Tensor([2, 8, 238, 96],"float16"), Tensor([2, 8, 238, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 111, 96],"float16"), Tensor([2, 8, 111, 96],"float16"), Tensor([2, 8, 111, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 111, 96],"float16"), Tensor([2, 8, 239, 96],"float16"), Tensor([2, 8, 239, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 112, 96],"float16"), Tensor([2, 8, 112, 96],"float16"), Tensor([2, 8, 112, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 112, 96],"float16"), Tensor([2, 8, 240, 96],"float16"), Tensor([2, 8, 240, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 74, 96],"float16"), Tensor([2, 8, 202, 96],"float16"), Tensor([2, 8, 202, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 74, 96],"float16"), Tensor([2, 8, 74, 96],"float16"), Tensor([2, 8, 74, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 79, 96],"float16"), Tensor([2, 8, 207, 96],"float16"), Tensor([2, 8, 207, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 79, 96],"float16"), Tensor([2, 8, 79, 96],"float16"), Tensor([2, 8, 79, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 80, 96],"float16"), Tensor([2, 8, 208, 96],"float16"), Tensor([2, 8, 208, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 80, 96],"float16"), Tensor([2, 8, 80, 96],"float16"), Tensor([2, 8, 80, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 82, 96],"float16"), Tensor([2, 8, 210, 96],"float16"), Tensor([2, 8, 210, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 82, 96],"float16"), Tensor([2, 8, 82, 96],"float16"), Tensor([2, 8, 82, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 91, 96],"float16"), Tensor([2, 8, 219, 96],"float16"), Tensor([2, 8, 219, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 91, 96],"float16"), Tensor([2, 8, 91, 96],"float16"), Tensor([2, 8, 91, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([3, 16, 64, 32],"float16"), Tensor([3, 2, 64, 32],"float16"), Tensor([3, 2, 64, 32],"float16"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([3, 1, 64, 64],"float16"), 0.17677669529663687, )
paddle.roll(Tensor([3, 3],"bool"), shifts=1, )
paddle.roll(Tensor([3, 3],"bool"), shifts=1, axis=0, )
paddle.meshgrid(list[Tensor([2],"int64"),Tensor([2],"int64"),Tensor([1],"int64"),Tensor([0],"int64"),], )
paddle.meshgrid(list[Tensor([3],"int32"),Tensor([5],"int32"),Tensor([3],"int32"),Tensor([0],"int32"),], )
paddle.meshgrid(list[Tensor([4],"int32"),Tensor([4],"int32"),Tensor([5],"int32"),Tensor([0],"int32"),], )
paddle.meshgrid(list[Tensor([5],"int64"),Tensor([4],"int64"),Tensor([4],"int64"),Tensor([0],"int64"),], )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 64, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 64, 64, False, out_scale=1.0, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, None, None, Tensor([2, 1, 128, 1, 32],"float32"), None, None, 64, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, Tensor([1],"int32"), Tensor([1],"int32"), None, None, None, 64, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"float16"), Tensor([4, 8, 64, 64],"uint8"), Tensor([4, 8, 64, 64],"uint8"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, Tensor([2, 8],"float32"), Tensor([2, 8],"float32"), Tensor([2, 8],"float32"), Tensor([2, 8],"float32"), None, None, None, None, None, None, None, None, None, 64, 64, False, use_dynamic_cachekv_quant=True, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"float16"), Tensor([4, 8, 64, 64],"uint8"), Tensor([4, 8, 64, 64],"uint8"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), None, None, None, None, None, None, None, None, None, 64, 64, False, use_dynamic_cachekv_quant=False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 768],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, Tensor([1],"int32"), Tensor([1],"int32"), None, None, None, 64, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([2, 1536],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, Tensor([1],"int32"), Tensor([1],"int32"), None, None, Tensor([2, 8, 1, 65],"float16"), 1, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([2, 768],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, Tensor([1],"int32"), Tensor([1],"int32"), None, None, Tensor([2, 8, 1, 65],"float16"), 1, 64, False, )
paddle.incubate.nn.functional.masked_multihead_attention(Tensor([2, 12288],"float16"), Tensor([2, 2, 32, 33, 128],"float16"), Tensor([3, 32, 128],"float16"), Tensor([2, 1, 1, 33],"float16"), None, None, None, None, None, None, None, 1, 0, False, "default", -1, 1, 126, -126, )
paddle.incubate.nn.functional.masked_multihead_attention(Tensor([2, 12288],"float16"), Tensor([2, 2, 32, 33, 128],"float16"), Tensor([3, 32, 128],"float16"), Tensor([2, 1, 1, 33],"float16"), None, None, None, None, None, None, None, 1, 0, False, "default", 10, 1, 126, -126, )
paddle.incubate.nn.functional.masked_multihead_attention(Tensor([2, 12288],"int32"), Tensor([2, 2, 32, 33, 128],"float16"), Tensor([3, 32, 128],"float16"), Tensor([2, 1, 1, 33],"float16"), None, None, None, None, Tensor([3, 32, 128],"float32"), None, None, 1, 0, False, "fp16", -1, 1, 126, -126, )
paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float16"), Tensor([3, 16, 64, 1024],"float16"), Tensor([1024, 1024],"float16"), False, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 16, 64],"float16"), Tensor([1024],"float16"), None, Tensor([8, 16, 128, 128],"float16"), 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, )
paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([1024, 3072],"float32"), Tensor([1024, 1024],"float32"), False, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, None, None, None, Tensor([8, 16, 128, 128],"float32"), 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=True, )
paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([1024, 3072],"float32"), Tensor([1024, 1024],"float32"), False, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3072],"float32"), Tensor([1024],"float32"), None, Tensor([8, 16, 128, 128],"float32"), 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=True, )
paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 16, 64, 1024],"float32"), Tensor([1024, 1024],"float32"), False, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, None, None, None, Tensor([8, 16, 128, 128],"float32"), 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, )
paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 16, 64, 1024],"float32"), Tensor([1024, 1024],"float32"), False, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 16, 64],"float32"), Tensor([1024],"float32"), None, Tensor([8, 16, 128, 128],"float32"), 0.0, 0.0, 1e-05, )
paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 16, 64, 1024],"float32"), Tensor([1024, 1024],"float32"), False, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 16, 64],"float32"), Tensor([1024],"float32"), None, Tensor([8, 16, 128, 128],"float32"), 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, )
paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 16, 64, 1024],"float32"), Tensor([1024, 1024],"float32"), True, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 16, 64],"float32"), Tensor([1024],"float32"), None, None, 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, )
paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 16, 64, 1024],"float32"), Tensor([1024, 1024],"float32"), True, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 16, 64],"float32"), Tensor([1024],"float32"), None, Tensor([8, 16, 128, 128],"float32"), 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, )
paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([1, 2, 4],"float32"), qkv_weight=Tensor([3, 2, 2, 4],"float32"), linear_weight=Tensor([4, 4],"float32"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([4],"float32"), ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=None, linear_bias=None, cache_kv=None, attn_mask=Tensor([1, 2, 2, 2],"float32"), dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=2, transpose_qkv_wb=False, name=None, )
paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([1, 2, 4],"float32"), qkv_weight=Tensor([3, 2, 2, 4],"float32"), linear_weight=Tensor([4, 4],"float32"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([4],"float32"), ln_bias=Tensor([4],"float32"), pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 2, 2],"float32"), linear_bias=Tensor([4],"float32"), cache_kv=None, attn_mask=Tensor([1, 1, 2, 2],"float32"), dropout_rate=0, attn_dropout_rate=0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=2, transpose_qkv_wb=False, name=None, )
paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([1, 2, 4],"float32"), qkv_weight=Tensor([3, 2, 2, 4],"float32"), linear_weight=Tensor([4, 4],"float32"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([4],"float32"), ln_bias=Tensor([4],"float32"), pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 2, 2],"float32"), linear_bias=Tensor([4],"float32"), cache_kv=None, attn_mask=Tensor([1, 2, 2, 2],"float32"), dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=2, transpose_qkv_wb=False, name=None, )
paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([1, 2, 4],"float32"), qkv_weight=Tensor([3, 2, 2, 4],"float32"), linear_weight=Tensor([4, 4],"float32"), pre_layer_norm=True, pre_ln_scale=Tensor([4],"float32"), pre_ln_bias=Tensor([4],"float32"), ln_scale=None, ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 2, 2],"float32"), linear_bias=Tensor([4],"float32"), cache_kv=None, attn_mask=None, dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=2, transpose_qkv_wb=False, name=None, )
paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([1, 2, 4],"float32"), qkv_weight=Tensor([3, 2, 2, 4],"float32"), linear_weight=Tensor([4, 4],"float32"), pre_layer_norm=True, pre_ln_scale=Tensor([4],"float32"), pre_ln_bias=Tensor([4],"float32"), ln_scale=None, ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 2, 2],"float32"), linear_bias=Tensor([4],"float32"), cache_kv=None, attn_mask=Tensor([1, 1, 2, 2],"float32"), dropout_rate=0, attn_dropout_rate=0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=2, transpose_qkv_wb=False, name=None, )
paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([1, 2, 4],"float32"), qkv_weight=Tensor([4, 12],"float32"), linear_weight=Tensor([4, 4],"float32"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([4],"float32"), ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=None, linear_bias=None, cache_kv=None, attn_mask=Tensor([1, 2, 2, 2],"float32"), dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=2, transpose_qkv_wb=True, name=None, )
paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([1, 2, 4],"float32"), qkv_weight=Tensor([4, 12],"float32"), linear_weight=Tensor([4, 4],"float32"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([4],"float32"), ln_bias=Tensor([4],"float32"), pre_ln_epsilon=1e-05, qkv_bias=Tensor([12],"float32"), linear_bias=Tensor([4],"float32"), cache_kv=None, attn_mask=Tensor([1, 2, 2, 2],"float32"), dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=2, transpose_qkv_wb=True, name=None, )
paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([32, 128, 768],"float16"), qkv_weight=Tensor([3, 12, 64, 768],"float16"), linear_weight=Tensor([768, 768],"float16"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([768],"float32"), ln_bias=Tensor([768],"float32"), pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 12, 64],"float16"), linear_bias=Tensor([768],"float16"), cache_kv=None, attn_mask=Tensor([32, 1, 1, 128],"float16"), dropout_rate=0.1, attn_dropout_rate=0.1, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=12, transpose_qkv_wb=False, name=None, )
paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([32, 128, 768],"float32"), qkv_weight=Tensor([3, 12, 64, 768],"float32"), linear_weight=Tensor([768, 768],"float32"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([768],"float32"), ln_bias=Tensor([768],"float32"), pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 12, 64],"float32"), linear_bias=Tensor([768],"float32"), cache_kv=None, attn_mask=Tensor([32, 1, 1, 128],"float32"), dropout_rate=0.1, attn_dropout_rate=0.1, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=12, transpose_qkv_wb=False, name=None, )
paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([64, 128, 768],"float16"), qkv_weight=Tensor([3, 12, 64, 768],"float16"), linear_weight=Tensor([768, 768],"float16"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([768],"float32"), ln_bias=Tensor([768],"float32"), pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 12, 64],"float16"), linear_bias=Tensor([768],"float16"), cache_kv=None, attn_mask=Tensor([64, 1, 1, 128],"float16"), dropout_rate=0.1, attn_dropout_rate=0.1, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=12, transpose_qkv_wb=False, name=None, )
paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([64, 128, 768],"float32"), qkv_weight=Tensor([3, 12, 64, 768],"float32"), linear_weight=Tensor([768, 768],"float32"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([768],"float32"), ln_bias=Tensor([768],"float32"), pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 12, 64],"float32"), linear_bias=Tensor([768],"float32"), cache_kv=None, attn_mask=Tensor([64, 1, 1, 128],"float32"), dropout_rate=0.1, attn_dropout_rate=0.1, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=12, transpose_qkv_wb=False, name=None, )
paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([8, 128, 256],"float32"), qkv_weight=Tensor([3, 16, 16, 256],"float32"), linear_weight=Tensor([256, 256],"float32"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([256],"float32"), ln_bias=Tensor([256],"float32"), pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 16, 16],"float32"), linear_bias=Tensor([256],"float32"), cache_kv=None, attn_mask=None, dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=16, transpose_qkv_wb=False, name=None, )
paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([8, 128, 256],"float32"), qkv_weight=Tensor([3, 16, 16, 256],"float32"), linear_weight=Tensor([256, 256],"float32"), pre_layer_norm=True, pre_ln_scale=Tensor([256],"float32"), pre_ln_bias=Tensor([256],"float32"), ln_scale=None, ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 16, 16],"float32"), linear_bias=Tensor([256],"float32"), cache_kv=None, attn_mask=None, dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=16, transpose_qkv_wb=False, name=None, )
paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([96, 128, 768],"float16"), qkv_weight=Tensor([3, 12, 64, 768],"float16"), linear_weight=Tensor([768, 768],"float16"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([768],"float32"), ln_bias=Tensor([768],"float32"), pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 12, 64],"float16"), linear_bias=Tensor([768],"float16"), cache_kv=None, attn_mask=Tensor([96, 1, 1, 128],"float16"), dropout_rate=0.1, attn_dropout_rate=0.1, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=12, transpose_qkv_wb=False, name=None, )
paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([96, 128, 768],"float32"), qkv_weight=Tensor([3, 12, 64, 768],"float32"), linear_weight=Tensor([768, 768],"float32"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([768],"float32"), ln_bias=Tensor([768],"float32"), pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 12, 64],"float32"), linear_bias=Tensor([768],"float32"), cache_kv=None, attn_mask=Tensor([96, 1, 1, 128],"float32"), dropout_rate=0.1, attn_dropout_rate=0.1, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=12, transpose_qkv_wb=False, name=None, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"float16"), Tensor([6, 8, 64, 64],"float16"), Tensor([6, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 3],"int32"), Tensor([2, 8, 64, 64],"float16"), Tensor([2, 8, 64, 64],"float16"), None, None, None, None, None, None, None, None, None, None, None, Tensor([2, 1, 64, 128],"float16"), None, 64, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"int32"), Tensor([4, 8, 64, 64],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, Tensor([1536],"float32"), Tensor([1536],"float16"), None, None, None, None, None, None, None, 64, 64, False, compute_dtype="fp16", )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"int32"), Tensor([4, 8, 64, 64],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, Tensor([1536],"float32"), Tensor([1536],"float16"), Tensor([512],"float16"), Tensor([512],"float16"), None, None, None, None, None, 64, 64, False, compute_dtype="fp16", out_scale=1.0, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 768],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 64, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 768],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 64, 64, False, out_scale=1.0, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 768],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, None, None, Tensor([2, 1, 128, 1, 32],"float32"), None, None, 64, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 768],"float16"), Tensor([4, 2, 64, 64],"uint8"), Tensor([4, 2, 64, 64],"uint8"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, Tensor([2, 2],"float32"), Tensor([2, 2],"float32"), Tensor([2, 2],"float32"), Tensor([2, 2],"float32"), None, None, None, None, None, None, None, None, None, 64, 64, False, use_dynamic_cachekv_quant=True, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 768],"float16"), Tensor([4, 2, 64, 64],"uint8"), Tensor([4, 2, 64, 64],"uint8"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, Tensor([2],"float32"), Tensor([2],"float32"), Tensor([2],"float32"), Tensor([2],"float32"), None, None, None, None, None, None, None, None, None, 64, 64, False, use_dynamic_cachekv_quant=False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 768],"int32"), Tensor([4, 2, 64, 64],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, Tensor([768],"float32"), Tensor([768],"float16"), None, None, None, None, None, None, None, 64, 64, False, compute_dtype="fp16", )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 768],"int32"), Tensor([4, 2, 64, 64],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, Tensor([768],"float32"), Tensor([768],"float16"), Tensor([512],"float16"), Tensor([512],"float16"), None, None, None, None, None, 64, 64, False, compute_dtype="fp16", out_scale=1.0, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([2, 1536],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 1, 64, False, out_scale=1.0, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([2, 1536],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, None, None, None, None, Tensor([2, 8, 1, 65],"float16"), 1, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([2, 1536],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, None, None, Tensor([2, 1, 128, 1, 32],"float32"), None, None, 1, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([2, 1536],"float16"), Tensor([4, 8, 64, 64],"uint8"), Tensor([4, 8, 64, 64],"uint8"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, Tensor([2, 8],"float32"), Tensor([2, 8],"float32"), Tensor([2, 8],"float32"), Tensor([2, 8],"float32"), None, None, None, None, None, None, None, None, None, 1, 64, False, use_dynamic_cachekv_quant=True, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([2, 1536],"float16"), Tensor([4, 8, 64, 64],"uint8"), Tensor([4, 8, 64, 64],"uint8"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), None, None, None, None, None, None, None, None, None, 1, 64, False, use_dynamic_cachekv_quant=False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([2, 1536],"float16"), Tensor([6, 8, 64, 64],"float16"), Tensor([6, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 3],"int32"), Tensor([2, 8, 64, 64],"float16"), Tensor([2, 8, 64, 64],"float16"), None, None, None, None, None, None, None, None, None, None, None, Tensor([2, 1, 64, 128],"float16"), None, 1, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([2, 1536],"int32"), Tensor([4, 8, 64, 64],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, Tensor([1536],"float32"), Tensor([1536],"float16"), None, None, None, None, None, None, None, 1, 64, False, compute_dtype="fp16", )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([2, 1536],"int32"), Tensor([4, 8, 64, 64],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, Tensor([1536],"float32"), Tensor([1536],"float16"), Tensor([512],"float16"), Tensor([512],"float16"), None, None, None, None, None, 1, 64, False, compute_dtype="fp16", out_scale=1.0, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([2, 768],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 1, 64, False, out_scale=1.0, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([2, 768],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, None, None, None, None, Tensor([2, 8, 1, 65],"float16"), 1, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([2, 768],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, None, None, Tensor([2, 1, 128, 1, 32],"float32"), None, None, 1, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([2, 768],"float16"), Tensor([4, 2, 64, 64],"uint8"), Tensor([4, 2, 64, 64],"uint8"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, Tensor([2, 2],"float32"), Tensor([2, 2],"float32"), Tensor([2, 2],"float32"), Tensor([2, 2],"float32"), None, None, None, None, None, None, None, None, None, 1, 64, False, use_dynamic_cachekv_quant=True, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([2, 768],"float16"), Tensor([4, 2, 64, 64],"uint8"), Tensor([4, 2, 64, 64],"uint8"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, Tensor([2],"float32"), Tensor([2],"float32"), Tensor([2],"float32"), Tensor([2],"float32"), None, None, None, None, None, None, None, None, None, 1, 64, False, use_dynamic_cachekv_quant=False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([2, 768],"int32"), Tensor([4, 2, 64, 64],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, Tensor([768],"float32"), Tensor([768],"float16"), None, None, None, None, None, None, None, 1, 64, False, compute_dtype="fp16", )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([2, 768],"int32"), Tensor([4, 2, 64, 64],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, Tensor([768],"float32"), Tensor([768],"float16"), Tensor([512],"float16"), Tensor([512],"float16"), None, None, None, None, None, 1, 64, False, compute_dtype="fp16", out_scale=1.0, )
paddle.nn.functional.feature_alpha_dropout(x=Tensor([40, 40],"bfloat16"), p=0.0, )
paddle.signal.istft(Tensor([257, 471],"complex128"), 512, None, None, Tensor([512],"float64"), True, False, True, None, False, )